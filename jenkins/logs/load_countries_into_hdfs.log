Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:21:21 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:21:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:21:22 INFO ResourceUtils: ==============================================================
25/04/01 10:21:22 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:21:22 INFO ResourceUtils: ==============================================================
25/04/01 10:21:22 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 10:21:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:21:22 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:21:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:21:22 INFO SecurityManager: Changing view acls to: root
25/04/01 10:21:22 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:21:22 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:21:22 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:21:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:21:22 INFO Utils: Successfully started service 'sparkDriver' on port 36703.
25/04/01 10:21:22 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:21:22 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:21:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:21:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:21:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:21:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b16966a9-20ed-4958-8e1c-6379f349d7df
25/04/01 10:21:22 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:21:22 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:21:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:21:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://67da0ec00716:4040
25/04/01 10:21:22 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:21:22 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 10:21:22 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401102122-0034
25/04/01 10:21:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401102122-0034/0 on worker-20250331112639-172.18.0.8-44535 (172.18.0.8:44535) with 4 core(s)
25/04/01 10:21:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401102122-0034/0 on hostPort 172.18.0.8:44535 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:21:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401102122-0034/1 on worker-20250331112639-172.18.0.12-35967 (172.18.0.12:35967) with 4 core(s)
25/04/01 10:21:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401102122-0034/1 on hostPort 172.18.0.12:35967 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:21:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401102122-0034/2 on worker-20250331112639-172.18.0.3-42795 (172.18.0.3:42795) with 4 core(s)
25/04/01 10:21:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401102122-0034/2 on hostPort 172.18.0.3:42795 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:21:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43775.
25/04/01 10:21:22 INFO NettyBlockTransferService: Server created on 67da0ec00716:43775
25/04/01 10:21:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:21:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 67da0ec00716, 43775, None)
25/04/01 10:21:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401102122-0034/1 is now RUNNING
25/04/01 10:21:22 INFO BlockManagerMasterEndpoint: Registering block manager 67da0ec00716:43775 with 366.3 MiB RAM, BlockManagerId(driver, 67da0ec00716, 43775, None)
25/04/01 10:21:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401102122-0034/2 is now RUNNING
25/04/01 10:21:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 67da0ec00716, 43775, None)
25/04/01 10:21:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401102122-0034/0 is now RUNNING
25/04/01 10:21:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 67da0ec00716, 43775, None)
25/04/01 10:21:23 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:21:23 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:21:23 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:21:24 INFO InMemoryFileIndex: It took 79 ms to list leaf files for 1 paths.
25/04/01 10:21:24 INFO InMemoryFileIndex: It took 11 ms to list leaf files for 5 paths.
25/04/01 10:21:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.3:59170) with ID 2,  ResourceProfileId 0
25/04/01 10:21:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:49690) with ID 0,  ResourceProfileId 0
25/04/01 10:21:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.12:57602) with ID 1,  ResourceProfileId 0
25/04/01 10:21:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44619 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 44619, None)
25/04/01 10:21:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.3:33705 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.3, 33705, None)
25/04/01 10:21:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.12:44801 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.12, 44801, None)
25/04/01 10:21:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:26 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:21:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:21:26 INFO CodeGenerator: Code generated in 141.047975 ms
25/04/01 10:21:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 10:21:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:21:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 67da0ec00716:43775 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:21:26 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:21:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:26 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:21:26 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:21:26 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:26 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:21:26 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:26 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:21:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:21:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 67da0ec00716:43775 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:21:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:21:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 10:21:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:44619 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:21:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:44619 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:21:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1566 ms on 172.18.0.8 (executor 0) (1/1)
25/04/01 10:21:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:21:28 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.642 s
25/04/01 10:21:28 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:21:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:21:28 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.680535 s
25/04/01 10:21:28 INFO CodeGenerator: Code generated in 11.574487 ms
25/04/01 10:21:28 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:28 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:21:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:21:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 10:21:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:21:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 67da0ec00716:43775 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:21:28 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:21:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:28 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:21:28 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:21:28 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:21:29 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:21:29 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:21:29 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:21:29 INFO metastore: Connected to metastore.
25/04/01 10:21:29 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=982c5fd9-8797-47fc-8888-4b3efa4448f6, clientType=HIVECLI]
25/04/01 10:21:29 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:21:29 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:21:29 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:21:29 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:21:29 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:21:29 INFO metastore: Connected to metastore.
25/04/01 10:21:29 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:21:29 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:21:29 INFO metastore: Connected to metastore.
25/04/01 10:21:29 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/04/01 10:21:29 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:21:29 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 10:21:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 10:21:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 10:21:29 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 10:21:29 INFO CodeGenerator: Code generated in 31.765584 ms
25/04/01 10:21:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 10:21:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 67da0ec00716:43775 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:21:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 10:21:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 67da0ec00716:43775 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 10:21:29 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:21:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6641804 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:44619 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:21:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:21:29 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 10 output partitions
25/04/01 10:21:29 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:21:29 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:21:29 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:29 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:21:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 10:21:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 10:21:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 67da0ec00716:43775 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 10:21:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:29 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
25/04/01 10:21:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks resource profile 0
25/04/01 10:21:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.12, executor 1, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 0, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.3, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.12, executor 1, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.8, executor 0, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.18.0.3, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.18.0.12, executor 1, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.18.0.8, executor 0, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (172.18.0.3, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (172.18.0.12, executor 1, partition 9, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 10:21:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:44619 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 10:21:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:44619 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 10:21:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.12:44801 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 10:21:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.3:33705 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 10:21:30 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 670 ms on 172.18.0.8 (executor 0) (1/10)
25/04/01 10:21:30 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 670 ms on 172.18.0.8 (executor 0) (2/10)
25/04/01 10:21:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 694 ms on 172.18.0.8 (executor 0) (3/10)
25/04/01 10:21:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.3:33705 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 10:21:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.12:44801 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 10:21:31 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 2033 ms on 172.18.0.3 (executor 2) (4/10)
25/04/01 10:21:31 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 2034 ms on 172.18.0.3 (executor 2) (5/10)
25/04/01 10:21:31 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 2034 ms on 172.18.0.3 (executor 2) (6/10)
25/04/01 10:21:31 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 2083 ms on 172.18.0.12 (executor 1) (7/10)
25/04/01 10:21:31 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 2083 ms on 172.18.0.12 (executor 1) (8/10)
25/04/01 10:21:31 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 2086 ms on 172.18.0.12 (executor 1) (9/10)
25/04/01 10:21:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2260 ms on 172.18.0.12 (executor 1) (10/10)
25/04/01 10:21:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:21:32 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.266 s
25/04/01 10:21:32 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:21:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 10:21:32 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.269752 s
25/04/01 10:21:32 INFO CodeGenerator: Code generated in 5.789059 ms
25/04/01 10:21:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1028.0 KiB, free 364.2 MiB)
25/04/01 10:21:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 364.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 67da0ec00716:43775 (size: 3.5 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:21:32 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:32 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:21:32 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 10:21:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:21:32 INFO CodeGenerator: Code generated in 20.710652 ms
25/04/01 10:21:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/01 10:21:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 67da0ec00716:43775 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:21:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:32 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:21:32 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 10:21:32 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:32 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:21:32 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:32 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.3 KiB, free 363.8 MiB)
25/04/01 10:21:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 363.7 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 67da0ec00716:43775 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 10:21:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 10:21:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
25/04/01 10:21:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 11) (172.18.0.8, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 12) (172.18.0.12, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:32 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 13) (172.18.0.3, executor 2, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:32 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 14) (172.18.0.8, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:32 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 15) (172.18.0.12, executor 1, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:44619 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.3:33705 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.12:44801 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:44619 (size: 3.5 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.3:33705 (size: 3.5 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.12:44801 (size: 3.5 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:44619 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.3:33705 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.12:44801 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:21:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 11) in 474 ms on 172.18.0.8 (executor 0) (1/5)
25/04/01 10:21:32 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 14) in 472 ms on 172.18.0.8 (executor 0) (2/5)
25/04/01 10:21:32 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 13) in 540 ms on 172.18.0.3 (executor 2) (3/5)
25/04/01 10:21:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 12) in 555 ms on 172.18.0.12 (executor 1) (4/5)
25/04/01 10:21:32 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 15) in 581 ms on 172.18.0.12 (executor 1) (5/5)
25/04/01 10:21:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 10:21:32 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.595 s
25/04/01 10:21:32 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:21:32 INFO DAGScheduler: running: Set()
25/04/01 10:21:32 INFO DAGScheduler: waiting: Set()
25/04/01 10:21:32 INFO DAGScheduler: failed: Set()
25/04/01 10:21:32 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:21:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:21:32 INFO CodeGenerator: Code generated in 10.30036 ms
25/04/01 10:21:32 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 10:21:32 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:21:32 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 10:21:32 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:32 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 44.5 KiB, free 363.7 MiB)
25/04/01 10:21:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 363.7 MiB)
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 67da0ec00716:43775 (size: 21.1 KiB, free: 366.1 MiB)
25/04/01 10:21:32 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 10:21:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 16) (172.18.0.12, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:21:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.12:44801 (size: 21.1 KiB, free: 366.2 MiB)
25/04/01 10:21:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.12:57602
25/04/01 10:21:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 16) in 112 ms on 172.18.0.12 (executor 1) (1/1)
25/04/01 10:21:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 10:21:33 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.120 s
25/04/01 10:21:33 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:21:33 INFO DAGScheduler: running: Set()
25/04/01 10:21:33 INFO DAGScheduler: waiting: Set()
25/04/01 10:21:33 INFO DAGScheduler: failed: Set()
25/04/01 10:21:33 INFO CodeGenerator: Code generated in 6.193933 ms
25/04/01 10:21:33 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:21:33 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:21:33 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 10:21:33 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:33 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 67da0ec00716:43775 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 10:21:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 17) (172.18.0.12, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.12:44801 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:21:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.12:57602
25/04/01 10:21:33 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 17) in 27 ms on 172.18.0.12 (executor 1) (1/1)
25/04/01 10:21:33 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 10:21:33 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
25/04/01 10:21:33 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:21:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 10:21:33 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.033662 s
25/04/01 10:21:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:21:33 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 10:21:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 10:21:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 10:21:33 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 10:21:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 10:21:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 10:21:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 10:21:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 10:21:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 10:21:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 10:21:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 67da0ec00716:43775 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:21:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6641804 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:21:33 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 10 output partitions
25/04/01 10:21:33 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:21:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:21:33 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:33 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 67da0ec00716:43775 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:33 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
25/04/01 10:21:33 INFO TaskSchedulerImpl: Adding task set 8.0 with 10 tasks resource profile 0
25/04/01 10:21:33 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 18) (172.18.0.8, executor 0, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 19) (172.18.0.12, executor 1, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 20) (172.18.0.3, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 21) (172.18.0.8, executor 0, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 22) (172.18.0.12, executor 1, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 23) (172.18.0.3, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 24) (172.18.0.8, executor 0, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 25) (172.18.0.12, executor 1, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 26) (172.18.0.3, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 27) (172.18.0.8, executor 0, partition 9, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.3:33705 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:44619 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.12:44801 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.12:44801 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:44619 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.3:33705 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 27) in 75 ms on 172.18.0.8 (executor 0) (1/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 22) in 93 ms on 172.18.0.12 (executor 1) (2/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 24) in 95 ms on 172.18.0.8 (executor 0) (3/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 19) in 97 ms on 172.18.0.12 (executor 1) (4/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 25) in 99 ms on 172.18.0.12 (executor 1) (5/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 21) in 105 ms on 172.18.0.8 (executor 0) (6/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 26) in 106 ms on 172.18.0.3 (executor 2) (7/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 23) in 106 ms on 172.18.0.3 (executor 2) (8/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 20) in 112 ms on 172.18.0.3 (executor 2) (9/10)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 18) in 323 ms on 172.18.0.8 (executor 0) (10/10)
25/04/01 10:21:33 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 10:21:33 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.328 s
25/04/01 10:21:33 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:21:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 10:21:33 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.330491 s
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1028.0 KiB, free 362.3 MiB)
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.5 KiB, free 362.3 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 67da0ec00716:43775 (size: 3.5 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:21:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:21:33 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 10:21:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 67da0ec00716:43775 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 10:21:33 INFO SparkContext: Created broadcast 13 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 10:21:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:33 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 10:21:33 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 10:21:33 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:21:33 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:33 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 39.3 KiB, free 361.8 MiB)
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 361.8 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 67da0ec00716:43775 (size: 18.7 KiB, free: 366.0 MiB)
25/04/01 10:21:33 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 10:21:33 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks resource profile 0
25/04/01 10:21:33 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 28) (172.18.0.3, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 29) (172.18.0.12, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 30) (172.18.0.8, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 31) (172.18.0.3, executor 2, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 32) (172.18.0.12, executor 1, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.12:44801 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:44619 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.3:33705 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.12:44801 (size: 3.5 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:44619 (size: 3.5 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.3:33705 (size: 3.5 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.12:44801 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:44619 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 29) in 72 ms on 172.18.0.12 (executor 1) (1/5)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 30) in 73 ms on 172.18.0.8 (executor 0) (2/5)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.3:33705 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 32) in 89 ms on 172.18.0.12 (executor 1) (3/5)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 31) in 100 ms on 172.18.0.3 (executor 2) (4/5)
25/04/01 10:21:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 28) in 102 ms on 172.18.0.3 (executor 2) (5/5)
25/04/01 10:21:33 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 10:21:33 INFO DAGScheduler: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.107 s
25/04/01 10:21:33 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:21:33 INFO DAGScheduler: running: Set()
25/04/01 10:21:33 INFO DAGScheduler: waiting: Set()
25/04/01 10:21:33 INFO DAGScheduler: failed: Set()
25/04/01 10:21:33 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:21:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:21:33 INFO CodeGenerator: Code generated in 12.6731 ms
25/04/01 10:21:33 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 10:21:33 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:21:33 INFO DAGScheduler: Final stage: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 10:21:33 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:33 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 235.3 KiB, free 361.6 MiB)
25/04/01 10:21:33 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 87.4 KiB, free 361.5 MiB)
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 67da0ec00716:43775 (size: 87.4 KiB, free: 365.9 MiB)
25/04/01 10:21:33 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:33 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 10:21:33 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 33) (172.18.0.12, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:21:33 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.12:44801 (size: 87.4 KiB, free: 366.0 MiB)
25/04/01 10:21:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.12:57602
25/04/01 10:21:34 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 33) in 245 ms on 172.18.0.12 (executor 1) (1/1)
25/04/01 10:21:34 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 10:21:34 INFO DAGScheduler: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.259 s
25/04/01 10:21:34 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:21:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 10:21:34 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.264801 s
25/04/01 10:21:34 INFO FileFormatWriter: Start to commit write Job afc9d6dc-e55b-4ceb-acad-a68dcc4ad4c0.
25/04/01 10:21:34 INFO FileFormatWriter: Write Job afc9d6dc-e55b-4ceb-acad-a68dcc4ad4c0 committed. Elapsed time: 39 ms.
25/04/01 10:21:34 INFO FileFormatWriter: Finished processing stats for write job afc9d6dc-e55b-4ceb-acad-a68dcc4ad4c0.
25/04/01 10:21:34 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/04/01 10:21:34 INFO SparkUI: Stopped Spark web UI at http://67da0ec00716:4040
25/04/01 10:21:34 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:21:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:21:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:21:34 INFO MemoryStore: MemoryStore cleared
25/04/01 10:21:34 INFO BlockManager: BlockManager stopped
25/04/01 10:21:34 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:21:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:21:34 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:21:34 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:21:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-ff5121c4-61e0-4fd3-926e-ac3b7ca7811d
25/04/01 10:21:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b6f690e-8bf7-4fe3-9285-b7f33352d139/pyspark-d58b255a-f113-4b34-90fc-1d45f4ebddba
25/04/01 10:21:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b6f690e-8bf7-4fe3-9285-b7f33352d139
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:37:25 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:37:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:37:25 INFO ResourceUtils: ==============================================================
25/04/01 10:37:25 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:37:25 INFO ResourceUtils: ==============================================================
25/04/01 10:37:25 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 10:37:25 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:37:25 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:37:25 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:37:25 INFO SecurityManager: Changing view acls to: root
25/04/01 10:37:25 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:37:25 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:37:25 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:37:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:37:25 INFO Utils: Successfully started service 'sparkDriver' on port 38965.
25/04/01 10:37:25 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:37:25 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:37:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:37:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:37:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:37:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5aeda2e5-c853-456f-9d24-d503bbbd2dca
25/04/01 10:37:26 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:37:26 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:37:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/01 10:37:26 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/01 10:37:26 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4041
25/04/01 10:37:26 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:37:26 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 27 ms (0 ms spent in bootstraps)
25/04/01 10:37:26 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401103726-0001
25/04/01 10:37:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41901.
25/04/01 10:37:26 INFO NettyBlockTransferService: Server created on 7796893c36d7:41901
25/04/01 10:37:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:37:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 41901, None)
25/04/01 10:37:26 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:41901 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 41901, None)
25/04/01 10:37:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 41901, None)
25/04/01 10:37:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 41901, None)
25/04/01 10:37:26 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:37:26 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:37:26 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:37:28 INFO InMemoryFileIndex: It took 70 ms to list leaf files for 1 paths.
25/04/01 10:37:28 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 5 paths.
25/04/01 10:37:30 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:37:30 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:37:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:37:30 INFO CodeGenerator: Code generated in 198.830243 ms
25/04/01 10:37:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 10:37:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:37:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:41901 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:37:30 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:37:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 10486900 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:37:30 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:37:30 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:37:30 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:37:30 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:37:30 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:30 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:37:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:37:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:37:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:41901 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:37:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:37:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:37:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401103726-0001/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:37:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401103726-0001/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:37:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401103726-0001/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:37:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401103726-0001/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:37:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401103726-0001/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:37:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401103726-0001/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:37:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401103726-0001/1 is now RUNNING
25/04/01 10:37:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401103726-0001/0 is now RUNNING
25/04/01 10:37:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401103726-0001/2 is now RUNNING
25/04/01 10:37:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:58508) with ID 1,  ResourceProfileId 0
25/04/01 10:37:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:41378) with ID 2,  ResourceProfileId 0
25/04/01 10:37:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:53864) with ID 0,  ResourceProfileId 0
25/04/01 10:37:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:43367 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 43367, None)
25/04/01 10:37:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:40539 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 40539, None)
25/04/01 10:37:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:46647 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 46647, None)
25/04/01 10:37:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 5096 bytes) taskResourceAssignments Map()
25/04/01 10:37:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:43367 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:37:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:43367 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:37:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1627 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 10:37:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:37:38 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 7.447 s
25/04/01 10:37:38 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:37:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:37:38 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 7.495338 s
25/04/01 10:37:38 INFO CodeGenerator: Code generated in 9.666125 ms
25/04/01 10:37:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:37:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:37:38 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:37:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 10:37:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:37:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:41901 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:37:38 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:37:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:37:38 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:37:38 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:37:38 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:37:38 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:37:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:37:38 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:37:38 INFO metastore: Connected to metastore.
25/04/01 10:37:39 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=589f275e-a740-4262-8ff2-f82d8a897ebc, clientType=HIVECLI]
25/04/01 10:37:39 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:37:39 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:37:39 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:37:39 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:37:39 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:37:39 INFO metastore: Connected to metastore.
25/04/01 10:37:39 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:37:39 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:37:39 INFO metastore: Connected to metastore.
25/04/01 10:37:39 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.
25/04/01 10:37:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:41901 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:37:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:43367 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:37:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:37:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:37:39 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 10:37:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 10:37:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 10:37:39 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 10:37:39 INFO CodeGenerator: Code generated in 17.853558 ms
25/04/01 10:37:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 10:37:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 10:37:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:41901 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 10:37:39 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:37:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6991427 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:37:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:37:39 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 10 output partitions
25/04/01 10:37:39 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:37:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:37:39 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:39 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:37:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 10:37:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 10:37:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:41901 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 10:37:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:39 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
25/04/01 10:37:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks resource profile 0
25/04/01 10:37:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.2, executor 0, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.6, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.8, executor 1, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.2, executor 0, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.18.0.6, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.18.0.8, executor 1, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.18.0.2, executor 0, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (172.18.0.6, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (172.18.0.8, executor 1, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 10:37:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:43367 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 10:37:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:43367 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 10:37:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:46647 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 10:37:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:40539 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 10:37:40 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 923 ms on 172.18.0.8 (executor 1) (1/10)
25/04/01 10:37:40 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 942 ms on 172.18.0.8 (executor 1) (2/10)
25/04/01 10:37:40 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 942 ms on 172.18.0.8 (executor 1) (3/10)
25/04/01 10:37:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1249 ms on 172.18.0.8 (executor 1) (4/10)
25/04/01 10:37:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:46647 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 10:37:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:40539 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 10:37:42 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 2509 ms on 172.18.0.6 (executor 2) (5/10)
25/04/01 10:37:42 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 2511 ms on 172.18.0.6 (executor 2) (6/10)
25/04/01 10:37:42 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 2511 ms on 172.18.0.6 (executor 2) (7/10)
25/04/01 10:37:42 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 2522 ms on 172.18.0.2 (executor 0) (8/10)
25/04/01 10:37:42 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 2522 ms on 172.18.0.2 (executor 0) (9/10)
25/04/01 10:37:42 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 2523 ms on 172.18.0.2 (executor 0) (10/10)
25/04/01 10:37:42 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:37:42 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.532 s
25/04/01 10:37:42 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:37:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 10:37:42 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.536519 s
25/04/01 10:37:42 INFO CodeGenerator: Code generated in 7.401081 ms
25/04/01 10:37:42 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/01 10:37:42 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 364.2 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:41901 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 10:37:42 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:37:42 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:37:42 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:37:42 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 10:37:42 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:37:42 INFO CodeGenerator: Code generated in 24.799897 ms
25/04/01 10:37:42 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/01 10:37:42 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:41901 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:37:42 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:37:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:37:42 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:37:42 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 10:37:42 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:37:42 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:37:42 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:42 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:37:42 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.3 KiB, free 363.7 MiB)
25/04/01 10:37:42 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 363.7 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:41901 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 10:37:42 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:42 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 10:37:42 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
25/04/01 10:37:42 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 11) (172.18.0.8, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:37:42 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 12) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:37:42 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 13) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:37:42 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 14) (172.18.0.8, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:37:42 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 15) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:43367 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:46647 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:40539 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:43367 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:46647 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:40539 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 10:37:42 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:43367 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:37:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:46647 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:37:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 11) in 601 ms on 172.18.0.8 (executor 1) (1/5)
25/04/01 10:37:43 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 14) in 601 ms on 172.18.0.8 (executor 1) (2/5)
25/04/01 10:37:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:40539 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:37:43 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 13) in 697 ms on 172.18.0.2 (executor 0) (3/5)
25/04/01 10:37:43 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 15) in 711 ms on 172.18.0.6 (executor 2) (4/5)
25/04/01 10:37:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 12) in 712 ms on 172.18.0.6 (executor 2) (5/5)
25/04/01 10:37:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 10:37:43 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.729 s
25/04/01 10:37:43 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:37:43 INFO DAGScheduler: running: Set()
25/04/01 10:37:43 INFO DAGScheduler: waiting: Set()
25/04/01 10:37:43 INFO DAGScheduler: failed: Set()
25/04/01 10:37:43 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:37:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:37:43 INFO CodeGenerator: Code generated in 15.230992 ms
25/04/01 10:37:43 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 10:37:43 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:37:43 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:37:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 10:37:43 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:43 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:37:43 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 44.5 KiB, free 363.7 MiB)
25/04/01 10:37:43 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 363.7 MiB)
25/04/01 10:37:43 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:41901 (size: 21.0 KiB, free: 366.1 MiB)
25/04/01 10:37:43 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:37:43 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 10:37:43 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 16) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:37:43 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:43367 (size: 21.0 KiB, free: 366.2 MiB)
25/04/01 10:37:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:58508
25/04/01 10:37:43 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 16) in 132 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 10:37:43 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 10:37:43 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.139 s
25/04/01 10:37:43 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:37:43 INFO DAGScheduler: running: Set()
25/04/01 10:37:43 INFO DAGScheduler: waiting: Set()
25/04/01 10:37:43 INFO DAGScheduler: failed: Set()
25/04/01 10:37:43 INFO CodeGenerator: Code generated in 7.753713 ms
25/04/01 10:37:43 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:37:43 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:37:43 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:37:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 10:37:43 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:43 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:37:43 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 10:37:43 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 10:37:43 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:41901 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:37:43 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:37:43 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 10:37:43 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 17) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:37:43 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:43367 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:37:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:58508
25/04/01 10:37:43 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 17) in 41 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 10:37:43 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 10:37:43 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.046 s
25/04/01 10:37:43 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:37:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 10:37:43 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.050287 s
25/04/01 10:37:43 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4041
25/04/01 10:37:43 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:37:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:37:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:37:43 INFO MemoryStore: MemoryStore cleared
25/04/01 10:37:43 INFO BlockManager: BlockManager stopped
25/04/01 10:37:43 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:37:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:37:43 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:37:43 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:37:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-79b1a9f2-f56c-4ca9-8b62-bfe302506e1d
25/04/01 10:37:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-8758ed81-6041-495d-bca6-1be845c8033c
25/04/01 10:37:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-8758ed81-6041-495d-bca6-1be845c8033c/pyspark-a84fcb51-6162-41a0-9e2e-201547c96f8a
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:56:16 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:56:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:56:16 INFO ResourceUtils: ==============================================================
25/04/01 11:56:16 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:56:16 INFO ResourceUtils: ==============================================================
25/04/01 11:56:16 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 11:56:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:56:16 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:56:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:56:16 INFO SecurityManager: Changing view acls to: root
25/04/01 11:56:16 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:56:16 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:56:16 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:56:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:56:16 INFO Utils: Successfully started service 'sparkDriver' on port 33255.
25/04/01 11:56:16 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:56:16 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:56:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:56:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:56:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:56:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d894d637-d11a-4dfd-b040-3700fd7e8e93
25/04/01 11:56:16 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:56:16 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:56:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:56:16 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:56:16 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:56:16 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:56:16 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401115616-0032
25/04/01 11:56:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115616-0032/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:56:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115616-0032/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:56:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115616-0032/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:56:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115616-0032/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:56:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115616-0032/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:56:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115616-0032/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:56:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38255.
25/04/01 11:56:17 INFO NettyBlockTransferService: Server created on 7796893c36d7:38255
25/04/01 11:56:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:56:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 38255, None)
25/04/01 11:56:17 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:38255 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 38255, None)
25/04/01 11:56:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115616-0032/1 is now RUNNING
25/04/01 11:56:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 38255, None)
25/04/01 11:56:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 38255, None)
25/04/01 11:56:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115616-0032/2 is now RUNNING
25/04/01 11:56:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115616-0032/0 is now RUNNING
25/04/01 11:56:17 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:56:17 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:56:17 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:56:18 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.
25/04/01 11:56:18 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 5 paths.
25/04/01 11:56:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:43480) with ID 0,  ResourceProfileId 0
25/04/01 11:56:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:44612) with ID 1,  ResourceProfileId 0
25/04/01 11:56:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:48156) with ID 2,  ResourceProfileId 0
25/04/01 11:56:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:42163 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 42163, None)
25/04/01 11:56:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:39767 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 39767, None)
25/04/01 11:56:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44185 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 44185, None)
25/04/01 11:56:20 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:56:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:56:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:56:20 INFO CodeGenerator: Code generated in 136.690267 ms
25/04/01 11:56:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 11:56:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:56:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:38255 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:56:20 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:56:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:56:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:56:20 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:56:20 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:56:20 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:56:20 INFO DAGScheduler: Missing parents: List()
25/04/01 11:56:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:56:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:56:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:56:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:38255 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:56:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:56:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:56:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:56:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 11:56:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:44185 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:56:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:44185 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:56:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1380 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:56:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:56:22 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.446 s
25/04/01 11:56:22 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:56:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:56:22 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.476353 s
25/04/01 11:56:22 INFO CodeGenerator: Code generated in 7.746388 ms
25/04/01 11:56:22 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:56:22 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:56:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:56:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 11:56:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:56:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:38255 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:56:22 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:56:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:56:22 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:56:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:56:22 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:56:22 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:56:22 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:56:22 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:56:22 INFO metastore: Connected to metastore.
25/04/01 11:56:22 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=744f0852-ee9c-4027-800b-c4e1bc0d90a7, clientType=HIVECLI]
25/04/01 11:56:22 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:56:22 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:56:22 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:56:22 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:56:22 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:56:22 INFO metastore: Connected to metastore.
25/04/01 11:56:22 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:56:22 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:56:22 INFO metastore: Connected to metastore.
25/04/01 11:56:23 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/04/01 11:56:23 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:56:23 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:56:23 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 11:56:23 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 11:56:23 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 11:56:23 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 11:56:23 INFO CodeGenerator: Code generated in 33.985268 ms
25/04/01 11:56:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:38255 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:56:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 11:56:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:44185 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:56:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 11:56:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:38255 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 11:56:23 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:56:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6991427 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:56:23 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:56:23 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 10 output partitions
25/04/01 11:56:23 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:56:23 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:56:23 INFO DAGScheduler: Missing parents: List()
25/04/01 11:56:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:56:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 11:56:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 11:56:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:38255 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:56:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:56:23 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
25/04/01 11:56:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks resource profile 0
25/04/01 11:56:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 1, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.6, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.2, executor 0, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.8, executor 1, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.18.0.6, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.18.0.2, executor 0, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.18.0.8, executor 1, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (172.18.0.6, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (172.18.0.2, executor 0, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:44185 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:56:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:44185 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 11:56:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:39767 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:56:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:42163 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:56:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 624 ms on 172.18.0.8 (executor 1) (1/10)
25/04/01 11:56:23 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 624 ms on 172.18.0.8 (executor 1) (2/10)
25/04/01 11:56:23 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 626 ms on 172.18.0.8 (executor 1) (3/10)
25/04/01 11:56:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:42163 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 11:56:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:39767 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 11:56:25 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 1961 ms on 172.18.0.6 (executor 2) (4/10)
25/04/01 11:56:25 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 1962 ms on 172.18.0.6 (executor 2) (5/10)
25/04/01 11:56:25 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1964 ms on 172.18.0.6 (executor 2) (6/10)
25/04/01 11:56:25 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1989 ms on 172.18.0.2 (executor 0) (7/10)
25/04/01 11:56:25 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 1989 ms on 172.18.0.2 (executor 0) (8/10)
25/04/01 11:56:25 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 1989 ms on 172.18.0.2 (executor 0) (9/10)
25/04/01 11:56:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2164 ms on 172.18.0.2 (executor 0) (10/10)
25/04/01 11:56:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:56:25 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.169 s
25/04/01 11:56:25 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:56:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 11:56:25 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.172485 s
25/04/01 11:56:25 INFO CodeGenerator: Code generated in 5.986369 ms
25/04/01 11:56:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/01 11:56:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 364.2 MiB)
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:38255 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 11:56:25 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:56:25 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:56:25 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:56:25 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 11:56:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:56:25 INFO CodeGenerator: Code generated in 22.805307 ms
25/04/01 11:56:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/01 11:56:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:38255 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:56:25 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:56:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:56:25 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:56:25 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 11:56:25 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:56:25 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:56:25 INFO DAGScheduler: Missing parents: List()
25/04/01 11:56:25 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:56:25 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.3 KiB, free 363.7 MiB)
25/04/01 11:56:25 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 363.7 MiB)
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:38255 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 11:56:25 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:56:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 11:56:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
25/04/01 11:56:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 11) (172.18.0.2, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:25 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 12) (172.18.0.8, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:25 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 13) (172.18.0.6, executor 2, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:25 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 14) (172.18.0.2, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:25 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 15) (172.18.0.8, executor 1, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:44185 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:42163 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:39767 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:44185 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:42163 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 11:56:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:39767 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:44185 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:42163 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 15) in 481 ms on 172.18.0.8 (executor 1) (1/5)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 12) in 482 ms on 172.18.0.8 (executor 1) (2/5)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:39767 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 13) in 536 ms on 172.18.0.6 (executor 2) (3/5)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 14) in 576 ms on 172.18.0.2 (executor 0) (4/5)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 11) in 597 ms on 172.18.0.2 (executor 0) (5/5)
25/04/01 11:56:26 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:56:26 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.608 s
25/04/01 11:56:26 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:56:26 INFO DAGScheduler: running: Set()
25/04/01 11:56:26 INFO DAGScheduler: waiting: Set()
25/04/01 11:56:26 INFO DAGScheduler: failed: Set()
25/04/01 11:56:26 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:56:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:56:26 INFO CodeGenerator: Code generated in 10.80924 ms
25/04/01 11:56:26 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:56:26 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:56:26 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:56:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:56:26 INFO DAGScheduler: Missing parents: List()
25/04/01 11:56:26 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 44.5 KiB, free 363.7 MiB)
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.0 KiB, free 363.7 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:38255 (size: 21.0 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:56:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:56:26 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:56:26 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 16) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:39767 (size: 21.0 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:43480
25/04/01 11:56:26 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 16) in 113 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:56:26 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:56:26 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.120 s
25/04/01 11:56:26 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:56:26 INFO DAGScheduler: running: Set()
25/04/01 11:56:26 INFO DAGScheduler: waiting: Set()
25/04/01 11:56:26 INFO DAGScheduler: failed: Set()
25/04/01 11:56:26 INFO CodeGenerator: Code generated in 6.52534 ms
25/04/01 11:56:26 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:56:26 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:56:26 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:56:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 11:56:26 INFO DAGScheduler: Missing parents: List()
25/04/01 11:56:26 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:38255 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:56:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:56:26 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:56:26 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 17) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:39767 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:43480
25/04/01 11:56:26 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 17) in 24 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:56:26 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:56:26 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.028 s
25/04/01 11:56:26 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:56:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 11:56:26 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.031367 s
25/04/01 11:56:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:56:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:56:26 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 11:56:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 11:56:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 11:56:26 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 11:56:26 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:56:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:56:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:56:26 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:56:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:56:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:56:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:38255 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:56:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 6991427 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:56:26 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:56:26 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 10 output partitions
25/04/01 11:56:26 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:56:26 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:56:26 INFO DAGScheduler: Missing parents: List()
25/04/01 11:56:26 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:38255 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:56:26 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
25/04/01 11:56:26 INFO TaskSchedulerImpl: Adding task set 8.0 with 10 tasks resource profile 0
25/04/01 11:56:26 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 18) (172.18.0.2, executor 0, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 19) (172.18.0.6, executor 2, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 20) (172.18.0.8, executor 1, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 21) (172.18.0.2, executor 0, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 22) (172.18.0.6, executor 2, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 23) (172.18.0.8, executor 1, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 24) (172.18.0.2, executor 0, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 25) (172.18.0.6, executor 2, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 26) (172.18.0.8, executor 1, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 27) (172.18.0.2, executor 0, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:42163 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:44185 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:39767 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:44185 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:39767 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:42163 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 27) in 104 ms on 172.18.0.2 (executor 0) (1/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 20) in 105 ms on 172.18.0.8 (executor 1) (2/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 21) in 105 ms on 172.18.0.2 (executor 0) (3/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 23) in 105 ms on 172.18.0.8 (executor 1) (4/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 26) in 104 ms on 172.18.0.8 (executor 1) (5/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 24) in 106 ms on 172.18.0.2 (executor 0) (6/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 22) in 106 ms on 172.18.0.6 (executor 2) (7/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 25) in 108 ms on 172.18.0.6 (executor 2) (8/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 18) in 112 ms on 172.18.0.2 (executor 0) (9/10)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 19) in 112 ms on 172.18.0.6 (executor 2) (10/10)
25/04/01 11:56:26 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:56:26 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.116 s
25/04/01 11:56:26 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:56:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:56:26 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.118769 s
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1032.0 KiB, free 362.2 MiB)
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 362.2 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:38255 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:56:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:56:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:56:26 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 11:56:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:38255 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 11:56:26 INFO SparkContext: Created broadcast 13 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:56:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:56:26 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:56:26 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 11:56:26 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:56:26 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:56:26 INFO DAGScheduler: Missing parents: List()
25/04/01 11:56:26 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 39.3 KiB, free 361.8 MiB)
25/04/01 11:56:26 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 361.8 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:38255 (size: 18.7 KiB, free: 366.0 MiB)
25/04/01 11:56:26 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:56:26 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 11:56:26 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks resource profile 0
25/04/01 11:56:26 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 28) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 29) (172.18.0.8, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 30) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 31) (172.18.0.6, executor 2, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 32) (172.18.0.8, executor 1, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:39767 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:42163 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:44185 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:39767 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:42163 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:44185 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:39767 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:44185 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:42163 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 30) in 81 ms on 172.18.0.2 (executor 0) (1/5)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 29) in 86 ms on 172.18.0.8 (executor 1) (2/5)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 32) in 87 ms on 172.18.0.8 (executor 1) (3/5)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 31) in 117 ms on 172.18.0.6 (executor 2) (4/5)
25/04/01 11:56:26 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 28) in 144 ms on 172.18.0.6 (executor 2) (5/5)
25/04/01 11:56:26 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:56:26 INFO DAGScheduler: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.150 s
25/04/01 11:56:26 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:56:26 INFO DAGScheduler: running: Set()
25/04/01 11:56:26 INFO DAGScheduler: waiting: Set()
25/04/01 11:56:26 INFO DAGScheduler: failed: Set()
25/04/01 11:56:26 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:56:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:56:26 INFO CodeGenerator: Code generated in 11.381317 ms
25/04/01 11:56:27 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:56:27 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:56:27 INFO DAGScheduler: Final stage: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:56:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 11:56:27 INFO DAGScheduler: Missing parents: List()
25/04/01 11:56:27 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:56:27 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 235.3 KiB, free 361.6 MiB)
25/04/01 11:56:27 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 87.4 KiB, free 361.5 MiB)
25/04/01 11:56:27 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:38255 (size: 87.4 KiB, free: 365.9 MiB)
25/04/01 11:56:27 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:56:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:56:27 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 11:56:27 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 33) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:56:27 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.6:42163 (size: 87.4 KiB, free: 366.0 MiB)
25/04/01 11:56:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:48156
25/04/01 11:56:27 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 33) in 485 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:56:27 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 11:56:27 INFO DAGScheduler: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.499 s
25/04/01 11:56:27 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:56:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 11:56:27 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.503082 s
25/04/01 11:56:27 INFO FileFormatWriter: Start to commit write Job fc4209a2-c987-4e5b-9424-c8dbd9c78382.
25/04/01 11:56:27 INFO FileFormatWriter: Write Job fc4209a2-c987-4e5b-9424-c8dbd9c78382 committed. Elapsed time: 36 ms.
25/04/01 11:56:27 INFO FileFormatWriter: Finished processing stats for write job fc4209a2-c987-4e5b-9424-c8dbd9c78382.
25/04/01 11:56:27 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/04/01 11:56:27 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:56:27 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:56:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:56:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:56:27 INFO MemoryStore: MemoryStore cleared
25/04/01 11:56:27 INFO BlockManager: BlockManager stopped
25/04/01 11:56:27 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:56:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:56:27 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:56:27 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:56:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-c66c1070-1b9e-40bf-a492-913da0090940
25/04/01 11:56:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-6d38d187-7fa9-4c2d-91ec-c4779eba6ec1
25/04/01 11:56:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-c66c1070-1b9e-40bf-a492-913da0090940/pyspark-ca2741a8-8caf-4f7b-9a00-8e26016fe6d1
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:59:10 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:59:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:59:10 INFO ResourceUtils: ==============================================================
25/04/01 11:59:10 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:59:10 INFO ResourceUtils: ==============================================================
25/04/01 11:59:10 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 11:59:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:59:10 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:59:10 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:59:10 INFO SecurityManager: Changing view acls to: root
25/04/01 11:59:10 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:59:10 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:59:10 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:59:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:59:10 INFO Utils: Successfully started service 'sparkDriver' on port 46853.
25/04/01 11:59:10 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:59:10 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:59:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:59:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:59:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:59:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-349cd57a-b9cf-4569-a4ac-92c735b014dd
25/04/01 11:59:10 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:59:10 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:59:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:59:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:59:11 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:59:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:59:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401115911-0033
25/04/01 11:59:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115911-0033/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:59:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115911-0033/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:59:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115911-0033/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:59:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115911-0033/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:59:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115911-0033/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:59:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115911-0033/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:59:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41053.
25/04/01 11:59:11 INFO NettyBlockTransferService: Server created on 7796893c36d7:41053
25/04/01 11:59:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:59:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 41053, None)
25/04/01 11:59:11 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:41053 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 41053, None)
25/04/01 11:59:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115911-0033/1 is now RUNNING
25/04/01 11:59:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 41053, None)
25/04/01 11:59:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115911-0033/2 is now RUNNING
25/04/01 11:59:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 41053, None)
25/04/01 11:59:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115911-0033/0 is now RUNNING
25/04/01 11:59:11 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:59:11 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:59:11 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:59:12 INFO InMemoryFileIndex: It took 66 ms to list leaf files for 1 paths.
25/04/01 11:59:12 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 5 paths.
25/04/01 11:59:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:49060) with ID 1,  ResourceProfileId 0
25/04/01 11:59:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:33110) with ID 0,  ResourceProfileId 0
25/04/01 11:59:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:46412) with ID 2,  ResourceProfileId 0
25/04/01 11:59:13 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:36681 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 36681, None)
25/04/01 11:59:13 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:46441 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 46441, None)
25/04/01 11:59:13 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:33611 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 33611, None)
25/04/01 11:59:14 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:59:14 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:59:14 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:59:14 INFO CodeGenerator: Code generated in 130.305662 ms
25/04/01 11:59:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 11:59:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:59:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:41053 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:59:14 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:59:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:59:14 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:59:14 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:59:14 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:59:14 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:59:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:59:14 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:59:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:59:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:59:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:41053 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:59:14 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:59:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:59:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:59:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 11:59:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:46441 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:59:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:46441 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:59:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1347 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:59:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:59:16 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.413 s
25/04/01 11:59:16 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:59:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:59:16 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.443328 s
25/04/01 11:59:16 INFO CodeGenerator: Code generated in 7.925254 ms
25/04/01 11:59:16 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:59:16 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:59:16 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:59:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 11:59:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:59:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:41053 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:59:16 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:59:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:59:16 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:59:16 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:59:16 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:59:16 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:59:16 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:59:16 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:59:16 INFO metastore: Connected to metastore.
25/04/01 11:59:17 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=896d1bd4-3d16-4e60-85ab-f7d5da88d47b, clientType=HIVECLI]
25/04/01 11:59:17 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:59:17 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:59:17 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:59:17 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:59:17 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:59:17 INFO metastore: Connected to metastore.
25/04/01 11:59:17 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:59:17 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:59:17 INFO metastore: Connected to metastore.
25/04/01 11:59:17 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
25/04/01 11:59:17 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:59:17 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:59:17 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 11:59:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 11:59:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 11:59:17 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 11:59:17 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:41053 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:59:17 INFO CodeGenerator: Code generated in 19.420134 ms
25/04/01 11:59:17 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:46441 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:59:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 11:59:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 11:59:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:41053 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 11:59:17 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:59:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7341015 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:59:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:59:17 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 11 output partitions
25/04/01 11:59:17 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:59:17 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:59:17 INFO DAGScheduler: Missing parents: List()
25/04/01 11:59:17 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:59:17 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 11:59:17 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 11:59:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:41053 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:59:17 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:59:17 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
25/04/01 11:59:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 11 tasks resource profile 0
25/04/01 11:59:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 1, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.6, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.2, executor 0, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.8, executor 1, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.18.0.6, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.18.0.2, executor 0, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.18.0.8, executor 1, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (172.18.0.6, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (172.18.0.2, executor 0, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11) (172.18.0.8, executor 1, partition 10, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 11:59:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:46441 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:59:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:46441 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 11:59:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:33611 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:59:17 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:36681 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:59:18 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 638 ms on 172.18.0.2 (executor 0) (1/11)
25/04/01 11:59:18 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 639 ms on 172.18.0.2 (executor 0) (2/11)
25/04/01 11:59:18 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 652 ms on 172.18.0.2 (executor 0) (3/11)
25/04/01 11:59:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 886 ms on 172.18.0.2 (executor 0) (4/11)
25/04/01 11:59:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:33611 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 11:59:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:36681 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 11:59:19 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 1986 ms on 172.18.0.8 (executor 1) (5/11)
25/04/01 11:59:19 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 11) in 1987 ms on 172.18.0.8 (executor 1) (6/11)
25/04/01 11:59:19 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1988 ms on 172.18.0.8 (executor 1) (7/11)
25/04/01 11:59:19 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 2009 ms on 172.18.0.6 (executor 2) (8/11)
25/04/01 11:59:19 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 2010 ms on 172.18.0.6 (executor 2) (9/11)
25/04/01 11:59:19 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 2010 ms on 172.18.0.6 (executor 2) (10/11)
25/04/01 11:59:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 2185 ms on 172.18.0.8 (executor 1) (11/11)
25/04/01 11:59:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:59:19 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.190 s
25/04/01 11:59:19 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:59:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 11:59:19 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.194617 s
25/04/01 11:59:19 INFO CodeGenerator: Code generated in 5.630594 ms
25/04/01 11:59:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/01 11:59:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 364.2 MiB)
25/04/01 11:59:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:41053 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 11:59:19 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:59:19 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:59:19 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:59:19 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 11:59:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:59:19 INFO CodeGenerator: Code generated in 26.645571 ms
25/04/01 11:59:19 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/01 11:59:19 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/01 11:59:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:41053 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:59:19 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:59:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:59:19 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:59:19 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 11:59:19 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:59:19 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:59:19 INFO DAGScheduler: Missing parents: List()
25/04/01 11:59:19 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:59:19 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.3 KiB, free 363.7 MiB)
25/04/01 11:59:19 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 363.7 MiB)
25/04/01 11:59:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:41053 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 11:59:19 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:59:19 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 11:59:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
25/04/01 11:59:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 12) (172.18.0.8, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 13) (172.18.0.2, executor 0, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:19 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 14) (172.18.0.6, executor 2, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:19 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 15) (172.18.0.8, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:19 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 16) (172.18.0.2, executor 0, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:46441 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 11:59:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:36681 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 11:59:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:33611 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:46441 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:36681 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:33611 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:46441 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 16) in 434 ms on 172.18.0.2 (executor 0) (1/5)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 13) in 435 ms on 172.18.0.2 (executor 0) (2/5)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:36681 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:33611 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 15) in 530 ms on 172.18.0.8 (executor 1) (3/5)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 14) in 548 ms on 172.18.0.6 (executor 2) (4/5)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 12) in 551 ms on 172.18.0.8 (executor 1) (5/5)
25/04/01 11:59:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:59:20 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.563 s
25/04/01 11:59:20 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:59:20 INFO DAGScheduler: running: Set()
25/04/01 11:59:20 INFO DAGScheduler: waiting: Set()
25/04/01 11:59:20 INFO DAGScheduler: failed: Set()
25/04/01 11:59:20 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:59:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:59:20 INFO CodeGenerator: Code generated in 11.544677 ms
25/04/01 11:59:20 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:59:20 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:59:20 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:59:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:59:20 INFO DAGScheduler: Missing parents: List()
25/04/01 11:59:20 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:59:20 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 44.5 KiB, free 363.7 MiB)
25/04/01 11:59:20 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 363.7 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:41053 (size: 21.1 KiB, free: 366.1 MiB)
25/04/01 11:59:20 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:59:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:59:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:59:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 17) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:36681 (size: 21.1 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:49060
25/04/01 11:59:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 17) in 120 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:59:20 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:59:20 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.128 s
25/04/01 11:59:20 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:59:20 INFO DAGScheduler: running: Set()
25/04/01 11:59:20 INFO DAGScheduler: waiting: Set()
25/04/01 11:59:20 INFO DAGScheduler: failed: Set()
25/04/01 11:59:20 INFO CodeGenerator: Code generated in 6.181089 ms
25/04/01 11:59:20 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:59:20 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:59:20 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:59:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 11:59:20 INFO DAGScheduler: Missing parents: List()
25/04/01 11:59:20 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:59:20 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 11:59:20 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:41053 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:59:20 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:59:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:59:20 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:59:20 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 18) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:36681 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:49060
25/04/01 11:59:20 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 18) in 23 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:59:20 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:59:20 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.027 s
25/04/01 11:59:20 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:59:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 11:59:20 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.029912 s
25/04/01 11:59:20 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:59:20 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:59:20 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 11:59:20 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 11:59:20 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 11:59:20 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 11:59:20 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:59:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:59:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:59:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:59:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:59:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:59:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:59:20 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/01 11:59:20 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:41053 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 11:59:20 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:59:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7341015 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:59:20 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:59:20 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 11 output partitions
25/04/01 11:59:20 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:59:20 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:59:20 INFO DAGScheduler: Missing parents: List()
25/04/01 11:59:20 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:59:20 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/01 11:59:20 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:41053 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 11:59:20 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:59:20 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
25/04/01 11:59:20 INFO TaskSchedulerImpl: Adding task set 8.0 with 11 tasks resource profile 0
25/04/01 11:59:20 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 19) (172.18.0.8, executor 1, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 20) (172.18.0.6, executor 2, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 21) (172.18.0.2, executor 0, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 22) (172.18.0.8, executor 1, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 23) (172.18.0.6, executor 2, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 24) (172.18.0.2, executor 0, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 25) (172.18.0.8, executor 1, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 26) (172.18.0.6, executor 2, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 27) (172.18.0.2, executor 0, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 28) (172.18.0.8, executor 1, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 29) (172.18.0.6, executor 2, partition 10, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:36681 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:33611 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:46441 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:36681 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:46441 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 11:59:20 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:33611 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 29) in 70 ms on 172.18.0.6 (executor 2) (1/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 28) in 83 ms on 172.18.0.8 (executor 1) (2/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 24) in 86 ms on 172.18.0.2 (executor 0) (3/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 26) in 88 ms on 172.18.0.6 (executor 2) (4/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 27) in 89 ms on 172.18.0.2 (executor 0) (5/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 25) in 90 ms on 172.18.0.8 (executor 1) (6/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 21) in 95 ms on 172.18.0.2 (executor 0) (7/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 23) in 96 ms on 172.18.0.6 (executor 2) (8/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 22) in 99 ms on 172.18.0.8 (executor 1) (9/11)
25/04/01 11:59:20 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 19) in 107 ms on 172.18.0.8 (executor 1) (10/11)
25/04/01 11:59:21 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 20) in 328 ms on 172.18.0.6 (executor 2) (11/11)
25/04/01 11:59:21 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:59:21 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.331 s
25/04/01 11:59:21 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:59:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:59:21 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.333712 s
25/04/01 11:59:21 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1032.0 KiB, free 362.2 MiB)
25/04/01 11:59:21 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 362.2 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:41053 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:59:21 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:59:21 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:59:21 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 11:59:21 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:59:21 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/01 11:59:21 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:41053 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 11:59:21 INFO SparkContext: Created broadcast 13 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:59:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:59:21 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:59:21 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 11:59:21 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:59:21 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:59:21 INFO DAGScheduler: Missing parents: List()
25/04/01 11:59:21 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:59:21 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 39.3 KiB, free 361.8 MiB)
25/04/01 11:59:21 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 361.8 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:41053 (size: 18.7 KiB, free: 366.0 MiB)
25/04/01 11:59:21 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:59:21 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 11:59:21 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks resource profile 0
25/04/01 11:59:21 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 30) (172.18.0.8, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:21 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 31) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:21 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 32) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:21 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 33) (172.18.0.8, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:21 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 34) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:36681 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:46441 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:33611 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:46441 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:36681 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:33611 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:36681 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:46441 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 33) in 66 ms on 172.18.0.8 (executor 1) (1/5)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:33611 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:59:21 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 32) in 73 ms on 172.18.0.2 (executor 0) (2/5)
25/04/01 11:59:21 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 30) in 75 ms on 172.18.0.8 (executor 1) (3/5)
25/04/01 11:59:21 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 31) in 94 ms on 172.18.0.6 (executor 2) (4/5)
25/04/01 11:59:21 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 34) in 93 ms on 172.18.0.6 (executor 2) (5/5)
25/04/01 11:59:21 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:59:21 INFO DAGScheduler: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.100 s
25/04/01 11:59:21 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:59:21 INFO DAGScheduler: running: Set()
25/04/01 11:59:21 INFO DAGScheduler: waiting: Set()
25/04/01 11:59:21 INFO DAGScheduler: failed: Set()
25/04/01 11:59:21 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:59:21 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:59:21 INFO CodeGenerator: Code generated in 12.594542 ms
25/04/01 11:59:21 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:59:21 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:59:21 INFO DAGScheduler: Final stage: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:59:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 11:59:21 INFO DAGScheduler: Missing parents: List()
25/04/01 11:59:21 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:59:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 235.3 KiB, free 361.6 MiB)
25/04/01 11:59:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 87.4 KiB, free 361.5 MiB)
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:41053 (size: 87.4 KiB, free: 365.9 MiB)
25/04/01 11:59:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:59:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:59:21 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 11:59:21 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 35) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:59:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:36681 (size: 87.4 KiB, free: 366.0 MiB)
25/04/01 11:59:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:49060
25/04/01 11:59:21 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 35) in 254 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:59:21 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 11:59:21 INFO DAGScheduler: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.268 s
25/04/01 11:59:21 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:59:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 11:59:21 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.272545 s
25/04/01 11:59:21 INFO FileFormatWriter: Start to commit write Job 4df7b05c-892c-465d-801e-646b3a7fe328.
25/04/01 11:59:21 INFO FileFormatWriter: Write Job 4df7b05c-892c-465d-801e-646b3a7fe328 committed. Elapsed time: 39 ms.
25/04/01 11:59:21 INFO FileFormatWriter: Finished processing stats for write job 4df7b05c-892c-465d-801e-646b3a7fe328.
25/04/01 11:59:21 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/04/01 11:59:21 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:59:21 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:59:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:59:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:59:21 INFO MemoryStore: MemoryStore cleared
25/04/01 11:59:21 INFO BlockManager: BlockManager stopped
25/04/01 11:59:21 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:59:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:59:21 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:59:21 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:59:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-d9735fa7-575d-4a52-bd3f-04c11b97cf2a
25/04/01 11:59:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-41c743c7-1991-4a44-a12d-a6134b8964c7/pyspark-f429b9ce-6947-4a67-aa1d-a98e492f29ef
25/04/01 11:59:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-41c743c7-1991-4a44-a12d-a6134b8964c7
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:00:29 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:00:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:00:29 INFO ResourceUtils: ==============================================================
25/04/01 12:00:29 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:00:29 INFO ResourceUtils: ==============================================================
25/04/01 12:00:29 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 12:00:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:00:29 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:00:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:00:29 INFO SecurityManager: Changing view acls to: root
25/04/01 12:00:29 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:00:29 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:00:29 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:00:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:00:29 INFO Utils: Successfully started service 'sparkDriver' on port 39989.
25/04/01 12:00:29 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:00:29 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:00:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:00:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:00:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:00:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9e2be85d-0f63-4cb5-883b-dea5965e77b4
25/04/01 12:00:29 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:00:29 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:00:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:00:29 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:00:30 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:00:30 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 12:00:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401120030-0034
25/04/01 12:00:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120030-0034/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:00:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120030-0034/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:00:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120030-0034/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:00:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120030-0034/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:00:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120030-0034/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:00:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120030-0034/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:00:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40839.
25/04/01 12:00:30 INFO NettyBlockTransferService: Server created on 7796893c36d7:40839
25/04/01 12:00:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:00:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 40839, None)
25/04/01 12:00:30 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:40839 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 40839, None)
25/04/01 12:00:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120030-0034/0 is now RUNNING
25/04/01 12:00:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 40839, None)
25/04/01 12:00:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120030-0034/1 is now RUNNING
25/04/01 12:00:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 40839, None)
25/04/01 12:00:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120030-0034/2 is now RUNNING
25/04/01 12:00:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:00:30 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:00:30 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:00:31 INFO InMemoryFileIndex: It took 66 ms to list leaf files for 1 paths.
25/04/01 12:00:31 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 5 paths.
25/04/01 12:00:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:34594) with ID 2,  ResourceProfileId 0
25/04/01 12:00:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:46206) with ID 1,  ResourceProfileId 0
25/04/01 12:00:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:44616) with ID 0,  ResourceProfileId 0
25/04/01 12:00:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35003 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 35003, None)
25/04/01 12:00:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:35191 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 35191, None)
25/04/01 12:00:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:39511 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 39511, None)
25/04/01 12:00:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:00:33 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:00:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:00:33 INFO CodeGenerator: Code generated in 140.765763 ms
25/04/01 12:00:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 12:00:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:00:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:40839 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:00:33 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:00:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:00:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:00:33 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:00:33 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:00:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:00:33 INFO DAGScheduler: Missing parents: List()
25/04/01 12:00:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:00:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:00:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:00:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:40839 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:00:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:00:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:00:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 12:00:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:35003 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:00:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:35003 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:00:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1362 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:00:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:00:35 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.427 s
25/04/01 12:00:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:00:35 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.458433 s
25/04/01 12:00:35 INFO CodeGenerator: Code generated in 8.296604 ms
25/04/01 12:00:35 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:00:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:00:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:00:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 12:00:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:00:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:40839 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:00:35 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:00:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:00:35 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:00:35 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:00:35 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:00:35 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:00:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:00:35 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:00:35 INFO metastore: Connected to metastore.
25/04/01 12:00:36 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=d59241af-3e56-4417-a002-c3211992cce4, clientType=HIVECLI]
25/04/01 12:00:36 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:00:36 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:00:36 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:00:36 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:00:36 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:00:36 INFO metastore: Connected to metastore.
25/04/01 12:00:36 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:00:36 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:00:36 INFO metastore: Connected to metastore.
25/04/01 12:00:36 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
25/04/01 12:00:36 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:00:36 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:00:36 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:00:36 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 12:00:36 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 12:00:36 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 12:00:36 INFO CodeGenerator: Code generated in 15.375652 ms
25/04/01 12:00:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 12:00:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 12:00:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:40839 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:00:36 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:00:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7690602 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:00:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:40839 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:00:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:35003 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:00:36 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:00:36 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 11 output partitions
25/04/01 12:00:36 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:00:36 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:00:36 INFO DAGScheduler: Missing parents: List()
25/04/01 12:00:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:00:36 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 12:00:36 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 12:00:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:40839 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:00:36 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:00:36 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
25/04/01 12:00:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 11 tasks resource profile 0
25/04/01 12:00:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 1, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.6, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.2, executor 0, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.8, executor 1, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.18.0.6, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.18.0.2, executor 0, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.18.0.8, executor 1, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (172.18.0.6, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (172.18.0.2, executor 0, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11) (172.18.0.8, executor 1, partition 10, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:35003 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 12:00:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:35003 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:00:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:39511 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 12:00:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:35191 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 12:00:37 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 657 ms on 172.18.0.6 (executor 2) (1/11)
25/04/01 12:00:37 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 658 ms on 172.18.0.6 (executor 2) (2/11)
25/04/01 12:00:37 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 671 ms on 172.18.0.6 (executor 2) (3/11)
25/04/01 12:00:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:39511 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 12:00:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:35191 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 12:00:38 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 2034 ms on 172.18.0.2 (executor 0) (4/11)
25/04/01 12:00:38 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 2035 ms on 172.18.0.2 (executor 0) (5/11)
25/04/01 12:00:38 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 2037 ms on 172.18.0.2 (executor 0) (6/11)
25/04/01 12:00:38 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 11) in 2087 ms on 172.18.0.8 (executor 1) (7/11)
25/04/01 12:00:38 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 2088 ms on 172.18.0.8 (executor 1) (8/11)
25/04/01 12:00:38 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 2089 ms on 172.18.0.8 (executor 1) (9/11)
25/04/01 12:00:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2256 ms on 172.18.0.2 (executor 0) (10/11)
25/04/01 12:00:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 2289 ms on 172.18.0.8 (executor 1) (11/11)
25/04/01 12:00:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:00:38 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.295 s
25/04/01 12:00:38 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 12:00:38 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.299080 s
25/04/01 12:00:38 INFO CodeGenerator: Code generated in 5.943975 ms
25/04/01 12:00:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/01 12:00:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 364.2 MiB)
25/04/01 12:00:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:40839 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 12:00:38 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:00:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:00:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:00:38 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:00:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:00:39 INFO CodeGenerator: Code generated in 25.754596 ms
25/04/01 12:00:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/01 12:00:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:40839 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:00:39 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:00:39 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:00:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:00:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:00:39 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.3 KiB, free 363.7 MiB)
25/04/01 12:00:39 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 363.7 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:40839 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 12:00:39 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:00:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:00:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
25/04/01 12:00:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 12) (172.18.0.8, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 13) (172.18.0.2, executor 0, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:39 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 14) (172.18.0.6, executor 2, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:39 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 15) (172.18.0.8, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:39 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 16) (172.18.0.2, executor 0, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:35003 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:39511 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:35191 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:35003 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:35191 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:39511 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:35003 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 14) in 436 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:35191 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:39511 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 15) in 540 ms on 172.18.0.8 (executor 1) (2/5)
25/04/01 12:00:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 13) in 558 ms on 172.18.0.2 (executor 0) (3/5)
25/04/01 12:00:39 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 16) in 557 ms on 172.18.0.2 (executor 0) (4/5)
25/04/01 12:00:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 12) in 561 ms on 172.18.0.8 (executor 1) (5/5)
25/04/01 12:00:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 12:00:39 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.574 s
25/04/01 12:00:39 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:00:39 INFO DAGScheduler: running: Set()
25/04/01 12:00:39 INFO DAGScheduler: waiting: Set()
25/04/01 12:00:39 INFO DAGScheduler: failed: Set()
25/04/01 12:00:39 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:00:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:00:39 INFO CodeGenerator: Code generated in 13.136657 ms
25/04/01 12:00:39 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:00:39 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 12:00:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:00:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 44.5 KiB, free 363.7 MiB)
25/04/01 12:00:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 363.7 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:40839 (size: 21.1 KiB, free: 366.1 MiB)
25/04/01 12:00:39 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:00:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 12:00:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 17) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:35191 (size: 21.1 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:46206
25/04/01 12:00:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 17) in 115 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:00:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 12:00:39 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.123 s
25/04/01 12:00:39 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:00:39 INFO DAGScheduler: running: Set()
25/04/01 12:00:39 INFO DAGScheduler: waiting: Set()
25/04/01 12:00:39 INFO DAGScheduler: failed: Set()
25/04/01 12:00:39 INFO CodeGenerator: Code generated in 6.135762 ms
25/04/01 12:00:39 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:00:39 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:00:39 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 12:00:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:00:39 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:00:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 12:00:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:40839 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:00:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:00:39 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 12:00:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 18) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:00:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:35191 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:00:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:46206
25/04/01 12:00:39 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 18) in 22 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:00:39 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:00:39 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.027 s
25/04/01 12:00:39 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 12:00:39 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.029977 s
25/04/01 12:00:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:00:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:00:39 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:00:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 12:00:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 12:00:39 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 12:00:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:00:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:00:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:00:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:00:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:00:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:00:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:40839 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7690602 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:00:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:00:40 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 11 output partitions
25/04/01 12:00:40 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:00:40 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:00:40 INFO DAGScheduler: Missing parents: List()
25/04/01 12:00:40 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:40839 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 12:00:40 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
25/04/01 12:00:40 INFO TaskSchedulerImpl: Adding task set 8.0 with 11 tasks resource profile 0
25/04/01 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 19) (172.18.0.2, executor 0, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 20) (172.18.0.8, executor 1, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 21) (172.18.0.6, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 22) (172.18.0.2, executor 0, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 23) (172.18.0.8, executor 1, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 24) (172.18.0.6, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 25) (172.18.0.2, executor 0, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 26) (172.18.0.8, executor 1, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 27) (172.18.0.6, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 28) (172.18.0.2, executor 0, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 29) (172.18.0.8, executor 1, partition 10, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:35191 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:39511 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:35003 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:35191 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:39511 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:35003 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 29) in 86 ms on 172.18.0.8 (executor 1) (1/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 26) in 87 ms on 172.18.0.8 (executor 1) (2/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 23) in 92 ms on 172.18.0.8 (executor 1) (3/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 28) in 96 ms on 172.18.0.2 (executor 0) (4/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 25) in 99 ms on 172.18.0.2 (executor 0) (5/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 27) in 103 ms on 172.18.0.6 (executor 2) (6/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 20) in 104 ms on 172.18.0.8 (executor 1) (7/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 21) in 104 ms on 172.18.0.6 (executor 2) (8/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 24) in 106 ms on 172.18.0.6 (executor 2) (9/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 22) in 107 ms on 172.18.0.2 (executor 0) (10/11)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 19) in 112 ms on 172.18.0.2 (executor 0) (11/11)
25/04/01 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 12:00:40 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.116 s
25/04/01 12:00:40 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 12:00:40 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.119572 s
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1032.0 KiB, free 362.2 MiB)
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 362.2 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:40839 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:00:40 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:00:40 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:00:40 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:00:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:40839 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 12:00:40 INFO SparkContext: Created broadcast 13 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:00:40 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:00:40 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:00:40 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:00:40 INFO DAGScheduler: Missing parents: List()
25/04/01 12:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 39.3 KiB, free 361.8 MiB)
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 361.8 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:40839 (size: 18.7 KiB, free: 366.0 MiB)
25/04/01 12:00:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 12:00:40 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:00:40 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks resource profile 0
25/04/01 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 30) (172.18.0.2, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 31) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 32) (172.18.0.8, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 33) (172.18.0.2, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 34) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:35003 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:35191 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:39511 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:35191 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:39511 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:35003 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:35191 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:39511 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:35003 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 32) in 76 ms on 172.18.0.8 (executor 1) (1/5)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 33) in 86 ms on 172.18.0.2 (executor 0) (2/5)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 34) in 90 ms on 172.18.0.6 (executor 2) (3/5)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 31) in 92 ms on 172.18.0.6 (executor 2) (4/5)
25/04/01 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 30) in 118 ms on 172.18.0.2 (executor 0) (5/5)
25/04/01 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 12:00:40 INFO DAGScheduler: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.123 s
25/04/01 12:00:40 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:00:40 INFO DAGScheduler: running: Set()
25/04/01 12:00:40 INFO DAGScheduler: waiting: Set()
25/04/01 12:00:40 INFO DAGScheduler: failed: Set()
25/04/01 12:00:40 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:00:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:00:40 INFO CodeGenerator: Code generated in 15.224933 ms
25/04/01 12:00:40 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:00:40 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:00:40 INFO DAGScheduler: Final stage: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 12:00:40 INFO DAGScheduler: Missing parents: List()
25/04/01 12:00:40 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 235.3 KiB, free 361.6 MiB)
25/04/01 12:00:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 87.4 KiB, free 361.5 MiB)
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:40839 (size: 87.4 KiB, free: 365.9 MiB)
25/04/01 12:00:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 12:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:00:40 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 12:00:40 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 35) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:00:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.2:39511 (size: 87.4 KiB, free: 366.0 MiB)
25/04/01 12:00:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:44616
25/04/01 12:00:40 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 35) in 292 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:00:40 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 12:00:40 INFO DAGScheduler: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.306 s
25/04/01 12:00:40 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 12:00:40 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.310592 s
25/04/01 12:00:40 INFO FileFormatWriter: Start to commit write Job 5fba68f2-d6d5-48fb-a0b4-85a866720af8.
25/04/01 12:00:40 INFO FileFormatWriter: Write Job 5fba68f2-d6d5-48fb-a0b4-85a866720af8 committed. Elapsed time: 37 ms.
25/04/01 12:00:40 INFO FileFormatWriter: Finished processing stats for write job 5fba68f2-d6d5-48fb-a0b4-85a866720af8.
25/04/01 12:00:40 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/04/01 12:00:40 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:00:40 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:00:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:00:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:00:40 INFO MemoryStore: MemoryStore cleared
25/04/01 12:00:40 INFO BlockManager: BlockManager stopped
25/04/01 12:00:40 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:00:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:00:40 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:00:40 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:00:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-c6d10a01-6331-47a3-a2ed-523a13f14a85
25/04/01 12:00:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-87705195-f54b-4fcc-89d3-0fa656635d06
25/04/01 12:00:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-c6d10a01-6331-47a3-a2ed-523a13f14a85/pyspark-73b14ae7-af48-4cc7-89ac-c8f243c09ff9
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:03:28 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:03:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:03:28 INFO ResourceUtils: ==============================================================
25/04/01 12:03:28 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:03:28 INFO ResourceUtils: ==============================================================
25/04/01 12:03:28 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 12:03:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:03:28 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:03:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:03:28 INFO SecurityManager: Changing view acls to: root
25/04/01 12:03:28 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:03:28 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:03:28 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:03:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:03:28 INFO Utils: Successfully started service 'sparkDriver' on port 44351.
25/04/01 12:03:28 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:03:28 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:03:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:03:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:03:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:03:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f0b3ee15-b20d-4eb9-b865-cfd543579365
25/04/01 12:03:28 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:03:28 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:03:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:03:29 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:03:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:03:29 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 12:03:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401120329-0035
25/04/01 12:03:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120329-0035/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:03:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120329-0035/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:03:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120329-0035/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:03:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120329-0035/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:03:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120329-0035/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:03:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120329-0035/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:03:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42237.
25/04/01 12:03:29 INFO NettyBlockTransferService: Server created on 7796893c36d7:42237
25/04/01 12:03:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:03:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 42237, None)
25/04/01 12:03:29 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:42237 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 42237, None)
25/04/01 12:03:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 42237, None)
25/04/01 12:03:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120329-0035/1 is now RUNNING
25/04/01 12:03:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120329-0035/0 is now RUNNING
25/04/01 12:03:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 42237, None)
25/04/01 12:03:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120329-0035/2 is now RUNNING
25/04/01 12:03:29 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:03:29 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:03:29 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:03:30 INFO InMemoryFileIndex: It took 66 ms to list leaf files for 1 paths.
25/04/01 12:03:30 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 5 paths.
25/04/01 12:03:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:45338) with ID 0,  ResourceProfileId 0
25/04/01 12:03:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:35712) with ID 2,  ResourceProfileId 0
25/04/01 12:03:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:44022) with ID 1,  ResourceProfileId 0
25/04/01 12:03:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:41643 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 41643, None)
25/04/01 12:03:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35211 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 35211, None)
25/04/01 12:03:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:36875 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 36875, None)
25/04/01 12:03:32 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:03:32 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:03:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:03:32 INFO CodeGenerator: Code generated in 130.739523 ms
25/04/01 12:03:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 12:03:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:03:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:42237 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:03:32 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:03:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:03:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:03:32 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:03:32 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:03:32 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:03:32 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:03:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:03:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:03:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:42237 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:03:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:03:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:03:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 12:03:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:36875 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:03:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:36875 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:03:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1358 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:03:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:03:34 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.425 s
25/04/01 12:03:34 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:03:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:03:34 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.454353 s
25/04/01 12:03:34 INFO CodeGenerator: Code generated in 8.583865 ms
25/04/01 12:03:34 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:03:34 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:03:34 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:03:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 12:03:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:03:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:42237 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:03:34 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:03:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:03:34 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:03:34 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:03:34 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:03:34 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:03:34 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:03:34 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:03:34 INFO metastore: Connected to metastore.
25/04/01 12:03:35 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=c2925539-af66-4c4d-8f24-c1ee63619b8f, clientType=HIVECLI]
25/04/01 12:03:35 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:03:35 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:03:35 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:03:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:03:35 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:03:35 INFO metastore: Connected to metastore.
25/04/01 12:03:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:03:35 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:03:35 INFO metastore: Connected to metastore.
25/04/01 12:03:35 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
25/04/01 12:03:35 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:03:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:03:35 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:03:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 12:03:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 12:03:35 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 12:03:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:42237 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:03:35 INFO CodeGenerator: Code generated in 19.053533 ms
25/04/01 12:03:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:36875 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:03:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 12:03:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 12:03:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:42237 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:03:35 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8040189 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:03:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:35 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 12 output partitions
25/04/01 12:03:35 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:03:35 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:03:35 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:35 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:03:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 12:03:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 12:03:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:42237 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:03:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:35 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
25/04/01 12:03:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 12 tasks resource profile 0
25/04/01 12:03:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.2, executor 0, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.8, executor 1, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.6, executor 2, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.2, executor 0, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.18.0.8, executor 1, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.18.0.6, executor 2, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.18.0.2, executor 0, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (172.18.0.8, executor 1, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (172.18.0.6, executor 2, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11) (172.18.0.2, executor 0, partition 10, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 12) (172.18.0.8, executor 1, partition 11, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 12:03:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:36875 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 12:03:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:36875 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:03:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:41643 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 12:03:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:35211 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 12:03:36 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 12) in 606 ms on 172.18.0.8 (executor 1) (1/12)
25/04/01 12:03:36 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 648 ms on 172.18.0.8 (executor 1) (2/12)
25/04/01 12:03:36 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 656 ms on 172.18.0.8 (executor 1) (3/12)
25/04/01 12:03:36 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 660 ms on 172.18.0.8 (executor 1) (4/12)
25/04/01 12:03:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:35211 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 12:03:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:41643 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 12:03:37 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 2032 ms on 172.18.0.6 (executor 2) (5/12)
25/04/01 12:03:37 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 2032 ms on 172.18.0.6 (executor 2) (6/12)
25/04/01 12:03:37 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 2034 ms on 172.18.0.6 (executor 2) (7/12)
25/04/01 12:03:37 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 2053 ms on 172.18.0.2 (executor 0) (8/12)
25/04/01 12:03:37 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 11) in 2054 ms on 172.18.0.2 (executor 0) (9/12)
25/04/01 12:03:37 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 2055 ms on 172.18.0.2 (executor 0) (10/12)
25/04/01 12:03:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2219 ms on 172.18.0.6 (executor 2) (11/12)
25/04/01 12:03:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 2227 ms on 172.18.0.2 (executor 0) (12/12)
25/04/01 12:03:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:03:37 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.231 s
25/04/01 12:03:37 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:03:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 12:03:37 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.236016 s
25/04/01 12:03:37 INFO CodeGenerator: Code generated in 6.544547 ms
25/04/01 12:03:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/01 12:03:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 364.2 MiB)
25/04/01 12:03:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:42237 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 12:03:37 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:37 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:03:37 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:03:37 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:03:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:03:37 INFO CodeGenerator: Code generated in 24.47516 ms
25/04/01 12:03:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/01 12:03:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/01 12:03:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:42237 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:03:37 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:03:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:03:37 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:03:37 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:03:37 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:03:37 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:03:37 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:37 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:03:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.3 KiB, free 363.7 MiB)
25/04/01 12:03:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 363.7 MiB)
25/04/01 12:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:42237 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 12:03:37 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:37 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:03:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
25/04/01 12:03:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 13) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 14) (172.18.0.2, executor 0, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:37 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 15) (172.18.0.8, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:37 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 16) (172.18.0.6, executor 2, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:37 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 17) (172.18.0.2, executor 0, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:36875 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 12:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:35211 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 12:03:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:41643 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:36875 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:35211 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:41643 (size: 4.4 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:36875 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 15) in 423 ms on 172.18.0.8 (executor 1) (1/5)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:35211 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:41643 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 16) in 544 ms on 172.18.0.6 (executor 2) (2/5)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 17) in 557 ms on 172.18.0.2 (executor 0) (3/5)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 14) in 557 ms on 172.18.0.2 (executor 0) (4/5)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 13) in 564 ms on 172.18.0.6 (executor 2) (5/5)
25/04/01 12:03:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 12:03:38 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.575 s
25/04/01 12:03:38 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:03:38 INFO DAGScheduler: running: Set()
25/04/01 12:03:38 INFO DAGScheduler: waiting: Set()
25/04/01 12:03:38 INFO DAGScheduler: failed: Set()
25/04/01 12:03:38 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:03:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:03:38 INFO CodeGenerator: Code generated in 12.819643 ms
25/04/01 12:03:38 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:03:38 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:03:38 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:03:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 12:03:38 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:38 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:03:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 44.5 KiB, free 363.7 MiB)
25/04/01 12:03:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 363.7 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:42237 (size: 21.1 KiB, free: 366.1 MiB)
25/04/01 12:03:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:03:38 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 12:03:38 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 18) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:35211 (size: 21.1 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:35712
25/04/01 12:03:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 18) in 112 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:03:38 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 12:03:38 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.119 s
25/04/01 12:03:38 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:03:38 INFO DAGScheduler: running: Set()
25/04/01 12:03:38 INFO DAGScheduler: waiting: Set()
25/04/01 12:03:38 INFO DAGScheduler: failed: Set()
25/04/01 12:03:38 INFO CodeGenerator: Code generated in 6.475962 ms
25/04/01 12:03:38 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:03:38 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:03:38 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:03:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 12:03:38 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:38 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:03:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 12:03:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:42237 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:03:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:03:38 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 12:03:38 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 19) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:35211 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:35712
25/04/01 12:03:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 19) in 24 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:03:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:03:38 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.027 s
25/04/01 12:03:38 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:03:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 12:03:38 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.030548 s
25/04/01 12:03:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:03:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:03:38 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:03:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 12:03:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 12:03:38 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 12:03:38 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/01 12:03:38 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:42237 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:03:38 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8040189 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:03:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:38 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 12 output partitions
25/04/01 12:03:38 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:03:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:03:38 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:38 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:03:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/01 12:03:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:42237 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 12:03:38 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:38 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
25/04/01 12:03:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 12 tasks resource profile 0
25/04/01 12:03:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20) (172.18.0.8, executor 1, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 21) (172.18.0.2, executor 0, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 22) (172.18.0.6, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 23) (172.18.0.8, executor 1, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 24) (172.18.0.2, executor 0, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 25) (172.18.0.6, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 26) (172.18.0.8, executor 1, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 27) (172.18.0.2, executor 0, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 28) (172.18.0.6, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 29) (172.18.0.8, executor 1, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 30) (172.18.0.2, executor 0, partition 10, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 31) (172.18.0.6, executor 2, partition 11, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:35211 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:41643 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:36875 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:35211 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:41643 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:03:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:36875 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 24) in 102 ms on 172.18.0.2 (executor 0) (1/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 27) in 105 ms on 172.18.0.2 (executor 0) (2/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 30) in 106 ms on 172.18.0.2 (executor 0) (3/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 26) in 110 ms on 172.18.0.8 (executor 1) (4/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 22) in 111 ms on 172.18.0.6 (executor 2) (5/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 31) in 112 ms on 172.18.0.6 (executor 2) (6/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 29) in 113 ms on 172.18.0.8 (executor 1) (7/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 28) in 113 ms on 172.18.0.6 (executor 2) (8/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 25) in 115 ms on 172.18.0.6 (executor 2) (9/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 23) in 117 ms on 172.18.0.8 (executor 1) (10/12)
25/04/01 12:03:38 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 21) in 121 ms on 172.18.0.2 (executor 0) (11/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 313 ms on 172.18.0.8 (executor 1) (12/12)
25/04/01 12:03:39 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 12:03:39 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.317 s
25/04/01 12:03:39 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:03:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 12:03:39 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.320223 s
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1032.0 KiB, free 362.2 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 362.2 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:42237 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:03:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:03:39 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:03:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:42237 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 13 from showString at NativeMethodAccessorImpl.java:0
25/04/01 12:03:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:03:39 INFO DAGScheduler: Registering RDD 31 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:03:39 INFO DAGScheduler: Got map stage job 6 (showString at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:03:39 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 12:03:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:03:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:39 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 39.3 KiB, free 361.8 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 361.8 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:42237 (size: 18.7 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:03:39 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks resource profile 0
25/04/01 12:03:39 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 32) (172.18.0.8, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 33) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 34) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 35) (172.18.0.8, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 36) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:35211 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:36875 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:41643 (size: 18.7 KiB, free: 366.2 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:35211 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:41643 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:36875 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:35211 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:41643 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:36875 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 33) in 77 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 36) in 77 ms on 172.18.0.6 (executor 2) (2/5)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 34) in 79 ms on 172.18.0.2 (executor 0) (3/5)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 35) in 84 ms on 172.18.0.8 (executor 1) (4/5)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 32) in 115 ms on 172.18.0.8 (executor 1) (5/5)
25/04/01 12:03:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 12:03:39 INFO DAGScheduler: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 0.120 s
25/04/01 12:03:39 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:03:39 INFO DAGScheduler: running: Set()
25/04/01 12:03:39 INFO DAGScheduler: waiting: Set()
25/04/01 12:03:39 INFO DAGScheduler: failed: Set()
25/04/01 12:03:39 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:03:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:03:39 INFO CodeGenerator: Code generated in 13.699094 ms
25/04/01 12:03:39 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 12:03:39 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:03:39 INFO DAGScheduler: Final stage: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 12:03:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 12:03:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:39 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[34] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 41.2 KiB, free 361.8 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 361.8 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:42237 (size: 19.6 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[34] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:03:39 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 12:03:39 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 37) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:36875 (size: 19.6 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:44022
25/04/01 12:03:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 37) in 117 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:03:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 12:03:39 INFO DAGScheduler: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0) finished in 0.123 s
25/04/01 12:03:39 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:03:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 12:03:39 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0.126659 s
25/04/01 12:03:39 INFO CodeGenerator: Code generated in 7.125842 ms
+---------+-----------+
|CountryID|CountryName|
+---------+-----------+
|     null|CountryName|
+---------+-----------+

25/04/01 12:03:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:03:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:03:39 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:03:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID),IsNotNull(CountryName)
25/04/01 12:03:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#24),isnotnull(CountryName#25)
25/04/01 12:03:39 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: int, CountryName: string>
25/04/01 12:03:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:03:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:03:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:03:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:03:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:03:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:03:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 349.9 KiB, free 361.4 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 361.4 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7796893c36d7:42237 (size: 33.5 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8040189 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:03:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:39 INFO DAGScheduler: Got job 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 12 output partitions
25/04/01 12:03:39 INFO DAGScheduler: Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:03:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:03:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:39 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[38] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 13.5 KiB, free 361.4 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 361.4 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7796893c36d7:42237 (size: 6.0 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:39 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 12 (MapPartitionsRDD[38] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
25/04/01 12:03:39 INFO TaskSchedulerImpl: Adding task set 12.0 with 12 tasks resource profile 0
25/04/01 12:03:39 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 38) (172.18.0.8, executor 1, partition 0, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 39) (172.18.0.2, executor 0, partition 1, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 40) (172.18.0.6, executor 2, partition 2, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 41) (172.18.0.8, executor 1, partition 3, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 4.0 in stage 12.0 (TID 42) (172.18.0.2, executor 0, partition 4, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 5.0 in stage 12.0 (TID 43) (172.18.0.6, executor 2, partition 5, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 6.0 in stage 12.0 (TID 44) (172.18.0.8, executor 1, partition 6, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 7.0 in stage 12.0 (TID 45) (172.18.0.2, executor 0, partition 7, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 8.0 in stage 12.0 (TID 46) (172.18.0.6, executor 2, partition 8, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 9.0 in stage 12.0 (TID 47) (172.18.0.8, executor 1, partition 9, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 10.0 in stage 12.0 (TID 48) (172.18.0.2, executor 0, partition 10, ANY, 5095 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 11.0 in stage 12.0 (TID 49) (172.18.0.6, executor 2, partition 11, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.8:36875 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.2:41643 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.6:35211 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.8:36875 (size: 33.5 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.2:41643 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.6:35211 (size: 33.5 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 11.0 in stage 12.0 (TID 49) in 75 ms on 172.18.0.6 (executor 2) (1/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 4.0 in stage 12.0 (TID 42) in 91 ms on 172.18.0.2 (executor 0) (2/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 39) in 92 ms on 172.18.0.2 (executor 0) (3/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 7.0 in stage 12.0 (TID 45) in 92 ms on 172.18.0.2 (executor 0) (4/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 10.0 in stage 12.0 (TID 48) in 93 ms on 172.18.0.2 (executor 0) (5/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 41) in 94 ms on 172.18.0.8 (executor 1) (6/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 9.0 in stage 12.0 (TID 47) in 98 ms on 172.18.0.8 (executor 1) (7/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 5.0 in stage 12.0 (TID 43) in 101 ms on 172.18.0.6 (executor 2) (8/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 8.0 in stage 12.0 (TID 46) in 103 ms on 172.18.0.6 (executor 2) (9/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 6.0 in stage 12.0 (TID 44) in 108 ms on 172.18.0.8 (executor 1) (10/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 40) in 112 ms on 172.18.0.6 (executor 2) (11/12)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 38) in 114 ms on 172.18.0.8 (executor 1) (12/12)
25/04/01 12:03:39 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/04/01 12:03:39 INFO DAGScheduler: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.117 s
25/04/01 12:03:39 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:03:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
25/04/01 12:03:39 INFO DAGScheduler: Job 8 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.119542 s
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 1032.0 KiB, free 360.4 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 360.4 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 7796893c36d7:42237 (size: 4.4 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 18 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:03:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:03:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:03:39 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:03:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 345.3 KiB, free 360.0 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 360.0 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 7796893c36d7:42237 (size: 32.6 KiB, free: 365.9 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 19 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:03:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:03:39 INFO DAGScheduler: Registering RDD 42 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 12:03:39 INFO DAGScheduler: Got map stage job 9 (insertInto at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:03:39 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:03:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:03:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:39 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[42] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 39.3 KiB, free 359.9 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 359.9 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 7796893c36d7:42237 (size: 18.7 KiB, free: 365.9 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[42] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:03:39 INFO TaskSchedulerImpl: Adding task set 13.0 with 5 tasks resource profile 0
25/04/01 12:03:39 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 50) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 51) (172.18.0.2, executor 0, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 52) (172.18.0.8, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 53) (172.18.0.6, executor 2, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 54) (172.18.0.2, executor 0, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.6:35211 (size: 18.7 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.8:36875 (size: 18.7 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.2:41643 (size: 18.7 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.6:35211 (size: 4.4 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.2:41643 (size: 4.4 KiB, free: 366.1 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.6:35211 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 53) in 56 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.2:41643 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.8:36875 (size: 4.4 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 50) in 69 ms on 172.18.0.6 (executor 2) (2/5)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 51) in 86 ms on 172.18.0.2 (executor 0) (3/5)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 54) in 89 ms on 172.18.0.2 (executor 0) (4/5)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.8:36875 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 12:03:39 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 52) in 107 ms on 172.18.0.8 (executor 1) (5/5)
25/04/01 12:03:39 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/04/01 12:03:39 INFO DAGScheduler: ShuffleMapStage 13 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.113 s
25/04/01 12:03:39 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:03:39 INFO DAGScheduler: running: Set()
25/04/01 12:03:39 INFO DAGScheduler: waiting: Set()
25/04/01 12:03:39 INFO DAGScheduler: failed: Set()
25/04/01 12:03:39 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:03:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:03:39 INFO CodeGenerator: Code generated in 11.197144 ms
25/04/01 12:03:39 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:03:39 INFO DAGScheduler: Got job 10 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:03:39 INFO DAGScheduler: Final stage: ResultStage 15 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:03:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
25/04/01 12:03:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:03:39 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[44] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 235.3 KiB, free 359.7 MiB)
25/04/01 12:03:39 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 87.4 KiB, free 359.6 MiB)
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 7796893c36d7:42237 (size: 87.4 KiB, free: 365.8 MiB)
25/04/01 12:03:39 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1478
25/04/01 12:03:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[44] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:03:39 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/04/01 12:03:39 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 55) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:03:39 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.6:35211 (size: 87.4 KiB, free: 365.9 MiB)
25/04/01 12:03:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:35712
25/04/01 12:03:40 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 55) in 231 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:03:40 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/04/01 12:03:40 INFO DAGScheduler: ResultStage 15 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.243 s
25/04/01 12:03:40 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:03:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/04/01 12:03:40 INFO DAGScheduler: Job 10 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.247050 s
25/04/01 12:03:40 INFO FileFormatWriter: Start to commit write Job 62de3578-97e1-4ef8-bb7d-1157759c9984.
25/04/01 12:03:40 INFO FileFormatWriter: Write Job 62de3578-97e1-4ef8-bb7d-1157759c9984 committed. Elapsed time: 35 ms.
25/04/01 12:03:40 INFO FileFormatWriter: Finished processing stats for write job 62de3578-97e1-4ef8-bb7d-1157759c9984.
25/04/01 12:03:40 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/04/01 12:03:40 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:03:40 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:03:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:03:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:03:40 INFO MemoryStore: MemoryStore cleared
25/04/01 12:03:40 INFO BlockManager: BlockManager stopped
25/04/01 12:03:40 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:03:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:03:40 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:03:40 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:03:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-ae79edc4-2088-4e4f-8792-45734fde645a
25/04/01 12:03:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-838f0d60-98be-49b8-9cd9-28aef90f3f05
25/04/01 12:03:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-838f0d60-98be-49b8-9cd9-28aef90f3f05/pyspark-d9ecd0f6-35c5-41ef-a47f-cf5872709dfc
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:06:23 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:06:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:06:23 INFO ResourceUtils: ==============================================================
25/04/01 12:06:23 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:06:23 INFO ResourceUtils: ==============================================================
25/04/01 12:06:23 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 12:06:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:06:23 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:06:23 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:06:23 INFO SecurityManager: Changing view acls to: root
25/04/01 12:06:23 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:06:23 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:06:23 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:06:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:06:23 INFO Utils: Successfully started service 'sparkDriver' on port 42649.
25/04/01 12:06:23 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:06:23 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:06:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:06:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:06:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:06:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d2729ad7-dbe7-4afc-a882-300b8a4d0cfc
25/04/01 12:06:23 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:06:23 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:06:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:06:24 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:06:24 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:06:24 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 12:06:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401120624-0036
25/04/01 12:06:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120624-0036/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:06:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120624-0036/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:06:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120624-0036/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:06:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120624-0036/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:06:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120624-0036/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:06:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120624-0036/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:06:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44179.
25/04/01 12:06:24 INFO NettyBlockTransferService: Server created on 7796893c36d7:44179
25/04/01 12:06:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:06:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 44179, None)
25/04/01 12:06:24 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:44179 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 44179, None)
25/04/01 12:06:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120624-0036/0 is now RUNNING
25/04/01 12:06:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120624-0036/1 is now RUNNING
25/04/01 12:06:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 44179, None)
25/04/01 12:06:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 44179, None)
25/04/01 12:06:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120624-0036/2 is now RUNNING
25/04/01 12:06:24 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:06:24 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:06:24 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:06:25 INFO InMemoryFileIndex: It took 72 ms to list leaf files for 1 paths.
25/04/01 12:06:25 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 5 paths.
25/04/01 12:06:26 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:57388) with ID 0,  ResourceProfileId 0
25/04/01 12:06:26 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:39484) with ID 2,  ResourceProfileId 0
25/04/01 12:06:26 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:57038) with ID 1,  ResourceProfileId 0
25/04/01 12:06:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:33303 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 33303, None)
25/04/01 12:06:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:45189 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 45189, None)
25/04/01 12:06:26 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:38847 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 38847, None)
25/04/01 12:06:27 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:06:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:06:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:06:27 INFO CodeGenerator: Code generated in 132.143628 ms
25/04/01 12:06:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 12:06:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:06:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:44179 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:06:27 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:06:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:06:28 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:06:28 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:06:28 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:06:28 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:06:28 INFO DAGScheduler: Missing parents: List()
25/04/01 12:06:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:06:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:06:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:06:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:44179 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:06:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:06:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:06:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:06:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 12:06:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:38847 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:06:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:38847 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:06:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1351 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:06:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:06:29 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.414 s
25/04/01 12:06:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:06:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:06:29 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.444803 s
25/04/01 12:06:29 INFO CodeGenerator: Code generated in 7.86994 ms
25/04/01 12:06:29 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:06:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:06:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:06:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 12:06:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:06:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:44179 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:06:29 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:06:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:06:29 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:06:29 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:06:29 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:06:29 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:06:29 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:06:29 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:06:29 INFO metastore: Connected to metastore.
25/04/01 12:06:30 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ae914df7-69b6-45d2-8999-0d50145fbbaf, clientType=HIVECLI]
25/04/01 12:06:30 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:06:30 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:06:30 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:06:30 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:06:30 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:06:30 INFO metastore: Connected to metastore.
25/04/01 12:06:30 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:06:30 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:06:30 INFO metastore: Connected to metastore.
25/04/01 12:06:30 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/04/01 12:06:30 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:06:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:06:30 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:06:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:06:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:06:30 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:06:30 INFO CodeGenerator: Code generated in 15.317334 ms
25/04/01 12:06:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 12:06:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 12:06:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:44179 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:06:30 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:06:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:44179 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:06:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:38847 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:06:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:30 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000195 s
25/04/01 12:06:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.0 B, free 365.2 MiB)
25/04/01 12:06:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 120.0 B, free 365.2 MiB)
25/04/01 12:06:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:44179 (size: 120.0 B, free: 366.2 MiB)
25/04/01 12:06:30 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:30 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:06:30 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:06:30 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:06:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:06:30 INFO CodeGenerator: Code generated in 22.1321 ms
25/04/01 12:06:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 345.3 KiB, free 364.9 MiB)
25/04/01 12:06:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 12:06:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:44179 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:06:30 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:06:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:06:30 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:06:30 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:06:30 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:06:30 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:06:30 INFO DAGScheduler: Missing parents: List()
25/04/01 12:06:30 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:06:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 30.3 KiB, free 364.8 MiB)
25/04/01 12:06:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 364.8 MiB)
25/04/01 12:06:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:44179 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 12:06:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 12:06:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:06:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks resource profile 0
25/04/01 12:06:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.2, executor 0, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:30 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.8, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:30 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.6, executor 2, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:30 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.2, executor 0, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:38847 (size: 14.3 KiB, free: 366.3 MiB)
25/04/01 12:06:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:45189 (size: 14.3 KiB, free: 366.3 MiB)
25/04/01 12:06:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:33303 (size: 14.3 KiB, free: 366.3 MiB)
25/04/01 12:06:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:38847 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:06:31 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 425 ms on 172.18.0.8 (executor 1) (1/5)
25/04/01 12:06:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:33303 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:06:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:45189 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:06:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1900 ms on 172.18.0.2 (executor 0) (2/5)
25/04/01 12:06:32 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1899 ms on 172.18.0.2 (executor 0) (3/5)
25/04/01 12:06:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1932 ms on 172.18.0.6 (executor 2) (4/5)
25/04/01 12:06:32 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1930 ms on 172.18.0.6 (executor 2) (5/5)
25/04/01 12:06:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:06:32 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.946 s
25/04/01 12:06:32 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:06:32 INFO DAGScheduler: running: Set()
25/04/01 12:06:32 INFO DAGScheduler: waiting: Set()
25/04/01 12:06:32 INFO DAGScheduler: failed: Set()
25/04/01 12:06:32 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:06:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:06:32 INFO CodeGenerator: Code generated in 13.889902 ms
25/04/01 12:06:32 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:06:32 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:06:32 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:06:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:06:32 INFO DAGScheduler: Missing parents: List()
25/04/01 12:06:32 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:06:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 37.6 KiB, free 364.7 MiB)
25/04/01 12:06:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 12:06:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:44179 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 12:06:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:06:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:06:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:06:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:45189 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 12:06:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:39484
25/04/01 12:06:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 156 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:06:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:06:32 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.165 s
25/04/01 12:06:32 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:06:32 INFO DAGScheduler: running: Set()
25/04/01 12:06:32 INFO DAGScheduler: waiting: Set()
25/04/01 12:06:32 INFO DAGScheduler: failed: Set()
25/04/01 12:06:33 INFO CodeGenerator: Code generated in 6.803032 ms
25/04/01 12:06:33 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:06:33 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:06:33 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:06:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 12:06:33 INFO DAGScheduler: Missing parents: List()
25/04/01 12:06:33 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:44179 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:06:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 12:06:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:45189 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:39484
25/04/01 12:06:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 89 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:06:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 12:06:33 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.094 s
25/04/01 12:06:33 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:06:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 12:06:33 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.098248 s
25/04/01 12:06:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:06:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:06:33 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:06:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:06:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:06:33 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.9 KiB, free 364.4 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 364.3 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:44179 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:06:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:33 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000204 s
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 24.0 B, free 364.3 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.3 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:44179 (size: 120.0 B, free: 366.1 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:06:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:06:33 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:06:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 345.3 KiB, free 364.0 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:44179 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 11 from showString at NativeMethodAccessorImpl.java:0
25/04/01 12:06:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:06:33 INFO DAGScheduler: Registering RDD 31 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:06:33 INFO DAGScheduler: Got map stage job 6 (showString at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:06:33 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 12:06:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:06:33 INFO DAGScheduler: Missing parents: List()
25/04/01 12:06:33 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[31] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 30.3 KiB, free 363.9 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 363.9 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:44179 (size: 14.3 KiB, free: 366.1 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 12:06:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[31] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:06:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 5 tasks resource profile 0
25/04/01 12:06:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (172.18.0.2, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 10) (172.18.0.8, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 11) (172.18.0.2, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 12) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:45189 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:38847 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:33303 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:45189 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:38847 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:33303 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 12) in 93 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 95 ms on 172.18.0.6 (executor 2) (2/5)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 10) in 97 ms on 172.18.0.8 (executor 1) (3/5)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 11) in 126 ms on 172.18.0.2 (executor 0) (4/5)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 131 ms on 172.18.0.2 (executor 0) (5/5)
25/04/01 12:06:33 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:06:33 INFO DAGScheduler: ShuffleMapStage 7 (showString at NativeMethodAccessorImpl.java:0) finished in 0.136 s
25/04/01 12:06:33 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:06:33 INFO DAGScheduler: running: Set()
25/04/01 12:06:33 INFO DAGScheduler: waiting: Set()
25/04/01 12:06:33 INFO DAGScheduler: failed: Set()
25/04/01 12:06:33 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:06:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:06:33 INFO CodeGenerator: Code generated in 14.787024 ms
25/04/01 12:06:33 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 12:06:33 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:06:33 INFO DAGScheduler: Final stage: ResultStage 9 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 12:06:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 12:06:33 INFO DAGScheduler: Missing parents: List()
25/04/01 12:06:33 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[34] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 34.4 KiB, free 363.9 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 363.9 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:44179 (size: 16.3 KiB, free: 366.0 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 12:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[34] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:06:33 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 12:06:33 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 13) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:45189 (size: 16.3 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:39484
25/04/01 12:06:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 13) in 43 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:06:33 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 12:06:33 INFO DAGScheduler: ResultStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 0.050 s
25/04/01 12:06:33 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:06:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 12:06:33 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0.056950 s
25/04/01 12:06:33 INFO CodeGenerator: Code generated in 7.07388 ms
+---------+--------------------+
|countryid|         countryname|
+---------+--------------------+
|    10000|                 ABC|
|     2231|Cote d'Ivoire (Iv...|
|     3306|              Bhutan|
|     5511|             Grenada|
|     4413|              Tuvalu|
|     3312|               India|
|     5513|               Haiti|
|     2201|             Algeria|
|     1119|             Croatia|
|     3321|          Kyrgyzstan|
|     2205|         South Sudan|
|     1139|              Greece|
|     2229|        Burkina Faso|
|     3324|            Malaysia|
|     2224|            Tanzania|
|     3334|               Qatar|
|     1137|             Germany|
|     6608|            Paraguay|
|     1122|              Poland|
|     1126|             Romania|
+---------+--------------------+
only showing top 20 rows

25/04/01 12:06:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:06:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:06:33 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:06:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:06:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:06:33 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:06:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:06:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:06:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:06:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:06:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:06:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:06:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 349.9 KiB, free 363.5 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.5 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:44179 (size: 33.5 KiB, free: 366.0 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:06:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:33 INFO DAGScheduler: Job 8 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000134 s
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 24.0 B, free 363.5 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 120.0 B, free 363.5 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:44179 (size: 120.0 B, free: 366.0 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 15 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:06:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:06:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:06:33 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:06:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 345.3 KiB, free 363.2 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.1 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7796893c36d7:44179 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 16 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:06:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:06:33 INFO DAGScheduler: Registering RDD 42 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 12:06:33 INFO DAGScheduler: Got map stage job 9 (insertInto at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:06:33 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:06:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:06:33 INFO DAGScheduler: Missing parents: List()
25/04/01 12:06:33 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[42] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 30.3 KiB, free 363.1 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 363.1 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7796893c36d7:44179 (size: 14.3 KiB, free: 366.0 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1478
25/04/01 12:06:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[42] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:06:33 INFO TaskSchedulerImpl: Adding task set 10.0 with 5 tasks resource profile 0
25/04/01 12:06:33 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 14) (172.18.0.8, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 15) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 16) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 17) (172.18.0.8, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 18) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.6:45189 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.8:38847 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.2:33303 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.6:45189 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.2:33303 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.8:38847 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 15) in 78 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 18) in 79 ms on 172.18.0.6 (executor 2) (2/5)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 16) in 86 ms on 172.18.0.2 (executor 0) (3/5)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 14) in 100 ms on 172.18.0.8 (executor 1) (4/5)
25/04/01 12:06:33 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 17) in 100 ms on 172.18.0.8 (executor 1) (5/5)
25/04/01 12:06:33 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 12:06:33 INFO DAGScheduler: ShuffleMapStage 10 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.105 s
25/04/01 12:06:33 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:06:33 INFO DAGScheduler: running: Set()
25/04/01 12:06:33 INFO DAGScheduler: waiting: Set()
25/04/01 12:06:33 INFO DAGScheduler: failed: Set()
25/04/01 12:06:33 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:06:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:06:33 INFO CodeGenerator: Code generated in 14.192039 ms
25/04/01 12:06:33 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:06:33 INFO DAGScheduler: Got job 10 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:06:33 INFO DAGScheduler: Final stage: ResultStage 12 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:06:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
25/04/01 12:06:33 INFO DAGScheduler: Missing parents: List()
25/04/01 12:06:33 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[44] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 228.6 KiB, free 362.9 MiB)
25/04/01 12:06:33 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 83.7 KiB, free 362.8 MiB)
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 7796893c36d7:44179 (size: 83.7 KiB, free: 365.9 MiB)
25/04/01 12:06:33 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1478
25/04/01 12:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[44] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:06:33 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/04/01 12:06:33 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 19) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:06:33 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.6:45189 (size: 83.7 KiB, free: 366.0 MiB)
25/04/01 12:06:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:39484
25/04/01 12:06:34 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 19) in 652 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:06:34 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/04/01 12:06:34 INFO DAGScheduler: ResultStage 12 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.664 s
25/04/01 12:06:34 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:06:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
25/04/01 12:06:34 INFO DAGScheduler: Job 10 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.669370 s
25/04/01 12:06:34 INFO FileFormatWriter: Start to commit write Job 4f4830fa-a0ad-46d9-8192-a24eff4367d8.
25/04/01 12:06:34 INFO FileFormatWriter: Write Job 4f4830fa-a0ad-46d9-8192-a24eff4367d8 committed. Elapsed time: 37 ms.
25/04/01 12:06:34 INFO FileFormatWriter: Finished processing stats for write job 4f4830fa-a0ad-46d9-8192-a24eff4367d8.
25/04/01 12:06:34 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 12:06:34 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:06:34 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:06:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:06:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:06:34 INFO MemoryStore: MemoryStore cleared
25/04/01 12:06:34 INFO BlockManager: BlockManager stopped
25/04/01 12:06:34 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:06:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:06:34 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:06:35 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:06:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-9e98f057-13d0-4151-97ec-94869b64b508
25/04/01 12:06:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-2e4639c8-38b2-43bb-8e74-42e5e92e96b5
25/04/01 12:06:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-2e4639c8-38b2-43bb-8e74-42e5e92e96b5/pyspark-607b958d-c5b9-41b8-b8e2-3f0837de88c4
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:07:38 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:07:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:07:38 INFO ResourceUtils: ==============================================================
25/04/01 12:07:38 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:07:38 INFO ResourceUtils: ==============================================================
25/04/01 12:07:38 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 12:07:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:07:38 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:07:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:07:38 INFO SecurityManager: Changing view acls to: root
25/04/01 12:07:38 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:07:38 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:07:38 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:07:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:07:38 INFO Utils: Successfully started service 'sparkDriver' on port 33105.
25/04/01 12:07:39 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:07:39 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:07:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:07:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:07:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:07:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ccdd67d0-dd5f-4d5b-ad87-bc3e11a61d86
25/04/01 12:07:39 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:07:39 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:07:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:07:39 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:07:39 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:07:39 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 12:07:39 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401120739-0037
25/04/01 12:07:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120739-0037/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:07:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120739-0037/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:07:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120739-0037/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:07:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120739-0037/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:07:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401120739-0037/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:07:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401120739-0037/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:07:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35121.
25/04/01 12:07:39 INFO NettyBlockTransferService: Server created on 7796893c36d7:35121
25/04/01 12:07:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:07:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 35121, None)
25/04/01 12:07:39 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:35121 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 35121, None)
25/04/01 12:07:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120739-0037/1 is now RUNNING
25/04/01 12:07:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120739-0037/0 is now RUNNING
25/04/01 12:07:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 35121, None)
25/04/01 12:07:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 35121, None)
25/04/01 12:07:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401120739-0037/2 is now RUNNING
25/04/01 12:07:39 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:07:39 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:07:39 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:07:41 INFO InMemoryFileIndex: It took 66 ms to list leaf files for 1 paths.
25/04/01 12:07:41 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 5 paths.
25/04/01 12:07:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:35788) with ID 2,  ResourceProfileId 0
25/04/01 12:07:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:38128) with ID 1,  ResourceProfileId 0
25/04/01 12:07:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:35440) with ID 0,  ResourceProfileId 0
25/04/01 12:07:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35285 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 35285, None)
25/04/01 12:07:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44041 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 44041, None)
25/04/01 12:07:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:34583 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 34583, None)
25/04/01 12:07:42 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:07:42 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:07:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:07:43 INFO CodeGenerator: Code generated in 132.290086 ms
25/04/01 12:07:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 12:07:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:07:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:35121 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:07:43 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:07:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:07:43 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:07:43 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:07:43 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:07:43 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:07:43 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:43 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:07:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:07:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:07:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:35121 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:07:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:07:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:07:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 12:07:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:35285 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:07:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:35285 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:07:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1406 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:07:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:07:44 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.471 s
25/04/01 12:07:44 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:07:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:07:44 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.503608 s
25/04/01 12:07:44 INFO CodeGenerator: Code generated in 7.408284 ms
25/04/01 12:07:44 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:07:44 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:07:44 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:07:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 12:07:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:07:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:35121 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:07:44 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:07:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:07:44 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:07:45 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:07:45 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:07:45 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:07:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:07:45 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:07:45 INFO metastore: Connected to metastore.
25/04/01 12:07:45 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=55ed6ffd-4d77-427a-9102-65ca797811b5, clientType=HIVECLI]
25/04/01 12:07:45 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:07:45 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:07:45 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:07:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:07:45 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:07:45 INFO metastore: Connected to metastore.
25/04/01 12:07:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:07:45 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:07:45 INFO metastore: Connected to metastore.
25/04/01 12:07:45 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/04/01 12:07:45 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:07:45 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:07:45 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:07:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:07:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:07:45 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:07:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:35121 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:07:45 INFO CodeGenerator: Code generated in 19.667026 ms
25/04/01 12:07:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:35285 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:07:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 12:07:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 12:07:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:35121 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:07:45 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:07:45 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:45 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 12:07:45 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:07:45 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:07:45 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:45 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:07:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 12:07:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 12:07:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:35121 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:07:45 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 12:07:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 12:07:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 12:07:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:44041 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 12:07:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:44041 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 12:07:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1793 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:07:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:07:47 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.797 s
25/04/01 12:07:47 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:07:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 12:07:47 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.800052 s
25/04/01 12:07:47 INFO CodeGenerator: Code generated in 6.13234 ms
25/04/01 12:07:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/01 12:07:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 364.2 MiB)
25/04/01 12:07:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:35121 (size: 4.3 KiB, free: 366.2 MiB)
25/04/01 12:07:47 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:47 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:07:47 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:07:47 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:07:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:07:47 INFO CodeGenerator: Code generated in 24.06407 ms
25/04/01 12:07:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/01 12:07:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/01 12:07:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:35121 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:07:47 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:07:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:07:47 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:07:47 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:07:47 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:07:47 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:07:47 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:47 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:07:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.5 KiB, free 363.7 MiB)
25/04/01 12:07:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 363.7 MiB)
25/04/01 12:07:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:35121 (size: 18.8 KiB, free: 366.1 MiB)
25/04/01 12:07:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:47 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:07:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
25/04/01 12:07:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (172.18.0.8, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:47 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:47 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5) (172.18.0.6, executor 2, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:47 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6) (172.18.0.8, executor 1, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:35285 (size: 18.8 KiB, free: 366.2 MiB)
25/04/01 12:07:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:44041 (size: 18.8 KiB, free: 366.2 MiB)
25/04/01 12:07:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:34583 (size: 18.8 KiB, free: 366.3 MiB)
25/04/01 12:07:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:44041 (size: 4.3 KiB, free: 366.2 MiB)
25/04/01 12:07:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:35285 (size: 4.3 KiB, free: 366.2 MiB)
25/04/01 12:07:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:35285 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:07:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:44041 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:07:48 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 542 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:07:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 574 ms on 172.18.0.6 (executor 2) (2/5)
25/04/01 12:07:48 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 583 ms on 172.18.0.8 (executor 1) (3/5)
25/04/01 12:07:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 585 ms on 172.18.0.8 (executor 1) (4/5)
25/04/01 12:07:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:34583 (size: 4.3 KiB, free: 366.3 MiB)
25/04/01 12:07:49 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:34583 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:07:49 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 1750 ms on 172.18.0.2 (executor 0) (5/5)
25/04/01 12:07:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 12:07:49 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 1.763 s
25/04/01 12:07:49 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:07:49 INFO DAGScheduler: running: Set()
25/04/01 12:07:49 INFO DAGScheduler: waiting: Set()
25/04/01 12:07:49 INFO DAGScheduler: failed: Set()
25/04/01 12:07:49 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:07:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:07:49 INFO CodeGenerator: Code generated in 10.861832 ms
25/04/01 12:07:49 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:07:49 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:07:49 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:07:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 12:07:49 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:49 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:07:49 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 44.8 KiB, free 363.7 MiB)
25/04/01 12:07:49 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.2 KiB, free 363.7 MiB)
25/04/01 12:07:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:35121 (size: 21.2 KiB, free: 366.1 MiB)
25/04/01 12:07:49 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:07:49 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 12:07:49 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 7) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:07:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:35285 (size: 21.2 KiB, free: 366.2 MiB)
25/04/01 12:07:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:35788
25/04/01 12:07:49 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 7) in 126 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:07:49 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 12:07:49 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.133 s
25/04/01 12:07:49 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:07:49 INFO DAGScheduler: running: Set()
25/04/01 12:07:49 INFO DAGScheduler: waiting: Set()
25/04/01 12:07:49 INFO DAGScheduler: failed: Set()
25/04/01 12:07:49 INFO CodeGenerator: Code generated in 6.458153 ms
25/04/01 12:07:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:07:49 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:07:49 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:07:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 12:07:49 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:49 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:07:49 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 12:07:49 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.6 MiB)
25/04/01 12:07:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:35121 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:07:49 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:07:49 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 12:07:49 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:07:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:35285 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:07:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:35788
25/04/01 12:07:49 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 24 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:07:49 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:07:49 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.027 s
25/04/01 12:07:49 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:07:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 12:07:49 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.030192 s
25/04/01 12:07:49 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:07:49 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:07:49 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:07:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:07:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:07:49 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:07:49 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/01 12:07:49 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/01 12:07:49 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:35121 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:07:49 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:07:49 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:49 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 12:07:49 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:07:49 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:07:49 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:49 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:07:49 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/01 12:07:49 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/01 12:07:49 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:35121 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 12:07:49 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 12:07:49 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 12:07:49 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 9) (172.18.0.2, executor 0, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 12:07:49 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:34583 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:34583 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 9) in 621 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:07:50 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 12:07:50 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.625 s
25/04/01 12:07:50 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:07:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 12:07:50 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.628461 s
25/04/01 12:07:50 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1032.0 KiB, free 362.2 MiB)
25/04/01 12:07:50 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 362.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:35121 (size: 4.3 KiB, free: 366.1 MiB)
25/04/01 12:07:50 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:50 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:07:50 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:07:50 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:07:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:07:50 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/01 12:07:50 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:35121 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 12:07:50 INFO SparkContext: Created broadcast 13 from showString at NativeMethodAccessorImpl.java:0
25/04/01 12:07:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:07:50 INFO DAGScheduler: Registering RDD 31 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:07:50 INFO DAGScheduler: Got map stage job 6 (showString at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:07:50 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 12:07:50 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:07:50 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:50 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:07:50 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 39.5 KiB, free 361.8 MiB)
25/04/01 12:07:50 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 361.8 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:35121 (size: 18.8 KiB, free: 366.0 MiB)
25/04/01 12:07:50 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:50 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:07:50 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks resource profile 0
25/04/01 12:07:50 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 10) (172.18.0.2, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:50 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 11) (172.18.0.8, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:50 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 12) (172.18.0.6, executor 2, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:50 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 13) (172.18.0.2, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:50 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 14) (172.18.0.8, executor 1, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:44041 (size: 18.8 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:35285 (size: 18.8 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:34583 (size: 18.8 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:35285 (size: 4.3 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:44041 (size: 4.3 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:34583 (size: 4.3 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:35285 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:44041 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:34583 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:07:50 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 12) in 78 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:07:50 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 14) in 80 ms on 172.18.0.8 (executor 1) (2/5)
25/04/01 12:07:50 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 11) in 82 ms on 172.18.0.8 (executor 1) (3/5)
25/04/01 12:07:50 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 13) in 108 ms on 172.18.0.2 (executor 0) (4/5)
25/04/01 12:07:50 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 10) in 142 ms on 172.18.0.2 (executor 0) (5/5)
25/04/01 12:07:50 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 12:07:50 INFO DAGScheduler: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 0.148 s
25/04/01 12:07:50 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:07:50 INFO DAGScheduler: running: Set()
25/04/01 12:07:50 INFO DAGScheduler: waiting: Set()
25/04/01 12:07:50 INFO DAGScheduler: failed: Set()
25/04/01 12:07:50 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:07:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:07:50 INFO CodeGenerator: Code generated in 12.819224 ms
25/04/01 12:07:50 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 12:07:50 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:07:50 INFO DAGScheduler: Final stage: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 12:07:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 12:07:50 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:50 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[34] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:07:50 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 41.5 KiB, free 361.8 MiB)
25/04/01 12:07:50 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 361.8 MiB)
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:35121 (size: 19.8 KiB, free: 366.0 MiB)
25/04/01 12:07:50 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[34] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:07:50 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 12:07:50 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 15) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:07:50 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.2:34583 (size: 19.8 KiB, free: 366.1 MiB)
25/04/01 12:07:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:35440
25/04/01 12:07:50 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 15) in 89 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:07:50 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 12:07:50 INFO DAGScheduler: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0) finished in 0.095 s
25/04/01 12:07:50 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:07:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 12:07:50 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0.098683 s
25/04/01 12:07:50 INFO CodeGenerator: Code generated in 6.005855 ms
+---------+-----------+
|countryid|countryname|
+---------+-----------+
|     null|CountryName|
+---------+-----------+

25/04/01 12:07:50 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:07:50 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:07:50 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:07:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:07:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:07:50 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:07:50 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:07:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:07:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:07:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:07:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:07:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:07:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 349.9 KiB, free 361.4 MiB)
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 361.4 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7796893c36d7:35121 (size: 33.5 KiB, free: 366.0 MiB)
25/04/01 12:07:51 INFO SparkContext: Created broadcast 16 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:07:51 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:51 INFO DAGScheduler: Got job 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 12:07:51 INFO DAGScheduler: Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:07:51 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:07:51 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:51 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[38] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 13.5 KiB, free 361.4 MiB)
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 361.4 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7796893c36d7:35121 (size: 6.0 KiB, free: 366.0 MiB)
25/04/01 12:07:51 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[38] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 12:07:51 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/04/01 12:07:51 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 16) (172.18.0.2, executor 0, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.2:34583 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.2:34583 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 16) in 41 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:07:51 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/04/01 12:07:51 INFO DAGScheduler: ResultStage 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.046 s
25/04/01 12:07:51 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:07:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
25/04/01 12:07:51 INFO DAGScheduler: Job 8 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.047372 s
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 1032.0 KiB, free 360.4 MiB)
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 360.4 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 7796893c36d7:35121 (size: 4.3 KiB, free: 366.0 MiB)
25/04/01 12:07:51 INFO SparkContext: Created broadcast 18 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:07:51 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:07:51 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:07:51 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:07:51 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 345.3 KiB, free 360.0 MiB)
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 360.0 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 7796893c36d7:35121 (size: 32.6 KiB, free: 365.9 MiB)
25/04/01 12:07:51 INFO SparkContext: Created broadcast 19 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:07:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:07:51 INFO DAGScheduler: Registering RDD 42 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 12:07:51 INFO DAGScheduler: Got map stage job 9 (insertInto at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:07:51 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:07:51 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:07:51 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:51 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[42] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 39.5 KiB, free 359.9 MiB)
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 359.9 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 7796893c36d7:35121 (size: 18.8 KiB, free: 365.9 MiB)
25/04/01 12:07:51 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:51 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[42] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:07:51 INFO TaskSchedulerImpl: Adding task set 13.0 with 5 tasks resource profile 0
25/04/01 12:07:51 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 17) (172.18.0.2, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:51 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 18) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:51 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 19) (172.18.0.8, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:51 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 20) (172.18.0.2, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:51 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 21) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.8:44041 (size: 18.8 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.6:35285 (size: 18.8 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.2:34583 (size: 18.8 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.2:34583 (size: 4.3 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.8:44041 (size: 4.3 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.6:35285 (size: 4.3 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.2:34583 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.6:35285 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.8:44041 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:07:51 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 20) in 74 ms on 172.18.0.2 (executor 0) (1/5)
25/04/01 12:07:51 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 19) in 77 ms on 172.18.0.8 (executor 1) (2/5)
25/04/01 12:07:51 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 21) in 82 ms on 172.18.0.6 (executor 2) (3/5)
25/04/01 12:07:51 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 18) in 82 ms on 172.18.0.6 (executor 2) (4/5)
25/04/01 12:07:51 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 17) in 86 ms on 172.18.0.2 (executor 0) (5/5)
25/04/01 12:07:51 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/04/01 12:07:51 INFO DAGScheduler: ShuffleMapStage 13 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.092 s
25/04/01 12:07:51 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:07:51 INFO DAGScheduler: running: Set()
25/04/01 12:07:51 INFO DAGScheduler: waiting: Set()
25/04/01 12:07:51 INFO DAGScheduler: failed: Set()
25/04/01 12:07:51 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:07:51 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:07:51 INFO CodeGenerator: Code generated in 13.855611 ms
25/04/01 12:07:51 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:07:51 INFO DAGScheduler: Got job 10 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:07:51 INFO DAGScheduler: Final stage: ResultStage 15 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:07:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
25/04/01 12:07:51 INFO DAGScheduler: Missing parents: List()
25/04/01 12:07:51 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[44] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 235.6 KiB, free 359.7 MiB)
25/04/01 12:07:51 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 87.5 KiB, free 359.6 MiB)
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 7796893c36d7:35121 (size: 87.5 KiB, free: 365.8 MiB)
25/04/01 12:07:51 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1478
25/04/01 12:07:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[44] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:07:51 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/04/01 12:07:51 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 22) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:07:51 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.2:34583 (size: 87.5 KiB, free: 366.0 MiB)
25/04/01 12:07:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.2:35440
25/04/01 12:07:51 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 22) in 251 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:07:51 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/04/01 12:07:51 INFO DAGScheduler: ResultStage 15 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.265 s
25/04/01 12:07:51 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:07:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/04/01 12:07:51 INFO DAGScheduler: Job 10 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.268821 s
25/04/01 12:07:51 INFO FileFormatWriter: Start to commit write Job a5645592-26f3-4afe-b23f-04f15c5f6f23.
25/04/01 12:07:51 INFO FileFormatWriter: Write Job a5645592-26f3-4afe-b23f-04f15c5f6f23 committed. Elapsed time: 37 ms.
25/04/01 12:07:51 INFO FileFormatWriter: Finished processing stats for write job a5645592-26f3-4afe-b23f-04f15c5f6f23.
25/04/01 12:07:51 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 12:07:51 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:07:51 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:07:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:07:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:07:51 INFO MemoryStore: MemoryStore cleared
25/04/01 12:07:51 INFO BlockManager: BlockManager stopped
25/04/01 12:07:51 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:07:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:07:51 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:07:51 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:07:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-2642022c-62c1-4179-89d8-aa34efa541a5
25/04/01 12:07:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-e1b2f577-4c1b-43f7-bb31-296303570a80
25/04/01 12:07:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-2642022c-62c1-4179-89d8-aa34efa541a5/pyspark-53bedef2-4f22-4947-8aee-88cb108409fa
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:10:14 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:10:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:10:14 INFO ResourceUtils: ==============================================================
25/04/01 12:10:14 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:10:14 INFO ResourceUtils: ==============================================================
25/04/01 12:10:14 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 12:10:14 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:10:14 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:10:14 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:10:14 INFO SecurityManager: Changing view acls to: root
25/04/01 12:10:14 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:10:14 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:10:14 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:10:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:10:14 INFO Utils: Successfully started service 'sparkDriver' on port 35191.
25/04/01 12:10:14 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:10:14 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:10:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:10:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:10:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:10:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2c0565d7-855a-4c76-82e5-1a5df4e710e8
25/04/01 12:10:14 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:10:14 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:10:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:10:14 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:10:14 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:10:14 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 12:10:15 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401121015-0038
25/04/01 12:10:15 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121015-0038/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:10:15 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121015-0038/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:10:15 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121015-0038/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:10:15 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121015-0038/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:10:15 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121015-0038/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:10:15 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121015-0038/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:10:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46427.
25/04/01 12:10:15 INFO NettyBlockTransferService: Server created on 7796893c36d7:46427
25/04/01 12:10:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:10:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 46427, None)
25/04/01 12:10:15 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121015-0038/0 is now RUNNING
25/04/01 12:10:15 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121015-0038/1 is now RUNNING
25/04/01 12:10:15 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:46427 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 46427, None)
25/04/01 12:10:15 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121015-0038/2 is now RUNNING
25/04/01 12:10:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 46427, None)
25/04/01 12:10:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 46427, None)
25/04/01 12:10:15 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:10:15 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:10:15 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:10:16 INFO InMemoryFileIndex: It took 68 ms to list leaf files for 1 paths.
25/04/01 12:10:16 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 5 paths.
25/04/01 12:10:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:49248) with ID 2,  ResourceProfileId 0
25/04/01 12:10:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:60696) with ID 0,  ResourceProfileId 0
25/04/01 12:10:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:38888) with ID 1,  ResourceProfileId 0
25/04/01 12:10:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:34735 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 34735, None)
25/04/01 12:10:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:37973 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 37973, None)
25/04/01 12:10:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:38633 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 38633, None)
25/04/01 12:10:18 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:10:18 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:10:18 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:10:18 INFO CodeGenerator: Code generated in 130.845264 ms
25/04/01 12:10:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 12:10:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:10:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:46427 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:10:18 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:10:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:18 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:10:18 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:10:18 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:18 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:10:18 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:10:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:10:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:46427 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:10:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:10:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:10:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 12:10:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:37973 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:10:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:37973 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:10:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1381 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:10:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:10:20 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.447 s
25/04/01 12:10:20 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:10:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:10:20 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.481242 s
25/04/01 12:10:20 INFO CodeGenerator: Code generated in 10.019957 ms
25/04/01 12:10:20 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:10:20 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:10:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:10:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 12:10:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:10:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:46427 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:20 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:10:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:20 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:10:20 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:10:20 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:10:20 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:10:20 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:10:20 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:10:20 INFO metastore: Connected to metastore.
25/04/01 12:10:20 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ac193654-1e16-4372-8a0d-733eed30ba7a, clientType=HIVECLI]
25/04/01 12:10:20 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:10:20 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:10:20 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:10:20 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:10:20 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:10:20 INFO metastore: Connected to metastore.
25/04/01 12:10:21 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:10:21 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:10:21 INFO metastore: Connected to metastore.
25/04/01 12:10:21 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/04/01 12:10:21 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/01 12:10:21 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/01 12:10:21 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:10:21 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:10:21 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:10:21 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:10:21 INFO CodeGenerator: Code generated in 15.48712 ms
25/04/01 12:10:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 12:10:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 12:10:21 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:46427 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:10:21 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:21 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:46427 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:10:21 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:37973 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:10:21 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:21 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000192 s
25/04/01 12:10:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.0 B, free 365.2 MiB)
25/04/01 12:10:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 120.0 B, free 365.2 MiB)
25/04/01 12:10:21 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:46427 (size: 120.0 B, free: 366.2 MiB)
25/04/01 12:10:21 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:21 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/01 12:10:21 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/01 12:10:21 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:10:21 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:10:21 INFO CodeGenerator: Code generated in 24.096477 ms
25/04/01 12:10:21 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 345.3 KiB, free 364.9 MiB)
25/04/01 12:10:21 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 12:10:21 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:46427 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:21 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:10:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:21 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:10:21 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:10:21 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:21 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:10:21 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:21 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 31.7 KiB, free 364.8 MiB)
25/04/01 12:10:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 364.8 MiB)
25/04/01 12:10:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:46427 (size: 14.9 KiB, free: 366.2 MiB)
25/04/01 12:10:21 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:21 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:10:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks resource profile 0
25/04/01 12:10:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:21 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.8, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:21 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.2, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:21 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:37973 (size: 14.9 KiB, free: 366.3 MiB)
25/04/01 12:10:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:34735 (size: 14.9 KiB, free: 366.3 MiB)
25/04/01 12:10:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:38633 (size: 14.9 KiB, free: 366.3 MiB)
25/04/01 12:10:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:37973 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:22 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 492 ms on 172.18.0.2 (executor 0) (1/5)
25/04/01 12:10:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 499 ms on 172.18.0.2 (executor 0) (2/5)
25/04/01 12:10:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:34735 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:10:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:38633 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:10:23 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1922 ms on 172.18.0.8 (executor 1) (3/5)
25/04/01 12:10:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1982 ms on 172.18.0.6 (executor 2) (4/5)
25/04/01 12:10:23 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 1983 ms on 172.18.0.6 (executor 2) (5/5)
25/04/01 12:10:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:10:23 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.997 s
25/04/01 12:10:23 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:10:23 INFO DAGScheduler: running: Set()
25/04/01 12:10:23 INFO DAGScheduler: waiting: Set()
25/04/01 12:10:23 INFO DAGScheduler: failed: Set()
25/04/01 12:10:23 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:10:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:10:23 INFO CodeGenerator: Code generated in 11.610259 ms
25/04/01 12:10:23 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:10:23 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:10:23 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:10:23 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:23 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 38.8 KiB, free 364.7 MiB)
25/04/01 12:10:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 364.7 MiB)
25/04/01 12:10:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:46427 (size: 18.5 KiB, free: 366.1 MiB)
25/04/01 12:10:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:10:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:10:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:10:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:38633 (size: 18.5 KiB, free: 366.2 MiB)
25/04/01 12:10:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:49248
25/04/01 12:10:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 159 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:10:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:10:23 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.168 s
25/04/01 12:10:23 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:10:23 INFO DAGScheduler: running: Set()
25/04/01 12:10:23 INFO DAGScheduler: waiting: Set()
25/04/01 12:10:23 INFO DAGScheduler: failed: Set()
25/04/01 12:10:23 INFO CodeGenerator: Code generated in 6.423162 ms
25/04/01 12:10:23 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:10:23 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:10:23 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 12:10:23 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:23 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:23 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 12:10:23 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 12:10:23 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:46427 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:10:23 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:10:23 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 12:10:23 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:10:23 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:38633 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:10:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:49248
25/04/01 12:10:24 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 88 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:10:24 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 12:10:24 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.092 s
25/04/01 12:10:24 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:10:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 12:10:24 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.095426 s
25/04/01 12:10:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/01 12:10:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/01 12:10:24 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:10:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:10:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:10:24 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:10:24 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:10:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:10:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:10:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:10:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:10:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:10:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.9 KiB, free 364.4 MiB)
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 364.3 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:46427 (size: 33.5 KiB, free: 366.1 MiB)
25/04/01 12:10:24 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:24 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000137 s
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 24.0 B, free 364.3 MiB)
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.3 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:46427 (size: 120.0 B, free: 366.1 MiB)
25/04/01 12:10:24 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/01 12:10:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/01 12:10:24 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:10:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 345.3 KiB, free 364.0 MiB)
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:46427 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:10:24 INFO SparkContext: Created broadcast 11 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:10:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:24 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:10:24 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:10:24 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:24 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:10:24 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:24 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.7 KiB, free 363.9 MiB)
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 363.9 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:46427 (size: 14.9 KiB, free: 366.1 MiB)
25/04/01 12:10:24 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:24 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:10:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 5 tasks resource profile 0
25/04/01 12:10:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:24 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9) (172.18.0.8, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:24 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 10) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:24 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 11) (172.18.0.6, executor 2, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:24 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 12) (172.18.0.8, executor 1, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:38633 (size: 14.9 KiB, free: 366.2 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:37973 (size: 14.9 KiB, free: 366.2 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:34735 (size: 14.9 KiB, free: 366.2 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:38633 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:37973 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:34735 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:24 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 11) in 86 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:10:24 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 10) in 89 ms on 172.18.0.2 (executor 0) (2/5)
25/04/01 12:10:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 92 ms on 172.18.0.6 (executor 2) (3/5)
25/04/01 12:10:24 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 12) in 114 ms on 172.18.0.8 (executor 1) (4/5)
25/04/01 12:10:24 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 116 ms on 172.18.0.8 (executor 1) (5/5)
25/04/01 12:10:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:10:24 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.121 s
25/04/01 12:10:24 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:10:24 INFO DAGScheduler: running: Set()
25/04/01 12:10:24 INFO DAGScheduler: waiting: Set()
25/04/01 12:10:24 INFO DAGScheduler: failed: Set()
25/04/01 12:10:24 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:10:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:10:24 INFO CodeGenerator: Code generated in 11.322999 ms
25/04/01 12:10:24 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:10:24 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:10:24 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 12:10:24 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:24 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 229.8 KiB, free 363.7 MiB)
25/04/01 12:10:24 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 84.4 KiB, free 363.6 MiB)
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:46427 (size: 84.4 KiB, free: 366.0 MiB)
25/04/01 12:10:24 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:10:24 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 12:10:24 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 13) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:10:24 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:37973 (size: 84.4 KiB, free: 366.1 MiB)
25/04/01 12:10:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:60696
25/04/01 12:10:25 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 13) in 714 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:10:25 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 12:10:25 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.726 s
25/04/01 12:10:25 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:10:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 12:10:25 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.732933 s
25/04/01 12:10:25 INFO FileFormatWriter: Start to commit write Job df3f22f8-bc16-49e1-b5c7-3ab577c184a8.
25/04/01 12:10:25 INFO FileFormatWriter: Write Job df3f22f8-bc16-49e1-b5c7-3ab577c184a8 committed. Elapsed time: 35 ms.
25/04/01 12:10:25 INFO FileFormatWriter: Finished processing stats for write job df3f22f8-bc16-49e1-b5c7-3ab577c184a8.
25/04/01 12:10:25 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 12:10:25 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:10:25 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:10:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:10:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:10:25 INFO MemoryStore: MemoryStore cleared
25/04/01 12:10:25 INFO BlockManager: BlockManager stopped
25/04/01 12:10:25 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:10:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:10:25 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:10:25 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:10:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-c0f9939c-4687-4cfe-9e06-8e256b2e4939/pyspark-c2dd8bfd-bff1-49ff-bbed-5062c2b9cdc7
25/04/01 12:10:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-c2297be8-ea56-4f2f-b5fc-d9d3c21829ed
25/04/01 12:10:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-c0f9939c-4687-4cfe-9e06-8e256b2e4939
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:10:38 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:10:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:10:38 INFO ResourceUtils: ==============================================================
25/04/01 12:10:38 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:10:38 INFO ResourceUtils: ==============================================================
25/04/01 12:10:38 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/01 12:10:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:10:38 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:10:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:10:38 INFO SecurityManager: Changing view acls to: root
25/04/01 12:10:38 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:10:38 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:10:38 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:10:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:10:38 INFO Utils: Successfully started service 'sparkDriver' on port 45745.
25/04/01 12:10:38 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:10:38 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:10:38 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:10:38 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:10:38 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:10:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c941fc99-bfbc-4264-9e1c-d488680d67c6
25/04/01 12:10:38 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:10:38 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:10:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:10:39 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:10:39 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:10:39 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 12:10:39 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401121039-0039
25/04/01 12:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121039-0039/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:10:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121039-0039/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121039-0039/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:10:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121039-0039/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121039-0039/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:10:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121039-0039/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:10:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34567.
25/04/01 12:10:39 INFO NettyBlockTransferService: Server created on 7796893c36d7:34567
25/04/01 12:10:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:10:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 34567, None)
25/04/01 12:10:39 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:34567 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 34567, None)
25/04/01 12:10:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 34567, None)
25/04/01 12:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121039-0039/1 is now RUNNING
25/04/01 12:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121039-0039/0 is now RUNNING
25/04/01 12:10:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 34567, None)
25/04/01 12:10:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121039-0039/2 is now RUNNING
25/04/01 12:10:39 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:10:39 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:10:39 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:10:40 INFO InMemoryFileIndex: It took 71 ms to list leaf files for 1 paths.
25/04/01 12:10:41 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 5 paths.
25/04/01 12:10:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:60248) with ID 2,  ResourceProfileId 0
25/04/01 12:10:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:43104) with ID 0,  ResourceProfileId 0
25/04/01 12:10:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:53542) with ID 1,  ResourceProfileId 0
25/04/01 12:10:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:32851 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 32851, None)
25/04/01 12:10:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:43107 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 43107, None)
25/04/01 12:10:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:35485 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 35485, None)
25/04/01 12:10:42 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:10:42 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:10:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:10:42 INFO CodeGenerator: Code generated in 130.394364 ms
25/04/01 12:10:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/01 12:10:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:10:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:34567 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:10:43 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:10:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:43 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:10:43 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:10:43 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:43 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:10:43 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:43 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:10:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:10:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:34567 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:10:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:10:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:10:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/01 12:10:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:32851 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:10:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:32851 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:10:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1358 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:10:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:10:44 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.426 s
25/04/01 12:10:44 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:10:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:10:44 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.459279 s
25/04/01 12:10:44 INFO CodeGenerator: Code generated in 7.707696 ms
25/04/01 12:10:44 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:10:44 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:10:44 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:10:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/01 12:10:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:10:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:34567 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:44 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:10:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:44 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:10:44 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:10:44 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:10:45 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:10:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:10:45 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:10:45 INFO metastore: Connected to metastore.
25/04/01 12:10:45 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=766c8a32-f2ea-4a42-936a-4502f89701ec, clientType=HIVECLI]
25/04/01 12:10:45 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:10:45 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:10:45 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:10:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:10:45 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:10:45 INFO metastore: Connected to metastore.
25/04/01 12:10:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:10:45 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:10:45 INFO metastore: Connected to metastore.
25/04/01 12:10:45 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 12:10:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/01 12:10:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/01 12:10:45 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:10:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/01 12:10:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/01 12:10:45 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/01 12:10:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:34567 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:10:45 INFO CodeGenerator: Code generated in 17.690357 ms
25/04/01 12:10:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:32851 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:10:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/01 12:10:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/01 12:10:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:34567 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 12:10:45 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:45 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:45 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 12:10:45 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 12:10:45 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:10:45 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:45 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 12:10:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 12:10:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 12:10:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:34567 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 12:10:45 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 12:10:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 12:10:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/01 12:10:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:43107 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 12:10:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:43107 (size: 33.5 KiB, free: 366.3 MiB)
25/04/01 12:10:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1782 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:10:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:10:47 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.788 s
25/04/01 12:10:47 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:10:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 12:10:47 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.790300 s
25/04/01 12:10:47 INFO CodeGenerator: Code generated in 5.722227 ms
25/04/01 12:10:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/01 12:10:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 364.2 MiB)
25/04/01 12:10:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:34567 (size: 4.1 KiB, free: 366.2 MiB)
25/04/01 12:10:47 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 12:10:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/01 12:10:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/01 12:10:47 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/01 12:10:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:10:47 INFO CodeGenerator: Code generated in 24.924035 ms
25/04/01 12:10:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/01 12:10:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/01 12:10:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:34567 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:47 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:10:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:10:47 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:10:47 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 5 output partitions
25/04/01 12:10:47 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:47 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:10:47 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:47 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.8 KiB, free 363.7 MiB)
25/04/01 12:10:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 363.7 MiB)
25/04/01 12:10:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:34567 (size: 19.2 KiB, free: 366.1 MiB)
25/04/01 12:10:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:47 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
25/04/01 12:10:47 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks resource profile 0
25/04/01 12:10:47 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:47 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (172.18.0.2, executor 0, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:47 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4) (172.18.0.8, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:47 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5) (172.18.0.6, executor 2, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:47 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6) (172.18.0.2, executor 0, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/01 12:10:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:43107 (size: 19.2 KiB, free: 366.2 MiB)
25/04/01 12:10:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:32851 (size: 19.2 KiB, free: 366.2 MiB)
25/04/01 12:10:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:35485 (size: 19.2 KiB, free: 366.3 MiB)
25/04/01 12:10:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:43107 (size: 4.1 KiB, free: 366.2 MiB)
25/04/01 12:10:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:32851 (size: 4.1 KiB, free: 366.2 MiB)
25/04/01 12:10:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:32851 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:43107 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:48 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 601 ms on 172.18.0.6 (executor 2) (1/5)
25/04/01 12:10:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 603 ms on 172.18.0.6 (executor 2) (2/5)
25/04/01 12:10:48 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 645 ms on 172.18.0.2 (executor 0) (3/5)
25/04/01 12:10:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 647 ms on 172.18.0.2 (executor 0) (4/5)
25/04/01 12:10:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:35485 (size: 4.1 KiB, free: 366.3 MiB)
25/04/01 12:10:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:35485 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:10:49 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 1859 ms on 172.18.0.8 (executor 1) (5/5)
25/04/01 12:10:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 12:10:49 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 1.873 s
25/04/01 12:10:49 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:10:49 INFO DAGScheduler: running: Set()
25/04/01 12:10:49 INFO DAGScheduler: waiting: Set()
25/04/01 12:10:49 INFO DAGScheduler: failed: Set()
25/04/01 12:10:49 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:10:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:10:49 INFO CodeGenerator: Code generated in 11.438168 ms
25/04/01 12:10:49 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:10:49 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:10:49 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 12:10:49 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:49 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:49 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 45.6 KiB, free 363.7 MiB)
25/04/01 12:10:49 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 363.7 MiB)
25/04/01 12:10:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:34567 (size: 21.5 KiB, free: 366.1 MiB)
25/04/01 12:10:49 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:10:49 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 12:10:49 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 7) (172.18.0.2, executor 0, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:10:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:43107 (size: 21.5 KiB, free: 366.2 MiB)
25/04/01 12:10:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:43104
25/04/01 12:10:49 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 7) in 128 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:10:49 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 12:10:49 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.136 s
25/04/01 12:10:49 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:10:49 INFO DAGScheduler: running: Set()
25/04/01 12:10:49 INFO DAGScheduler: waiting: Set()
25/04/01 12:10:49 INFO DAGScheduler: failed: Set()
25/04/01 12:10:49 INFO CodeGenerator: Code generated in 6.5787 ms
25/04/01 12:10:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:10:49 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:10:49 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:10:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 12:10:49 INFO DAGScheduler: Missing parents: List()
25/04/01 12:10:49 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:10:49 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 12:10:49 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.6 MiB)
25/04/01 12:10:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:34567 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:10:49 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:10:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:10:49 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 12:10:49 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:10:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:43107 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:10:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:43104
25/04/01 12:10:49 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 35 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:10:49 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:10:49 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.039 s
25/04/01 12:10:49 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:10:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 12:10:49 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.043146 s
25/04/01 12:10:49 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:10:49 INFO MemoryStore: MemoryStore cleared
25/04/01 12:10:49 INFO BlockManager: BlockManager stopped
25/04/01 12:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:10:49 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:10:50 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:10:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-23e24fb8-d769-44a6-9cb8-0630862730f2/pyspark-83a21551-2b63-47e9-8d78-4b4d48fce7ec
25/04/01 12:10:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-ea2968d7-bb3b-4fc0-b874-85c607873c18
25/04/01 12:10:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-23e24fb8-d769-44a6-9cb8-0630862730f2
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/02 08:16:50 INFO SparkContext: Running Spark version 3.2.2
25/04/02 08:16:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/02 08:16:50 INFO ResourceUtils: ==============================================================
25/04/02 08:16:50 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/02 08:16:50 INFO ResourceUtils: ==============================================================
25/04/02 08:16:50 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/02 08:16:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/02 08:16:50 INFO ResourceProfile: Limiting resource is cpu
25/04/02 08:16:50 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/02 08:16:50 INFO SecurityManager: Changing view acls to: root
25/04/02 08:16:50 INFO SecurityManager: Changing modify acls to: root
25/04/02 08:16:50 INFO SecurityManager: Changing view acls groups to: 
25/04/02 08:16:50 INFO SecurityManager: Changing modify acls groups to: 
25/04/02 08:16:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/02 08:16:51 INFO Utils: Successfully started service 'sparkDriver' on port 36773.
25/04/02 08:16:51 INFO SparkEnv: Registering MapOutputTracker
25/04/02 08:16:51 INFO SparkEnv: Registering BlockManagerMaster
25/04/02 08:16:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/02 08:16:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/02 08:16:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/02 08:16:51 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c4fcacd0-7621-4c07-be28-3c926c3396a4
25/04/02 08:16:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/02 08:16:51 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/02 08:16:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/02 08:16:51 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/02 08:16:51 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/02 08:16:51 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 24 ms (0 ms spent in bootstraps)
25/04/02 08:16:51 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250402081651-0059
25/04/02 08:16:51 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250402081651-0059/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/02 08:16:51 INFO StandaloneSchedulerBackend: Granted executor ID app-20250402081651-0059/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/02 08:16:51 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250402081651-0059/1 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/02 08:16:51 INFO StandaloneSchedulerBackend: Granted executor ID app-20250402081651-0059/1 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/02 08:16:51 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250402081651-0059/2 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/02 08:16:51 INFO StandaloneSchedulerBackend: Granted executor ID app-20250402081651-0059/2 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/02 08:16:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35373.
25/04/02 08:16:51 INFO NettyBlockTransferService: Server created on 7796893c36d7:35373
25/04/02 08:16:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/02 08:16:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 35373, None)
25/04/02 08:16:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250402081651-0059/2 is now RUNNING
25/04/02 08:16:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250402081651-0059/1 is now RUNNING
25/04/02 08:16:51 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:35373 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 35373, None)
25/04/02 08:16:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250402081651-0059/0 is now RUNNING
25/04/02 08:16:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 35373, None)
25/04/02 08:16:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 35373, None)
25/04/02 08:16:51 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/02 08:16:52 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/02 08:16:52 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/02 08:16:53 INFO InMemoryFileIndex: It took 71 ms to list leaf files for 1 paths.
25/04/02 08:16:53 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 6 paths.
25/04/02 08:16:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:47232) with ID 0,  ResourceProfileId 0
25/04/02 08:16:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:53938) with ID 2,  ResourceProfileId 0
25/04/02 08:16:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:35810) with ID 1,  ResourceProfileId 0
25/04/02 08:16:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:43905 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.8, 43905, None)
25/04/02 08:16:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:46279 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 46279, None)
25/04/02 08:16:53 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:36219 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.6, 36219, None)
25/04/02 08:16:55 INFO FileSourceStrategy: Pushed Filters: 
25/04/02 08:16:55 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/02 08:16:55 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/02 08:16:55 INFO CodeGenerator: Code generated in 146.926069 ms
25/04/02 08:16:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/02 08:16:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/02 08:16:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:35373 (size: 32.6 KiB, free: 366.3 MiB)
25/04/02 08:16:55 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/02 08:16:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:16:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/02 08:16:55 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:16:55 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/02 08:16:55 INFO DAGScheduler: Parents of final stage: List()
25/04/02 08:16:55 INFO DAGScheduler: Missing parents: List()
25/04/02 08:16:55 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:16:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/02 08:16:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/02 08:16:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:35373 (size: 5.8 KiB, free: 366.3 MiB)
25/04/02 08:16:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/02 08:16:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:16:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/02 08:16:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 1, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/02 08:16:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:36219 (size: 5.8 KiB, free: 366.3 MiB)
25/04/02 08:16:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:36219 (size: 32.6 KiB, free: 366.3 MiB)
25/04/02 08:16:57 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1387 ms on 172.18.0.6 (executor 1) (1/1)
25/04/02 08:16:57 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/02 08:16:57 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.465 s
25/04/02 08:16:57 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/02 08:16:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/02 08:16:57 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.506894 s
25/04/02 08:16:57 INFO CodeGenerator: Code generated in 7.751687 ms
25/04/02 08:16:57 INFO FileSourceStrategy: Pushed Filters: 
25/04/02 08:16:57 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/02 08:16:57 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/02 08:16:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/02 08:16:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/02 08:16:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:35373 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:16:57 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/02 08:16:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:16:57 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/02 08:16:57 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/02 08:16:57 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/02 08:16:57 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/02 08:16:57 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/02 08:16:57 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/02 08:16:57 INFO metastore: Connected to metastore.
25/04/02 08:16:58 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=2f6f050e-426f-4f35-8f86-ab5e66f744c4, clientType=HIVECLI]
25/04/02 08:16:58 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/02 08:16:58 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/02 08:16:58 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/02 08:16:58 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/02 08:16:58 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/02 08:16:58 INFO metastore: Connected to metastore.
25/04/02 08:16:58 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/02 08:16:58 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/02 08:16:58 INFO metastore: Connected to metastore.
25/04/02 08:16:58 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/04/02 08:16:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/02 08:16:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/02 08:16:58 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/02 08:16:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/02 08:16:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/02 08:16:58 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/02 08:16:58 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:35373 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/02 08:16:58 INFO CodeGenerator: Code generated in 22.001887 ms
25/04/02 08:16:58 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:36219 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/02 08:16:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/02 08:16:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/02 08:16:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:35373 (size: 33.5 KiB, free: 366.2 MiB)
25/04/02 08:16:58 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/02 08:16:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:16:58 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/02 08:16:58 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/02 08:16:58 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/02 08:16:58 INFO DAGScheduler: Parents of final stage: List()
25/04/02 08:16:58 INFO DAGScheduler: Missing parents: List()
25/04/02 08:16:58 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/02 08:16:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/02 08:16:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/02 08:16:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:35373 (size: 6.0 KiB, free: 366.2 MiB)
25/04/02 08:16:58 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/02 08:16:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/02 08:16:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/02 08:16:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 2, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/02 08:16:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:43905 (size: 6.0 KiB, free: 366.3 MiB)
25/04/02 08:16:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:43905 (size: 33.5 KiB, free: 366.3 MiB)
25/04/02 08:17:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1893 ms on 172.18.0.8 (executor 2) (1/1)
25/04/02 08:17:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/02 08:17:00 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.897 s
25/04/02 08:17:00 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/02 08:17:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/02 08:17:00 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.900368 s
25/04/02 08:17:00 INFO CodeGenerator: Code generated in 5.862812 ms
25/04/02 08:17:00 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/02 08:17:00 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 364.2 MiB)
25/04/02 08:17:00 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:35373 (size: 4.1 KiB, free: 366.2 MiB)
25/04/02 08:17:00 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/02 08:17:00 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/02 08:17:00 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/02 08:17:00 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/02 08:17:00 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/02 08:17:00 INFO CodeGenerator: Code generated in 26.454241 ms
25/04/02 08:17:00 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/02 08:17:00 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/02 08:17:00 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:35373 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:17:00 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/02 08:17:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:17:00 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/02 08:17:00 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 6 output partitions
25/04/02 08:17:00 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:00 INFO DAGScheduler: Parents of final stage: List()
25/04/02 08:17:00 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:00 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:00 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.8 KiB, free 363.7 MiB)
25/04/02 08:17:00 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 363.7 MiB)
25/04/02 08:17:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:35373 (size: 19.2 KiB, free: 366.1 MiB)
25/04/02 08:17:00 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:00 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
25/04/02 08:17:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 6 tasks resource profile 0
25/04/02 08:17:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.2, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:00 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (172.18.0.8, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:00 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4) (172.18.0.6, executor 1, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:00 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5) (172.18.0.2, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:00 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6) (172.18.0.8, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:00 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7) (172.18.0.6, executor 1, partition 5, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:43905 (size: 19.2 KiB, free: 366.2 MiB)
25/04/02 08:17:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:36219 (size: 19.2 KiB, free: 366.2 MiB)
25/04/02 08:17:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:46279 (size: 19.2 KiB, free: 366.3 MiB)
25/04/02 08:17:00 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:43905 (size: 4.1 KiB, free: 366.2 MiB)
25/04/02 08:17:00 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:36219 (size: 4.1 KiB, free: 366.2 MiB)
25/04/02 08:17:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:36219 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:17:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:43905 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:17:01 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 583 ms on 172.18.0.6 (executor 1) (1/6)
25/04/02 08:17:01 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 582 ms on 172.18.0.6 (executor 1) (2/6)
25/04/02 08:17:01 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 652 ms on 172.18.0.8 (executor 2) (3/6)
25/04/02 08:17:01 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 686 ms on 172.18.0.8 (executor 2) (4/6)
25/04/02 08:17:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:46279 (size: 4.1 KiB, free: 366.3 MiB)
25/04/02 08:17:01 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:46279 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:17:02 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 1919 ms on 172.18.0.2 (executor 0) (5/6)
25/04/02 08:17:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1920 ms on 172.18.0.2 (executor 0) (6/6)
25/04/02 08:17:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/02 08:17:02 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 1.932 s
25/04/02 08:17:02 INFO DAGScheduler: looking for newly runnable stages
25/04/02 08:17:02 INFO DAGScheduler: running: Set()
25/04/02 08:17:02 INFO DAGScheduler: waiting: Set()
25/04/02 08:17:02 INFO DAGScheduler: failed: Set()
25/04/02 08:17:02 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/02 08:17:02 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/02 08:17:02 INFO CodeGenerator: Code generated in 10.746161 ms
25/04/02 08:17:02 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/02 08:17:02 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:02 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/02 08:17:02 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:02 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:02 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 45.6 KiB, free 363.7 MiB)
25/04/02 08:17:02 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 363.7 MiB)
25/04/02 08:17:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:35373 (size: 21.5 KiB, free: 366.1 MiB)
25/04/02 08:17:02 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/02 08:17:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8) (172.18.0.8, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/02 08:17:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:43905 (size: 21.5 KiB, free: 366.2 MiB)
25/04/02 08:17:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:53938
25/04/02 08:17:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 126 ms on 172.18.0.8 (executor 2) (1/1)
25/04/02 08:17:02 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/02 08:17:02 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.134 s
25/04/02 08:17:02 INFO DAGScheduler: looking for newly runnable stages
25/04/02 08:17:02 INFO DAGScheduler: running: Set()
25/04/02 08:17:02 INFO DAGScheduler: waiting: Set()
25/04/02 08:17:02 INFO DAGScheduler: failed: Set()
25/04/02 08:17:02 INFO CodeGenerator: Code generated in 6.471624 ms
25/04/02 08:17:02 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/02 08:17:02 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:02 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/02 08:17:02 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:02 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:02 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/02 08:17:02 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.6 MiB)
25/04/02 08:17:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:35373 (size: 5.5 KiB, free: 366.1 MiB)
25/04/02 08:17:02 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:02 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/02 08:17:02 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 9) (172.18.0.8, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/02 08:17:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:43905 (size: 5.5 KiB, free: 366.2 MiB)
25/04/02 08:17:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:53938
25/04/02 08:17:02 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 9) in 28 ms on 172.18.0.8 (executor 2) (1/1)
25/04/02 08:17:02 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/02 08:17:02 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s
25/04/02 08:17:02 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/02 08:17:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/02 08:17:02 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.036289 s
25/04/02 08:17:02 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/02 08:17:02 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/02 08:17:02 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/02 08:17:02 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/02 08:17:02 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/02 08:17:02 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/02 08:17:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/02 08:17:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/02 08:17:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/02 08:17:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/02 08:17:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/02 08:17:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/02 08:17:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/02 08:17:02 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/02 08:17:02 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/02 08:17:02 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:35373 (size: 33.5 KiB, free: 366.1 MiB)
25/04/02 08:17:02 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/02 08:17:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:17:02 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/02 08:17:02 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/02 08:17:02 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/02 08:17:02 INFO DAGScheduler: Parents of final stage: List()
25/04/02 08:17:02 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:02 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/02 08:17:02 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/02 08:17:02 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/02 08:17:02 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:35373 (size: 6.0 KiB, free: 366.1 MiB)
25/04/02 08:17:02 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:02 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/02 08:17:02 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10) (172.18.0.2, executor 0, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/02 08:17:02 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:46279 (size: 6.0 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:46279 (size: 33.5 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 621 ms on 172.18.0.2 (executor 0) (1/1)
25/04/02 08:17:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/02 08:17:03 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.626 s
25/04/02 08:17:03 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/02 08:17:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/02 08:17:03 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.628355 s
25/04/02 08:17:03 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1032.0 KiB, free 362.2 MiB)
25/04/02 08:17:03 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 362.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:35373 (size: 4.1 KiB, free: 366.1 MiB)
25/04/02 08:17:03 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/02 08:17:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/02 08:17:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/02 08:17:03 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/02 08:17:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/02 08:17:03 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/02 08:17:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:35373 (size: 32.6 KiB, free: 366.0 MiB)
25/04/02 08:17:03 INFO SparkContext: Created broadcast 13 from insertInto at NativeMethodAccessorImpl.java:0
25/04/02 08:17:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:17:03 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/02 08:17:03 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 6 output partitions
25/04/02 08:17:03 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:03 INFO DAGScheduler: Parents of final stage: List()
25/04/02 08:17:03 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:03 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:03 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 40.8 KiB, free 361.8 MiB)
25/04/02 08:17:03 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 361.8 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:35373 (size: 19.2 KiB, free: 366.0 MiB)
25/04/02 08:17:03 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:03 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
25/04/02 08:17:03 INFO TaskSchedulerImpl: Adding task set 9.0 with 6 tasks resource profile 0
25/04/02 08:17:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 11) (172.18.0.6, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:03 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 12) (172.18.0.8, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:03 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 13) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:03 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 14) (172.18.0.6, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:03 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 15) (172.18.0.8, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:03 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 16) (172.18.0.2, executor 0, partition 5, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:43905 (size: 19.2 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:36219 (size: 19.2 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:46279 (size: 19.2 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:43905 (size: 4.1 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:46279 (size: 4.1 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:36219 (size: 4.1 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:43905 (size: 32.6 KiB, free: 366.1 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:46279 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:36219 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:17:03 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 15) in 93 ms on 172.18.0.8 (executor 2) (1/6)
25/04/02 08:17:03 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 16) in 98 ms on 172.18.0.2 (executor 0) (2/6)
25/04/02 08:17:03 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 13) in 101 ms on 172.18.0.2 (executor 0) (3/6)
25/04/02 08:17:03 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 11) in 105 ms on 172.18.0.6 (executor 1) (4/6)
25/04/02 08:17:03 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 14) in 107 ms on 172.18.0.6 (executor 1) (5/6)
25/04/02 08:17:03 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 12) in 116 ms on 172.18.0.8 (executor 2) (6/6)
25/04/02 08:17:03 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/02 08:17:03 INFO DAGScheduler: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.121 s
25/04/02 08:17:03 INFO DAGScheduler: looking for newly runnable stages
25/04/02 08:17:03 INFO DAGScheduler: running: Set()
25/04/02 08:17:03 INFO DAGScheduler: waiting: Set()
25/04/02 08:17:03 INFO DAGScheduler: failed: Set()
25/04/02 08:17:03 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/02 08:17:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/02 08:17:03 INFO CodeGenerator: Code generated in 21.657077 ms
25/04/02 08:17:03 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/02 08:17:03 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:03 INFO DAGScheduler: Final stage: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/02 08:17:03 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:03 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:03 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 236.4 KiB, free 361.6 MiB)
25/04/02 08:17:03 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 87.9 KiB, free 361.5 MiB)
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:35373 (size: 87.9 KiB, free: 365.9 MiB)
25/04/02 08:17:03 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:03 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/02 08:17:03 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 17) (172.18.0.8, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/02 08:17:03 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:43905 (size: 87.9 KiB, free: 366.0 MiB)
25/04/02 08:17:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:53938
25/04/02 08:17:04 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 17) in 245 ms on 172.18.0.8 (executor 2) (1/1)
25/04/02 08:17:04 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/02 08:17:04 INFO DAGScheduler: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.261 s
25/04/02 08:17:04 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/02 08:17:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/02 08:17:04 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.266177 s
25/04/02 08:17:04 INFO FileFormatWriter: Start to commit write Job b8d72471-c29b-45bc-bc15-7278d6b6c9d7.
25/04/02 08:17:04 INFO FileFormatWriter: Write Job b8d72471-c29b-45bc-bc15-7278d6b6c9d7 committed. Elapsed time: 36 ms.
25/04/02 08:17:04 INFO FileFormatWriter: Finished processing stats for write job b8d72471-c29b-45bc-bc15-7278d6b6c9d7.
25/04/02 08:17:04 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/02 08:17:04 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/02 08:17:04 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/02 08:17:04 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/02 08:17:04 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/02 08:17:04 INFO MemoryStore: MemoryStore cleared
25/04/02 08:17:04 INFO BlockManager: BlockManager stopped
25/04/02 08:17:04 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/02 08:17:04 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/02 08:17:04 INFO SparkContext: Successfully stopped SparkContext
25/04/02 08:17:04 INFO ShutdownHookManager: Shutdown hook called
25/04/02 08:17:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-6af44f27-6f51-4d2d-ac19-cf9a5e095dce/pyspark-d4b82867-8469-4628-b1bd-3006d7075405
25/04/02 08:17:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-c28fa0f1-0315-4d42-aa96-d19d1554b9c7
25/04/02 08:17:04 INFO ShutdownHookManager: Deleting directory /tmp/spark-6af44f27-6f51-4d2d-ac19-cf9a5e095dce
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/03 08:48:45 INFO SparkContext: Running Spark version 3.2.2
25/04/03 08:48:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/03 08:48:45 INFO ResourceUtils: ==============================================================
25/04/03 08:48:45 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/03 08:48:45 INFO ResourceUtils: ==============================================================
25/04/03 08:48:45 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/03 08:48:45 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/03 08:48:45 INFO ResourceProfile: Limiting resource is cpu
25/04/03 08:48:45 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/03 08:48:45 INFO SecurityManager: Changing view acls to: root
25/04/03 08:48:45 INFO SecurityManager: Changing modify acls to: root
25/04/03 08:48:45 INFO SecurityManager: Changing view acls groups to: 
25/04/03 08:48:45 INFO SecurityManager: Changing modify acls groups to: 
25/04/03 08:48:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/03 08:48:45 INFO Utils: Successfully started service 'sparkDriver' on port 42891.
25/04/03 08:48:45 INFO SparkEnv: Registering MapOutputTracker
25/04/03 08:48:45 INFO SparkEnv: Registering BlockManagerMaster
25/04/03 08:48:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/03 08:48:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/03 08:48:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/03 08:48:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f1f374f3-31c1-474f-9506-2922719046fa
25/04/03 08:48:45 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/03 08:48:45 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/03 08:48:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/03 08:48:45 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/03 08:48:45 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4041
25/04/03 08:48:46 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/03 08:48:46 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 28 ms (0 ms spent in bootstraps)
25/04/03 08:48:46 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250403084846-0066
25/04/03 08:48:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46317.
25/04/03 08:48:46 INFO NettyBlockTransferService: Server created on 7796893c36d7:46317
25/04/03 08:48:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/03 08:48:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 46317, None)
25/04/03 08:48:46 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:46317 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 46317, None)
25/04/03 08:48:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 46317, None)
25/04/03 08:48:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 46317, None)
25/04/03 08:48:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/03 08:48:46 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/03 08:48:46 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/03 08:48:48 INFO InMemoryFileIndex: It took 74 ms to list leaf files for 1 paths.
25/04/03 08:48:48 INFO InMemoryFileIndex: It took 17 ms to list leaf files for 7 paths.
25/04/03 08:48:50 INFO FileSourceStrategy: Pushed Filters: 
25/04/03 08:48:50 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/03 08:48:50 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/03 08:48:50 INFO CodeGenerator: Code generated in 178.820525 ms
25/04/03 08:48:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/03 08:48:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/03 08:48:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:46317 (size: 32.6 KiB, free: 366.3 MiB)
25/04/03 08:48:50 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/03 08:48:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14681829 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:48:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/03 08:48:50 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:48:50 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/03 08:48:50 INFO DAGScheduler: Parents of final stage: List()
25/04/03 08:48:50 INFO DAGScheduler: Missing parents: List()
25/04/03 08:48:50 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:48:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/03 08:48:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/03 08:48:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:46317 (size: 5.8 KiB, free: 366.3 MiB)
25/04/03 08:48:50 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/03 08:48:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:48:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/03 08:49:05 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
25/04/03 08:49:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250403084846-0066/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/03 08:49:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250403084846-0066/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/03 08:49:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250403084846-0066/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/03 08:49:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250403084846-0066/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/03 08:49:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250403084846-0066/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/03 08:49:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250403084846-0066/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/03 08:49:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250403084846-0066/1 is now RUNNING
25/04/03 08:49:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250403084846-0066/2 is now RUNNING
25/04/03 08:49:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250403084846-0066/0 is now RUNNING
25/04/03 08:49:08 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:49604) with ID 2,  ResourceProfileId 0
25/04/03 08:49:08 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:39990) with ID 1,  ResourceProfileId 0
25/04/03 08:49:08 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:47246) with ID 0,  ResourceProfileId 0
25/04/03 08:49:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:45397 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 45397, None)
25/04/03 08:49:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:38913 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 38913, None)
25/04/03 08:49:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:41417 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 41417, None)
25/04/03 08:49:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 5195 bytes) taskResourceAssignments Map()
25/04/03 08:49:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:45397 (size: 5.8 KiB, free: 366.3 MiB)
25/04/03 08:49:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:45397 (size: 32.6 KiB, free: 366.3 MiB)
25/04/03 08:49:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1603 ms on 172.18.0.6 (executor 2) (1/1)
25/04/03 08:49:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/03 08:49:12 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 21.812 s
25/04/03 08:49:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/03 08:49:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/03 08:49:12 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 19.774883 s
25/04/03 08:49:12 INFO CodeGenerator: Code generated in 9.610895 ms
25/04/03 08:49:12 INFO FileSourceStrategy: Pushed Filters: 
25/04/03 08:49:12 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/03 08:49:12 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/03 08:49:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/03 08:49:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/03 08:49:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:46317 (size: 32.6 KiB, free: 366.2 MiB)
25/04/03 08:49:12 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/03 08:49:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:12 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/03 08:49:12 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/03 08:49:12 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/03 08:49:13 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/03 08:49:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/03 08:49:13 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/03 08:49:13 INFO metastore: Connected to metastore.
25/04/03 08:49:13 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=b84014fd-3817-44d1-a03e-5dce9b0a512d, clientType=HIVECLI]
25/04/03 08:49:13 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/03 08:49:13 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/03 08:49:13 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/03 08:49:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/03 08:49:13 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/03 08:49:13 INFO metastore: Connected to metastore.
25/04/03 08:49:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/03 08:49:13 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/03 08:49:13 INFO metastore: Connected to metastore.
25/04/03 08:49:13 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/03 08:49:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:46317 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/03 08:49:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:45397 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/03 08:49:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/03 08:49:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/03 08:49:13 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/03 08:49:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/03 08:49:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/03 08:49:13 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/03 08:49:13 INFO CodeGenerator: Code generated in 16.830693 ms
25/04/03 08:49:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/03 08:49:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/03 08:49:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:46317 (size: 33.5 KiB, free: 366.2 MiB)
25/04/03 08:49:13 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/03 08:49:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/03 08:49:13 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 2 output partitions
25/04/03 08:49:13 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/03 08:49:13 INFO DAGScheduler: Parents of final stage: List()
25/04/03 08:49:13 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:13 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/03 08:49:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/03 08:49:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/03 08:49:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:46317 (size: 6.0 KiB, free: 366.2 MiB)
25/04/03 08:49:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:13 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1))
25/04/03 08:49:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0
25/04/03 08:49:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/03 08:49:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.2, executor 0, partition 1, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/03 08:49:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:38913 (size: 6.0 KiB, free: 366.3 MiB)
25/04/03 08:49:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:41417 (size: 6.0 KiB, free: 366.3 MiB)
25/04/03 08:49:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:38913 (size: 33.5 KiB, free: 366.3 MiB)
25/04/03 08:49:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:41417 (size: 33.5 KiB, free: 366.3 MiB)
25/04/03 08:49:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2339 ms on 172.18.0.8 (executor 1) (1/2)
25/04/03 08:49:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 2341 ms on 172.18.0.2 (executor 0) (2/2)
25/04/03 08:49:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/03 08:49:16 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.347 s
25/04/03 08:49:16 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/03 08:49:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/03 08:49:16 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.350907 s
25/04/03 08:49:16 INFO CodeGenerator: Code generated in 6.575059 ms
25/04/03 08:49:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/03 08:49:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 364.2 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:46317 (size: 4.9 KiB, free: 366.2 MiB)
25/04/03 08:49:16 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/03 08:49:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/03 08:49:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/03 08:49:16 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/03 08:49:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/03 08:49:16 INFO CodeGenerator: Code generated in 25.274045 ms
25/04/03 08:49:16 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/03 08:49:16 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:46317 (size: 32.6 KiB, free: 366.2 MiB)
25/04/03 08:49:16 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/03 08:49:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:16 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/03 08:49:16 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions
25/04/03 08:49:16 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:16 INFO DAGScheduler: Parents of final stage: List()
25/04/03 08:49:16 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:16 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.8 KiB, free 363.7 MiB)
25/04/03 08:49:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 363.7 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:46317 (size: 19.2 KiB, free: 366.1 MiB)
25/04/03 08:49:16 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:16 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
25/04/03 08:49:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 7 tasks resource profile 0
25/04/03 08:49:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3) (172.18.0.8, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:16 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:16 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 5) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:16 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 6) (172.18.0.8, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:16 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 7) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:16 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 8) (172.18.0.2, executor 0, partition 5, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:16 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 9) (172.18.0.8, executor 1, partition 6, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:41417 (size: 19.2 KiB, free: 366.2 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:45397 (size: 19.2 KiB, free: 366.2 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:38913 (size: 19.2 KiB, free: 366.2 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:38913 (size: 4.9 KiB, free: 366.2 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:45397 (size: 4.9 KiB, free: 366.2 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:41417 (size: 4.9 KiB, free: 366.2 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:45397 (size: 32.6 KiB, free: 366.2 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:38913 (size: 32.6 KiB, free: 366.2 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:41417 (size: 32.6 KiB, free: 366.2 MiB)
25/04/03 08:49:17 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 7) in 648 ms on 172.18.0.6 (executor 2) (1/7)
25/04/03 08:49:17 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 4) in 648 ms on 172.18.0.6 (executor 2) (2/7)
25/04/03 08:49:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 699 ms on 172.18.0.8 (executor 1) (3/7)
25/04/03 08:49:17 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 6) in 699 ms on 172.18.0.8 (executor 1) (4/7)
25/04/03 08:49:17 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 8) in 720 ms on 172.18.0.2 (executor 0) (5/7)
25/04/03 08:49:17 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 5) in 722 ms on 172.18.0.2 (executor 0) (6/7)
25/04/03 08:49:17 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 9) in 723 ms on 172.18.0.8 (executor 1) (7/7)
25/04/03 08:49:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/03 08:49:17 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.739 s
25/04/03 08:49:17 INFO DAGScheduler: looking for newly runnable stages
25/04/03 08:49:17 INFO DAGScheduler: running: Set()
25/04/03 08:49:17 INFO DAGScheduler: waiting: Set()
25/04/03 08:49:17 INFO DAGScheduler: failed: Set()
25/04/03 08:49:17 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/03 08:49:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/03 08:49:17 INFO CodeGenerator: Code generated in 12.210455 ms
25/04/03 08:49:17 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/03 08:49:17 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:17 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/03 08:49:17 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:17 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 45.6 KiB, free 363.7 MiB)
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 363.7 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:46317 (size: 21.5 KiB, free: 366.1 MiB)
25/04/03 08:49:17 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:17 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/03 08:49:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:38913 (size: 21.5 KiB, free: 366.2 MiB)
25/04/03 08:49:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:39990
25/04/03 08:49:17 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 126 ms on 172.18.0.8 (executor 1) (1/1)
25/04/03 08:49:17 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/03 08:49:17 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.135 s
25/04/03 08:49:17 INFO DAGScheduler: looking for newly runnable stages
25/04/03 08:49:17 INFO DAGScheduler: running: Set()
25/04/03 08:49:17 INFO DAGScheduler: waiting: Set()
25/04/03 08:49:17 INFO DAGScheduler: failed: Set()
25/04/03 08:49:17 INFO CodeGenerator: Code generated in 6.686031 ms
25/04/03 08:49:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/03 08:49:17 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:17 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/03 08:49:17 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:17 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.6 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:46317 (size: 5.5 KiB, free: 366.1 MiB)
25/04/03 08:49:17 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:17 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/03 08:49:17 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 11) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:38913 (size: 5.5 KiB, free: 366.2 MiB)
25/04/03 08:49:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:39990
25/04/03 08:49:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 11) in 29 ms on 172.18.0.8 (executor 1) (1/1)
25/04/03 08:49:17 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/03 08:49:17 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.036 s
25/04/03 08:49:17 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/03 08:49:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/03 08:49:17 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.038446 s
25/04/03 08:49:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/03 08:49:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/03 08:49:17 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/03 08:49:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/03 08:49:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/03 08:49:17 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/03 08:49:17 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/03 08:49:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/03 08:49:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/03 08:49:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/03 08:49:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/03 08:49:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/03 08:49:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:46317 (size: 33.5 KiB, free: 366.1 MiB)
25/04/03 08:49:17 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/03 08:49:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/03 08:49:17 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 2 output partitions
25/04/03 08:49:17 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/03 08:49:17 INFO DAGScheduler: Parents of final stage: List()
25/04/03 08:49:17 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:17 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:46317 (size: 6.0 KiB, free: 366.1 MiB)
25/04/03 08:49:17 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1))
25/04/03 08:49:17 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks resource profile 0
25/04/03 08:49:17 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 12) (172.18.0.6, executor 2, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/03 08:49:17 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 13) (172.18.0.8, executor 1, partition 1, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:38913 (size: 6.0 KiB, free: 366.2 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:45397 (size: 6.0 KiB, free: 366.2 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:38913 (size: 33.5 KiB, free: 366.1 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:45397 (size: 33.5 KiB, free: 366.2 MiB)
25/04/03 08:49:17 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 13) in 56 ms on 172.18.0.8 (executor 1) (1/2)
25/04/03 08:49:18 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 12) in 588 ms on 172.18.0.6 (executor 2) (2/2)
25/04/03 08:49:18 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/03 08:49:18 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.592 s
25/04/03 08:49:18 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/03 08:49:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/03 08:49:18 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.594192 s
25/04/03 08:49:18 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1032.0 KiB, free 362.2 MiB)
25/04/03 08:49:18 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 362.2 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:46317 (size: 4.9 KiB, free: 366.1 MiB)
25/04/03 08:49:18 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/03 08:49:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/03 08:49:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/03 08:49:18 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/03 08:49:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/03 08:49:18 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/03 08:49:18 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:46317 (size: 32.6 KiB, free: 366.0 MiB)
25/04/03 08:49:18 INFO SparkContext: Created broadcast 13 from insertInto at NativeMethodAccessorImpl.java:0
25/04/03 08:49:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:18 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/03 08:49:18 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 7 output partitions
25/04/03 08:49:18 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:18 INFO DAGScheduler: Parents of final stage: List()
25/04/03 08:49:18 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:18 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:18 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 40.8 KiB, free 361.8 MiB)
25/04/03 08:49:18 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 361.8 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:46317 (size: 19.2 KiB, free: 366.0 MiB)
25/04/03 08:49:18 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:18 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
25/04/03 08:49:18 INFO TaskSchedulerImpl: Adding task set 9.0 with 7 tasks resource profile 0
25/04/03 08:49:18 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 14) (172.18.0.8, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:18 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 15) (172.18.0.6, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:18 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 16) (172.18.0.2, executor 0, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:18 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 17) (172.18.0.8, executor 1, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:18 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 18) (172.18.0.6, executor 2, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:18 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 19) (172.18.0.2, executor 0, partition 5, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:18 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 20) (172.18.0.8, executor 1, partition 6, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:38913 (size: 19.2 KiB, free: 366.1 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:45397 (size: 19.2 KiB, free: 366.2 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:41417 (size: 19.2 KiB, free: 366.2 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:38913 (size: 4.9 KiB, free: 366.1 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:45397 (size: 4.9 KiB, free: 366.2 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:41417 (size: 4.9 KiB, free: 366.2 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:38913 (size: 32.6 KiB, free: 366.1 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:45397 (size: 32.6 KiB, free: 366.1 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:41417 (size: 32.6 KiB, free: 366.2 MiB)
25/04/03 08:49:18 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 18) in 111 ms on 172.18.0.6 (executor 2) (1/7)
25/04/03 08:49:18 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 15) in 116 ms on 172.18.0.6 (executor 2) (2/7)
25/04/03 08:49:18 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 19) in 123 ms on 172.18.0.2 (executor 0) (3/7)
25/04/03 08:49:18 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 16) in 124 ms on 172.18.0.2 (executor 0) (4/7)
25/04/03 08:49:18 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 14) in 141 ms on 172.18.0.8 (executor 1) (5/7)
25/04/03 08:49:18 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 17) in 152 ms on 172.18.0.8 (executor 1) (6/7)
25/04/03 08:49:18 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 20) in 161 ms on 172.18.0.8 (executor 1) (7/7)
25/04/03 08:49:18 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/03 08:49:18 INFO DAGScheduler: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.168 s
25/04/03 08:49:18 INFO DAGScheduler: looking for newly runnable stages
25/04/03 08:49:18 INFO DAGScheduler: running: Set()
25/04/03 08:49:18 INFO DAGScheduler: waiting: Set()
25/04/03 08:49:18 INFO DAGScheduler: failed: Set()
25/04/03 08:49:18 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/03 08:49:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/03 08:49:18 INFO CodeGenerator: Code generated in 18.467963 ms
25/04/03 08:49:18 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/03 08:49:18 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:18 INFO DAGScheduler: Final stage: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/03 08:49:18 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:18 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:18 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 236.4 KiB, free 361.6 MiB)
25/04/03 08:49:18 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 87.9 KiB, free 361.5 MiB)
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:46317 (size: 87.9 KiB, free: 365.9 MiB)
25/04/03 08:49:18 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:18 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/03 08:49:18 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 21) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/03 08:49:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:38913 (size: 87.9 KiB, free: 366.0 MiB)
25/04/03 08:49:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:39990
25/04/03 08:49:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 21) in 263 ms on 172.18.0.8 (executor 1) (1/1)
25/04/03 08:49:18 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/03 08:49:18 INFO DAGScheduler: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.282 s
25/04/03 08:49:18 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/03 08:49:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/03 08:49:18 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.287985 s
25/04/03 08:49:18 INFO FileFormatWriter: Start to commit write Job 21f6640a-a8c7-4822-8205-16d4ebe46ac9.
25/04/03 08:49:18 INFO FileFormatWriter: Write Job 21f6640a-a8c7-4822-8205-16d4ebe46ac9 committed. Elapsed time: 41 ms.
25/04/03 08:49:18 INFO FileFormatWriter: Finished processing stats for write job 21f6640a-a8c7-4822-8205-16d4ebe46ac9.
25/04/03 08:49:18 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/03 08:49:18 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4041
25/04/03 08:49:18 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/03 08:49:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/03 08:49:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/03 08:49:18 INFO MemoryStore: MemoryStore cleared
25/04/03 08:49:18 INFO BlockManager: BlockManager stopped
25/04/03 08:49:18 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/03 08:49:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/03 08:49:18 INFO SparkContext: Successfully stopped SparkContext
25/04/03 08:49:19 INFO ShutdownHookManager: Shutdown hook called
25/04/03 08:49:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-1fed0ce7-838d-43c0-a0ff-46caf4b17802
25/04/03 08:49:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-b5bc306a-6eb8-40a0-bd14-e8544ac816b1
25/04/03 08:49:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-b5bc306a-6eb8-40a0-bd14-e8544ac816b1/pyspark-25b17cc0-903c-4d8a-9129-1e079107419c
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/04 08:14:08 INFO SparkContext: Running Spark version 3.2.2
25/04/04 08:14:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/04 08:14:08 INFO ResourceUtils: ==============================================================
25/04/04 08:14:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/04 08:14:08 INFO ResourceUtils: ==============================================================
25/04/04 08:14:08 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/04 08:14:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/04 08:14:08 INFO ResourceProfile: Limiting resource is cpu
25/04/04 08:14:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/04 08:14:08 INFO SecurityManager: Changing view acls to: root
25/04/04 08:14:08 INFO SecurityManager: Changing modify acls to: root
25/04/04 08:14:08 INFO SecurityManager: Changing view acls groups to: 
25/04/04 08:14:08 INFO SecurityManager: Changing modify acls groups to: 
25/04/04 08:14:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/04 08:14:08 INFO Utils: Successfully started service 'sparkDriver' on port 39231.
25/04/04 08:14:08 INFO SparkEnv: Registering MapOutputTracker
25/04/04 08:14:08 INFO SparkEnv: Registering BlockManagerMaster
25/04/04 08:14:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/04 08:14:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/04 08:14:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/04 08:14:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-018df8d1-4c55-4305-872e-f6e2c4080e9f
25/04/04 08:14:08 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/04 08:14:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/04 08:14:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/04 08:14:09 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/04 08:14:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4041
25/04/04 08:14:09 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/04 08:14:09 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 28 ms (0 ms spent in bootstraps)
25/04/04 08:14:09 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250404081409-0070
25/04/04 08:14:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36677.
25/04/04 08:14:09 INFO NettyBlockTransferService: Server created on 7796893c36d7:36677
25/04/04 08:14:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/04 08:14:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 36677, None)
25/04/04 08:14:09 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:36677 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 36677, None)
25/04/04 08:14:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 36677, None)
25/04/04 08:14:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 36677, None)
25/04/04 08:14:09 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/04 08:14:09 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/04 08:14:10 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/04 08:14:11 INFO InMemoryFileIndex: It took 78 ms to list leaf files for 1 paths.
25/04/04 08:14:11 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 7 paths.
25/04/04 08:14:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/04 08:14:13 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/04 08:14:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/04 08:14:13 INFO CodeGenerator: Code generated in 146.929623 ms
25/04/04 08:14:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/04 08:14:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/04 08:14:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:36677 (size: 32.6 KiB, free: 366.3 MiB)
25/04/04 08:14:13 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/04 08:14:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14681829 bytes, open cost is considered as scanning 4194304 bytes.
25/04/04 08:14:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/04 08:14:13 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:13 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:13 INFO DAGScheduler: Parents of final stage: List()
25/04/04 08:14:13 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/04 08:14:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/04 08:14:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:36677 (size: 5.8 KiB, free: 366.3 MiB)
25/04/04 08:14:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/04 08:14:28 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
25/04/04 08:14:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250404081409-0070/0 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/04 08:14:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250404081409-0070/0 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/04 08:14:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250404081409-0070/1 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/04 08:14:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250404081409-0070/1 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/04 08:14:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250404081409-0070/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/04 08:14:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250404081409-0070/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/04 08:14:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250404081409-0070/1 is now RUNNING
25/04/04 08:14:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250404081409-0070/2 is now RUNNING
25/04/04 08:14:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250404081409-0070/0 is now RUNNING
25/04/04 08:14:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:40254) with ID 2,  ResourceProfileId 0
25/04/04 08:14:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:48428) with ID 1,  ResourceProfileId 0
25/04/04 08:14:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:50918) with ID 0,  ResourceProfileId 0
25/04/04 08:14:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:45973 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.2, 45973, None)
25/04/04 08:14:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:39753 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 39753, None)
25/04/04 08:14:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42533 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 42533, None)
25/04/04 08:14:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 5195 bytes) taskResourceAssignments Map()
25/04/04 08:14:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:39753 (size: 5.8 KiB, free: 366.3 MiB)
25/04/04 08:14:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:39753 (size: 32.6 KiB, free: 366.3 MiB)
25/04/04 08:14:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1561 ms on 172.18.0.6 (executor 2) (1/1)
25/04/04 08:14:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/04 08:14:33 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 20.155 s
25/04/04 08:14:33 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/04 08:14:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/04 08:14:33 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 20.191658 s
25/04/04 08:14:33 INFO CodeGenerator: Code generated in 8.898133 ms
25/04/04 08:14:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/04 08:14:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/04 08:14:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/04 08:14:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/04 08:14:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/04 08:14:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:36677 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:33 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/04 08:14:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/04 08:14:34 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/04 08:14:34 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/04 08:14:34 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/04 08:14:34 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/04 08:14:34 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/04 08:14:34 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/04 08:14:34 INFO metastore: Connected to metastore.
25/04/04 08:14:34 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=eddcc556-e92e-47c7-8da9-dbda74caec0b, clientType=HIVECLI]
25/04/04 08:14:34 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/04 08:14:34 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/04 08:14:34 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/04 08:14:34 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/04 08:14:34 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/04 08:14:34 INFO metastore: Connected to metastore.
25/04/04 08:14:34 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/04 08:14:34 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/04 08:14:34 INFO metastore: Connected to metastore.
25/04/04 08:14:34 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/04 08:14:34 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:36677 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/04 08:14:34 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:39753 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/04 08:14:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/04 08:14:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/04 08:14:34 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/04 08:14:34 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/04 08:14:34 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/04 08:14:34 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/04 08:14:35 INFO CodeGenerator: Code generated in 16.71714 ms
25/04/04 08:14:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/04 08:14:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/04 08:14:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:36677 (size: 33.5 KiB, free: 366.2 MiB)
25/04/04 08:14:35 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/04 08:14:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/04 08:14:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/04 08:14:35 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 3 output partitions
25/04/04 08:14:35 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/04 08:14:35 INFO DAGScheduler: Parents of final stage: List()
25/04/04 08:14:35 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:35 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/04 08:14:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/04 08:14:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/04 08:14:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:36677 (size: 6.0 KiB, free: 366.2 MiB)
25/04/04 08:14:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:35 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2))
25/04/04 08:14:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks resource profile 0
25/04/04 08:14:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 1, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/04 08:14:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 0, partition 1, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/04 08:14:35 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.6, executor 2, partition 2, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/04 08:14:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:39753 (size: 6.0 KiB, free: 366.3 MiB)
25/04/04 08:14:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:39753 (size: 33.5 KiB, free: 366.2 MiB)
25/04/04 08:14:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:42533 (size: 6.0 KiB, free: 366.3 MiB)
25/04/04 08:14:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:45973 (size: 6.0 KiB, free: 366.3 MiB)
25/04/04 08:14:35 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 886 ms on 172.18.0.6 (executor 2) (1/3)
25/04/04 08:14:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:42533 (size: 33.5 KiB, free: 366.3 MiB)
25/04/04 08:14:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:45973 (size: 33.5 KiB, free: 366.3 MiB)
25/04/04 08:14:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2376 ms on 172.18.0.2 (executor 1) (2/3)
25/04/04 08:14:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 2383 ms on 172.18.0.8 (executor 0) (3/3)
25/04/04 08:14:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/04 08:14:37 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.388 s
25/04/04 08:14:37 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/04 08:14:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/04 08:14:37 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.391778 s
25/04/04 08:14:37 INFO CodeGenerator: Code generated in 6.591745 ms
25/04/04 08:14:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1032.0 KiB, free 364.2 MiB)
25/04/04 08:14:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 364.2 MiB)
25/04/04 08:14:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:36677 (size: 5.3 KiB, free: 366.2 MiB)
25/04/04 08:14:37 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/04 08:14:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/04 08:14:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/04 08:14:37 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/04 08:14:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/04 08:14:37 INFO CodeGenerator: Code generated in 26.173101 ms
25/04/04 08:14:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/04 08:14:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/04 08:14:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:36677 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:37 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/04 08:14:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/04 08:14:37 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/04 08:14:37 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 7 output partitions
25/04/04 08:14:37 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:37 INFO DAGScheduler: Parents of final stage: List()
25/04/04 08:14:37 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:37 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.8 KiB, free 363.7 MiB)
25/04/04 08:14:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 363.7 MiB)
25/04/04 08:14:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:36677 (size: 19.2 KiB, free: 366.1 MiB)
25/04/04 08:14:37 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:37 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6))
25/04/04 08:14:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 7 tasks resource profile 0
25/04/04 08:14:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4) (172.18.0.8, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/04 08:14:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5) (172.18.0.2, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/04 08:14:37 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 6) (172.18.0.6, executor 2, partition 2, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/04 08:14:37 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 7) (172.18.0.8, executor 0, partition 3, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/04 08:14:37 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 8) (172.18.0.2, executor 1, partition 4, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/04 08:14:37 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 9) (172.18.0.6, executor 2, partition 5, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/04 08:14:37 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 10) (172.18.0.8, executor 0, partition 6, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/04 08:14:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:39753 (size: 19.2 KiB, free: 366.2 MiB)
25/04/04 08:14:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:45973 (size: 19.2 KiB, free: 366.2 MiB)
25/04/04 08:14:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:42533 (size: 19.2 KiB, free: 366.2 MiB)
25/04/04 08:14:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:39753 (size: 5.3 KiB, free: 366.2 MiB)
25/04/04 08:14:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:45973 (size: 5.3 KiB, free: 366.2 MiB)
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:42533 (size: 5.3 KiB, free: 366.2 MiB)
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:39753 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:45973 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:42533 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:38 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 9) in 588 ms on 172.18.0.6 (executor 2) (1/7)
25/04/04 08:14:38 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 6) in 590 ms on 172.18.0.6 (executor 2) (2/7)
25/04/04 08:14:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 662 ms on 172.18.0.2 (executor 1) (3/7)
25/04/04 08:14:38 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 8) in 661 ms on 172.18.0.2 (executor 1) (4/7)
25/04/04 08:14:38 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 10) in 691 ms on 172.18.0.8 (executor 0) (5/7)
25/04/04 08:14:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 693 ms on 172.18.0.8 (executor 0) (6/7)
25/04/04 08:14:38 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 7) in 692 ms on 172.18.0.8 (executor 0) (7/7)
25/04/04 08:14:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/04 08:14:38 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.707 s
25/04/04 08:14:38 INFO DAGScheduler: looking for newly runnable stages
25/04/04 08:14:38 INFO DAGScheduler: running: Set()
25/04/04 08:14:38 INFO DAGScheduler: waiting: Set()
25/04/04 08:14:38 INFO DAGScheduler: failed: Set()
25/04/04 08:14:38 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/04 08:14:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/04 08:14:38 INFO CodeGenerator: Code generated in 14.266948 ms
25/04/04 08:14:38 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/04 08:14:38 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:38 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/04 08:14:38 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:38 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 45.6 KiB, free 363.7 MiB)
25/04/04 08:14:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 363.7 MiB)
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:36677 (size: 21.5 KiB, free: 366.1 MiB)
25/04/04 08:14:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:38 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/04 08:14:38 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 11) (172.18.0.2, executor 1, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:45973 (size: 21.5 KiB, free: 366.2 MiB)
25/04/04 08:14:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:48428
25/04/04 08:14:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 11) in 138 ms on 172.18.0.2 (executor 1) (1/1)
25/04/04 08:14:38 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/04 08:14:38 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.146 s
25/04/04 08:14:38 INFO DAGScheduler: looking for newly runnable stages
25/04/04 08:14:38 INFO DAGScheduler: running: Set()
25/04/04 08:14:38 INFO DAGScheduler: waiting: Set()
25/04/04 08:14:38 INFO DAGScheduler: failed: Set()
25/04/04 08:14:38 INFO CodeGenerator: Code generated in 7.6539 ms
25/04/04 08:14:38 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/04 08:14:38 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:38 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/04 08:14:38 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:38 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/04 08:14:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.6 MiB)
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:36677 (size: 5.5 KiB, free: 366.1 MiB)
25/04/04 08:14:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:38 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/04 08:14:38 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 12) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:45973 (size: 5.5 KiB, free: 366.2 MiB)
25/04/04 08:14:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:48428
25/04/04 08:14:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 12) in 40 ms on 172.18.0.2 (executor 1) (1/1)
25/04/04 08:14:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/04 08:14:38 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.045 s
25/04/04 08:14:38 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/04 08:14:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/04 08:14:38 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.048812 s
25/04/04 08:14:38 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4041
25/04/04 08:14:38 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/04 08:14:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/04 08:14:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/04 08:14:38 INFO MemoryStore: MemoryStore cleared
25/04/04 08:14:38 INFO BlockManager: BlockManager stopped
25/04/04 08:14:38 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/04 08:14:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/04 08:14:38 INFO SparkContext: Successfully stopped SparkContext
25/04/04 08:14:38 INFO ShutdownHookManager: Shutdown hook called
25/04/04 08:14:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-77fd3ebb-41a9-4749-9955-33c7df14fec4
25/04/04 08:14:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-32da9b2d-25a0-4a89-b572-77ecef45760b
25/04/04 08:14:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-77fd3ebb-41a9-4749-9955-33c7df14fec4/pyspark-2f99fdbd-c24f-4398-8358-9b0923db5def
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/05 07:04:42 INFO SparkContext: Running Spark version 3.2.2
25/04/05 07:04:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/05 07:04:42 INFO ResourceUtils: ==============================================================
25/04/05 07:04:42 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/05 07:04:42 INFO ResourceUtils: ==============================================================
25/04/05 07:04:42 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/05 07:04:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/05 07:04:42 INFO ResourceProfile: Limiting resource is cpu
25/04/05 07:04:42 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/05 07:04:42 INFO SecurityManager: Changing view acls to: root
25/04/05 07:04:42 INFO SecurityManager: Changing modify acls to: root
25/04/05 07:04:42 INFO SecurityManager: Changing view acls groups to: 
25/04/05 07:04:42 INFO SecurityManager: Changing modify acls groups to: 
25/04/05 07:04:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/05 07:04:42 INFO Utils: Successfully started service 'sparkDriver' on port 39449.
25/04/05 07:04:42 INFO SparkEnv: Registering MapOutputTracker
25/04/05 07:04:42 INFO SparkEnv: Registering BlockManagerMaster
25/04/05 07:04:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/05 07:04:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/05 07:04:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/05 07:04:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bab912a3-9a96-48f4-9a42-c2f8eabb9bb9
25/04/05 07:04:42 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/05 07:04:42 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/05 07:04:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/05 07:04:43 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/05 07:04:43 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4041
25/04/05 07:04:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/05 07:04:43 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/05 07:04:43 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250405070443-0077
25/04/05 07:04:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39061.
25/04/05 07:04:43 INFO NettyBlockTransferService: Server created on 7796893c36d7:39061
25/04/05 07:04:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/05 07:04:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 39061, None)
25/04/05 07:04:43 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:39061 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 39061, None)
25/04/05 07:04:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 39061, None)
25/04/05 07:04:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 39061, None)
25/04/05 07:04:43 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/05 07:04:43 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/05 07:04:43 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_countries_into_hive.py", line 17, in <module>
    df = spark.read.option("header", True).csv(COUNTRIES_CSV_PATH)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 410, in csv
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Path does not exist: hdfs://namenode:9000/data/raw/countries
25/04/05 07:04:45 INFO SparkContext: Invoking stop() from shutdown hook
25/04/05 07:04:45 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4041
25/04/05 07:04:45 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/05 07:04:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/05 07:04:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/05 07:04:45 INFO MemoryStore: MemoryStore cleared
25/04/05 07:04:45 INFO BlockManager: BlockManager stopped
25/04/05 07:04:45 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/05 07:04:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/05 07:04:45 INFO SparkContext: Successfully stopped SparkContext
25/04/05 07:04:45 INFO ShutdownHookManager: Shutdown hook called
25/04/05 07:04:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-0fbc6deb-6698-4bc5-a03c-27c0ab3d8e7f
25/04/05 07:04:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-88ab72a3-bd29-49b4-aad3-a7d0260afe7b
25/04/05 07:04:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-88ab72a3-bd29-49b4-aad3-a7d0260afe7b/pyspark-dd35b305-a78f-4187-b020-614b613557c6
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/06 00:05:42 INFO SparkContext: Running Spark version 3.2.2
25/04/06 00:05:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/06 00:05:42 INFO ResourceUtils: ==============================================================
25/04/06 00:05:42 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/06 00:05:42 INFO ResourceUtils: ==============================================================
25/04/06 00:05:42 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/06 00:05:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/06 00:05:42 INFO ResourceProfile: Limiting resource is cpu
25/04/06 00:05:42 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/06 00:05:42 INFO SecurityManager: Changing view acls to: root
25/04/06 00:05:42 INFO SecurityManager: Changing modify acls to: root
25/04/06 00:05:42 INFO SecurityManager: Changing view acls groups to: 
25/04/06 00:05:42 INFO SecurityManager: Changing modify acls groups to: 
25/04/06 00:05:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/06 00:05:42 INFO Utils: Successfully started service 'sparkDriver' on port 45147.
25/04/06 00:05:42 INFO SparkEnv: Registering MapOutputTracker
25/04/06 00:05:42 INFO SparkEnv: Registering BlockManagerMaster
25/04/06 00:05:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/06 00:05:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/06 00:05:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/06 00:05:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f46c152c-cf1d-4005-b8a8-b059eb64c726
25/04/06 00:05:42 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/06 00:05:42 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/06 00:05:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/06 00:05:42 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/06 00:05:43 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4041
25/04/06 00:05:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/06 00:05:43 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 24 ms (0 ms spent in bootstraps)
25/04/06 00:05:43 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250406000543-0085
25/04/06 00:05:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45383.
25/04/06 00:05:43 INFO NettyBlockTransferService: Server created on 7796893c36d7:45383
25/04/06 00:05:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/06 00:05:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 45383, None)
25/04/06 00:05:43 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:45383 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 45383, None)
25/04/06 00:05:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 45383, None)
25/04/06 00:05:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 45383, None)
25/04/06 00:05:43 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/06 00:05:43 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/06 00:05:43 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/06 00:05:45 INFO InMemoryFileIndex: It took 62 ms to list leaf files for 1 paths.
25/04/06 00:05:45 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/06 00:05:46 INFO FileSourceStrategy: Pushed Filters: 
25/04/06 00:05:46 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/06 00:05:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/06 00:05:47 INFO CodeGenerator: Code generated in 141.450444 ms
25/04/06 00:05:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/06 00:05:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/06 00:05:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:45383 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 00:05:47 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/06 00:05:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:05:47 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/06 00:05:47 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:05:47 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/06 00:05:47 INFO DAGScheduler: Parents of final stage: List()
25/04/06 00:05:47 INFO DAGScheduler: Missing parents: List()
25/04/06 00:05:47 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:05:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/06 00:05:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/06 00:05:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:45383 (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 00:05:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/06 00:05:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:05:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/06 00:06:02 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
25/04/06 00:06:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406000543-0085/0 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/06 00:06:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406000543-0085/0 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/06 00:06:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406000543-0085/1 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/06 00:06:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406000543-0085/1 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/06 00:06:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406000543-0085/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/06 00:06:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406000543-0085/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/06 00:06:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406000543-0085/0 is now RUNNING
25/04/06 00:06:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406000543-0085/1 is now RUNNING
25/04/06 00:06:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406000543-0085/2 is now RUNNING
25/04/06 00:06:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:59076) with ID 2,  ResourceProfileId 0
25/04/06 00:06:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:36150) with ID 0,  ResourceProfileId 0
25/04/06 00:06:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:51626) with ID 1,  ResourceProfileId 0
25/04/06 00:06:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:38479 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 38479, None)
25/04/06 00:06:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:34523 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 34523, None)
25/04/06 00:06:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:42519 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.2, 42519, None)
25/04/06 00:06:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 0, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/06 00:06:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:38479 (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 00:06:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:38479 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 00:06:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1522 ms on 172.18.0.8 (executor 0) (1/1)
25/04/06 00:06:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/06 00:06:07 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 19.890 s
25/04/06 00:06:07 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 00:06:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/06 00:06:07 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 19.923542 s
25/04/06 00:06:07 INFO CodeGenerator: Code generated in 9.670114 ms
25/04/06 00:06:07 INFO FileSourceStrategy: Pushed Filters: 
25/04/06 00:06:07 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/06 00:06:07 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/06 00:06:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/06 00:06:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/06 00:06:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:45383 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 00:06:07 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/06 00:06:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:07 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/06 00:06:07 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/06 00:06:07 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/06 00:06:07 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/06 00:06:07 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 00:06:07 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/06 00:06:07 INFO metastore: Connected to metastore.
25/04/06 00:06:07 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ebf7b6a6-3390-43db-af56-5c5ad69d6c8e, clientType=HIVECLI]
25/04/06 00:06:07 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/06 00:06:07 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/06 00:06:07 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/06 00:06:07 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 00:06:07 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/06 00:06:07 INFO metastore: Connected to metastore.
25/04/06 00:06:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:45383 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/06 00:06:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:38479 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 00:06:08 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 00:06:08 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/06 00:06:08 INFO metastore: Connected to metastore.
25/04/06 00:06:08 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/04/06 00:06:08 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/06 00:06:08 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/06 00:06:08 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/06 00:06:08 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/06 00:06:08 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/06 00:06:08 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/06 00:06:08 INFO CodeGenerator: Code generated in 16.850011 ms
25/04/06 00:06:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/06 00:06:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/06 00:06:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:45383 (size: 33.5 KiB, free: 366.2 MiB)
25/04/06 00:06:08 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 00:06:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:08 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 00:06:08 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000198 s
25/04/06 00:06:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.0 B, free 365.2 MiB)
25/04/06 00:06:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 120.0 B, free 365.2 MiB)
25/04/06 00:06:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:45383 (size: 120.0 B, free: 366.2 MiB)
25/04/06 00:06:08 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 00:06:08 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/06 00:06:08 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/06 00:06:08 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/06 00:06:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 00:06:08 INFO CodeGenerator: Code generated in 20.024191 ms
25/04/06 00:06:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 345.3 KiB, free 364.9 MiB)
25/04/06 00:06:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/06 00:06:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:45383 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 00:06:08 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/06 00:06:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:08 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/06 00:06:08 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:08 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:08 INFO DAGScheduler: Parents of final stage: List()
25/04/06 00:06:08 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:08 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:08 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 31.7 KiB, free 364.8 MiB)
25/04/06 00:06:08 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 364.8 MiB)
25/04/06 00:06:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:45383 (size: 14.9 KiB, free: 366.2 MiB)
25/04/06 00:06:08 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/06 00:06:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/06 00:06:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:38479 (size: 14.9 KiB, free: 366.3 MiB)
25/04/06 00:06:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:38479 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 00:06:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 354 ms on 172.18.0.8 (executor 0) (1/1)
25/04/06 00:06:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/06 00:06:09 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.367 s
25/04/06 00:06:09 INFO DAGScheduler: looking for newly runnable stages
25/04/06 00:06:09 INFO DAGScheduler: running: Set()
25/04/06 00:06:09 INFO DAGScheduler: waiting: Set()
25/04/06 00:06:09 INFO DAGScheduler: failed: Set()
25/04/06 00:06:09 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/06 00:06:09 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 00:06:09 INFO CodeGenerator: Code generated in 13.064016 ms
25/04/06 00:06:09 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/06 00:06:09 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:09 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/06 00:06:09 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:09 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 38.8 KiB, free 364.7 MiB)
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 364.7 MiB)
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:45383 (size: 18.5 KiB, free: 366.1 MiB)
25/04/06 00:06:09 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:09 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/06 00:06:09 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:38479 (size: 18.5 KiB, free: 366.2 MiB)
25/04/06 00:06:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:36150
25/04/06 00:06:09 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 138 ms on 172.18.0.8 (executor 0) (1/1)
25/04/06 00:06:09 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/06 00:06:09 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.149 s
25/04/06 00:06:09 INFO DAGScheduler: looking for newly runnable stages
25/04/06 00:06:09 INFO DAGScheduler: running: Set()
25/04/06 00:06:09 INFO DAGScheduler: waiting: Set()
25/04/06 00:06:09 INFO DAGScheduler: failed: Set()
25/04/06 00:06:09 INFO CodeGenerator: Code generated in 6.993699 ms
25/04/06 00:06:09 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/06 00:06:09 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:09 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/06 00:06:09 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:09 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:45383 (size: 5.5 KiB, free: 366.1 MiB)
25/04/06 00:06:09 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:09 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/06 00:06:09 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:38479 (size: 5.5 KiB, free: 366.2 MiB)
25/04/06 00:06:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:36150
25/04/06 00:06:09 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 29 ms on 172.18.0.8 (executor 0) (1/1)
25/04/06 00:06:09 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/06 00:06:09 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s
25/04/06 00:06:09 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 00:06:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/06 00:06:09 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.036844 s
25/04/06 00:06:09 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/06 00:06:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/06 00:06:09 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/06 00:06:09 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/06 00:06:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/06 00:06:09 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/06 00:06:09 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 00:06:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/06 00:06:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/06 00:06:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 00:06:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/06 00:06:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/06 00:06:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.9 KiB, free 364.4 MiB)
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 364.3 MiB)
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:45383 (size: 33.5 KiB, free: 366.1 MiB)
25/04/06 00:06:09 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 00:06:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:09 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 00:06:09 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000154 s
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 24.0 B, free 364.3 MiB)
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.3 MiB)
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:45383 (size: 120.0 B, free: 366.1 MiB)
25/04/06 00:06:09 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 00:06:09 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/06 00:06:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/06 00:06:09 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/06 00:06:09 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 345.3 KiB, free 364.0 MiB)
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:45383 (size: 32.6 KiB, free: 366.1 MiB)
25/04/06 00:06:09 INFO SparkContext: Created broadcast 11 from insertInto at NativeMethodAccessorImpl.java:0
25/04/06 00:06:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:09 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/06 00:06:09 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:09 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:09 INFO DAGScheduler: Parents of final stage: List()
25/04/06 00:06:09 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:09 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.7 KiB, free 363.9 MiB)
25/04/06 00:06:09 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 363.9 MiB)
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:45383 (size: 14.9 KiB, free: 366.1 MiB)
25/04/06 00:06:09 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:09 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/06 00:06:09 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/06 00:06:09 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:34523 (size: 14.9 KiB, free: 366.3 MiB)
25/04/06 00:06:10 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:34523 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 00:06:11 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1701 ms on 172.18.0.6 (executor 2) (1/1)
25/04/06 00:06:11 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/06 00:06:11 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.709 s
25/04/06 00:06:11 INFO DAGScheduler: looking for newly runnable stages
25/04/06 00:06:11 INFO DAGScheduler: running: Set()
25/04/06 00:06:11 INFO DAGScheduler: waiting: Set()
25/04/06 00:06:11 INFO DAGScheduler: failed: Set()
25/04/06 00:06:11 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/06 00:06:11 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 00:06:11 INFO CodeGenerator: Code generated in 11.610324 ms
25/04/06 00:06:11 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/06 00:06:11 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:11 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/06 00:06:11 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:11 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:11 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 229.8 KiB, free 363.7 MiB)
25/04/06 00:06:11 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 84.4 KiB, free 363.6 MiB)
25/04/06 00:06:11 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:45383 (size: 84.4 KiB, free: 366.0 MiB)
25/04/06 00:06:11 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:11 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/06 00:06:11 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/06 00:06:11 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:34523 (size: 84.4 KiB, free: 366.2 MiB)
25/04/06 00:06:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:59076
25/04/06 00:06:12 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 725 ms on 172.18.0.6 (executor 2) (1/1)
25/04/06 00:06:12 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/06 00:06:12 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.739 s
25/04/06 00:06:12 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 00:06:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/06 00:06:12 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.743336 s
25/04/06 00:06:12 INFO FileFormatWriter: Start to commit write Job 9012b8d0-866a-4695-b224-c24d0c559170.
25/04/06 00:06:12 INFO FileFormatWriter: Write Job 9012b8d0-866a-4695-b224-c24d0c559170 committed. Elapsed time: 35 ms.
25/04/06 00:06:12 INFO FileFormatWriter: Finished processing stats for write job 9012b8d0-866a-4695-b224-c24d0c559170.
25/04/06 00:06:12 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/06 00:06:12 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4041
25/04/06 00:06:12 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/06 00:06:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/06 00:06:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/06 00:06:12 INFO MemoryStore: MemoryStore cleared
25/04/06 00:06:12 INFO BlockManager: BlockManager stopped
25/04/06 00:06:12 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/06 00:06:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/06 00:06:12 INFO SparkContext: Successfully stopped SparkContext
25/04/06 00:06:12 INFO ShutdownHookManager: Shutdown hook called
25/04/06 00:06:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-1759b4b0-354d-4081-b7d4-02d3790fe424/pyspark-4068a4f9-551b-484a-9a80-d60647ef66e1
25/04/06 00:06:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-0d671cbe-b457-4508-b13a-484da63479bf
25/04/06 00:06:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-1759b4b0-354d-4081-b7d4-02d3790fe424
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/06 10:21:06 INFO SparkContext: Running Spark version 3.2.2
25/04/06 10:21:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/06 10:21:07 INFO ResourceUtils: ==============================================================
25/04/06 10:21:07 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/06 10:21:07 INFO ResourceUtils: ==============================================================
25/04/06 10:21:07 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/06 10:21:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/06 10:21:07 INFO ResourceProfile: Limiting resource is cpu
25/04/06 10:21:07 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/06 10:21:07 INFO SecurityManager: Changing view acls to: root
25/04/06 10:21:07 INFO SecurityManager: Changing modify acls to: root
25/04/06 10:21:07 INFO SecurityManager: Changing view acls groups to: 
25/04/06 10:21:07 INFO SecurityManager: Changing modify acls groups to: 
25/04/06 10:21:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/06 10:21:07 INFO Utils: Successfully started service 'sparkDriver' on port 33381.
25/04/06 10:21:07 INFO SparkEnv: Registering MapOutputTracker
25/04/06 10:21:07 INFO SparkEnv: Registering BlockManagerMaster
25/04/06 10:21:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/06 10:21:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/06 10:21:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/06 10:21:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f4421e4a-ea19-424f-8243-e1ae25a6bac7
25/04/06 10:21:07 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/06 10:21:07 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/06 10:21:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/06 10:21:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/06 10:21:07 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/06 10:21:07 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/06 10:21:07 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250406102107-0100
25/04/06 10:21:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406102107-0100/0 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/06 10:21:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406102107-0100/0 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/06 10:21:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406102107-0100/1 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/06 10:21:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406102107-0100/1 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/06 10:21:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406102107-0100/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/06 10:21:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406102107-0100/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/06 10:21:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41083.
25/04/06 10:21:07 INFO NettyBlockTransferService: Server created on 7796893c36d7:41083
25/04/06 10:21:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/06 10:21:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 41083, None)
25/04/06 10:21:07 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:41083 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 41083, None)
25/04/06 10:21:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406102107-0100/2 is now RUNNING
25/04/06 10:21:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406102107-0100/1 is now RUNNING
25/04/06 10:21:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 41083, None)
25/04/06 10:21:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406102107-0100/0 is now RUNNING
25/04/06 10:21:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 41083, None)
25/04/06 10:21:08 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/06 10:21:08 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/06 10:21:08 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/06 10:21:09 INFO InMemoryFileIndex: It took 59 ms to list leaf files for 1 paths.
25/04/06 10:21:09 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/06 10:21:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:53726) with ID 1,  ResourceProfileId 0
25/04/06 10:21:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:38398) with ID 0,  ResourceProfileId 0
25/04/06 10:21:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:37628) with ID 2,  ResourceProfileId 0
25/04/06 10:21:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:41109 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 41109, None)
25/04/06 10:21:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:34057 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 34057, None)
25/04/06 10:21:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:42043 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.2, 42043, None)
25/04/06 10:21:11 INFO FileSourceStrategy: Pushed Filters: 
25/04/06 10:21:11 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/06 10:21:11 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/06 10:21:11 INFO CodeGenerator: Code generated in 137.733448 ms
25/04/06 10:21:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/06 10:21:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/06 10:21:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:41083 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 10:21:11 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/06 10:21:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 10:21:11 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/06 10:21:11 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 10:21:11 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/06 10:21:11 INFO DAGScheduler: Parents of final stage: List()
25/04/06 10:21:11 INFO DAGScheduler: Missing parents: List()
25/04/06 10:21:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 10:21:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/06 10:21:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/06 10:21:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:41083 (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 10:21:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/06 10:21:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 10:21:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/06 10:21:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/06 10:21:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:34057 (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 10:21:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:34057 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 10:21:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1410 ms on 172.18.0.6 (executor 2) (1/1)
25/04/06 10:21:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/06 10:21:13 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.476 s
25/04/06 10:21:13 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 10:21:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/06 10:21:13 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.505951 s
25/04/06 10:21:13 INFO CodeGenerator: Code generated in 7.803515 ms
25/04/06 10:21:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/06 10:21:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/06 10:21:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/06 10:21:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/06 10:21:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/06 10:21:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:41083 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 10:21:13 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/06 10:21:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 10:21:13 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/06 10:21:13 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/06 10:21:13 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/06 10:21:13 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/06 10:21:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 10:21:13 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/06 10:21:13 INFO metastore: Connected to metastore.
25/04/06 10:21:13 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4e922727-4b8a-4290-a366-7deddd849484, clientType=HIVECLI]
25/04/06 10:21:13 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/06 10:21:13 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/06 10:21:13 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/06 10:21:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 10:21:13 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/06 10:21:13 INFO metastore: Connected to metastore.
25/04/06 10:21:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 10:21:13 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/06 10:21:13 INFO metastore: Connected to metastore.
25/04/06 10:21:14 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/04/06 10:21:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/06 10:21:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/06 10:21:14 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/06 10:21:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/06 10:21:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/06 10:21:14 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/06 10:21:14 INFO CodeGenerator: Code generated in 15.06527 ms
25/04/06 10:21:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/06 10:21:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/06 10:21:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:41083 (size: 33.5 KiB, free: 366.2 MiB)
25/04/06 10:21:14 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 10:21:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 10:21:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:41083 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/06 10:21:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:34057 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 10:21:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 10:21:14 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000194 s
25/04/06 10:21:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.0 B, free 365.2 MiB)
25/04/06 10:21:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 120.0 B, free 365.2 MiB)
25/04/06 10:21:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:41083 (size: 120.0 B, free: 366.2 MiB)
25/04/06 10:21:14 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 10:21:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/06 10:21:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/06 10:21:14 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/06 10:21:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 10:21:14 INFO CodeGenerator: Code generated in 25.853735 ms
25/04/06 10:21:14 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 345.3 KiB, free 364.9 MiB)
25/04/06 10:21:14 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/06 10:21:14 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:41083 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 10:21:14 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/06 10:21:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 10:21:14 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/06 10:21:14 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 10:21:14 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/06 10:21:14 INFO DAGScheduler: Parents of final stage: List()
25/04/06 10:21:14 INFO DAGScheduler: Missing parents: List()
25/04/06 10:21:14 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 10:21:14 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 31.7 KiB, free 364.8 MiB)
25/04/06 10:21:14 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 364.8 MiB)
25/04/06 10:21:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:41083 (size: 14.9 KiB, free: 366.2 MiB)
25/04/06 10:21:14 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/06 10:21:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 10:21:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/06 10:21:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/06 10:21:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:42043 (size: 14.9 KiB, free: 366.3 MiB)
25/04/06 10:21:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:42043 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 10:21:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1610 ms on 172.18.0.2 (executor 1) (1/1)
25/04/06 10:21:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/06 10:21:16 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.624 s
25/04/06 10:21:16 INFO DAGScheduler: looking for newly runnable stages
25/04/06 10:21:16 INFO DAGScheduler: running: Set()
25/04/06 10:21:16 INFO DAGScheduler: waiting: Set()
25/04/06 10:21:16 INFO DAGScheduler: failed: Set()
25/04/06 10:21:16 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/06 10:21:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 10:21:16 INFO CodeGenerator: Code generated in 11.793621 ms
25/04/06 10:21:16 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/06 10:21:16 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 10:21:16 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/06 10:21:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/06 10:21:16 INFO DAGScheduler: Missing parents: List()
25/04/06 10:21:16 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 38.8 KiB, free 364.7 MiB)
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 364.7 MiB)
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:41083 (size: 18.5 KiB, free: 366.1 MiB)
25/04/06 10:21:16 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/06 10:21:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 10:21:16 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/06 10:21:16 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:42043 (size: 18.5 KiB, free: 366.2 MiB)
25/04/06 10:21:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:53726
25/04/06 10:21:16 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 143 ms on 172.18.0.2 (executor 1) (1/1)
25/04/06 10:21:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/06 10:21:16 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.151 s
25/04/06 10:21:16 INFO DAGScheduler: looking for newly runnable stages
25/04/06 10:21:16 INFO DAGScheduler: running: Set()
25/04/06 10:21:16 INFO DAGScheduler: waiting: Set()
25/04/06 10:21:16 INFO DAGScheduler: failed: Set()
25/04/06 10:21:16 INFO CodeGenerator: Code generated in 7.029672 ms
25/04/06 10:21:16 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/06 10:21:16 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 10:21:16 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/06 10:21:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/06 10:21:16 INFO DAGScheduler: Missing parents: List()
25/04/06 10:21:16 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:41083 (size: 5.5 KiB, free: 366.1 MiB)
25/04/06 10:21:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/06 10:21:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 10:21:16 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/06 10:21:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:42043 (size: 5.5 KiB, free: 366.2 MiB)
25/04/06 10:21:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:53726
25/04/06 10:21:16 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 96 ms on 172.18.0.2 (executor 1) (1/1)
25/04/06 10:21:16 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/06 10:21:16 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.100 s
25/04/06 10:21:16 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 10:21:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/06 10:21:16 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.103445 s
25/04/06 10:21:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/06 10:21:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/06 10:21:16 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/06 10:21:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/06 10:21:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/06 10:21:16 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/06 10:21:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 10:21:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/06 10:21:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/06 10:21:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 10:21:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/06 10:21:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/06 10:21:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.9 KiB, free 364.4 MiB)
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 364.3 MiB)
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:41083 (size: 33.5 KiB, free: 366.1 MiB)
25/04/06 10:21:16 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 10:21:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 10:21:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 10:21:16 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000171 s
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 24.0 B, free 364.3 MiB)
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.3 MiB)
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:41083 (size: 120.0 B, free: 366.1 MiB)
25/04/06 10:21:16 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/06 10:21:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/06 10:21:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/06 10:21:16 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/06 10:21:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 345.3 KiB, free 364.0 MiB)
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:41083 (size: 32.6 KiB, free: 366.1 MiB)
25/04/06 10:21:16 INFO SparkContext: Created broadcast 11 from insertInto at NativeMethodAccessorImpl.java:0
25/04/06 10:21:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 10:21:16 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/06 10:21:16 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 10:21:16 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/06 10:21:16 INFO DAGScheduler: Parents of final stage: List()
25/04/06 10:21:16 INFO DAGScheduler: Missing parents: List()
25/04/06 10:21:16 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.7 KiB, free 363.9 MiB)
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 363.9 MiB)
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:41083 (size: 14.9 KiB, free: 366.1 MiB)
25/04/06 10:21:16 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/06 10:21:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 10:21:16 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/06 10:21:16 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.2, executor 1, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:42043 (size: 14.9 KiB, free: 366.2 MiB)
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:42043 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 10:21:16 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 68 ms on 172.18.0.2 (executor 1) (1/1)
25/04/06 10:21:16 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/06 10:21:16 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.074 s
25/04/06 10:21:16 INFO DAGScheduler: looking for newly runnable stages
25/04/06 10:21:16 INFO DAGScheduler: running: Set()
25/04/06 10:21:16 INFO DAGScheduler: waiting: Set()
25/04/06 10:21:16 INFO DAGScheduler: failed: Set()
25/04/06 10:21:16 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/06 10:21:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 10:21:16 INFO CodeGenerator: Code generated in 11.590802 ms
25/04/06 10:21:16 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/06 10:21:16 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 10:21:16 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/06 10:21:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/06 10:21:16 INFO DAGScheduler: Missing parents: List()
25/04/06 10:21:16 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 229.8 KiB, free 363.7 MiB)
25/04/06 10:21:16 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 84.4 KiB, free 363.6 MiB)
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:41083 (size: 84.4 KiB, free: 366.0 MiB)
25/04/06 10:21:16 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/06 10:21:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 10:21:16 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/06 10:21:16 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/06 10:21:16 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:42043 (size: 84.4 KiB, free: 366.1 MiB)
25/04/06 10:21:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:53726
25/04/06 10:21:17 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 668 ms on 172.18.0.2 (executor 1) (1/1)
25/04/06 10:21:17 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/06 10:21:17 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.682 s
25/04/06 10:21:17 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 10:21:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/06 10:21:17 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.688129 s
25/04/06 10:21:17 INFO FileFormatWriter: Start to commit write Job 000c8b3d-2532-4bab-9b7a-f53e6919ea8e.
25/04/06 10:21:17 INFO FileFormatWriter: Write Job 000c8b3d-2532-4bab-9b7a-f53e6919ea8e committed. Elapsed time: 36 ms.
25/04/06 10:21:17 INFO FileFormatWriter: Finished processing stats for write job 000c8b3d-2532-4bab-9b7a-f53e6919ea8e.
25/04/06 10:21:17 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/06 10:21:17 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/06 10:21:17 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/06 10:21:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/06 10:21:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/06 10:21:17 INFO MemoryStore: MemoryStore cleared
25/04/06 10:21:17 INFO BlockManager: BlockManager stopped
25/04/06 10:21:17 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/06 10:21:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/06 10:21:17 INFO SparkContext: Successfully stopped SparkContext
25/04/06 10:21:17 INFO ShutdownHookManager: Shutdown hook called
25/04/06 10:21:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-43deecc6-7d90-40f5-b76e-32ddf3d1852c
25/04/06 10:21:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-4f002164-5c4e-4ec3-8e45-928d6ea8d43f/pyspark-d2f217e3-deca-4367-a0b6-e8d22f188d1d
25/04/06 10:21:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-4f002164-5c4e-4ec3-8e45-928d6ea8d43f
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/07 00:05:02 INFO SparkContext: Running Spark version 3.2.2
25/04/07 00:05:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/07 00:05:02 INFO ResourceUtils: ==============================================================
25/04/07 00:05:02 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/07 00:05:02 INFO ResourceUtils: ==============================================================
25/04/07 00:05:02 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/07 00:05:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/07 00:05:02 INFO ResourceProfile: Limiting resource is cpu
25/04/07 00:05:02 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/07 00:05:02 INFO SecurityManager: Changing view acls to: root
25/04/07 00:05:02 INFO SecurityManager: Changing modify acls to: root
25/04/07 00:05:02 INFO SecurityManager: Changing view acls groups to: 
25/04/07 00:05:02 INFO SecurityManager: Changing modify acls groups to: 
25/04/07 00:05:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/07 00:05:02 INFO Utils: Successfully started service 'sparkDriver' on port 34677.
25/04/07 00:05:02 INFO SparkEnv: Registering MapOutputTracker
25/04/07 00:05:02 INFO SparkEnv: Registering BlockManagerMaster
25/04/07 00:05:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/07 00:05:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/07 00:05:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/07 00:05:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-92546deb-a36c-441f-8f0e-47b6712294b8
25/04/07 00:05:02 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/07 00:05:02 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/07 00:05:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/07 00:05:02 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://cfd5ae002cf8:4040
25/04/07 00:05:02 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/07 00:05:03 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.13:7077 after 23 ms (0 ms spent in bootstraps)
25/04/07 00:05:03 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250407000503-0000
25/04/07 00:05:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45383.
25/04/07 00:05:03 INFO NettyBlockTransferService: Server created on cfd5ae002cf8:45383
25/04/07 00:05:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/07 00:05:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, cfd5ae002cf8, 45383, None)
25/04/07 00:05:03 INFO BlockManagerMasterEndpoint: Registering block manager cfd5ae002cf8:45383 with 366.3 MiB RAM, BlockManagerId(driver, cfd5ae002cf8, 45383, None)
25/04/07 00:05:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, cfd5ae002cf8, 45383, None)
25/04/07 00:05:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, cfd5ae002cf8, 45383, None)
25/04/07 00:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250407000503-0000/0 on worker-20250406221201-172.18.0.7-43403 (172.18.0.7:43403) with 4 core(s)
25/04/07 00:05:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250407000503-0000/0 on hostPort 172.18.0.7:43403 with 4 core(s), 1024.0 MiB RAM
25/04/07 00:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250407000503-0000/1 on worker-20250406221201-172.18.0.3-43441 (172.18.0.3:43441) with 4 core(s)
25/04/07 00:05:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250407000503-0000/1 on hostPort 172.18.0.3:43441 with 4 core(s), 1024.0 MiB RAM
25/04/07 00:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250407000503-0000/2 on worker-20250406221201-172.18.0.11-45757 (172.18.0.11:45757) with 4 core(s)
25/04/07 00:05:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250407000503-0000/2 on hostPort 172.18.0.11:45757 with 4 core(s), 1024.0 MiB RAM
25/04/07 00:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250407000503-0000/2 is now RUNNING
25/04/07 00:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250407000503-0000/0 is now RUNNING
25/04/07 00:05:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250407000503-0000/1 is now RUNNING
25/04/07 00:05:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/07 00:05:03 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/07 00:05:03 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/07 00:05:05 INFO InMemoryFileIndex: It took 62 ms to list leaf files for 1 paths.
25/04/07 00:05:05 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/04/07 00:05:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.11:38222) with ID 2,  ResourceProfileId 0
25/04/07 00:05:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:37674) with ID 0,  ResourceProfileId 0
25/04/07 00:05:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.3:57124) with ID 1,  ResourceProfileId 0
25/04/07 00:05:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.11:43211 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.11, 43211, None)
25/04/07 00:05:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:39549 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.7, 39549, None)
25/04/07 00:05:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.3:33619 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.3, 33619, None)
25/04/07 00:05:06 INFO FileSourceStrategy: Pushed Filters: 
25/04/07 00:05:06 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/07 00:05:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/07 00:05:07 INFO CodeGenerator: Code generated in 140.164743 ms
25/04/07 00:05:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/07 00:05:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/07 00:05:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on cfd5ae002cf8:45383 (size: 32.6 KiB, free: 366.3 MiB)
25/04/07 00:05:07 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/07 00:05:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/07 00:05:07 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/07 00:05:07 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:07 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:07 INFO DAGScheduler: Parents of final stage: List()
25/04/07 00:05:07 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/07 00:05:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/07 00:05:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on cfd5ae002cf8:45383 (size: 5.8 KiB, free: 366.3 MiB)
25/04/07 00:05:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/07 00:05:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.3, executor 1, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/07 00:05:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.3:33619 (size: 5.8 KiB, free: 366.3 MiB)
25/04/07 00:05:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.3:33619 (size: 32.6 KiB, free: 366.3 MiB)
25/04/07 00:05:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1377 ms on 172.18.0.3 (executor 1) (1/1)
25/04/07 00:05:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/07 00:05:08 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.445 s
25/04/07 00:05:08 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/07 00:05:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/07 00:05:08 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.476362 s
25/04/07 00:05:08 INFO CodeGenerator: Code generated in 7.673744 ms
25/04/07 00:05:08 INFO FileSourceStrategy: Pushed Filters: 
25/04/07 00:05:08 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/07 00:05:08 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/07 00:05:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/07 00:05:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/07 00:05:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on cfd5ae002cf8:45383 (size: 32.6 KiB, free: 366.2 MiB)
25/04/07 00:05:08 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/07 00:05:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/07 00:05:09 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/07 00:05:09 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/07 00:05:09 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/07 00:05:09 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/07 00:05:09 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/07 00:05:09 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/07 00:05:09 INFO metastore: Connected to metastore.
25/04/07 00:05:09 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=aab247a2-d872-4d39-a48b-e4ed780bdbca, clientType=HIVECLI]
25/04/07 00:05:09 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/07 00:05:09 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/07 00:05:09 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/07 00:05:09 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/07 00:05:09 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/07 00:05:09 INFO metastore: Connected to metastore.
25/04/07 00:05:09 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/07 00:05:09 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/07 00:05:09 INFO metastore: Connected to metastore.
25/04/07 00:05:09 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/07 00:05:09 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/07 00:05:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/07 00:05:09 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/07 00:05:09 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/07 00:05:09 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/07 00:05:09 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/07 00:05:09 INFO CodeGenerator: Code generated in 16.860333 ms
25/04/07 00:05:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/07 00:05:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/07 00:05:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on cfd5ae002cf8:45383 (size: 33.5 KiB, free: 366.2 MiB)
25/04/07 00:05:09 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/07 00:05:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/07 00:05:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on cfd5ae002cf8:45383 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/07 00:05:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.3:33619 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/07 00:05:10 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/07 00:05:10 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/07 00:05:10 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/07 00:05:10 INFO DAGScheduler: Parents of final stage: List()
25/04/07 00:05:10 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:10 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/07 00:05:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/07 00:05:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/07 00:05:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on cfd5ae002cf8:45383 (size: 6.0 KiB, free: 366.2 MiB)
25/04/07 00:05:10 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/07 00:05:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.3, executor 1, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/07 00:05:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.3:33619 (size: 6.0 KiB, free: 366.3 MiB)
25/04/07 00:05:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.3:33619 (size: 33.5 KiB, free: 366.2 MiB)
25/04/07 00:05:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 579 ms on 172.18.0.3 (executor 1) (1/1)
25/04/07 00:05:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/07 00:05:10 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.585 s
25/04/07 00:05:10 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/07 00:05:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/07 00:05:10 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.588220 s
25/04/07 00:05:10 INFO CodeGenerator: Code generated in 6.522888 ms
25/04/07 00:05:10 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/04/07 00:05:10 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1136.0 B, free 364.2 MiB)
25/04/07 00:05:10 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on cfd5ae002cf8:45383 (size: 1136.0 B, free: 366.2 MiB)
25/04/07 00:05:10 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/07 00:05:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/07 00:05:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/07 00:05:10 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/07 00:05:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/07 00:05:10 INFO CodeGenerator: Code generated in 26.165794 ms
25/04/07 00:05:10 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/07 00:05:10 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/07 00:05:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on cfd5ae002cf8:45383 (size: 32.6 KiB, free: 366.2 MiB)
25/04/07 00:05:10 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/07 00:05:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/07 00:05:10 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/07 00:05:10 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:10 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:10 INFO DAGScheduler: Parents of final stage: List()
25/04/07 00:05:10 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:10 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.8 KiB, free 363.8 MiB)
25/04/07 00:05:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 363.7 MiB)
25/04/07 00:05:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on cfd5ae002cf8:45383 (size: 19.2 KiB, free: 366.1 MiB)
25/04/07 00:05:10 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/07 00:05:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.11, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/07 00:05:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.11:43211 (size: 19.2 KiB, free: 366.3 MiB)
25/04/07 00:05:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.11:43211 (size: 1136.0 B, free: 366.3 MiB)
25/04/07 00:05:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.11:43211 (size: 32.6 KiB, free: 366.2 MiB)
25/04/07 00:05:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1582 ms on 172.18.0.11 (executor 2) (1/1)
25/04/07 00:05:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/07 00:05:12 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 1.594 s
25/04/07 00:05:12 INFO DAGScheduler: looking for newly runnable stages
25/04/07 00:05:12 INFO DAGScheduler: running: Set()
25/04/07 00:05:12 INFO DAGScheduler: waiting: Set()
25/04/07 00:05:12 INFO DAGScheduler: failed: Set()
25/04/07 00:05:12 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/07 00:05:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/07 00:05:12 INFO CodeGenerator: Code generated in 10.716478 ms
25/04/07 00:05:12 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/07 00:05:12 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:12 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/07 00:05:12 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:12 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:12 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 45.6 KiB, free 363.7 MiB)
25/04/07 00:05:12 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.4 KiB, free 363.7 MiB)
25/04/07 00:05:12 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on cfd5ae002cf8:45383 (size: 21.4 KiB, free: 366.1 MiB)
25/04/07 00:05:12 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:12 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/07 00:05:12 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.11, executor 2, partition 0, PROCESS_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/07 00:05:12 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.11:43211 (size: 21.4 KiB, free: 366.2 MiB)
25/04/07 00:05:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.11:38222
25/04/07 00:05:12 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 127 ms on 172.18.0.11 (executor 2) (1/1)
25/04/07 00:05:12 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/07 00:05:12 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.135 s
25/04/07 00:05:12 INFO DAGScheduler: looking for newly runnable stages
25/04/07 00:05:12 INFO DAGScheduler: running: Set()
25/04/07 00:05:12 INFO DAGScheduler: waiting: Set()
25/04/07 00:05:12 INFO DAGScheduler: failed: Set()
25/04/07 00:05:12 INFO CodeGenerator: Code generated in 6.324188 ms
25/04/07 00:05:12 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/07 00:05:12 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:12 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/07 00:05:12 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:12 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:12 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/07 00:05:12 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/07 00:05:12 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on cfd5ae002cf8:45383 (size: 5.5 KiB, free: 366.1 MiB)
25/04/07 00:05:12 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:12 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/07 00:05:12 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.11, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/07 00:05:12 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.11:43211 (size: 5.5 KiB, free: 366.2 MiB)
25/04/07 00:05:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.11:38222
25/04/07 00:05:12 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 94 ms on 172.18.0.11 (executor 2) (1/1)
25/04/07 00:05:12 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/07 00:05:12 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.098 s
25/04/07 00:05:12 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/07 00:05:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/07 00:05:12 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.101928 s
25/04/07 00:05:12 INFO SparkUI: Stopped Spark web UI at http://cfd5ae002cf8:4040
25/04/07 00:05:12 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/07 00:05:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/07 00:05:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/07 00:05:12 INFO MemoryStore: MemoryStore cleared
25/04/07 00:05:12 INFO BlockManager: BlockManager stopped
25/04/07 00:05:12 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/07 00:05:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/07 00:05:12 INFO SparkContext: Successfully stopped SparkContext
25/04/07 00:05:12 INFO ShutdownHookManager: Shutdown hook called
25/04/07 00:05:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-8cf8b4c2-b8bb-4715-9f75-d7f59bb58722/pyspark-93616a2e-6d1a-4775-a212-bdaa39480401
25/04/07 00:05:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-b829c3bf-6d09-4364-ae83-2bbe5e281d62
25/04/07 00:05:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-8cf8b4c2-b8bb-4715-9f75-d7f59bb58722
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/08 00:05:02 INFO SparkContext: Running Spark version 3.2.2
25/04/08 00:05:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/08 00:05:02 INFO ResourceUtils: ==============================================================
25/04/08 00:05:02 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/08 00:05:02 INFO ResourceUtils: ==============================================================
25/04/08 00:05:02 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/08 00:05:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/08 00:05:02 INFO ResourceProfile: Limiting resource is cpu
25/04/08 00:05:02 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/08 00:05:02 INFO SecurityManager: Changing view acls to: root
25/04/08 00:05:02 INFO SecurityManager: Changing modify acls to: root
25/04/08 00:05:02 INFO SecurityManager: Changing view acls groups to: 
25/04/08 00:05:02 INFO SecurityManager: Changing modify acls groups to: 
25/04/08 00:05:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/08 00:05:02 INFO Utils: Successfully started service 'sparkDriver' on port 34999.
25/04/08 00:05:02 INFO SparkEnv: Registering MapOutputTracker
25/04/08 00:05:02 INFO SparkEnv: Registering BlockManagerMaster
25/04/08 00:05:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/08 00:05:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/08 00:05:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/08 00:05:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b9515f83-9a9b-4f37-acf8-f428741a31f0
25/04/08 00:05:02 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/08 00:05:02 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/08 00:05:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/08 00:05:03 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://98d2d932c324:4040
25/04/08 00:05:03 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/08 00:05:03 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.18:7077 after 24 ms (0 ms spent in bootstraps)
25/04/08 00:05:03 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250408000503-0001
25/04/08 00:05:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42483.
25/04/08 00:05:03 INFO NettyBlockTransferService: Server created on 98d2d932c324:42483
25/04/08 00:05:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/08 00:05:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 98d2d932c324, 42483, None)
25/04/08 00:05:03 INFO BlockManagerMasterEndpoint: Registering block manager 98d2d932c324:42483 with 366.3 MiB RAM, BlockManagerId(driver, 98d2d932c324, 42483, None)
25/04/08 00:05:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 98d2d932c324, 42483, None)
25/04/08 00:05:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 98d2d932c324, 42483, None)
25/04/08 00:05:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/08 00:05:04 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/08 00:05:04 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/08 00:05:05 INFO InMemoryFileIndex: It took 71 ms to list leaf files for 1 paths.
25/04/08 00:05:05 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/04/08 00:05:07 INFO FileSourceStrategy: Pushed Filters: 
25/04/08 00:05:07 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/08 00:05:07 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/08 00:05:07 INFO CodeGenerator: Code generated in 141.869307 ms
25/04/08 00:05:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/08 00:05:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/08 00:05:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 98d2d932c324:42483 (size: 32.6 KiB, free: 366.3 MiB)
25/04/08 00:05:07 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/08 00:05:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:07 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/08 00:05:07 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:07 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:07 INFO DAGScheduler: Parents of final stage: List()
25/04/08 00:05:07 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/08 00:05:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/08 00:05:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 98d2d932c324:42483 (size: 5.8 KiB, free: 366.3 MiB)
25/04/08 00:05:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/08 00:05:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250408000503-0001/0 on worker-20250407214357-172.18.0.4-36701 (172.18.0.4:36701) with 4 core(s)
25/04/08 00:05:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250408000503-0001/0 on hostPort 172.18.0.4:36701 with 4 core(s), 1024.0 MiB RAM
25/04/08 00:05:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250408000503-0001/1 on worker-20250407214357-172.18.0.7-35443 (172.18.0.7:35443) with 4 core(s)
25/04/08 00:05:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250408000503-0001/1 on hostPort 172.18.0.7:35443 with 4 core(s), 1024.0 MiB RAM
25/04/08 00:05:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250408000503-0001/2 on worker-20250407214357-172.18.0.6-37199 (172.18.0.6:37199) with 4 core(s)
25/04/08 00:05:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250408000503-0001/2 on hostPort 172.18.0.6:37199 with 4 core(s), 1024.0 MiB RAM
25/04/08 00:05:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250408000503-0001/1 is now RUNNING
25/04/08 00:05:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250408000503-0001/2 is now RUNNING
25/04/08 00:05:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250408000503-0001/0 is now RUNNING
25/04/08 00:05:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:57490) with ID 2,  ResourceProfileId 0
25/04/08 00:05:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.4:46096) with ID 0,  ResourceProfileId 0
25/04/08 00:05:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:59004) with ID 1,  ResourceProfileId 0
25/04/08 00:05:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:32857 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 32857, None)
25/04/08 00:05:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.4:38241 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.4, 38241, None)
25/04/08 00:05:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:35733 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.7, 35733, None)
25/04/08 00:05:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/08 00:05:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:32857 (size: 5.8 KiB, free: 366.3 MiB)
25/04/08 00:05:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:32857 (size: 32.6 KiB, free: 366.3 MiB)
25/04/08 00:05:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1527 ms on 172.18.0.6 (executor 2) (1/1)
25/04/08 00:05:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/08 00:05:23 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 15.871 s
25/04/08 00:05:23 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/08 00:05:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/08 00:05:23 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 15.905673 s
25/04/08 00:05:23 INFO CodeGenerator: Code generated in 10.548572 ms
25/04/08 00:05:23 INFO FileSourceStrategy: Pushed Filters: 
25/04/08 00:05:23 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/08 00:05:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/08 00:05:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/08 00:05:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/08 00:05:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 98d2d932c324:42483 (size: 32.6 KiB, free: 366.2 MiB)
25/04/08 00:05:23 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/08 00:05:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:23 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/08 00:05:23 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/08 00:05:23 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/08 00:05:24 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/08 00:05:24 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/08 00:05:24 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/08 00:05:24 INFO metastore: Connected to metastore.
25/04/08 00:05:24 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=d0ff758c-008b-46e2-a1d1-e7674a7ae9de, clientType=HIVECLI]
25/04/08 00:05:24 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/08 00:05:24 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/08 00:05:24 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/08 00:05:24 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/08 00:05:24 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/08 00:05:24 INFO metastore: Connected to metastore.
25/04/08 00:05:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 98d2d932c324:42483 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/08 00:05:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:32857 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/08 00:05:24 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/08 00:05:24 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/08 00:05:24 INFO metastore: Connected to metastore.
25/04/08 00:05:24 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/04/08 00:05:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/08 00:05:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/08 00:05:24 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/08 00:05:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/08 00:05:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/08 00:05:24 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/08 00:05:24 INFO CodeGenerator: Code generated in 16.919551 ms
25/04/08 00:05:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/08 00:05:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/08 00:05:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 98d2d932c324:42483 (size: 33.5 KiB, free: 366.2 MiB)
25/04/08 00:05:24 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/08 00:05:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/08 00:05:24 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000208 s
25/04/08 00:05:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 24.0 B, free 365.2 MiB)
25/04/08 00:05:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 120.0 B, free 365.2 MiB)
25/04/08 00:05:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 98d2d932c324:42483 (size: 120.0 B, free: 366.2 MiB)
25/04/08 00:05:24 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/08 00:05:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/08 00:05:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/08 00:05:24 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/08 00:05:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/08 00:05:25 INFO CodeGenerator: Code generated in 22.338934 ms
25/04/08 00:05:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 345.3 KiB, free 364.9 MiB)
25/04/08 00:05:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/08 00:05:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 98d2d932c324:42483 (size: 32.6 KiB, free: 366.2 MiB)
25/04/08 00:05:25 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/08 00:05:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:25 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/08 00:05:25 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:25 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:25 INFO DAGScheduler: Parents of final stage: List()
25/04/08 00:05:25 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:25 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 31.7 KiB, free 364.8 MiB)
25/04/08 00:05:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 364.8 MiB)
25/04/08 00:05:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 98d2d932c324:42483 (size: 14.9 KiB, free: 366.2 MiB)
25/04/08 00:05:25 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/08 00:05:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.4, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/08 00:05:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.4:38241 (size: 14.9 KiB, free: 366.3 MiB)
25/04/08 00:05:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.4:38241 (size: 32.6 KiB, free: 366.3 MiB)
25/04/08 00:05:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1702 ms on 172.18.0.4 (executor 0) (1/1)
25/04/08 00:05:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/08 00:05:26 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.715 s
25/04/08 00:05:26 INFO DAGScheduler: looking for newly runnable stages
25/04/08 00:05:26 INFO DAGScheduler: running: Set()
25/04/08 00:05:26 INFO DAGScheduler: waiting: Set()
25/04/08 00:05:26 INFO DAGScheduler: failed: Set()
25/04/08 00:05:26 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/08 00:05:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/08 00:05:26 INFO CodeGenerator: Code generated in 12.943172 ms
25/04/08 00:05:26 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/08 00:05:26 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:26 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/08 00:05:26 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:26 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:26 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 38.8 KiB, free 364.7 MiB)
25/04/08 00:05:26 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.5 KiB, free 364.7 MiB)
25/04/08 00:05:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 98d2d932c324:42483 (size: 18.5 KiB, free: 366.1 MiB)
25/04/08 00:05:26 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:26 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/08 00:05:26 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/08 00:05:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.4:38241 (size: 18.5 KiB, free: 366.2 MiB)
25/04/08 00:05:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.4:46096
25/04/08 00:05:27 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 148 ms on 172.18.0.4 (executor 0) (1/1)
25/04/08 00:05:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/08 00:05:27 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.156 s
25/04/08 00:05:27 INFO DAGScheduler: looking for newly runnable stages
25/04/08 00:05:27 INFO DAGScheduler: running: Set()
25/04/08 00:05:27 INFO DAGScheduler: waiting: Set()
25/04/08 00:05:27 INFO DAGScheduler: failed: Set()
25/04/08 00:05:27 INFO CodeGenerator: Code generated in 8.095655 ms
25/04/08 00:05:27 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/08 00:05:27 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:27 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/08 00:05:27 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:27 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 98d2d932c324:42483 (size: 5.5 KiB, free: 366.1 MiB)
25/04/08 00:05:27 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:27 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/08 00:05:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.4, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.4:38241 (size: 5.5 KiB, free: 366.2 MiB)
25/04/08 00:05:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.4:46096
25/04/08 00:05:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 98 ms on 172.18.0.4 (executor 0) (1/1)
25/04/08 00:05:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/08 00:05:27 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.103 s
25/04/08 00:05:27 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/08 00:05:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/08 00:05:27 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.106505 s
25/04/08 00:05:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/08 00:05:27 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/08 00:05:27 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/08 00:05:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/08 00:05:27 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/08 00:05:27 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/08 00:05:27 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/08 00:05:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/08 00:05:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/08 00:05:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/08 00:05:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/08 00:05:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/08 00:05:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.9 KiB, free 364.4 MiB)
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 364.3 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 98d2d932c324:42483 (size: 33.5 KiB, free: 366.1 MiB)
25/04/08 00:05:27 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/08 00:05:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:27 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/08 00:05:27 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000160 s
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 24.0 B, free 364.3 MiB)
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.3 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 98d2d932c324:42483 (size: 120.0 B, free: 366.1 MiB)
25/04/08 00:05:27 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/08 00:05:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/08 00:05:27 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/08 00:05:27 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/08 00:05:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 345.3 KiB, free 364.0 MiB)
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 98d2d932c324:42483 (size: 32.6 KiB, free: 366.1 MiB)
25/04/08 00:05:27 INFO SparkContext: Created broadcast 11 from insertInto at NativeMethodAccessorImpl.java:0
25/04/08 00:05:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:27 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/08 00:05:27 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:27 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:27 INFO DAGScheduler: Parents of final stage: List()
25/04/08 00:05:27 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:27 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 31.7 KiB, free 363.9 MiB)
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.9 KiB, free 363.9 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 98d2d932c324:42483 (size: 14.9 KiB, free: 366.1 MiB)
25/04/08 00:05:27 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:27 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/08 00:05:27 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:32857 (size: 14.9 KiB, free: 366.3 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:32857 (size: 32.6 KiB, free: 366.2 MiB)
25/04/08 00:05:27 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 370 ms on 172.18.0.6 (executor 2) (1/1)
25/04/08 00:05:27 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/08 00:05:27 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.377 s
25/04/08 00:05:27 INFO DAGScheduler: looking for newly runnable stages
25/04/08 00:05:27 INFO DAGScheduler: running: Set()
25/04/08 00:05:27 INFO DAGScheduler: waiting: Set()
25/04/08 00:05:27 INFO DAGScheduler: failed: Set()
25/04/08 00:05:27 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/08 00:05:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/08 00:05:27 INFO CodeGenerator: Code generated in 12.892118 ms
25/04/08 00:05:27 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/08 00:05:27 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:27 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/08 00:05:27 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:27 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 229.8 KiB, free 363.7 MiB)
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 84.4 KiB, free 363.6 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 98d2d932c324:42483 (size: 84.4 KiB, free: 366.0 MiB)
25/04/08 00:05:27 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:27 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/08 00:05:27 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:32857 (size: 84.4 KiB, free: 366.1 MiB)
25/04/08 00:05:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:57490
25/04/08 00:05:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 699 ms on 172.18.0.6 (executor 2) (1/1)
25/04/08 00:05:28 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/08 00:05:28 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.715 s
25/04/08 00:05:28 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/08 00:05:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/08 00:05:28 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.720682 s
25/04/08 00:05:28 INFO FileFormatWriter: Start to commit write Job a9b6eb41-15e3-42e0-b861-0a2a1a9d0565.
25/04/08 00:05:28 INFO FileFormatWriter: Write Job a9b6eb41-15e3-42e0-b861-0a2a1a9d0565 committed. Elapsed time: 37 ms.
25/04/08 00:05:28 INFO FileFormatWriter: Finished processing stats for write job a9b6eb41-15e3-42e0-b861-0a2a1a9d0565.
25/04/08 00:05:28 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/08 00:05:28 INFO SparkUI: Stopped Spark web UI at http://98d2d932c324:4040
25/04/08 00:05:28 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/08 00:05:28 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/08 00:05:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/08 00:05:28 INFO MemoryStore: MemoryStore cleared
25/04/08 00:05:28 INFO BlockManager: BlockManager stopped
25/04/08 00:05:28 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/08 00:05:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/08 00:05:28 INFO SparkContext: Successfully stopped SparkContext
25/04/08 00:05:28 INFO ShutdownHookManager: Shutdown hook called
25/04/08 00:05:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-5935a093-ac2f-4456-a570-b60ce60f312d
25/04/08 00:05:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-7a8045c9-1d13-412f-bb2e-6c1dade39802
25/04/08 00:05:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-7a8045c9-1d13-412f-bb2e-6c1dade39802/pyspark-f47d1796-0bf0-4851-bb50-55ad73f1f61e
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/09 00:05:50 INFO SparkContext: Running Spark version 3.2.2
25/04/09 00:05:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/09 00:05:50 INFO ResourceUtils: ==============================================================
25/04/09 00:05:50 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/09 00:05:50 INFO ResourceUtils: ==============================================================
25/04/09 00:05:50 INFO SparkContext: Submitted application: Load countries data into Hive
25/04/09 00:05:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/09 00:05:50 INFO ResourceProfile: Limiting resource is cpu
25/04/09 00:05:50 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/09 00:05:50 INFO SecurityManager: Changing view acls to: root
25/04/09 00:05:50 INFO SecurityManager: Changing modify acls to: root
25/04/09 00:05:50 INFO SecurityManager: Changing view acls groups to: 
25/04/09 00:05:50 INFO SecurityManager: Changing modify acls groups to: 
25/04/09 00:05:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/09 00:05:50 INFO Utils: Successfully started service 'sparkDriver' on port 45089.
25/04/09 00:05:50 INFO SparkEnv: Registering MapOutputTracker
25/04/09 00:05:50 INFO SparkEnv: Registering BlockManagerMaster
25/04/09 00:05:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/09 00:05:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/09 00:05:50 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/09 00:05:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0ddbaed4-9587-47c2-b02d-7776840e1a84
25/04/09 00:05:50 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/09 00:05:50 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/09 00:05:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/09 00:05:50 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/09 00:05:50 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://3fada93ce917:4041
25/04/09 00:05:51 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/09 00:05:51 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.14:7077 after 22 ms (0 ms spent in bootstraps)
25/04/09 00:05:51 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250409000551-0013
25/04/09 00:05:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35741.
25/04/09 00:05:51 INFO NettyBlockTransferService: Server created on 3fada93ce917:35741
25/04/09 00:05:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/09 00:05:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 3fada93ce917, 35741, None)
25/04/09 00:05:51 INFO BlockManagerMasterEndpoint: Registering block manager 3fada93ce917:35741 with 366.3 MiB RAM, BlockManagerId(driver, 3fada93ce917, 35741, None)
25/04/09 00:05:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 3fada93ce917, 35741, None)
25/04/09 00:05:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 3fada93ce917, 35741, None)
25/04/09 00:05:51 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/09 00:05:51 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/09 00:05:51 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/09 00:05:52 INFO InMemoryFileIndex: It took 67 ms to list leaf files for 1 paths.
25/04/09 00:05:53 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 2 paths.
25/04/09 00:05:54 INFO FileSourceStrategy: Pushed Filters: 
25/04/09 00:05:54 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/09 00:05:54 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/09 00:05:55 INFO CodeGenerator: Code generated in 146.720996 ms
25/04/09 00:05:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.4 KiB, free 366.0 MiB)
25/04/09 00:05:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/09 00:05:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 3fada93ce917:35741 (size: 32.6 KiB, free: 366.3 MiB)
25/04/09 00:05:55 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/09 00:05:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194759 bytes, open cost is considered as scanning 4194304 bytes.
25/04/09 00:05:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/09 00:05:55 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/09 00:05:55 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/09 00:05:55 INFO DAGScheduler: Parents of final stage: List()
25/04/09 00:05:55 INFO DAGScheduler: Missing parents: List()
25/04/09 00:05:55 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/09 00:05:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/09 00:05:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/09 00:05:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 3fada93ce917:35741 (size: 5.8 KiB, free: 366.3 MiB)
25/04/09 00:05:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/09 00:05:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/09 00:05:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/09 00:06:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250409000551-0013/0 on worker-20250408075749-172.18.0.9-36639 (172.18.0.9:36639) with 4 core(s)
25/04/09 00:06:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250409000551-0013/0 on hostPort 172.18.0.9:36639 with 4 core(s), 1024.0 MiB RAM
25/04/09 00:06:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250409000551-0013/1 on worker-20250408075749-172.18.0.3-40933 (172.18.0.3:40933) with 4 core(s)
25/04/09 00:06:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250409000551-0013/1 on hostPort 172.18.0.3:40933 with 4 core(s), 1024.0 MiB RAM
25/04/09 00:06:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250409000551-0013/2 on worker-20250408075749-172.18.0.12-42009 (172.18.0.12:42009) with 4 core(s)
25/04/09 00:06:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250409000551-0013/2 on hostPort 172.18.0.12:42009 with 4 core(s), 1024.0 MiB RAM
25/04/09 00:06:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250409000551-0013/0 is now RUNNING
25/04/09 00:06:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250409000551-0013/1 is now RUNNING
25/04/09 00:06:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250409000551-0013/2 is now RUNNING
25/04/09 00:06:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.9:44950) with ID 0,  ResourceProfileId 0
25/04/09 00:06:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.12:59094) with ID 2,  ResourceProfileId 0
25/04/09 00:06:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.3:60794) with ID 1,  ResourceProfileId 0
25/04/09 00:06:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.9:41467 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.9, 41467, None)
25/04/09 00:06:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.12:40263 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.12, 40263, None)
25/04/09 00:06:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.3:45339 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.3, 45339, None)
25/04/09 00:06:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.9, executor 0, partition 0, ANY, 4898 bytes) taskResourceAssignments Map()
25/04/09 00:06:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.9:41467 (size: 5.8 KiB, free: 366.3 MiB)
25/04/09 00:06:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.9:41467 (size: 32.6 KiB, free: 366.3 MiB)
25/04/09 00:06:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1538 ms on 172.18.0.9 (executor 0) (1/1)
25/04/09 00:06:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/09 00:06:11 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 16.516 s
25/04/09 00:06:11 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/09 00:06:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/09 00:06:11 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 16.550203 s
25/04/09 00:06:11 INFO CodeGenerator: Code generated in 8.875377 ms
25/04/09 00:06:11 INFO FileSourceStrategy: Pushed Filters: 
25/04/09 00:06:11 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/09 00:06:11 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/09 00:06:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.4 KiB, free 365.6 MiB)
25/04/09 00:06:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/09 00:06:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 3fada93ce917:35741 (size: 32.6 KiB, free: 366.2 MiB)
25/04/09 00:06:11 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/09 00:06:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/09 00:06:12 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/09 00:06:12 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/09 00:06:12 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/09 00:06:12 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/09 00:06:12 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/09 00:06:12 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/09 00:06:12 INFO metastore: Connected to metastore.
25/04/09 00:06:12 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=d38bfb54-5077-4b9b-9e4d-8290d6ad820a, clientType=HIVECLI]
25/04/09 00:06:12 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/09 00:06:12 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/09 00:06:12 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/09 00:06:12 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/09 00:06:12 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/09 00:06:12 INFO metastore: Connected to metastore.
25/04/09 00:06:12 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/09 00:06:12 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/09 00:06:12 INFO metastore: Connected to metastore.
25/04/09 00:06:12 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/09 00:06:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 3fada93ce917:35741 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/09 00:06:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.9:41467 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/09 00:06:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/09 00:06:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/09 00:06:12 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/09 00:06:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/09 00:06:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/09 00:06:12 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/09 00:06:13 INFO CodeGenerator: Code generated in 18.040878 ms
25/04/09 00:06:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.9 KiB, free 365.2 MiB)
25/04/09 00:06:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 365.2 MiB)
25/04/09 00:06:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 3fada93ce917:35741 (size: 33.5 KiB, free: 366.2 MiB)
25/04/09 00:06:13 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/09 00:06:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/09 00:06:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/09 00:06:13 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/09 00:06:13 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/09 00:06:13 INFO DAGScheduler: Parents of final stage: List()
25/04/09 00:06:13 INFO DAGScheduler: Missing parents: List()
25/04/09 00:06:13 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/09 00:06:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/09 00:06:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/09 00:06:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 3fada93ce917:35741 (size: 6.0 KiB, free: 366.2 MiB)
25/04/09 00:06:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/09 00:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/09 00:06:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/09 00:06:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.3, executor 1, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/09 00:06:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.3:45339 (size: 6.0 KiB, free: 366.3 MiB)
25/04/09 00:06:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.3:45339 (size: 33.5 KiB, free: 366.3 MiB)
25/04/09 00:06:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1970 ms on 172.18.0.3 (executor 1) (1/1)
25/04/09 00:06:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/09 00:06:15 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.983 s
25/04/09 00:06:15 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/09 00:06:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/09 00:06:15 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.986391 s
25/04/09 00:06:15 INFO CodeGenerator: Code generated in 7.054527 ms
25/04/09 00:06:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 1025.0 KiB, free 364.2 MiB)
25/04/09 00:06:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 963.0 B, free 364.2 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 3fada93ce917:35741 (size: 963.0 B, free: 366.2 MiB)
25/04/09 00:06:15 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/09 00:06:15 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/09 00:06:15 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/09 00:06:15 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/09 00:06:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/09 00:06:15 INFO CodeGenerator: Code generated in 25.314639 ms
25/04/09 00:06:15 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.3 KiB, free 363.8 MiB)
25/04/09 00:06:15 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.8 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 3fada93ce917:35741 (size: 32.6 KiB, free: 366.2 MiB)
25/04/09 00:06:15 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/09 00:06:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/09 00:06:15 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/09 00:06:15 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
25/04/09 00:06:15 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/09 00:06:15 INFO DAGScheduler: Parents of final stage: List()
25/04/09 00:06:15 INFO DAGScheduler: Missing parents: List()
25/04/09 00:06:15 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/09 00:06:15 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.8 KiB, free 363.8 MiB)
25/04/09 00:06:15 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 363.7 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 3fada93ce917:35741 (size: 19.2 KiB, free: 366.1 MiB)
25/04/09 00:06:15 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/09 00:06:15 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
25/04/09 00:06:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks resource profile 0
25/04/09 00:06:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.9, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/09 00:06:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (172.18.0.3, executor 1, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.9:41467 (size: 19.2 KiB, free: 366.2 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.3:45339 (size: 19.2 KiB, free: 366.2 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.3:45339 (size: 963.0 B, free: 366.2 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.9:41467 (size: 963.0 B, free: 366.2 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.9:41467 (size: 32.6 KiB, free: 366.2 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.3:45339 (size: 32.6 KiB, free: 366.2 MiB)
25/04/09 00:06:15 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 483 ms on 172.18.0.9 (executor 0) (1/2)
25/04/09 00:06:15 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 555 ms on 172.18.0.3 (executor 1) (2/2)
25/04/09 00:06:15 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/09 00:06:15 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.571 s
25/04/09 00:06:15 INFO DAGScheduler: looking for newly runnable stages
25/04/09 00:06:15 INFO DAGScheduler: running: Set()
25/04/09 00:06:15 INFO DAGScheduler: waiting: Set()
25/04/09 00:06:15 INFO DAGScheduler: failed: Set()
25/04/09 00:06:15 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/09 00:06:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/09 00:06:15 INFO CodeGenerator: Code generated in 12.181207 ms
25/04/09 00:06:15 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/09 00:06:15 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/09 00:06:15 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/09 00:06:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/09 00:06:15 INFO DAGScheduler: Missing parents: List()
25/04/09 00:06:15 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/09 00:06:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 45.6 KiB, free 363.7 MiB)
25/04/09 00:06:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 21.4 KiB, free 363.7 MiB)
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 3fada93ce917:35741 (size: 21.4 KiB, free: 366.1 MiB)
25/04/09 00:06:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/09 00:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/09 00:06:15 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/09 00:06:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.3, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/09 00:06:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.3:45339 (size: 21.4 KiB, free: 366.2 MiB)
25/04/09 00:06:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.3:60794
25/04/09 00:06:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 134 ms on 172.18.0.3 (executor 1) (1/1)
25/04/09 00:06:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/09 00:06:16 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.143 s
25/04/09 00:06:16 INFO DAGScheduler: looking for newly runnable stages
25/04/09 00:06:16 INFO DAGScheduler: running: Set()
25/04/09 00:06:16 INFO DAGScheduler: waiting: Set()
25/04/09 00:06:16 INFO DAGScheduler: failed: Set()
25/04/09 00:06:16 INFO CodeGenerator: Code generated in 6.929789 ms
25/04/09 00:06:16 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/09 00:06:16 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/09 00:06:16 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/09 00:06:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/09 00:06:16 INFO DAGScheduler: Missing parents: List()
25/04/09 00:06:16 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/09 00:06:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/09 00:06:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/09 00:06:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 3fada93ce917:35741 (size: 5.5 KiB, free: 366.1 MiB)
25/04/09 00:06:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/09 00:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/09 00:06:16 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/09 00:06:16 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.18.0.3, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/09 00:06:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.3:45339 (size: 5.5 KiB, free: 366.2 MiB)
25/04/09 00:06:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.3:60794
25/04/09 00:06:16 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 29 ms on 172.18.0.3 (executor 1) (1/1)
25/04/09 00:06:16 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/09 00:06:16 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s
25/04/09 00:06:16 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/09 00:06:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/09 00:06:16 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.036036 s
25/04/09 00:06:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/09 00:06:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/09 00:06:16 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/09 00:06:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(countryid),IsNotNull(countryname)
25/04/09 00:06:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(countryid#24),isnotnull(countryname#25)
25/04/09 00:06:16 INFO FileSourceStrategy: Output Data Schema: struct<countryid: int, countryname: string>
25/04/09 00:06:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/09 00:06:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/09 00:06:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/09 00:06:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/09 00:06:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/09 00:06:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/09 00:06:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/09 00:06:16 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 349.9 KiB, free 363.3 MiB)
25/04/09 00:06:16 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 363.3 MiB)
25/04/09 00:06:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 3fada93ce917:35741 (size: 33.5 KiB, free: 366.1 MiB)
25/04/09 00:06:16 INFO SparkContext: Created broadcast 10 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/09 00:06:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/09 00:06:16 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/09 00:06:16 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/09 00:06:16 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/09 00:06:16 INFO DAGScheduler: Parents of final stage: List()
25/04/09 00:06:16 INFO DAGScheduler: Missing parents: List()
25/04/09 00:06:16 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/09 00:06:16 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.3 MiB)
25/04/09 00:06:16 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.3 MiB)
25/04/09 00:06:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 3fada93ce917:35741 (size: 6.0 KiB, free: 366.1 MiB)
25/04/09 00:06:16 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/09 00:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/09 00:06:16 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/09 00:06:16 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.18.0.12, executor 2, partition 0, ANY, 4947 bytes) taskResourceAssignments Map()
25/04/09 00:06:16 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.12:40263 (size: 6.0 KiB, free: 366.3 MiB)
25/04/09 00:06:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.12:40263 (size: 33.5 KiB, free: 366.3 MiB)
25/04/09 00:06:18 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 1826 ms on 172.18.0.12 (executor 2) (1/1)
25/04/09 00:06:18 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/09 00:06:18 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.831 s
25/04/09 00:06:18 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/09 00:06:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/09 00:06:18 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.833148 s
25/04/09 00:06:18 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 1025.0 KiB, free 362.3 MiB)
25/04/09 00:06:18 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 963.0 B, free 362.3 MiB)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 3fada93ce917:35741 (size: 963.0 B, free: 366.1 MiB)
25/04/09 00:06:18 INFO SparkContext: Created broadcast 12 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/09 00:06:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(CountryID)
25/04/09 00:06:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(CountryID#16),isnotnull(cast(CountryID#16 as int))
25/04/09 00:06:18 INFO FileSourceStrategy: Output Data Schema: struct<CountryID: string, CountryName: string>
25/04/09 00:06:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/09 00:06:18 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 345.3 KiB, free 361.9 MiB)
25/04/09 00:06:18 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 361.9 MiB)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 3fada93ce917:35741 (size: 32.6 KiB, free: 366.0 MiB)
25/04/09 00:06:18 INFO SparkContext: Created broadcast 13 from insertInto at NativeMethodAccessorImpl.java:0
25/04/09 00:06:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/09 00:06:18 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/09 00:06:18 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 2 output partitions
25/04/09 00:06:18 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/09 00:06:18 INFO DAGScheduler: Parents of final stage: List()
25/04/09 00:06:18 INFO DAGScheduler: Missing parents: List()
25/04/09 00:06:18 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/09 00:06:18 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 40.8 KiB, free 361.9 MiB)
25/04/09 00:06:18 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 361.8 MiB)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 3fada93ce917:35741 (size: 19.2 KiB, free: 366.0 MiB)
25/04/09 00:06:18 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/09 00:06:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
25/04/09 00:06:18 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0
25/04/09 00:06:18 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (172.18.0.9, executor 0, partition 0, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/09 00:06:18 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 8) (172.18.0.12, executor 2, partition 1, ANY, 4887 bytes) taskResourceAssignments Map()
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.9:41467 (size: 19.2 KiB, free: 366.2 MiB)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.12:40263 (size: 19.2 KiB, free: 366.2 MiB)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.9:41467 (size: 963.0 B, free: 366.2 MiB)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.9:41467 (size: 32.6 KiB, free: 366.2 MiB)
25/04/09 00:06:18 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 62 ms on 172.18.0.9 (executor 0) (1/2)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.12:40263 (size: 963.0 B, free: 366.2 MiB)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.12:40263 (size: 32.6 KiB, free: 366.2 MiB)
25/04/09 00:06:18 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 8) in 438 ms on 172.18.0.12 (executor 2) (2/2)
25/04/09 00:06:18 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/09 00:06:18 INFO DAGScheduler: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.442 s
25/04/09 00:06:18 INFO DAGScheduler: looking for newly runnable stages
25/04/09 00:06:18 INFO DAGScheduler: running: Set()
25/04/09 00:06:18 INFO DAGScheduler: waiting: Set()
25/04/09 00:06:18 INFO DAGScheduler: failed: Set()
25/04/09 00:06:18 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/09 00:06:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/09 00:06:18 INFO CodeGenerator: Code generated in 10.931245 ms
25/04/09 00:06:18 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/09 00:06:18 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/09 00:06:18 INFO DAGScheduler: Final stage: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/09 00:06:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/09 00:06:18 INFO DAGScheduler: Missing parents: List()
25/04/09 00:06:18 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/09 00:06:18 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 236.4 KiB, free 361.6 MiB)
25/04/09 00:06:18 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 87.9 KiB, free 361.5 MiB)
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 3fada93ce917:35741 (size: 87.9 KiB, free: 365.9 MiB)
25/04/09 00:06:18 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/09 00:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/09 00:06:18 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/09 00:06:18 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 9) (172.18.0.12, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/09 00:06:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.12:40263 (size: 87.9 KiB, free: 366.1 MiB)
25/04/09 00:06:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.12:59094
25/04/09 00:06:18 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 9) in 322 ms on 172.18.0.12 (executor 2) (1/1)
25/04/09 00:06:18 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/09 00:06:18 INFO DAGScheduler: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.334 s
25/04/09 00:06:18 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/09 00:06:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/09 00:06:18 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.338802 s
25/04/09 00:06:18 INFO FileFormatWriter: Start to commit write Job 9c0daaec-a657-4623-bd05-23b69ef8c4af.
25/04/09 00:06:19 INFO FileFormatWriter: Write Job 9c0daaec-a657-4623-bd05-23b69ef8c4af committed. Elapsed time: 35 ms.
25/04/09 00:06:19 INFO FileFormatWriter: Finished processing stats for write job 9c0daaec-a657-4623-bd05-23b69ef8c4af.
25/04/09 00:06:19 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/09 00:06:19 INFO SparkUI: Stopped Spark web UI at http://3fada93ce917:4041
25/04/09 00:06:19 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/09 00:06:19 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/09 00:06:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/09 00:06:19 INFO MemoryStore: MemoryStore cleared
25/04/09 00:06:19 INFO BlockManager: BlockManager stopped
25/04/09 00:06:19 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/09 00:06:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/09 00:06:19 INFO SparkContext: Successfully stopped SparkContext
25/04/09 00:06:19 INFO ShutdownHookManager: Shutdown hook called
25/04/09 00:06:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-f928fb63-e740-4337-a0ae-1057921eb9ad
25/04/09 00:06:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-8dcd0d66-04c5-4ce1-bb30-a0dcc4a5b9e5
25/04/09 00:06:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-8dcd0d66-04c5-4ce1-bb30-a0dcc4a5b9e5/pyspark-fd2b73ed-2131-4c9c-9460-69006ae1b7da
Spark job completed successfully.
