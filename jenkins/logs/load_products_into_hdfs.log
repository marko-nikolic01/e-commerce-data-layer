Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:21:24 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:21:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:21:24 INFO ResourceUtils: ==============================================================
25/04/01 10:21:24 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:21:24 INFO ResourceUtils: ==============================================================
25/04/01 10:21:24 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 10:21:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:21:24 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:21:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:21:24 INFO SecurityManager: Changing view acls to: root
25/04/01 10:21:24 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:21:24 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:21:24 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:21:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:21:24 INFO Utils: Successfully started service 'sparkDriver' on port 42317.
25/04/01 10:21:24 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:21:24 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:21:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:21:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:21:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:21:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-642a7f94-5df3-4b48-8927-1821b2e2d021
25/04/01 10:21:25 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:21:25 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:21:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/01 10:21:25 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/01 10:21:25 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://67da0ec00716:4041
25/04/01 10:21:25 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:21:25 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.4:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 10:21:25 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401102125-0035
25/04/01 10:21:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36569.
25/04/01 10:21:25 INFO NettyBlockTransferService: Server created on 67da0ec00716:36569
25/04/01 10:21:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:21:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 67da0ec00716, 36569, None)
25/04/01 10:21:25 INFO BlockManagerMasterEndpoint: Registering block manager 67da0ec00716:36569 with 366.3 MiB RAM, BlockManagerId(driver, 67da0ec00716, 36569, None)
25/04/01 10:21:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 67da0ec00716, 36569, None)
25/04/01 10:21:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 67da0ec00716, 36569, None)
25/04/01 10:21:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:21:25 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:21:25 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:21:26 INFO InMemoryFileIndex: It took 54 ms to list leaf files for 1 paths.
25/04/01 10:21:26 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 10:21:28 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:28 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:21:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:21:29 INFO CodeGenerator: Code generated in 153.813896 ms
25/04/01 10:21:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:21:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:21:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 67da0ec00716:36569 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:21:29 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:21:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:29 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:21:29 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:21:29 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:29 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:21:29 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:29 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:21:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:21:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 67da0ec00716:36569 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:21:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:21:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401102125-0035/0 on worker-20250331112639-172.18.0.8-44535 (172.18.0.8:44535) with 4 core(s)
25/04/01 10:21:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401102125-0035/0 on hostPort 172.18.0.8:44535 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:21:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401102125-0035/1 on worker-20250331112639-172.18.0.12-35967 (172.18.0.12:35967) with 4 core(s)
25/04/01 10:21:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401102125-0035/1 on hostPort 172.18.0.12:35967 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:21:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401102125-0035/2 on worker-20250331112639-172.18.0.3-42795 (172.18.0.3:42795) with 4 core(s)
25/04/01 10:21:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401102125-0035/2 on hostPort 172.18.0.3:42795 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:21:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401102125-0035/2 is now RUNNING
25/04/01 10:21:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401102125-0035/1 is now RUNNING
25/04/01 10:21:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401102125-0035/0 is now RUNNING
25/04/01 10:21:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:47560) with ID 0,  ResourceProfileId 0
25/04/01 10:21:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.12:55418) with ID 1,  ResourceProfileId 0
25/04/01 10:21:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.3:35678) with ID 2,  ResourceProfileId 0
25/04/01 10:21:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.3:46327 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.3, 46327, None)
25/04/01 10:21:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.12:39727 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.12, 39727, None)
25/04/01 10:21:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:37813 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 37813, None)
25/04/01 10:21:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.12, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:21:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.12:39727 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:21:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.12:39727 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:21:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1366 ms on 172.18.0.12 (executor 1) (1/1)
25/04/01 10:21:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:21:37 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 8.051 s
25/04/01 10:21:37 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:21:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:21:37 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 8.085181 s
25/04/01 10:21:37 INFO CodeGenerator: Code generated in 7.827466 ms
25/04/01 10:21:37 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:37 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:21:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:21:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:21:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:21:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 67da0ec00716:36569 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:21:37 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:21:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 10:21:37 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:21:37 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:21:37 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:21:37 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:21:37 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:21:37 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:21:37 INFO metastore: Connected to metastore.
25/04/01 10:21:38 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=268a333d-d15c-4cd3-9fb6-12e42db45a4b, clientType=HIVECLI]
25/04/01 10:21:38 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:21:38 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:21:38 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:21:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:21:38 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:21:38 INFO metastore: Connected to metastore.
25/04/01 10:21:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:21:38 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:21:38 INFO metastore: Connected to metastore.
25/04/01 10:21:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 67da0ec00716:36569 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:21:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.12:39727 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:21:38 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 10:21:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:21:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:21:38 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:21:38 INFO DataSourceStrategy: Pruning directories with: isnotnull(Date#40)
25/04/01 10:21:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(StockCode)
25/04/01 10:21:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 10:21:38 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string>
25/04/01 10:21:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:21:38 INFO CodeGenerator: Code generated in 19.383375 ms
25/04/01 10:21:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:21:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 67da0ec00716:36569 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:21:38 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:21:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:21:38 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:21:38 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:21:38 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 10:21:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 67da0ec00716:36569 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:21:38 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 10:21:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.12, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:21:38 INFO CodeGenerator: Code generated in 27.256937 ms
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.12:39727 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:21:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 10:21:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 67da0ec00716:36569 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:21:38 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:21:38 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 10:21:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:21:38 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 10:21:38 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
25/04/01 10:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:21:38 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:38 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 32.2 KiB, free 364.7 MiB)
25/04/01 10:21:38 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 364.7 MiB)
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 67da0ec00716:36569 (size: 14.3 KiB, free: 366.1 MiB)
25/04/01 10:21:38 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
25/04/01 10:21:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks resource profile 0
25/04/01 10:21:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.3, executor 2, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 10:21:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (172.18.0.12, executor 1, partition 1, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.12:39727 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.12:39727 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.12:39727 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:21:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.3:46327 (size: 14.3 KiB, free: 366.3 MiB)
25/04/01 10:21:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 465 ms on 172.18.0.12 (executor 1) (1/1)
25/04/01 10:21:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:21:39 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.479 s
25/04/01 10:21:39 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:21:39 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
25/04/01 10:21:39 INFO DAGScheduler: waiting: Set()
25/04/01 10:21:39 INFO DAGScheduler: failed: Set()
25/04/01 10:21:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 913 ms on 172.18.0.12 (executor 1) (1/2)
25/04/01 10:21:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.3:46327 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 10:21:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2292 ms on 172.18.0.3 (executor 2) (2/2)
25/04/01 10:21:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 10:21:41 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 2.299 s
25/04/01 10:21:41 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:21:41 INFO DAGScheduler: running: Set()
25/04/01 10:21:41 INFO DAGScheduler: waiting: Set()
25/04/01 10:21:41 INFO DAGScheduler: failed: Set()
25/04/01 10:21:41 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:21:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:21:41 INFO CodeGenerator: Code generated in 12.727088 ms
25/04/01 10:21:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:21:41 INFO DAGScheduler: Got job 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 10:21:41 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 10:21:41 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:41 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:21:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 10:21:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 364.7 MiB)
25/04/01 10:21:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 67da0ec00716:36569 (size: 15.8 KiB, free: 366.1 MiB)
25/04/01 10:21:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:41 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 10:21:41 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.3, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:21:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.3:46327 (size: 15.8 KiB, free: 366.2 MiB)
25/04/01 10:21:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.3:35678
25/04/01 10:21:41 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 245 ms on 172.18.0.3 (executor 2) (1/1)
25/04/01 10:21:41 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 10:21:41 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.253 s
25/04/01 10:21:41 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 10:21:41 INFO DAGScheduler: Job 3 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.267542 s
25/04/01 10:21:41 INFO CodeGenerator: Code generated in 6.305121 ms
25/04/01 10:21:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1040.0 KiB, free 363.7 MiB)
25/04/01 10:21:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 363.7 MiB)
25/04/01 10:21:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 67da0ec00716:36569 (size: 5.8 KiB, free: 366.1 MiB)
25/04/01 10:21:41 INFO SparkContext: Created broadcast 8 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:21:41 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:21:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:21:41 INFO CodeGenerator: Code generated in 16.055337 ms
25/04/01 10:21:41 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 10:21:41 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 10:21:41 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:41 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 53.3 KiB, free 363.6 MiB)
25/04/01 10:21:41 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 363.6 MiB)
25/04/01 10:21:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 67da0ec00716:36569 (size: 23.6 KiB, free: 366.1 MiB)
25/04/01 10:21:41 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 10:21:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.18.0.12, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:21:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.12:39727 (size: 23.6 KiB, free: 366.2 MiB)
25/04/01 10:21:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.12:55418
25/04/01 10:21:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.12:39727 (size: 5.8 KiB, free: 366.1 MiB)
25/04/01 10:21:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 191 ms on 172.18.0.12 (executor 1) (1/1)
25/04/01 10:21:41 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 10:21:41 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.200 s
25/04/01 10:21:41 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:21:41 INFO DAGScheduler: running: Set()
25/04/01 10:21:41 INFO DAGScheduler: waiting: Set()
25/04/01 10:21:41 INFO DAGScheduler: failed: Set()
25/04/01 10:21:41 INFO CodeGenerator: Code generated in 6.161875 ms
25/04/01 10:21:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:21:41 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:21:41 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 10:21:41 INFO DAGScheduler: Missing parents: List()
25/04/01 10:21:41 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:21:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.0 KiB, free 363.6 MiB)
25/04/01 10:21:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.6 MiB)
25/04/01 10:21:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 67da0ec00716:36569 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:21:41 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 10:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:21:41 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 10:21:41 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (172.18.0.12, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:21:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.12:39727 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:21:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.12:55418
25/04/01 10:21:41 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 30 ms on 172.18.0.12 (executor 1) (1/1)
25/04/01 10:21:41 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 10:21:41 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.036 s
25/04/01 10:21:41 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 10:21:41 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.039774 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 76, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'UnitPrice': string to decimal(10,5)
25/04/01 10:21:41 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:21:41 INFO SparkUI: Stopped Spark web UI at http://67da0ec00716:4041
25/04/01 10:21:41 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:21:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:21:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:21:41 INFO MemoryStore: MemoryStore cleared
25/04/01 10:21:41 INFO BlockManager: BlockManager stopped
25/04/01 10:21:41 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:21:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:21:41 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:21:41 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:21:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-8e5f1a53-9a21-4806-aca0-a0c7430431e6/pyspark-a97380c2-8e46-4301-ae38-69544b8c4f69
25/04/01 10:21:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-3335bbc9-0a06-4374-956b-019922d5a5dc
25/04/01 10:21:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-8e5f1a53-9a21-4806-aca0-a0c7430431e6
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:37:21 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:37:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:37:22 INFO ResourceUtils: ==============================================================
25/04/01 10:37:22 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:37:22 INFO ResourceUtils: ==============================================================
25/04/01 10:37:22 INFO SparkContext: Submitted application: Load products data into Hive
25/04/01 10:37:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:37:22 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:37:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:37:22 INFO SecurityManager: Changing view acls to: root
25/04/01 10:37:22 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:37:22 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:37:22 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:37:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:37:22 INFO Utils: Successfully started service 'sparkDriver' on port 44413.
25/04/01 10:37:22 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:37:22 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:37:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:37:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:37:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:37:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a2c18e9f-b3f3-4fed-81ff-21f0b2f98349
25/04/01 10:37:22 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:37:22 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:37:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:37:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 10:37:22 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:37:22 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 25 ms (0 ms spent in bootstraps)
25/04/01 10:37:22 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401103722-0000
25/04/01 10:37:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40535.
25/04/01 10:37:22 INFO NettyBlockTransferService: Server created on 7796893c36d7:40535
25/04/01 10:37:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:37:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 40535, None)
25/04/01 10:37:22 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:40535 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 40535, None)
25/04/01 10:37:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 40535, None)
25/04/01 10:37:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 40535, None)
25/04/01 10:37:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401103722-0000/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:37:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401103722-0000/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:37:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401103722-0000/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:37:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401103722-0000/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:37:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401103722-0000/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:37:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401103722-0000/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:37:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401103722-0000/1 is now RUNNING
25/04/01 10:37:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401103722-0000/2 is now RUNNING
25/04/01 10:37:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401103722-0000/0 is now RUNNING
25/04/01 10:37:23 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:37:23 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:37:23 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:37:25 INFO InMemoryFileIndex: It took 98 ms to list leaf files for 1 paths.
25/04/01 10:37:25 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/04/01 10:37:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:45684) with ID 0,  ResourceProfileId 0
25/04/01 10:37:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:45150) with ID 2,  ResourceProfileId 0
25/04/01 10:37:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:50570) with ID 1,  ResourceProfileId 0
25/04/01 10:37:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:45065 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 45065, None)
25/04/01 10:37:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:45015 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 45015, None)
25/04/01 10:37:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:43579 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 43579, None)
25/04/01 10:37:27 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:37:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:37:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:37:27 INFO CodeGenerator: Code generated in 165.323499 ms
25/04/01 10:37:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:37:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.9 MiB)
25/04/01 10:37:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:40535 (size: 32.5 KiB, free: 366.3 MiB)
25/04/01 10:37:27 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:37:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:37:27 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:37:27 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:37:27 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:37:27 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:37:27 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:37:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:37:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:37:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:40535 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:37:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:37:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:37:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:37:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:45065 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:37:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:45065 (size: 32.5 KiB, free: 366.3 MiB)
25/04/01 10:37:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1711 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:37:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:37:29 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.791 s
25/04/01 10:37:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:37:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:37:29 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.827757 s
25/04/01 10:37:29 INFO CodeGenerator: Code generated in 12.384304 ms
25/04/01 10:37:29 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:37:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:37:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:37:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:37:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.5 MiB)
25/04/01 10:37:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:40535 (size: 32.5 KiB, free: 366.2 MiB)
25/04/01 10:37:29 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:37:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:37:29 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:37:29 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:37:29 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:37:30 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:37:30 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:37:30 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:37:30 INFO metastore: Connected to metastore.
25/04/01 10:37:30 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=14a8f47b-9ad0-43da-96c6-656723639701, clientType=HIVECLI]
25/04/01 10:37:30 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:37:30 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:37:30 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:37:30 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:37:30 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:37:30 INFO metastore: Connected to metastore.
25/04/01 10:37:30 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:37:30 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:37:30 INFO metastore: Connected to metastore.
25/04/01 10:37:31 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 10:37:31 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:37:31 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:37:31 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:37:31 INFO DataSourceStrategy: Pruning directories with: isnotnull(Date#40)
25/04/01 10:37:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(StockCode)
25/04/01 10:37:31 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 10:37:31 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string>
25/04/01 10:37:31 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:37:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:40535 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:37:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:45065 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:37:31 INFO CodeGenerator: Code generated in 26.176971 ms
25/04/01 10:37:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 10:37:31 INFO CodeGenerator: Code generated in 33.745463 ms
25/04/01 10:37:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:40535 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:37:31 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:37:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 10:37:31 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 10:37:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:37:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:40535 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:37:31 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:37:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:37:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:37:31 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 2 output partitions
25/04/01 10:37:31 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:37:31 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:37:31 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:31 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:37:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.7 KiB, free 364.8 MiB)
25/04/01 10:37:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 364.8 MiB)
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:40535 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 10:37:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1))
25/04/01 10:37:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0
25/04/01 10:37:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 10:37:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.2, executor 0, partition 1, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 10:37:31 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:37:31 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:37:31 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:37:31 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:37:31 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:31 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:45065 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 10:37:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 29.9 KiB, free 364.8 MiB)
25/04/01 10:37:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.8 MiB)
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:40535 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:37:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:37:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 10:37:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:45065 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:45065 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:45015 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 10:37:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:45065 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:37:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 640 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:37:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 10:37:32 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.659 s
25/04/01 10:37:32 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:37:32 INFO DAGScheduler: running: Set(ResultStage 1)
25/04/01 10:37:32 INFO DAGScheduler: waiting: Set()
25/04/01 10:37:32 INFO DAGScheduler: failed: Set()
25/04/01 10:37:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 856 ms on 172.18.0.2 (executor 0) (1/2)
25/04/01 10:37:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:45015 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 10:37:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2369 ms on 172.18.0.6 (executor 2) (2/2)
25/04/01 10:37:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:37:33 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.375 s
25/04/01 10:37:33 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:37:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 10:37:33 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.378887 s
25/04/01 10:37:33 INFO CodeGenerator: Code generated in 8.997947 ms
25/04/01 10:37:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1040.0 KiB, free 363.7 MiB)
25/04/01 10:37:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 363.7 MiB)
25/04/01 10:37:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:40535 (size: 12.3 KiB, free: 366.1 MiB)
25/04/01 10:37:33 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:37:33 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:37:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:37:33 INFO CodeGenerator: Code generated in 21.149747 ms
25/04/01 10:37:33 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 10:37:33 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:37:33 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:37:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 10:37:33 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:33 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:37:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 48.1 KiB, free 363.7 MiB)
25/04/01 10:37:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 363.7 MiB)
25/04/01 10:37:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:40535 (size: 22.3 KiB, free: 366.1 MiB)
25/04/01 10:37:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:37:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 10:37:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:37:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:45065 (size: 22.3 KiB, free: 366.2 MiB)
25/04/01 10:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:45684
25/04/01 10:37:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:45065 (size: 12.3 KiB, free: 366.2 MiB)
25/04/01 10:37:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 202 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:37:34 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 10:37:34 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.213 s
25/04/01 10:37:34 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:37:34 INFO DAGScheduler: running: Set()
25/04/01 10:37:34 INFO DAGScheduler: waiting: Set()
25/04/01 10:37:34 INFO DAGScheduler: failed: Set()
25/04/01 10:37:34 INFO CodeGenerator: Code generated in 6.865114 ms
25/04/01 10:37:34 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:37:34 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:37:34 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:37:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 10:37:34 INFO DAGScheduler: Missing parents: List()
25/04/01 10:37:34 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:37:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.6 MiB)
25/04/01 10:37:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.6 MiB)
25/04/01 10:37:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:40535 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:37:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 10:37:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:37:34 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 10:37:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:37:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:45065 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:37:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:45684
25/04/01 10:37:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 28 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:37:34 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 10:37:34 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s
25/04/01 10:37:34 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:37:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 10:37:34 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.037925 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 68, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'UnitPrice': string to decimal(10,5)
25/04/01 10:37:34 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:37:34 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 10:37:34 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:37:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:37:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:37:34 INFO MemoryStore: MemoryStore cleared
25/04/01 10:37:34 INFO BlockManager: BlockManager stopped
25/04/01 10:37:34 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:37:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:37:34 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:37:34 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:37:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-604b5769-4dd9-4b22-ae84-d81aa033139d/pyspark-e1c95f31-9dd7-48fd-8128-73862278f356
25/04/01 10:37:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-604b5769-4dd9-4b22-ae84-d81aa033139d
25/04/01 10:37:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-23e4eeef-cd7f-4004-8ad3-76e4c3fc0579
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:42:33 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:42:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:42:33 INFO ResourceUtils: ==============================================================
25/04/01 10:42:33 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:42:33 INFO ResourceUtils: ==============================================================
25/04/01 10:42:33 INFO SparkContext: Submitted application: Load products data into Hive
25/04/01 10:42:34 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:42:34 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:42:34 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:42:34 INFO SecurityManager: Changing view acls to: root
25/04/01 10:42:34 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:42:34 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:42:34 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:42:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:42:34 INFO Utils: Successfully started service 'sparkDriver' on port 46641.
25/04/01 10:42:34 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:42:34 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:42:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:42:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:42:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:42:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d0604bdb-e6b6-4187-bd4e-a635b1939eb0
25/04/01 10:42:34 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:42:34 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:42:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:42:34 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 10:42:34 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:42:34 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 10:42:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401104234-0002
25/04/01 10:42:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104234-0002/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:42:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104234-0002/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:42:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104234-0002/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:42:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104234-0002/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:42:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104234-0002/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:42:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104234-0002/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:42:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32903.
25/04/01 10:42:34 INFO NettyBlockTransferService: Server created on 7796893c36d7:32903
25/04/01 10:42:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:42:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 32903, None)
25/04/01 10:42:34 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:32903 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 32903, None)
25/04/01 10:42:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 32903, None)
25/04/01 10:42:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 32903, None)
25/04/01 10:42:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104234-0002/0 is now RUNNING
25/04/01 10:42:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104234-0002/2 is now RUNNING
25/04/01 10:42:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104234-0002/1 is now RUNNING
25/04/01 10:42:34 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:42:35 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:42:35 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:42:36 INFO InMemoryFileIndex: It took 62 ms to list leaf files for 1 paths.
25/04/01 10:42:36 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 4 paths.
25/04/01 10:42:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:48968) with ID 0,  ResourceProfileId 0
25/04/01 10:42:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:38296) with ID 2,  ResourceProfileId 0
25/04/01 10:42:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:39642) with ID 1,  ResourceProfileId 0
25/04/01 10:42:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:34911 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 34911, None)
25/04/01 10:42:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:33777 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 33777, None)
25/04/01 10:42:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:33517 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 33517, None)
25/04/01 10:42:37 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:42:37 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:42:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:42:38 INFO CodeGenerator: Code generated in 132.167223 ms
25/04/01 10:42:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:42:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.9 MiB)
25/04/01 10:42:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:32903 (size: 32.5 KiB, free: 366.3 MiB)
25/04/01 10:42:38 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:42:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:42:38 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:42:38 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:42:38 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:42:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:42:38 INFO DAGScheduler: Missing parents: List()
25/04/01 10:42:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:42:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:42:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:42:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:32903 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:42:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:42:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:42:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:42:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:42:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:33777 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:42:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:33777 (size: 32.5 KiB, free: 366.3 MiB)
25/04/01 10:42:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1338 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 10:42:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:42:39 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.401 s
25/04/01 10:42:39 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:42:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:42:39 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.431378 s
25/04/01 10:42:39 INFO CodeGenerator: Code generated in 7.682684 ms
25/04/01 10:42:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:42:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:42:39 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:42:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:42:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.5 MiB)
25/04/01 10:42:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:32903 (size: 32.5 KiB, free: 366.2 MiB)
25/04/01 10:42:39 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:42:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:42:40 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:42:40 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:42:40 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:42:40 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:42:40 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:42:40 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:42:40 INFO metastore: Connected to metastore.
25/04/01 10:42:40 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=de5afcbe-4aaa-4a86-b8c2-c338c85784ba, clientType=HIVECLI]
25/04/01 10:42:40 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:42:40 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:42:40 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:42:40 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:42:40 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:42:40 INFO metastore: Connected to metastore.
25/04/01 10:42:40 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:42:40 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:42:40 INFO metastore: Connected to metastore.
25/04/01 10:42:40 WARN HadoopFSUtils: The directory hdfs://namenode:9000/user/hive/warehouse/products/Date=2025-03-27 was not found. Was it deleted very recently?
25/04/01 10:42:40 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 10:42:41 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:42:41 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:42:41 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:42:41 INFO DataSourceStrategy: Pruning directories with: isnotnull(Date#40)
25/04/01 10:42:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(StockCode)
25/04/01 10:42:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 10:42:41 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string>
25/04/01 10:42:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:42:41 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:32903 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:42:41 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:33777 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:42:41 INFO CodeGenerator: Code generated in 24.051401 ms
25/04/01 10:42:41 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 10:42:41 INFO CodeGenerator: Code generated in 27.895432 ms
25/04/01 10:42:41 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.6 KiB, free 364.9 MiB)
25/04/01 10:42:41 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 10:42:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:32903 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:42:41 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:42:41 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 10:42:41 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:32903 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:42:41 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:42:41 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 10:42:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:42:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:42:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:42:41 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000218 s
25/04/01 10:42:41 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 24.0 B, free 364.8 MiB)
25/04/01 10:42:41 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.8 MiB)
25/04/01 10:42:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:32903 (size: 120.0 B, free: 366.2 MiB)
25/04/01 10:42:41 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:42:41 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:42:41 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/04/01 10:42:41 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:42:41 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:42:41 INFO DAGScheduler: Missing parents: List()
25/04/01 10:42:41 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:42:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 29.9 KiB, free 364.8 MiB)
25/04/01 10:42:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.8 MiB)
25/04/01 10:42:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:32903 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:42:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:42:41 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/04/01 10:42:41 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
25/04/01 10:42:41 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:42:41 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.2, executor 0, partition 1, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:42:41 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.8, executor 1, partition 2, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:42:41 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.6, executor 2, partition 3, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:42:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:33777 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:42:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:33517 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:42:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:34911 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:42:41 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:33777 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:42:41 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 446 ms on 172.18.0.8 (executor 1) (1/4)
25/04/01 10:42:42 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:33517 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:42:42 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:34911 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:42:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1844 ms on 172.18.0.2 (executor 0) (2/4)
25/04/01 10:42:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1875 ms on 172.18.0.6 (executor 2) (3/4)
25/04/01 10:42:43 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1874 ms on 172.18.0.6 (executor 2) (4/4)
25/04/01 10:42:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:42:43 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.888 s
25/04/01 10:42:43 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:42:43 INFO DAGScheduler: running: Set()
25/04/01 10:42:43 INFO DAGScheduler: waiting: Set()
25/04/01 10:42:43 INFO DAGScheduler: failed: Set()
25/04/01 10:42:43 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:42:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:42:43 INFO CodeGenerator: Code generated in 15.464613 ms
25/04/01 10:42:43 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 10:42:43 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:42:43 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:42:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 10:42:43 INFO DAGScheduler: Missing parents: List()
25/04/01 10:42:43 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:42:43 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 10:42:43 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 10:42:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:32903 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 10:42:43 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 10:42:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:42:43 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 10:42:43 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:42:43 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:34911 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 10:42:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:38296
25/04/01 10:42:43 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 170 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:42:43 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 10:42:43 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.180 s
25/04/01 10:42:43 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:42:43 INFO DAGScheduler: running: Set()
25/04/01 10:42:43 INFO DAGScheduler: waiting: Set()
25/04/01 10:42:43 INFO DAGScheduler: failed: Set()
25/04/01 10:42:43 INFO CodeGenerator: Code generated in 6.719563 ms
25/04/01 10:42:43 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:42:43 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:42:43 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:42:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 10:42:43 INFO DAGScheduler: Missing parents: List()
25/04/01 10:42:43 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:42:43 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 10:42:43 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 10:42:43 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:32903 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:42:43 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:42:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:42:43 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 10:42:43 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:42:43 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:34911 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:42:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:38296
25/04/01 10:42:43 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 76 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:42:43 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 10:42:43 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.081 s
25/04/01 10:42:43 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:42:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 10:42:43 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.083772 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 68, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'UnitPrice': string to decimal(10,5)
25/04/01 10:42:43 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:42:43 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 10:42:43 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:42:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:42:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:42:43 INFO MemoryStore: MemoryStore cleared
25/04/01 10:42:43 INFO BlockManager: BlockManager stopped
25/04/01 10:42:43 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:42:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:42:43 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:42:43 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:42:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-3b11ad02-5ed2-4111-a408-839f31fcd749/pyspark-2292b502-8400-42e8-a471-d89039f3b9e7
25/04/01 10:42:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-3b11ad02-5ed2-4111-a408-839f31fcd749
25/04/01 10:42:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-a132186e-242c-43f0-beca-b7d1189c06b0
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:43:57 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:43:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:43:57 INFO ResourceUtils: ==============================================================
25/04/01 10:43:57 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:43:57 INFO ResourceUtils: ==============================================================
25/04/01 10:43:57 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 10:43:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:43:57 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:43:57 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:43:57 INFO SecurityManager: Changing view acls to: root
25/04/01 10:43:57 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:43:57 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:43:57 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:43:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:43:57 INFO Utils: Successfully started service 'sparkDriver' on port 36677.
25/04/01 10:43:57 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:43:57 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:43:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:43:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:43:57 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:43:57 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8959535b-c1c4-4ead-a94c-9a35bdd02a37
25/04/01 10:43:57 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:43:57 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:43:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:43:57 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 10:43:58 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:43:58 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 10:43:58 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401104358-0003
25/04/01 10:43:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104358-0003/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:43:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104358-0003/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:43:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104358-0003/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:43:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104358-0003/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:43:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104358-0003/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:43:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104358-0003/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:43:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38337.
25/04/01 10:43:58 INFO NettyBlockTransferService: Server created on 7796893c36d7:38337
25/04/01 10:43:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:43:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 38337, None)
25/04/01 10:43:58 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:38337 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 38337, None)
25/04/01 10:43:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 38337, None)
25/04/01 10:43:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 38337, None)
25/04/01 10:43:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104358-0003/0 is now RUNNING
25/04/01 10:43:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104358-0003/2 is now RUNNING
25/04/01 10:43:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104358-0003/1 is now RUNNING
25/04/01 10:43:58 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:43:58 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:43:58 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:43:59 INFO InMemoryFileIndex: It took 69 ms to list leaf files for 1 paths.
25/04/01 10:43:59 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 4 paths.
25/04/01 10:43:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:60500) with ID 0,  ResourceProfileId 0
25/04/01 10:43:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:53078) with ID 2,  ResourceProfileId 0
25/04/01 10:43:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:46484) with ID 1,  ResourceProfileId 0
25/04/01 10:43:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:38905 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 38905, None)
25/04/01 10:43:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:36629 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 36629, None)
25/04/01 10:43:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:37511 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 37511, None)
25/04/01 10:44:01 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:44:01 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:44:01 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:44:01 INFO CodeGenerator: Code generated in 136.360953 ms
25/04/01 10:44:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:44:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:44:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:38337 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:44:01 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:44:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:44:01 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:44:01 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:44:01 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:44:01 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:44:01 INFO DAGScheduler: Missing parents: List()
25/04/01 10:44:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:44:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:44:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:44:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:38337 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:44:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:44:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:44:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:44:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:44:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:37511 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:44:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:37511 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:44:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1344 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:44:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:44:03 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.408 s
25/04/01 10:44:03 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:44:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:44:03 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.437509 s
25/04/01 10:44:03 INFO CodeGenerator: Code generated in 7.982376 ms
25/04/01 10:44:03 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:44:03 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:44:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:44:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:44:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:44:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:38337 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:44:03 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:44:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 10:44:03 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:44:03 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:44:03 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:44:03 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:44:03 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:44:03 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:44:03 INFO metastore: Connected to metastore.
25/04/01 10:44:03 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=975df27b-5395-4701-aae5-311203c38b07, clientType=HIVECLI]
25/04/01 10:44:03 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:44:03 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:44:03 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:44:04 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:44:04 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:44:04 INFO metastore: Connected to metastore.
25/04/01 10:44:04 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:44:04 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:44:04 INFO metastore: Connected to metastore.
25/04/01 10:44:04 WARN HadoopFSUtils: The directory hdfs://namenode:9000/user/hive/warehouse/products/Date=2025-03-27 was not found. Was it deleted very recently?
25/04/01 10:44:04 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 10:44:04 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:44:04 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:44:04 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:44:04 INFO DataSourceStrategy: Pruning directories with: isnotnull(Date#40)
25/04/01 10:44:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(StockCode)
25/04/01 10:44:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 10:44:04 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string>
25/04/01 10:44:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:38337 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:37511 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:44:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:44:04 INFO CodeGenerator: Code generated in 19.530532 ms
25/04/01 10:44:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:44:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:38337 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:44:04 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:44:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:44:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:44:04 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:44:04 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/04/01 10:44:04 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:44:04 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:44:04 INFO DAGScheduler: Missing parents: List()
25/04/01 10:44:04 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:44:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 10:44:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:38337 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:44:04 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:44:04 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/04/01 10:44:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
25/04/01 10:44:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:44:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.6, executor 2, partition 1, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:44:04 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.2, executor 0, partition 2, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:44:04 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.8, executor 1, partition 3, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:44:04 INFO CodeGenerator: Code generated in 25.917229 ms
25/04/01 10:44:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:37511 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:44:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:38337 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:44:04 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:44:04 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 10:44:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:44:04 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:44:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:44:04 INFO CodeGenerator: Code generated in 24.273917 ms
25/04/01 10:44:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:44:04 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 10:44:04 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 10:44:04 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:44:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 10:44:04 INFO DAGScheduler: Missing parents: List()
25/04/01 10:44:04 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:44:04 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 10:44:04 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 364.7 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:38337 (size: 15.8 KiB, free: 366.1 MiB)
25/04/01 10:44:04 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:44:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 10:44:04 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 10:44:04 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5) (172.18.0.2, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:38905 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:38905 (size: 15.8 KiB, free: 366.3 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:36629 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:44:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:37511 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:44:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 518 ms on 172.18.0.6 (executor 2) (1/4)
25/04/01 10:44:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:60500
25/04/01 10:44:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 894 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:44:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 10:44:05 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.910 s
25/04/01 10:44:05 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:44:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 10:44:05 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.916730 s
25/04/01 10:44:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 10:44:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 10:44:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:38337 (size: 120.0 B, free: 366.1 MiB)
25/04/01 10:44:05 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:44:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:38905 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:44:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:36629 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:44:06 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1848 ms on 172.18.0.2 (executor 0) (2/4)
25/04/01 10:44:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1997 ms on 172.18.0.8 (executor 1) (3/4)
25/04/01 10:44:06 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 1996 ms on 172.18.0.8 (executor 1) (4/4)
25/04/01 10:44:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:44:06 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 2.011 s
25/04/01 10:44:06 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:44:06 INFO DAGScheduler: running: Set()
25/04/01 10:44:06 INFO DAGScheduler: waiting: Set()
25/04/01 10:44:06 INFO DAGScheduler: failed: Set()
25/04/01 10:44:06 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:44:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:44:06 INFO CodeGenerator: Code generated in 11.189937 ms
25/04/01 10:44:06 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 10:44:06 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:44:06 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:44:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 10:44:06 INFO DAGScheduler: Missing parents: List()
25/04/01 10:44:06 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:44:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 10:44:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 10:44:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:38337 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 10:44:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:44:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:44:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 10:44:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:44:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:38905 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 10:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:60500
25/04/01 10:44:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 106 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:44:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 10:44:06 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.114 s
25/04/01 10:44:06 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:44:06 INFO DAGScheduler: running: Set()
25/04/01 10:44:06 INFO DAGScheduler: waiting: Set()
25/04/01 10:44:06 INFO DAGScheduler: failed: Set()
25/04/01 10:44:06 INFO CodeGenerator: Code generated in 7.407227 ms
25/04/01 10:44:06 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:44:06 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:44:06 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:44:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 10:44:06 INFO DAGScheduler: Missing parents: List()
25/04/01 10:44:06 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:44:06 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 10:44:06 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 10:44:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:38337 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:44:06 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 10:44:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:44:06 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 10:44:06 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:44:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:38905 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:44:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:60500
25/04/01 10:44:06 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 29 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:44:06 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 10:44:06 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/01 10:44:06 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:44:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 10:44:06 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.036149 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 76, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'UnitPrice': string to decimal(10,5)
25/04/01 10:44:06 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:44:06 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 10:44:06 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:44:06 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:44:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:44:06 INFO MemoryStore: MemoryStore cleared
25/04/01 10:44:06 INFO BlockManager: BlockManager stopped
25/04/01 10:44:06 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:44:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:44:06 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:44:06 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:44:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-e83248d3-af56-49a9-9ee4-cd016f5e6170
25/04/01 10:44:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-7620fe9f-80d7-4082-b7fc-9f6468fe66d0
25/04/01 10:44:06 INFO ShutdownHookManager: Deleting directory /tmp/spark-e83248d3-af56-49a9-9ee4-cd016f5e6170/pyspark-f02db471-40e4-444b-a870-5dd12a8d4095
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:47:32 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:47:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:47:32 INFO ResourceUtils: ==============================================================
25/04/01 10:47:32 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:47:32 INFO ResourceUtils: ==============================================================
25/04/01 10:47:32 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 10:47:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:47:32 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:47:32 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:47:32 INFO SecurityManager: Changing view acls to: root
25/04/01 10:47:32 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:47:32 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:47:32 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:47:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:47:32 INFO Utils: Successfully started service 'sparkDriver' on port 40905.
25/04/01 10:47:32 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:47:32 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:47:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:47:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:47:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:47:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3271a271-42c8-4bf4-bad2-e61115fa49bf
25/04/01 10:47:32 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:47:32 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:47:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:47:33 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 10:47:33 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:47:33 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 10:47:33 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401104733-0004
25/04/01 10:47:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104733-0004/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:47:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104733-0004/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:47:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104733-0004/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:47:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104733-0004/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:47:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401104733-0004/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:47:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401104733-0004/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:47:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45213.
25/04/01 10:47:33 INFO NettyBlockTransferService: Server created on 7796893c36d7:45213
25/04/01 10:47:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:47:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 45213, None)
25/04/01 10:47:33 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:45213 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 45213, None)
25/04/01 10:47:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 45213, None)
25/04/01 10:47:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 45213, None)
25/04/01 10:47:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104733-0004/1 is now RUNNING
25/04/01 10:47:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104733-0004/2 is now RUNNING
25/04/01 10:47:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401104733-0004/0 is now RUNNING
25/04/01 10:47:33 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:47:33 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:47:33 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:47:34 INFO InMemoryFileIndex: It took 63 ms to list leaf files for 1 paths.
25/04/01 10:47:34 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 10:47:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:59686) with ID 1,  ResourceProfileId 0
25/04/01 10:47:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:56520) with ID 2,  ResourceProfileId 0
25/04/01 10:47:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:45558) with ID 0,  ResourceProfileId 0
25/04/01 10:47:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:37887 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 37887, None)
25/04/01 10:47:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:38861 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 38861, None)
25/04/01 10:47:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:42921 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 42921, None)
25/04/01 10:47:36 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:47:36 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:47:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:47:36 INFO CodeGenerator: Code generated in 131.39966 ms
25/04/01 10:47:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:47:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:47:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:45213 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:47:36 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:47:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:47:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:47:37 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:47:37 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:47:37 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:47:37 INFO DAGScheduler: Missing parents: List()
25/04/01 10:47:37 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:47:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:47:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:47:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:45213 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:47:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:47:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:47:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:47:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:47:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:42921 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:47:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:42921 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:47:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1348 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:47:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:47:38 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.412 s
25/04/01 10:47:38 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:47:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:47:38 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.443282 s
25/04/01 10:47:38 INFO CodeGenerator: Code generated in 7.979792 ms
25/04/01 10:47:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:47:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:47:38 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:47:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:47:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:47:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:45213 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:47:38 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:47:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 10:47:38 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:47:38 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:47:38 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:47:38 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:47:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:47:38 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:47:38 INFO metastore: Connected to metastore.
25/04/01 10:47:39 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=0e2fa4e6-53fe-4b59-8926-79f52d10d908, clientType=HIVECLI]
25/04/01 10:47:39 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:47:39 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:47:39 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:47:39 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:47:39 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:47:39 INFO metastore: Connected to metastore.
25/04/01 10:47:39 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:47:39 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:47:39 INFO metastore: Connected to metastore.
25/04/01 10:47:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:45213 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:47:39 WARN HadoopFSUtils: The directory hdfs://namenode:9000/user/hive/warehouse/products/Date=2025-03-27 was not found. Was it deleted very recently?
25/04/01 10:47:39 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 10:47:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:42921 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:47:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:47:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:47:39 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:47:39 INFO DataSourceStrategy: Pruning directories with: isnotnull(Date#40)
25/04/01 10:47:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(StockCode)
25/04/01 10:47:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 10:47:39 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string>
25/04/01 10:47:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:47:39 INFO CodeGenerator: Code generated in 20.292717 ms
25/04/01 10:47:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:47:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:47:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:45213 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:47:39 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:47:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:47:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:47:39 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:47:39 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:47:39 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:47:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:47:39 INFO DAGScheduler: Missing parents: List()
25/04/01 10:47:39 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:47:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 10:47:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:47:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:45213 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:47:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:47:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:47:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 10:47:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:47:39 INFO CodeGenerator: Code generated in 20.700524 ms
25/04/01 10:47:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 10:47:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 10:47:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:45213 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:47:39 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:47:39 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 10:47:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:47:39 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:47:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:47:39 INFO CodeGenerator: Code generated in 14.710809 ms
25/04/01 10:47:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:47:39 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 10:47:39 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 10:47:39 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:47:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 10:47:39 INFO DAGScheduler: Missing parents: List()
25/04/01 10:47:39 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:47:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 10:47:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 10:47:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:45213 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 10:47:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:47:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 10:47:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 10:47:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:47:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:42921 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 10:47:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:38861 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:47:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:45558
25/04/01 10:47:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 248 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:47:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 10:47:40 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.257 s
25/04/01 10:47:40 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:47:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 10:47:40 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.260183 s
25/04/01 10:47:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 10:47:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 10:47:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:45213 (size: 120.0 B, free: 366.1 MiB)
25/04/01 10:47:40 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:47:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:38861 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:47:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1576 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:47:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:47:41 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.591 s
25/04/01 10:47:41 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:47:41 INFO DAGScheduler: running: Set()
25/04/01 10:47:41 INFO DAGScheduler: waiting: Set()
25/04/01 10:47:41 INFO DAGScheduler: failed: Set()
25/04/01 10:47:41 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:47:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:47:41 INFO CodeGenerator: Code generated in 11.028323 ms
25/04/01 10:47:41 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 10:47:41 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:47:41 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:47:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 10:47:41 INFO DAGScheduler: Missing parents: List()
25/04/01 10:47:41 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:47:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 10:47:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 10:47:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:45213 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 10:47:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:47:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:47:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 10:47:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:47:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:38861 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 10:47:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:56520
25/04/01 10:47:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 119 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:47:41 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 10:47:41 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.127 s
25/04/01 10:47:41 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:47:41 INFO DAGScheduler: running: Set()
25/04/01 10:47:41 INFO DAGScheduler: waiting: Set()
25/04/01 10:47:41 INFO DAGScheduler: failed: Set()
25/04/01 10:47:41 INFO CodeGenerator: Code generated in 5.844723 ms
25/04/01 10:47:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:47:41 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:47:41 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:47:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 10:47:41 INFO DAGScheduler: Missing parents: List()
25/04/01 10:47:41 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:47:41 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 10:47:41 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 10:47:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:45213 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:47:41 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 10:47:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:47:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 10:47:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:47:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:38861 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:47:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:56520
25/04/01 10:47:41 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 87 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:47:41 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 10:47:41 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.092 s
25/04/01 10:47:41 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:47:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 10:47:41 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.094894 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 76, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'UnitPrice': string to decimal(10,5)
25/04/01 10:47:41 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:47:41 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 10:47:41 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:47:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:47:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:47:41 INFO MemoryStore: MemoryStore cleared
25/04/01 10:47:41 INFO BlockManager: BlockManager stopped
25/04/01 10:47:41 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:47:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:47:41 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:47:41 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:47:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-96b75001-97fc-4180-ac74-a163600a1568/pyspark-3216eec9-2142-4c9e-b02c-9752dd61c2d2
25/04/01 10:47:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-8b6cbdda-28ad-4ee5-ac79-d8ba87094c54
25/04/01 10:47:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-96b75001-97fc-4180-ac74-a163600a1568
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:52:38 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:52:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:52:38 INFO ResourceUtils: ==============================================================
25/04/01 10:52:38 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:52:38 INFO ResourceUtils: ==============================================================
25/04/01 10:52:38 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 10:52:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:52:38 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:52:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:52:38 INFO SecurityManager: Changing view acls to: root
25/04/01 10:52:38 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:52:38 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:52:38 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:52:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:52:38 INFO Utils: Successfully started service 'sparkDriver' on port 40851.
25/04/01 10:52:38 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:52:38 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:52:38 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:52:38 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:52:38 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:52:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f5eeab3b-d56e-4783-a417-e57c93e78b09
25/04/01 10:52:38 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:52:38 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:52:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:52:39 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 10:52:39 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:52:39 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 10:52:39 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401105239-0005
25/04/01 10:52:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105239-0005/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:52:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105239-0005/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:52:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105239-0005/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:52:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105239-0005/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:52:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105239-0005/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:52:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105239-0005/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:52:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37797.
25/04/01 10:52:39 INFO NettyBlockTransferService: Server created on 7796893c36d7:37797
25/04/01 10:52:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:52:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 37797, None)
25/04/01 10:52:39 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:37797 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 37797, None)
25/04/01 10:52:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 37797, None)
25/04/01 10:52:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 37797, None)
25/04/01 10:52:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105239-0005/2 is now RUNNING
25/04/01 10:52:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105239-0005/0 is now RUNNING
25/04/01 10:52:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105239-0005/1 is now RUNNING
25/04/01 10:52:39 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:52:39 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:52:39 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:52:40 INFO InMemoryFileIndex: It took 59 ms to list leaf files for 1 paths.
25/04/01 10:52:40 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 10:52:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:50376) with ID 1,  ResourceProfileId 0
25/04/01 10:52:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:48170) with ID 2,  ResourceProfileId 0
25/04/01 10:52:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:43936) with ID 0,  ResourceProfileId 0
25/04/01 10:52:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:39211 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 39211, None)
25/04/01 10:52:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:45183 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 45183, None)
25/04/01 10:52:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44125 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 44125, None)
25/04/01 10:52:42 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:52:42 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:52:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:52:42 INFO CodeGenerator: Code generated in 130.000306 ms
25/04/01 10:52:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:52:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:52:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:37797 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:52:42 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:52:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:52:42 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:52:42 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:52:42 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:52:42 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:52:42 INFO DAGScheduler: Missing parents: List()
25/04/01 10:52:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:52:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:52:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:52:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:37797 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:52:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:52:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:52:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:52:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:52:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:39211 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:52:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:39211 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:52:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1345 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:52:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:52:44 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.412 s
25/04/01 10:52:44 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:52:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:52:44 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.442823 s
25/04/01 10:52:44 INFO CodeGenerator: Code generated in 7.844788 ms
25/04/01 10:52:44 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:52:44 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:52:44 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:52:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:52:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:52:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:37797 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:52:44 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:52:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

<bound method DataFrame.count of DataFrame[stockcode: string, productname: string, productdescription: string, unitprice: decimal(10,5), date: string]>
25/04/01 10:52:44 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:52:44 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:52:44 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:52:44 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:52:44 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:52:44 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:52:44 INFO metastore: Connected to metastore.
25/04/01 10:52:45 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5fc8def4-b4d9-4ffa-8824-3419812541cb, clientType=HIVECLI]
25/04/01 10:52:45 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:52:45 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:52:45 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:52:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:52:45 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:52:45 INFO metastore: Connected to metastore.
25/04/01 10:52:45 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:52:45 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:52:45 INFO metastore: Connected to metastore.
25/04/01 10:52:45 WARN HadoopFSUtils: The directory hdfs://namenode:9000/user/hive/warehouse/products/Date=2025-03-27 was not found. Was it deleted very recently?
25/04/01 10:52:45 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 10:52:45 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:52:45 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:52:45 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:52:45 INFO DataSourceStrategy: Pruning directories with: isnotnull(Date#40)
25/04/01 10:52:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(StockCode)
25/04/01 10:52:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 10:52:45 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string>
25/04/01 10:52:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:37797 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:52:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:39211 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:52:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:52:45 INFO CodeGenerator: Code generated in 19.938339 ms
25/04/01 10:52:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:52:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:52:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:37797 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:52:45 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:52:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:52:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:52:45 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:52:45 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:52:45 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:52:45 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:52:45 INFO DAGScheduler: Missing parents: List()
25/04/01 10:52:45 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:52:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 10:52:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:52:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:37797 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:52:45 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:52:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:52:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 10:52:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:52:45 INFO CodeGenerator: Code generated in 25.226283 ms
25/04/01 10:52:45 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 10:52:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 10:52:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:37797 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:52:45 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:52:45 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 10:52:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:52:45 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:52:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:52:45 INFO CodeGenerator: Code generated in 16.043952 ms
25/04/01 10:52:45 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:52:45 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 10:52:45 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 10:52:45 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:52:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 10:52:45 INFO DAGScheduler: Missing parents: List()
25/04/01 10:52:45 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:52:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 10:52:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 10:52:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:37797 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 10:52:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:52:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 10:52:45 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 10:52:45 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:52:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:45183 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:52:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:45183 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 10:52:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:43936
25/04/01 10:52:46 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 688 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:52:46 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 10:52:46 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.697 s
25/04/01 10:52:46 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:52:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 10:52:46 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.700536 s
25/04/01 10:52:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:45183 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:52:46 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 10:52:46 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 10:52:46 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:37797 (size: 120.0 B, free: 366.1 MiB)
25/04/01 10:52:46 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:52:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1478 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:52:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:52:47 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.491 s
25/04/01 10:52:47 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:52:47 INFO DAGScheduler: running: Set()
25/04/01 10:52:47 INFO DAGScheduler: waiting: Set()
25/04/01 10:52:47 INFO DAGScheduler: failed: Set()
25/04/01 10:52:47 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:52:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:52:47 INFO CodeGenerator: Code generated in 11.390243 ms
25/04/01 10:52:47 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 10:52:47 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:52:47 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:52:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 10:52:47 INFO DAGScheduler: Missing parents: List()
25/04/01 10:52:47 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:52:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 10:52:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 10:52:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:37797 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 10:52:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:52:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:52:47 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 10:52:47 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:52:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:45183 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 10:52:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:43936
25/04/01 10:52:47 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 80 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:52:47 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 10:52:47 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.089 s
25/04/01 10:52:47 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:52:47 INFO DAGScheduler: running: Set()
25/04/01 10:52:47 INFO DAGScheduler: waiting: Set()
25/04/01 10:52:47 INFO DAGScheduler: failed: Set()
25/04/01 10:52:47 INFO CodeGenerator: Code generated in 7.123111 ms
25/04/01 10:52:47 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:52:47 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:52:47 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:52:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 10:52:47 INFO DAGScheduler: Missing parents: List()
25/04/01 10:52:47 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:52:47 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 10:52:47 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 10:52:47 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:37797 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:52:47 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 10:52:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:52:47 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 10:52:47 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:52:47 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:45183 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:52:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:43936
25/04/01 10:52:47 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 27 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:52:47 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 10:52:47 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.032 s
25/04/01 10:52:47 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:52:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 10:52:47 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.034544 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 72, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'UnitPrice': string to decimal(10,5)
25/04/01 10:52:47 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:52:47 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 10:52:47 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:52:47 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:52:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:52:47 INFO MemoryStore: MemoryStore cleared
25/04/01 10:52:47 INFO BlockManager: BlockManager stopped
25/04/01 10:52:47 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:52:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:52:47 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:52:47 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:52:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-9512b60c-f319-429f-b828-71d21d2efe28/pyspark-28e66e4f-11fc-4be5-a880-87de7029febe
25/04/01 10:52:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-44874a6c-f93c-4514-bc4a-4bca341827e7
25/04/01 10:52:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-9512b60c-f319-429f-b828-71d21d2efe28
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:53:40 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:53:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:53:40 INFO ResourceUtils: ==============================================================
25/04/01 10:53:40 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:53:40 INFO ResourceUtils: ==============================================================
25/04/01 10:53:40 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 10:53:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:53:40 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:53:40 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:53:41 INFO SecurityManager: Changing view acls to: root
25/04/01 10:53:41 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:53:41 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:53:41 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:53:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:53:41 INFO Utils: Successfully started service 'sparkDriver' on port 38009.
25/04/01 10:53:41 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:53:41 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:53:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:53:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:53:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:53:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-476b6a47-a812-4b74-8034-232a71648d1d
25/04/01 10:53:41 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:53:41 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:53:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:53:41 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 10:53:41 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:53:41 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 10:53:41 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401105341-0006
25/04/01 10:53:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105341-0006/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:53:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105341-0006/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:53:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105341-0006/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:53:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105341-0006/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:53:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105341-0006/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:53:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105341-0006/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:53:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40291.
25/04/01 10:53:41 INFO NettyBlockTransferService: Server created on 7796893c36d7:40291
25/04/01 10:53:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:53:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 40291, None)
25/04/01 10:53:41 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:40291 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 40291, None)
25/04/01 10:53:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 40291, None)
25/04/01 10:53:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 40291, None)
25/04/01 10:53:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105341-0006/0 is now RUNNING
25/04/01 10:53:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105341-0006/2 is now RUNNING
25/04/01 10:53:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105341-0006/1 is now RUNNING
25/04/01 10:53:41 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:53:42 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:53:42 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:53:43 INFO InMemoryFileIndex: It took 57 ms to list leaf files for 1 paths.
25/04/01 10:53:43 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/04/01 10:53:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:49518) with ID 2,  ResourceProfileId 0
25/04/01 10:53:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:55804) with ID 1,  ResourceProfileId 0
25/04/01 10:53:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:42870) with ID 0,  ResourceProfileId 0
25/04/01 10:53:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:46865 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 46865, None)
25/04/01 10:53:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42813 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 42813, None)
25/04/01 10:53:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:33905 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 33905, None)
25/04/01 10:53:44 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:53:44 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:53:44 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:53:45 INFO CodeGenerator: Code generated in 132.112327 ms
25/04/01 10:53:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:53:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:53:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:40291 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:53:45 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:53:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:53:45 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:53:45 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:53:45 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:53:45 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:53:45 INFO DAGScheduler: Missing parents: List()
25/04/01 10:53:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:53:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:53:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:53:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:40291 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:53:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:53:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:53:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:53:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:53:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:33905 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:53:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:33905 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:53:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1339 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:53:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:53:46 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.405 s
25/04/01 10:53:46 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:53:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:53:46 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.436478 s
25/04/01 10:53:46 INFO CodeGenerator: Code generated in 7.919937 ms
25/04/01 10:53:46 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:53:46 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:53:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:53:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:53:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:53:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:40291 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:53:46 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:53:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)





25/04/01 10:53:47 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:53:47 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:53:47 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:53:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:53:47 INFO CodeGenerator: Code generated in 21.708273 ms
25/04/01 10:53:47 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:53:47 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:53:47 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:40291 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:53:47 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:53:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:53:47 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:53:47 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:53:47 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:53:47 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:53:47 INFO DAGScheduler: Missing parents: List()
25/04/01 10:53:47 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:53:47 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.1 MiB)
25/04/01 10:53:47 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:53:47 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:40291 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:53:47 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:53:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:53:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 10:53:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:53:47 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:33905 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:53:47 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:33905 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:53:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 306 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:53:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:53:47 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.318 s
25/04/01 10:53:47 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:53:47 INFO DAGScheduler: running: Set()
25/04/01 10:53:47 INFO DAGScheduler: waiting: Set()
25/04/01 10:53:47 INFO DAGScheduler: failed: Set()
25/04/01 10:53:47 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:53:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:53:47 INFO CodeGenerator: Code generated in 15.518671 ms
25/04/01 10:53:47 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 10:53:47 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:53:47 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:53:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 10:53:47 INFO DAGScheduler: Missing parents: List()
25/04/01 10:53:47 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:53:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.1 MiB)
25/04/01 10:53:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 10:53:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:40291 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 10:53:47 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 10:53:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:53:47 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 10:53:47 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:53:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:33905 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 10:53:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:49518
25/04/01 10:53:47 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 131 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:53:47 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 10:53:47 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.140 s
25/04/01 10:53:47 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:53:47 INFO DAGScheduler: running: Set()
25/04/01 10:53:47 INFO DAGScheduler: waiting: Set()
25/04/01 10:53:47 INFO DAGScheduler: failed: Set()
25/04/01 10:53:47 INFO CodeGenerator: Code generated in 6.965896 ms
25/04/01 10:53:47 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:53:47 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:53:47 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:53:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 10:53:47 INFO DAGScheduler: Missing parents: List()
25/04/01 10:53:47 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:53:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 10:53:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 10:53:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:40291 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:53:47 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:53:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:53:47 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 10:53:47 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:53:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:33905 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:53:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:49518
25/04/01 10:53:47 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 32 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:53:47 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 10:53:47 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.038 s
25/04/01 10:53:47 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:53:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 10:53:47 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.041644 s
100




25/04/01 10:53:47 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:53:48 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:53:48 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:53:48 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 7796893c36d7:40291 in memory (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.6:33905 in memory (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 7796893c36d7:40291 in memory (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.6:33905 in memory (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 7796893c36d7:40291 in memory (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.6:33905 in memory (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:40291 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:33905 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 7796893c36d7:40291 in memory (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.6:33905 in memory (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:53:48 INFO metastore: Connected to metastore.
25/04/01 10:53:48 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=842c366c-6f9e-4593-a3b2-43a4f156dcac, clientType=HIVECLI]
25/04/01 10:53:48 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:53:48 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:53:48 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:53:48 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:53:48 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:53:48 INFO metastore: Connected to metastore.
25/04/01 10:53:48 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:53:48 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:53:48 INFO metastore: Connected to metastore.
25/04/01 10:53:48 WARN HadoopFSUtils: The directory hdfs://namenode:9000/user/hive/warehouse/products/Date=2025-03-27 was not found. Was it deleted very recently?
25/04/01 10:53:48 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 10:53:48 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:53:48 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:53:48 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:53:48 INFO DataSourceStrategy: Pruning directories with: isnotnull(Date#58)
25/04/01 10:53:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(StockCode)
25/04/01 10:53:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#54)
25/04/01 10:53:48 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string>
25/04/01 10:53:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:53:48 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:53:48 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:40291 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO SparkContext: Created broadcast 7 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:53:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:53:48 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 10:53:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:53:48 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:53:48 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:53:48 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:53:48 INFO DAGScheduler: Missing parents: List()
25/04/01 10:53:48 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:53:48 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 10:53:48 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:40291 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:53:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:53:48 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 10:53:48 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:53:48 INFO CodeGenerator: Code generated in 17.467541 ms
25/04/01 10:53:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 10:53:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:40291 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:53:48 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:53:48 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 10:53:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:53:48 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:53:48 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:53:48 INFO CodeGenerator: Code generated in 21.86919 ms
25/04/01 10:53:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:53:48 INFO DAGScheduler: Registering RDD 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 3
25/04/01 10:53:48 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 10:53:48 INFO DAGScheduler: Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:53:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 10:53:48 INFO DAGScheduler: Missing parents: List()
25/04/01 10:53:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:53:48 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 10:53:48 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 10:53:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:40291 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 10:53:48 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 10:53:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 10:53:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 10:53:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:53:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:33905 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 10:53:49 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:49518
25/04/01 10:53:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:42813 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:53:49 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 71 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:53:49 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 10:53:49 INFO DAGScheduler: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.078 s
25/04/01 10:53:49 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:53:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 10:53:49 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.080805 s
25/04/01 10:53:49 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 10:53:49 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 10:53:49 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:40291 (size: 120.0 B, free: 366.1 MiB)
25/04/01 10:53:49 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:53:49 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:42813 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:53:50 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1562 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 10:53:50 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 10:53:50 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 1.569 s
25/04/01 10:53:50 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:53:50 INFO DAGScheduler: running: Set()
25/04/01 10:53:50 INFO DAGScheduler: waiting: Set()
25/04/01 10:53:50 INFO DAGScheduler: failed: Set()
25/04/01 10:53:50 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:53:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:53:50 INFO CodeGenerator: Code generated in 9.605712 ms
25/04/01 10:53:50 INFO DAGScheduler: Registering RDD 33 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 10:53:50 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:53:50 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:53:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 10:53:50 INFO DAGScheduler: Missing parents: List()
25/04/01 10:53:50 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:53:50 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 10:53:50 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 10:53:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:40291 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 10:53:50 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 10:53:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:53:50 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 10:53:50 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 6) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:53:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:42813 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 10:53:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:55804
25/04/01 10:53:50 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 6) in 116 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 10:53:50 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 10:53:50 INFO DAGScheduler: ShuffleMapStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.122 s
25/04/01 10:53:50 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:53:50 INFO DAGScheduler: running: Set()
25/04/01 10:53:50 INFO DAGScheduler: waiting: Set()
25/04/01 10:53:50 INFO DAGScheduler: failed: Set()
25/04/01 10:53:50 INFO CodeGenerator: Code generated in 5.893962 ms
25/04/01 10:53:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:53:50 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:53:50 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:53:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
25/04/01 10:53:50 INFO DAGScheduler: Missing parents: List()
25/04/01 10:53:50 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:53:50 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 10:53:50 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 10:53:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:40291 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:53:50 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 10:53:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:53:50 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/04/01 10:53:50 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 7) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:53:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:42813 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:53:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.8:55804
25/04/01 10:53:50 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 7) in 89 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 10:53:50 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/04/01 10:53:50 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.093 s
25/04/01 10:53:50 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:53:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/04/01 10:53:50 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.096232 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 74, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'UnitPrice': string to decimal(10,5)
25/04/01 10:53:50 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:53:50 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 10:53:50 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:53:50 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:53:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:53:50 INFO MemoryStore: MemoryStore cleared
25/04/01 10:53:50 INFO BlockManager: BlockManager stopped
25/04/01 10:53:50 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:53:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:53:50 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:53:50 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:53:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-23109b86-8299-4270-aa26-0bf94e929ff7
25/04/01 10:53:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-e94092e8-308c-41bb-bb53-47cf45f166c1/pyspark-8a9f43ea-163f-4089-abc6-73b929348a71
25/04/01 10:53:50 INFO ShutdownHookManager: Deleting directory /tmp/spark-e94092e8-308c-41bb-bb53-47cf45f166c1
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:55:29 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:55:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:55:29 INFO ResourceUtils: ==============================================================
25/04/01 10:55:29 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:55:29 INFO ResourceUtils: ==============================================================
25/04/01 10:55:29 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 10:55:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:55:29 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:55:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:55:29 INFO SecurityManager: Changing view acls to: root
25/04/01 10:55:29 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:55:29 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:55:29 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:55:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:55:29 INFO Utils: Successfully started service 'sparkDriver' on port 33441.
25/04/01 10:55:29 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:55:29 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:55:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:55:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:55:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:55:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-688ab542-5921-4b66-a323-b4321f4ed917
25/04/01 10:55:29 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:55:29 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:55:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:55:29 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 10:55:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:55:30 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 10:55:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401105530-0007
25/04/01 10:55:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105530-0007/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:55:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105530-0007/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:55:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105530-0007/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:55:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105530-0007/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:55:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105530-0007/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:55:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105530-0007/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:55:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37759.
25/04/01 10:55:30 INFO NettyBlockTransferService: Server created on 7796893c36d7:37759
25/04/01 10:55:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:55:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 37759, None)
25/04/01 10:55:30 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:37759 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 37759, None)
25/04/01 10:55:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 37759, None)
25/04/01 10:55:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 37759, None)
25/04/01 10:55:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105530-0007/0 is now RUNNING
25/04/01 10:55:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105530-0007/1 is now RUNNING
25/04/01 10:55:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105530-0007/2 is now RUNNING
25/04/01 10:55:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:55:30 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:55:30 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:55:31 INFO InMemoryFileIndex: It took 58 ms to list leaf files for 1 paths.
25/04/01 10:55:31 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 10:55:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:57192) with ID 0,  ResourceProfileId 0
25/04/01 10:55:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:58934) with ID 2,  ResourceProfileId 0
25/04/01 10:55:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:38828) with ID 1,  ResourceProfileId 0
25/04/01 10:55:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:45749 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 45749, None)
25/04/01 10:55:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:41745 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 41745, None)
25/04/01 10:55:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:46127 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 46127, None)
25/04/01 10:55:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:55:33 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:55:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:55:33 INFO CodeGenerator: Code generated in 137.493201 ms
25/04/01 10:55:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:55:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:55:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:37759 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:55:33 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:55:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:55:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:55:33 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:55:33 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:55:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:55:33 INFO DAGScheduler: Missing parents: List()
25/04/01 10:55:33 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:55:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:55:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:55:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:37759 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:55:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:55:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:55:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:55:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:55:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:46127 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:55:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:46127 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:55:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1366 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 10:55:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:55:35 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.429 s
25/04/01 10:55:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:55:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:55:35 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.459368 s
25/04/01 10:55:35 INFO CodeGenerator: Code generated in 7.548887 ms
25/04/01 10:55:35 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:55:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:55:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:55:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:55:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:55:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:37759 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:55:35 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:55:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)





25/04/01 10:55:35 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:55:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:55:35 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:55:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:55:35 INFO CodeGenerator: Code generated in 21.570453 ms
25/04/01 10:55:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:55:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:55:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:37759 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:55:35 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:55:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:55:35 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:55:35 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:55:35 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:55:35 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:55:35 INFO DAGScheduler: Missing parents: List()
25/04/01 10:55:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:55:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.1 MiB)
25/04/01 10:55:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:55:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:37759 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:55:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:55:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:55:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 10:55:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:55:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:41745 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:55:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:41745 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:55:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1505 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:55:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:55:37 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.517 s
25/04/01 10:55:37 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:55:37 INFO DAGScheduler: running: Set()
25/04/01 10:55:37 INFO DAGScheduler: waiting: Set()
25/04/01 10:55:37 INFO DAGScheduler: failed: Set()
25/04/01 10:55:37 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:55:37 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:55:37 INFO CodeGenerator: Code generated in 13.037322 ms
25/04/01 10:55:37 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 10:55:37 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:55:37 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:55:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 10:55:37 INFO DAGScheduler: Missing parents: List()
25/04/01 10:55:37 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:55:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.1 MiB)
25/04/01 10:55:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:37759 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 10:55:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:55:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 10:55:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:55:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:41745 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:58934
25/04/01 10:55:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 144 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:55:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 10:55:37 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.153 s
25/04/01 10:55:37 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:55:37 INFO DAGScheduler: running: Set()
25/04/01 10:55:37 INFO DAGScheduler: waiting: Set()
25/04/01 10:55:37 INFO DAGScheduler: failed: Set()
25/04/01 10:55:37 INFO CodeGenerator: Code generated in 6.535668 ms
25/04/01 10:55:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:55:37 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:55:37 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:55:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 10:55:37 INFO DAGScheduler: Missing parents: List()
25/04/01 10:55:37 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:55:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 10:55:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:37759 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:55:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:55:37 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 10:55:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:55:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:41745 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:58934
25/04/01 10:55:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 91 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:55:37 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 10:55:37 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.096 s
25/04/01 10:55:37 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:55:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 10:55:37 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.099439 s
100




25/04/01 10:55:37 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:55:37 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:55:37 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:37759 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:46127 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 7796893c36d7:37759 in memory (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.6:41745 in memory (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 7796893c36d7:37759 in memory (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.18.0.6:41745 in memory (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 7796893c36d7:37759 in memory (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.6:41745 in memory (size: 17.8 KiB, free: 366.3 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 7796893c36d7:37759 in memory (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:55:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.6:41745 in memory (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:55:37 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:55:37 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:55:37 INFO metastore: Connected to metastore.
25/04/01 10:55:38 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=8930080b-5f71-4897-8a25-72a46c81e5bc, clientType=HIVECLI]
25/04/01 10:55:38 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:55:38 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:55:38 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:55:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:55:38 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:55:38 INFO metastore: Connected to metastore.
25/04/01 10:55:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:55:38 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:55:38 INFO metastore: Connected to metastore.
25/04/01 10:55:38 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 10:55:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:55:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:55:38 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:55:38 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#58)
25/04/01 10:55:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 10:55:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#54)
25/04/01 10:55:38 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 10:55:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:55:38 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:37759 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:55:38 INFO SparkContext: Created broadcast 7 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:55:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:55:38 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 10:55:38 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:55:38 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:55:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:55:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:55:38 INFO DAGScheduler: Missing parents: List()
25/04/01 10:55:38 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:55:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:37759 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:55:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:55:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:55:38 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 10:55:38 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:55:38 INFO CodeGenerator: Code generated in 19.180672 ms
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 10:55:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:37759 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:55:38 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:55:38 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 10:55:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:55:38 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:55:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:55:38 INFO CodeGenerator: Code generated in 17.323696 ms
25/04/01 10:55:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:55:38 INFO DAGScheduler: Registering RDD 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 3
25/04/01 10:55:38 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 10:55:38 INFO DAGScheduler: Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:55:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 10:55:38 INFO DAGScheduler: Missing parents: List()
25/04/01 10:55:38 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 10:55:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:37759 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 10:55:38 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 10:55:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 10:55:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 10:55:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:55:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:41745 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 10:55:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:58934
25/04/01 10:55:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:45749 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:55:38 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 67 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 10:55:38 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 10:55:38 INFO DAGScheduler: ResultStage 9 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.073 s
25/04/01 10:55:38 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:55:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 10:55:38 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.076417 s
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 10:55:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 10:55:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:37759 (size: 120.0 B, free: 366.1 MiB)
25/04/01 10:55:38 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:55:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:45749 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:55:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1533 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:55:40 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 10:55:40 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 1.539 s
25/04/01 10:55:40 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:55:40 INFO DAGScheduler: running: Set()
25/04/01 10:55:40 INFO DAGScheduler: waiting: Set()
25/04/01 10:55:40 INFO DAGScheduler: failed: Set()
25/04/01 10:55:40 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:55:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:55:40 INFO CodeGenerator: Code generated in 10.559704 ms
25/04/01 10:55:40 INFO DAGScheduler: Registering RDD 33 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 10:55:40 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:55:40 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:55:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 10:55:40 INFO DAGScheduler: Missing parents: List()
25/04/01 10:55:40 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:55:40 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 10:55:40 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 10:55:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:37759 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 10:55:40 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 10:55:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:55:40 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 10:55:40 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 6) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:55:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:45749 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 10:55:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:57192
25/04/01 10:55:40 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 6) in 113 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:55:40 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 10:55:40 INFO DAGScheduler: ShuffleMapStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.118 s
25/04/01 10:55:40 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:55:40 INFO DAGScheduler: running: Set()
25/04/01 10:55:40 INFO DAGScheduler: waiting: Set()
25/04/01 10:55:40 INFO DAGScheduler: failed: Set()
25/04/01 10:55:40 INFO CodeGenerator: Code generated in 5.883606 ms
25/04/01 10:55:40 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:55:40 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:55:40 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:55:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
25/04/01 10:55:40 INFO DAGScheduler: Missing parents: List()
25/04/01 10:55:40 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:55:40 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 10:55:40 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 10:55:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:37759 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:55:40 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 10:55:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:55:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/04/01 10:55:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 7) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:55:40 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:45749 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:55:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.2:57192
25/04/01 10:55:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 7) in 85 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:55:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/04/01 10:55:40 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.088 s
25/04/01 10:55:40 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:55:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/04/01 10:55:40 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.091526 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 74, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(10,5)
25/04/01 10:55:40 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:55:40 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 10:55:40 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:55:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:55:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:55:40 INFO MemoryStore: MemoryStore cleared
25/04/01 10:55:40 INFO BlockManager: BlockManager stopped
25/04/01 10:55:40 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:55:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:55:40 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:55:40 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:55:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-8890292b-d259-48ee-bbdd-5b4bf0fc882b
25/04/01 10:55:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-4ba24048-65e5-47d2-8d6b-947b444f533f/pyspark-0e5022af-ef96-446f-96d6-85557fd19a09
25/04/01 10:55:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-4ba24048-65e5-47d2-8d6b-947b444f533f
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 10:56:21 INFO SparkContext: Running Spark version 3.2.2
25/04/01 10:56:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 10:56:21 INFO ResourceUtils: ==============================================================
25/04/01 10:56:21 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 10:56:21 INFO ResourceUtils: ==============================================================
25/04/01 10:56:21 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 10:56:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 10:56:21 INFO ResourceProfile: Limiting resource is cpu
25/04/01 10:56:21 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 10:56:21 INFO SecurityManager: Changing view acls to: root
25/04/01 10:56:21 INFO SecurityManager: Changing modify acls to: root
25/04/01 10:56:21 INFO SecurityManager: Changing view acls groups to: 
25/04/01 10:56:21 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 10:56:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 10:56:22 INFO Utils: Successfully started service 'sparkDriver' on port 35065.
25/04/01 10:56:22 INFO SparkEnv: Registering MapOutputTracker
25/04/01 10:56:22 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 10:56:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 10:56:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 10:56:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 10:56:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dbf940da-fb5e-455a-98f8-ed15f70e0335
25/04/01 10:56:22 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 10:56:22 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 10:56:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 10:56:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 10:56:22 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 10:56:22 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 10:56:22 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401105622-0008
25/04/01 10:56:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105622-0008/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 10:56:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105622-0008/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:56:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105622-0008/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 10:56:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105622-0008/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:56:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401105622-0008/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 10:56:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401105622-0008/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 10:56:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33863.
25/04/01 10:56:22 INFO NettyBlockTransferService: Server created on 7796893c36d7:33863
25/04/01 10:56:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 10:56:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 33863, None)
25/04/01 10:56:22 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:33863 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 33863, None)
25/04/01 10:56:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 33863, None)
25/04/01 10:56:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105622-0008/0 is now RUNNING
25/04/01 10:56:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 33863, None)
25/04/01 10:56:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105622-0008/1 is now RUNNING
25/04/01 10:56:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401105622-0008/2 is now RUNNING
25/04/01 10:56:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 10:56:22 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 10:56:23 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 10:56:24 INFO InMemoryFileIndex: It took 59 ms to list leaf files for 1 paths.
25/04/01 10:56:24 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 10:56:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:59898) with ID 1,  ResourceProfileId 0
25/04/01 10:56:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:41852) with ID 0,  ResourceProfileId 0
25/04/01 10:56:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:57496) with ID 2,  ResourceProfileId 0
25/04/01 10:56:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:33229 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 33229, None)
25/04/01 10:56:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:40231 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 40231, None)
25/04/01 10:56:24 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:46347 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 46347, None)
25/04/01 10:56:25 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:56:25 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 10:56:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:56:26 INFO CodeGenerator: Code generated in 136.955406 ms
25/04/01 10:56:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 10:56:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 10:56:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:33863 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:56:26 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:56:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:56:26 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 10:56:26 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:56:26 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 10:56:26 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:56:26 INFO DAGScheduler: Missing parents: List()
25/04/01 10:56:26 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:56:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 10:56:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 10:56:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:33863 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:56:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 10:56:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:56:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 10:56:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 10:56:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:40231 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:56:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:40231 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 10:56:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1368 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:56:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 10:56:27 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.439 s
25/04/01 10:56:27 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:56:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 10:56:27 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.471295 s
25/04/01 10:56:27 INFO CodeGenerator: Code generated in 7.854392 ms
25/04/01 10:56:27 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:56:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:56:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 10:56:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 10:56:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 10:56:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:33863 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:56:27 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 10:56:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:56:28 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:56:28 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 10:56:28 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 10:56:28 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 10:56:28 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:56:28 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:56:28 INFO metastore: Connected to metastore.
25/04/01 10:56:28 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=6105f2d1-f064-42e9-a2e5-7d6d3607553f, clientType=HIVECLI]
25/04/01 10:56:28 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 10:56:28 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 10:56:28 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 10:56:28 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:56:28 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 10:56:28 INFO metastore: Connected to metastore.
25/04/01 10:56:28 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 10:56:28 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 10:56:28 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)

25/04/01 10:56:28 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 10:56:28 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 10:56:28 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 10:56:28 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 10:56:28 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 10:56:28 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 10:56:28 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 10:56:28 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 10:56:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:33863 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 10:56:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:40231 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 10:56:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:56:28 INFO CodeGenerator: Code generated in 22.01622 ms
25/04/01 10:56:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 10:56:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 10:56:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:33863 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:56:28 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:56:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:56:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:56:29 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 10:56:29 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:56:29 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:56:29 INFO DAGScheduler: Parents of final stage: List()
25/04/01 10:56:29 INFO DAGScheduler: Missing parents: List()
25/04/01 10:56:29 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:33863 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 10:56:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 10:56:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:56:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 10:56:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 10:56:29 INFO CodeGenerator: Code generated in 24.558493 ms
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:40231 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:33863 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 10:56:29 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 10:56:29 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 10:56:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 10:56:29 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:56:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:56:29 INFO CodeGenerator: Code generated in 15.517336 ms
25/04/01 10:56:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:56:29 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 10:56:29 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 10:56:29 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 10:56:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 10:56:29 INFO DAGScheduler: Missing parents: List()
25/04/01 10:56:29 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:33863 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 10:56:29 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 10:56:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 10:56:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 10:56:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:40231 (size: 15.7 KiB, free: 366.2 MiB)
25/04/01 10:56:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:41852
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:40231 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 10:56:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 160 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:56:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 10:56:29 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.166 s
25/04/01 10:56:29 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:56:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 10:56:29 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.171255 s
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:33863 (size: 120.0 B, free: 366.1 MiB)
25/04/01 10:56:29 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 10:56:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 354 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:56:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 10:56:29 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.370 s
25/04/01 10:56:29 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:56:29 INFO DAGScheduler: running: Set()
25/04/01 10:56:29 INFO DAGScheduler: waiting: Set()
25/04/01 10:56:29 INFO DAGScheduler: failed: Set()
25/04/01 10:56:29 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 10:56:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 10:56:29 INFO CodeGenerator: Code generated in 11.44431 ms
25/04/01 10:56:29 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 10:56:29 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:56:29 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:56:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 10:56:29 INFO DAGScheduler: Missing parents: List()
25/04/01 10:56:29 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:33863 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 10:56:29 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 10:56:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:56:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 10:56:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:40231 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 10:56:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:41852
25/04/01 10:56:29 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 72 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:56:29 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 10:56:29 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.080 s
25/04/01 10:56:29 INFO DAGScheduler: looking for newly runnable stages
25/04/01 10:56:29 INFO DAGScheduler: running: Set()
25/04/01 10:56:29 INFO DAGScheduler: waiting: Set()
25/04/01 10:56:29 INFO DAGScheduler: failed: Set()
25/04/01 10:56:29 INFO CodeGenerator: Code generated in 7.619925 ms
25/04/01 10:56:29 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 10:56:29 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 10:56:29 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 10:56:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 10:56:29 INFO DAGScheduler: Missing parents: List()
25/04/01 10:56:29 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 10:56:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:33863 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 10:56:29 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 10:56:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 10:56:29 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 10:56:29 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 10:56:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:40231 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 10:56:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:41852
25/04/01 10:56:29 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 28 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 10:56:29 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 10:56:29 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/01 10:56:29 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 10:56:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 10:56:29 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.036088 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 69, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(10,5)
25/04/01 10:56:29 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 10:56:29 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 10:56:29 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 10:56:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 10:56:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 10:56:29 INFO MemoryStore: MemoryStore cleared
25/04/01 10:56:29 INFO BlockManager: BlockManager stopped
25/04/01 10:56:29 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 10:56:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 10:56:29 INFO SparkContext: Successfully stopped SparkContext
25/04/01 10:56:29 INFO ShutdownHookManager: Shutdown hook called
25/04/01 10:56:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-b8612366-5b8f-4729-be53-79fd9ddcd651
25/04/01 10:56:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-486facf1-c2f2-4c24-8ffa-13caa841c3a0
25/04/01 10:56:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-b8612366-5b8f-4729-be53-79fd9ddcd651/pyspark-be61df4b-878e-4d95-a155-291c7764be3d
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:00:12 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:00:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:00:12 INFO ResourceUtils: ==============================================================
25/04/01 11:00:12 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:00:12 INFO ResourceUtils: ==============================================================
25/04/01 11:00:12 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:00:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:00:12 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:00:12 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:00:12 INFO SecurityManager: Changing view acls to: root
25/04/01 11:00:12 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:00:12 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:00:12 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:00:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:00:12 INFO Utils: Successfully started service 'sparkDriver' on port 43601.
25/04/01 11:00:12 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:00:12 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:00:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:00:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:00:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:00:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5370beed-21b7-44ad-8b43-5a077b7ba762
25/04/01 11:00:12 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:00:12 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:00:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:00:12 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:00:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:00:13 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:00:13 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401110013-0009
25/04/01 11:00:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401110013-0009/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:00:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401110013-0009/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:00:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401110013-0009/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:00:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401110013-0009/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:00:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401110013-0009/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:00:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401110013-0009/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:00:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46051.
25/04/01 11:00:13 INFO NettyBlockTransferService: Server created on 7796893c36d7:46051
25/04/01 11:00:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:00:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 46051, None)
25/04/01 11:00:13 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:46051 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 46051, None)
25/04/01 11:00:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401110013-0009/0 is now RUNNING
25/04/01 11:00:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 46051, None)
25/04/01 11:00:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401110013-0009/1 is now RUNNING
25/04/01 11:00:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 46051, None)
25/04/01 11:00:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401110013-0009/2 is now RUNNING
25/04/01 11:00:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:00:13 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:00:13 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:00:14 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.
25/04/01 11:00:14 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:00:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:44316) with ID 1,  ResourceProfileId 0
25/04/01 11:00:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:51926) with ID 2,  ResourceProfileId 0
25/04/01 11:00:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:55948) with ID 0,  ResourceProfileId 0
25/04/01 11:00:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:46355 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 46355, None)
25/04/01 11:00:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44813 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 44813, None)
25/04/01 11:00:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:40399 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 40399, None)
25/04/01 11:00:16 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:00:16 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:00:16 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:00:16 INFO CodeGenerator: Code generated in 135.233648 ms
25/04/01 11:00:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:00:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:00:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:46051 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:00:16 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:00:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:00:16 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:00:16 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:00:16 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:00:16 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:00:16 INFO DAGScheduler: Missing parents: List()
25/04/01 11:00:16 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:00:16 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:00:16 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:00:16 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:46051 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:00:16 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:00:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:00:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:00:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:00:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:40399 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:00:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:40399 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:00:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1355 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:00:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:00:18 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.417 s
25/04/01 11:00:18 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:00:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:00:18 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.448214 s
25/04/01 11:00:18 INFO CodeGenerator: Code generated in 9.358711 ms
25/04/01 11:00:18 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:00:18 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:00:18 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:00:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:00:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:00:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:46051 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:00:18 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:00:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:00:18 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:00:18 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:00:18 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:00:18 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:00:18 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:00:18 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:00:18 INFO metastore: Connected to metastore.
25/04/01 11:00:18 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=071f7ad7-fa9d-472e-a969-77b31226cab8, clientType=HIVECLI]
25/04/01 11:00:18 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:00:18 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:00:18 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:00:18 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:00:18 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:00:18 INFO metastore: Connected to metastore.
25/04/01 11:00:18 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:00:18 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:00:18 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)

25/04/01 11:00:19 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:00:19 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:00:19 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:00:19 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:00:19 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:00:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:00:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 11:00:19 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:00:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:00:19 INFO CodeGenerator: Code generated in 39.315903 ms
25/04/01 11:00:19 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:00:19 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:46051 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:00:19 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:00:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:46051 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:00:19 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:00:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:00:19 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:40399 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:00:19 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:00:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:00:19 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:00:19 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:00:19 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:00:19 INFO DAGScheduler: Missing parents: List()
25/04/01 11:00:19 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:00:19 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 11:00:19 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 11:00:19 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:46051 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:00:19 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:00:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:00:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:00:19 INFO CodeGenerator: Code generated in 23.455096 ms
25/04/01 11:00:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:00:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:00:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:46051 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:00:19 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:40399 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:00:19 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:00:19 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:00:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:00:19 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:00:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:00:19 INFO CodeGenerator: Code generated in 18.217073 ms
25/04/01 11:00:19 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:00:19 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 11:00:19 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:00:19 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:00:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:00:19 INFO DAGScheduler: Missing parents: List()
25/04/01 11:00:19 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:00:19 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 11:00:19 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 11:00:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:46051 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 11:00:19 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:00:19 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:00:19 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:00:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:40399 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:00:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:44813 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 11:00:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 393 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:00:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:00:19 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.409 s
25/04/01 11:00:19 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:00:19 INFO DAGScheduler: running: Set(ResultStage 3)
25/04/01 11:00:19 INFO DAGScheduler: waiting: Set()
25/04/01 11:00:19 INFO DAGScheduler: failed: Set()
25/04/01 11:00:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:44316
25/04/01 11:00:20 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 950 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:00:20 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:00:20 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.958 s
25/04/01 11:00:20 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:00:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:00:20 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.960914 s
25/04/01 11:00:20 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 11:00:20 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 11:00:20 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:46051 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:00:20 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:00:20 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:00:20 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:00:20 INFO CodeGenerator: Code generated in 10.512574 ms
25/04/01 11:00:20 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:00:20 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:00:20 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:00:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 11:00:20 INFO DAGScheduler: Missing parents: List()
25/04/01 11:00:20 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:00:20 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 11:00:20 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 11:00:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:46051 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 11:00:20 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:00:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:00:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:00:20 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:00:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:40399 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:00:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:55948
25/04/01 11:00:20 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 113 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:00:20 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:00:20 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.121 s
25/04/01 11:00:20 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:00:20 INFO DAGScheduler: running: Set()
25/04/01 11:00:20 INFO DAGScheduler: waiting: Set()
25/04/01 11:00:20 INFO DAGScheduler: failed: Set()
25/04/01 11:00:20 INFO CodeGenerator: Code generated in 6.24396 ms
25/04/01 11:00:20 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:00:20 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:00:20 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:00:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:00:20 INFO DAGScheduler: Missing parents: List()
25/04/01 11:00:20 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:00:20 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 11:00:20 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 11:00:20 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:46051 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:00:20 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:00:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:00:20 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:00:20 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:00:20 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:40399 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:00:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:55948
25/04/01 11:00:20 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 26 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:00:20 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:00:20 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
25/04/01 11:00:20 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:00:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:00:20 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.034349 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 69, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(10,5)
25/04/01 11:00:20 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:00:20 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:00:20 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:00:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:00:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:00:21 INFO MemoryStore: MemoryStore cleared
25/04/01 11:00:21 INFO BlockManager: BlockManager stopped
25/04/01 11:00:21 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:00:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:00:21 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:00:21 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:00:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-c76b158f-cac3-4c99-bc60-f9f6e9da5987/pyspark-61dbaeaa-ee71-4167-8589-3351df7519b3
25/04/01 11:00:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-75eb3fba-d0f2-4418-bd8b-61554964c6ca
25/04/01 11:00:21 INFO ShutdownHookManager: Deleting directory /tmp/spark-c76b158f-cac3-4c99-bc60-f9f6e9da5987
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:06:38 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:06:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:06:38 INFO ResourceUtils: ==============================================================
25/04/01 11:06:38 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:06:38 INFO ResourceUtils: ==============================================================
25/04/01 11:06:38 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:06:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:06:38 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:06:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:06:38 INFO SecurityManager: Changing view acls to: root
25/04/01 11:06:38 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:06:38 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:06:38 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:06:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:06:38 INFO Utils: Successfully started service 'sparkDriver' on port 39333.
25/04/01 11:06:38 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:06:38 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:06:38 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:06:38 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:06:38 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:06:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-89a89b9f-6b8c-4dbe-974d-008d395c225d
25/04/01 11:06:38 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:06:38 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:06:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:06:38 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:06:38 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:06:38 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:06:38 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401110638-0010
25/04/01 11:06:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401110638-0010/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:06:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401110638-0010/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:06:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401110638-0010/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:06:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401110638-0010/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:06:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401110638-0010/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:06:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401110638-0010/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:06:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39219.
25/04/01 11:06:38 INFO NettyBlockTransferService: Server created on 7796893c36d7:39219
25/04/01 11:06:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:06:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 39219, None)
25/04/01 11:06:38 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:39219 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 39219, None)
25/04/01 11:06:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 39219, None)
25/04/01 11:06:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 39219, None)
25/04/01 11:06:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401110638-0010/2 is now RUNNING
25/04/01 11:06:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401110638-0010/0 is now RUNNING
25/04/01 11:06:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401110638-0010/1 is now RUNNING
25/04/01 11:06:39 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:06:39 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:06:39 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:06:40 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/01 11:06:40 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:06:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:34650) with ID 0,  ResourceProfileId 0
25/04/01 11:06:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:38586) with ID 2,  ResourceProfileId 0
25/04/01 11:06:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:46730) with ID 1,  ResourceProfileId 0
25/04/01 11:06:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35527 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 35527, None)
25/04/01 11:06:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:46203 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 46203, None)
25/04/01 11:06:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44785 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 44785, None)
25/04/01 11:06:42 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:06:42 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:06:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:06:42 INFO CodeGenerator: Code generated in 139.885082 ms
25/04/01 11:06:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:06:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:06:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:39219 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:06:42 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:06:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:06:42 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:06:42 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:06:42 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:06:42 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:06:42 INFO DAGScheduler: Missing parents: List()
25/04/01 11:06:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:06:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:06:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:06:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:39219 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:06:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:06:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:06:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:06:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:06:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:35527 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:06:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:35527 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:06:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1403 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:06:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:06:44 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.469 s
25/04/01 11:06:44 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:06:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:06:44 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.500120 s
25/04/01 11:06:44 INFO CodeGenerator: Code generated in 7.912055 ms
25/04/01 11:06:44 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:06:44 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:06:44 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:06:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:06:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:06:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:39219 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:06:44 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:06:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:06:44 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:06:44 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:06:44 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:06:44 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:06:44 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:06:44 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:06:44 INFO metastore: Connected to metastore.
25/04/01 11:06:44 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=c21ad67d-2b17-467b-b523-fe82c99b69d0, clientType=HIVECLI]
25/04/01 11:06:44 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:06:44 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:06:44 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:06:44 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:06:44 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:06:44 INFO metastore: Connected to metastore.
25/04/01 11:06:44 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:06:44 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:06:44 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:06:45 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:06:45 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:06:45 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:06:45 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:06:45 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:06:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:06:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 11:06:45 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:06:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:06:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:39219 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:06:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:35527 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:06:45 INFO CodeGenerator: Code generated in 22.985015 ms
25/04/01 11:06:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:06:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:06:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:39219 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:06:45 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:06:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:06:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:06:45 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:06:45 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:06:45 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:06:45 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:06:45 INFO DAGScheduler: Missing parents: List()
25/04/01 11:06:45 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:06:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 11:06:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 11:06:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:39219 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:06:45 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:06:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:06:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:06:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:06:45 INFO CodeGenerator: Code generated in 29.733153 ms
25/04/01 11:06:45 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:06:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:06:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:39219 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:06:45 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:06:45 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:06:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:06:45 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:06:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:06:45 INFO CodeGenerator: Code generated in 21.178901 ms
25/04/01 11:06:45 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:06:45 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 11:06:45 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:06:45 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:06:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:06:45 INFO DAGScheduler: Missing parents: List()
25/04/01 11:06:45 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:06:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 11:06:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 11:06:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:39219 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 11:06:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:06:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:06:45 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:06:45 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:06:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:44785 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 11:06:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:44785 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:06:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:46730
25/04/01 11:06:46 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 738 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:06:46 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:06:46 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.746 s
25/04/01 11:06:46 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:06:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:06:46 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.750683 s
25/04/01 11:06:46 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 11:06:46 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 11:06:46 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:39219 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:06:46 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:06:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:44785 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:06:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1595 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:06:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:06:47 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.613 s
25/04/01 11:06:47 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:06:47 INFO DAGScheduler: running: Set()
25/04/01 11:06:47 INFO DAGScheduler: waiting: Set()
25/04/01 11:06:47 INFO DAGScheduler: failed: Set()
25/04/01 11:06:47 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:06:47 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:06:47 INFO CodeGenerator: Code generated in 11.073944 ms
25/04/01 11:06:47 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:06:47 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:06:47 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:06:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 11:06:47 INFO DAGScheduler: Missing parents: List()
25/04/01 11:06:47 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:06:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 11:06:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 11:06:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:39219 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 11:06:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:06:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:06:47 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:06:47 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:06:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:44785 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:06:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:46730
25/04/01 11:06:47 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 81 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:06:47 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:06:47 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.090 s
25/04/01 11:06:47 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:06:47 INFO DAGScheduler: running: Set()
25/04/01 11:06:47 INFO DAGScheduler: waiting: Set()
25/04/01 11:06:47 INFO DAGScheduler: failed: Set()
25/04/01 11:06:47 INFO CodeGenerator: Code generated in 6.695337 ms
25/04/01 11:06:47 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:06:47 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:06:47 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:06:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:06:47 INFO DAGScheduler: Missing parents: List()
25/04/01 11:06:47 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:06:47 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 11:06:47 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 11:06:47 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:39219 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:06:47 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:06:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:06:47 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:06:47 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:06:47 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:44785 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:06:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:46730
25/04/01 11:06:47 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 29 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:06:47 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:06:47 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.035 s
25/04/01 11:06:47 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:06:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:06:47 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.037554 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 69, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:06:47 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:06:47 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:06:47 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:06:47 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:06:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:06:47 INFO MemoryStore: MemoryStore cleared
25/04/01 11:06:47 INFO BlockManager: BlockManager stopped
25/04/01 11:06:47 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:06:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:06:47 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:06:47 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:06:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-c913adae-73e4-4cf7-863a-dd89d9fd7cb9
25/04/01 11:06:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-d0613dac-8f79-4479-bbde-0a7d9c7a3f46
25/04/01 11:06:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-d0613dac-8f79-4479-bbde-0a7d9c7a3f46/pyspark-3a0349ed-2c26-40f9-af56-ef9e4a88a279
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:10:20 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:10:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:10:20 INFO ResourceUtils: ==============================================================
25/04/01 11:10:20 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:10:20 INFO ResourceUtils: ==============================================================
25/04/01 11:10:20 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:10:20 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:10:20 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:10:20 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:10:20 INFO SecurityManager: Changing view acls to: root
25/04/01 11:10:20 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:10:20 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:10:20 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:10:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:10:20 INFO Utils: Successfully started service 'sparkDriver' on port 46525.
25/04/01 11:10:20 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:10:20 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:10:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:10:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:10:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:10:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-75ff2c4a-82c0-41c9-a1d0-1395a819b441
25/04/01 11:10:20 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:10:20 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:10:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:10:20 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:10:21 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:10:21 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:10:21 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401111021-0011
25/04/01 11:10:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111021-0011/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:10:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111021-0011/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:10:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111021-0011/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:10:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111021-0011/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:10:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111021-0011/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:10:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111021-0011/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:10:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45955.
25/04/01 11:10:21 INFO NettyBlockTransferService: Server created on 7796893c36d7:45955
25/04/01 11:10:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:10:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 45955, None)
25/04/01 11:10:21 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:45955 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 45955, None)
25/04/01 11:10:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 45955, None)
25/04/01 11:10:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111021-0011/2 is now RUNNING
25/04/01 11:10:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111021-0011/1 is now RUNNING
25/04/01 11:10:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 45955, None)
25/04/01 11:10:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111021-0011/0 is now RUNNING
25/04/01 11:10:21 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:10:21 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:10:21 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:10:22 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/01 11:10:22 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:10:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:59638) with ID 0,  ResourceProfileId 0
25/04/01 11:10:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:48500) with ID 2,  ResourceProfileId 0
25/04/01 11:10:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:43238) with ID 1,  ResourceProfileId 0
25/04/01 11:10:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:43223 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 43223, None)
25/04/01 11:10:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:34673 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 34673, None)
25/04/01 11:10:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:46797 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 46797, None)
25/04/01 11:10:24 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:10:24 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:10:24 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:10:24 INFO CodeGenerator: Code generated in 128.563575 ms
25/04/01 11:10:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:10:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:10:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:45955 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:10:24 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:10:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:10:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:10:24 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:10:24 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:10:24 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:10:24 INFO DAGScheduler: Missing parents: List()
25/04/01 11:10:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:10:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:10:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:10:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:45955 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:10:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:10:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:10:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:10:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:10:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:43223 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:10:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:43223 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:10:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1351 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:10:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:10:26 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.416 s
25/04/01 11:10:26 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:10:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:10:26 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.449367 s
25/04/01 11:10:26 INFO CodeGenerator: Code generated in 8.927845 ms
25/04/01 11:10:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:10:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:10:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:10:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:10:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:10:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:45955 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:10:26 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:10:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:10:26 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:10:26 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:10:26 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:10:26 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:10:26 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:10:26 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:10:26 INFO metastore: Connected to metastore.
25/04/01 11:10:26 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=c1343800-4a67-4e8b-ab69-d95147811d0e, clientType=HIVECLI]
25/04/01 11:10:26 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:10:26 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:10:26 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:10:26 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:10:26 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:10:26 INFO metastore: Connected to metastore.
25/04/01 11:10:26 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:10:26 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:10:26 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:10:27 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:10:27 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:10:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:10:27 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string, UnitPrice: string ... 1 more fields>
25/04/01 11:10:27 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:10:27 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:10:27 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 11:10:27 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:10:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:45955 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:10:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:43223 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:10:27 INFO CodeGenerator: Code generated in 52.057152 ms
25/04/01 11:10:27 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:10:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:10:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:45955 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:10:27 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:10:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:10:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:10:27 INFO DAGScheduler: Registering RDD 13 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:10:27 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:10:27 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:10:27 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:10:27 INFO DAGScheduler: Missing parents: List()
25/04/01 11:10:27 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:10:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 39.6 KiB, free 365.2 MiB)
25/04/01 11:10:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 365.1 MiB)
25/04/01 11:10:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:45955 (size: 18.6 KiB, free: 366.2 MiB)
25/04/01 11:10:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:10:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:10:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:10:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:10:27 INFO CodeGenerator: Code generated in 19.118364 ms
25/04/01 11:10:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:10:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:10:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:45955 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:10:27 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:10:27 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:10:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:10:27 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:10:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:10:27 INFO CodeGenerator: Code generated in 17.789968 ms
25/04/01 11:10:27 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:10:27 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 11:10:27 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:10:27 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:10:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:10:27 INFO DAGScheduler: Missing parents: List()
25/04/01 11:10:27 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:10:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.3 KiB, free 364.7 MiB)
25/04/01 11:10:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 11:10:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:45955 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 11:10:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:10:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:10:27 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:10:27 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:10:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:46797 (size: 18.6 KiB, free: 366.3 MiB)
25/04/01 11:10:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:34673 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 11:10:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:48500
25/04/01 11:10:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:46797 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:10:28 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 1105 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:10:28 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:10:28 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.113 s
25/04/01 11:10:28 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:10:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:10:28 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.116914 s
25/04/01 11:10:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 11:10:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 11:10:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:45955 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:10:28 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:10:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1828 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:10:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:10:29 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.842 s
25/04/01 11:10:29 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:10:29 INFO DAGScheduler: running: Set()
25/04/01 11:10:29 INFO DAGScheduler: waiting: Set()
25/04/01 11:10:29 INFO DAGScheduler: failed: Set()
25/04/01 11:10:29 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:10:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:10:29 INFO CodeGenerator: Code generated in 11.391874 ms
25/04/01 11:10:29 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:10:29 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:10:29 INFO DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:10:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 11:10:29 INFO DAGScheduler: Missing parents: List()
25/04/01 11:10:29 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 40.5 KiB, free 364.7 MiB)
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 364.7 MiB)
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:45955 (size: 19.1 KiB, free: 366.1 MiB)
25/04/01 11:10:29 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:10:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:10:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:10:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:46797 (size: 19.1 KiB, free: 366.2 MiB)
25/04/01 11:10:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:43238
25/04/01 11:10:29 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 185 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:10:29 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:10:29 INFO DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 0.191 s
25/04/01 11:10:29 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:10:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/01 11:10:29 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.199754 s
25/04/01 11:10:29 INFO CodeGenerator: Code generated in 6.004325 ms
+---------+
|unitprice|
+---------+
|4.95000  |
|29.95000 |
|12.95000 |
|17.95000 |
|17.95000 |
|17.95000 |
|17.95000 |
|14.95000 |
|12.95000 |
|17.95000 |
|15.95000 |
|11.95000 |
|14.95000 |
|17.95000 |
|17.95000 |
|14.95000 |
|23.95000 |
|16.95000 |
|14.95000 |
|17.95000 |
+---------+
only showing top 20 rows

25/04/01 11:10:29 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:10:29 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:10:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:10:29 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:10:29 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:10:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:10:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 11:10:29 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:10:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:10:29 INFO CodeGenerator: Code generated in 9.338796 ms
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 345.6 KiB, free 364.3 MiB)
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.3 MiB)
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:45955 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:10:29 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:10:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:10:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:10:29 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:10:29 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:10:29 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:10:29 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:10:29 INFO DAGScheduler: Missing parents: List()
25/04/01 11:10:29 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 29.9 KiB, free 364.3 MiB)
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.2 MiB)
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:45955 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:10:29 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 11:10:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:10:29 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:10:29 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 349.8 KiB, free 363.9 MiB)
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.9 MiB)
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:45955 (size: 33.4 KiB, free: 366.0 MiB)
25/04/01 11:10:29 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:10:29 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:10:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:10:29 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:43223 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:10:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:10:29 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:10:29 INFO DAGScheduler: Registering RDD 31 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 3
25/04/01 11:10:29 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:10:29 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:10:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:10:29 INFO DAGScheduler: Missing parents: List()
25/04/01 11:10:29 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[34] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 34.3 KiB, free 363.8 MiB)
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 363.8 MiB)
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:45955 (size: 15.7 KiB, free: 366.0 MiB)
25/04/01 11:10:29 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:10:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[34] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:10:29 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:10:29 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.18.0.6, executor 2, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:34673 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 11:10:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:48500
25/04/01 11:10:29 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 39 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:10:29 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:10:29 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.045 s
25/04/01 11:10:29 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:10:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:10:29 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.049253 s
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 24.0 B, free 363.8 MiB)
25/04/01 11:10:29 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 120.0 B, free 363.8 MiB)
25/04/01 11:10:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:45955 (size: 120.0 B, free: 366.0 MiB)
25/04/01 11:10:29 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:10:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:43223 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:10:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 340 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:10:30 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:10:30 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.346 s
25/04/01 11:10:30 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:10:30 INFO DAGScheduler: running: Set()
25/04/01 11:10:30 INFO DAGScheduler: waiting: Set()
25/04/01 11:10:30 INFO DAGScheduler: failed: Set()
25/04/01 11:10:30 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:10:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:10:30 INFO CodeGenerator: Code generated in 10.246743 ms
25/04/01 11:10:30 INFO DAGScheduler: Registering RDD 37 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 11:10:30 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:10:30 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:10:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 11:10:30 INFO DAGScheduler: Missing parents: List()
25/04/01 11:10:30 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:10:30 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 37.9 KiB, free 363.8 MiB)
25/04/01 11:10:30 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 363.8 MiB)
25/04/01 11:10:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:45955 (size: 17.9 KiB, free: 366.0 MiB)
25/04/01 11:10:30 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:10:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:10:30 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:10:30 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 6) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:10:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:43223 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:10:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:59638
25/04/01 11:10:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 6) in 109 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:10:30 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:10:30 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.117 s
25/04/01 11:10:30 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:10:30 INFO DAGScheduler: running: Set()
25/04/01 11:10:30 INFO DAGScheduler: waiting: Set()
25/04/01 11:10:30 INFO DAGScheduler: failed: Set()
25/04/01 11:10:30 INFO CodeGenerator: Code generated in 5.900469 ms
25/04/01 11:10:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:10:30 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:10:30 INFO DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:10:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/04/01 11:10:30 INFO DAGScheduler: Missing parents: List()
25/04/01 11:10:30 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:10:30 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 363.8 MiB)
25/04/01 11:10:30 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 11:10:30 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:45955 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:10:30 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:10:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:10:30 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/04/01 11:10:30 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 7) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:10:30 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.2:43223 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:10:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.2:59638
25/04/01 11:10:30 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 7) in 30 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:10:30 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/04/01 11:10:30 INFO DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/01 11:10:30 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:10:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/04/01 11:10:30 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.035604 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 70, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:10:30 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:10:30 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:10:30 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:10:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:10:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:10:30 INFO MemoryStore: MemoryStore cleared
25/04/01 11:10:30 INFO BlockManager: BlockManager stopped
25/04/01 11:10:30 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:10:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:10:30 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:10:30 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:10:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-2d11537a-66c4-4333-9b0d-0cef09d241e7
25/04/01 11:10:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-2d11537a-66c4-4333-9b0d-0cef09d241e7/pyspark-09a49a1d-bdd0-4bc5-9694-e3db6124fa03
25/04/01 11:10:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-1daad0bd-ce16-402e-92cd-cba699dba6ff
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:14:08 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:14:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:14:08 INFO ResourceUtils: ==============================================================
25/04/01 11:14:08 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:14:08 INFO ResourceUtils: ==============================================================
25/04/01 11:14:08 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:14:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:14:08 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:14:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:14:08 INFO SecurityManager: Changing view acls to: root
25/04/01 11:14:08 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:14:08 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:14:08 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:14:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:14:08 INFO Utils: Successfully started service 'sparkDriver' on port 39903.
25/04/01 11:14:08 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:14:08 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:14:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:14:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:14:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:14:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1813d970-77f4-424c-b6d0-29314366fdba
25/04/01 11:14:08 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:14:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:14:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:14:08 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:14:08 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:14:08 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:14:08 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401111408-0012
25/04/01 11:14:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111408-0012/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:14:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111408-0012/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:14:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111408-0012/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:14:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111408-0012/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:14:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111408-0012/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:14:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45637.
25/04/01 11:14:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111408-0012/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:14:08 INFO NettyBlockTransferService: Server created on 7796893c36d7:45637
25/04/01 11:14:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:14:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 45637, None)
25/04/01 11:14:08 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:45637 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 45637, None)
25/04/01 11:14:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 45637, None)
25/04/01 11:14:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 45637, None)
25/04/01 11:14:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111408-0012/2 is now RUNNING
25/04/01 11:14:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111408-0012/1 is now RUNNING
25/04/01 11:14:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111408-0012/0 is now RUNNING
25/04/01 11:14:09 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:14:09 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:14:09 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:14:10 INFO InMemoryFileIndex: It took 61 ms to list leaf files for 1 paths.
25/04/01 11:14:10 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:14:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:49196) with ID 1,  ResourceProfileId 0
25/04/01 11:14:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:37398) with ID 2,  ResourceProfileId 0
25/04/01 11:14:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:56584) with ID 0,  ResourceProfileId 0
25/04/01 11:14:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:43883 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 43883, None)
25/04/01 11:14:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:33083 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 33083, None)
25/04/01 11:14:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:41959 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 41959, None)
25/04/01 11:14:12 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:14:12 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:14:12 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:14:12 INFO CodeGenerator: Code generated in 132.446757 ms
25/04/01 11:14:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:14:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:14:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:45637 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:14:12 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:14:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:14:12 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:14:12 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:14:12 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:14:12 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:14:12 INFO DAGScheduler: Missing parents: List()
25/04/01 11:14:12 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:14:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:14:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:14:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:45637 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:14:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:14:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:14:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:14:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:14:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:41959 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:14:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:41959 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:14:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1348 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:14:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:14:14 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.415 s
25/04/01 11:14:14 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:14:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:14:14 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.446501 s
25/04/01 11:14:14 INFO CodeGenerator: Code generated in 8.276832 ms
25/04/01 11:14:14 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:14:14 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:14:14 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:14:14 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:14:14 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:14:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:45637 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:14:14 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:14:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:14:14 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:14:14 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:14:14 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:14:14 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:14:14 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:14:14 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:14:14 INFO metastore: Connected to metastore.
25/04/01 11:14:14 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=92bdfae3-0c35-434e-84fe-499c056963fe, clientType=HIVECLI]
25/04/01 11:14:14 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:14:14 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:14:14 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:14:14 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:14:14 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:14:14 INFO metastore: Connected to metastore.
25/04/01 11:14:14 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:14:14 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:14:14 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:14:15 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:14:15 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:14:15 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:14:15 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string, UnitPrice: string ... 1 more fields>
25/04/01 11:14:15 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:14:15 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:14:15 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:14:15 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:14:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:45637 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:14:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:41959 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:14:15 INFO CodeGenerator: Code generated in 47.840068 ms
25/04/01 11:14:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:14:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:14:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:45637 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:14:15 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:14:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:14:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:14:15 INFO DAGScheduler: Registering RDD 13 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:14:15 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:14:15 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:14:15 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:14:15 INFO DAGScheduler: Missing parents: List()
25/04/01 11:14:15 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:14:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 39.6 KiB, free 365.2 MiB)
25/04/01 11:14:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 365.1 MiB)
25/04/01 11:14:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:45637 (size: 18.6 KiB, free: 366.2 MiB)
25/04/01 11:14:15 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:14:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:14:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:14:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:14:15 INFO CodeGenerator: Code generated in 17.852234 ms
25/04/01 11:14:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:14:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:14:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:45637 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:14:15 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:14:15 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:14:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:14:15 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:14:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:14:15 INFO CodeGenerator: Code generated in 19.996452 ms
25/04/01 11:14:15 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:14:15 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 11:14:15 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:14:15 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:14:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:14:15 INFO DAGScheduler: Missing parents: List()
25/04/01 11:14:15 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:14:15 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 33.2 KiB, free 364.7 MiB)
25/04/01 11:14:15 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 364.7 MiB)
25/04/01 11:14:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:45637 (size: 15.1 KiB, free: 366.1 MiB)
25/04/01 11:14:15 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:14:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:14:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:14:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:14:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:33083 (size: 15.1 KiB, free: 366.3 MiB)
25/04/01 11:14:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:33083 (size: 18.6 KiB, free: 366.3 MiB)
25/04/01 11:14:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:37398
25/04/01 11:14:16 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 700 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:14:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:14:16 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.708 s
25/04/01 11:14:16 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:14:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:14:16 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.712146 s
25/04/01 11:14:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 11:14:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 11:14:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:45637 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:14:16 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:14:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:33083 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:14:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1492 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:14:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:14:16 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.505 s
25/04/01 11:14:16 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:14:16 INFO DAGScheduler: running: Set()
25/04/01 11:14:16 INFO DAGScheduler: waiting: Set()
25/04/01 11:14:16 INFO DAGScheduler: failed: Set()
25/04/01 11:14:16 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:14:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:14:16 INFO CodeGenerator: Code generated in 11.368595 ms
25/04/01 11:14:16 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:14:16 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:14:16 INFO DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:14:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 11:14:16 INFO DAGScheduler: Missing parents: List()
25/04/01 11:14:16 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:14:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 40.5 KiB, free 364.7 MiB)
25/04/01 11:14:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 364.7 MiB)
25/04/01 11:14:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:45637 (size: 19.1 KiB, free: 366.1 MiB)
25/04/01 11:14:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:14:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:14:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:14:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:14:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:33083 (size: 19.1 KiB, free: 366.2 MiB)
25/04/01 11:14:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:37398
25/04/01 11:14:17 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 63 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:14:17 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:14:17 INFO DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 0.070 s
25/04/01 11:14:17 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:14:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/01 11:14:17 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.078649 s
25/04/01 11:14:17 INFO CodeGenerator: Code generated in 5.438524 ms
+---------+
|unitprice|
+---------+
|4.95000  |
|29.95000 |
|12.95000 |
|17.95000 |
|17.95000 |
|17.95000 |
|17.95000 |
|14.95000 |
|12.95000 |
|17.95000 |
|15.95000 |
|11.95000 |
|14.95000 |
|17.95000 |
|17.95000 |
|14.95000 |
|23.95000 |
|16.95000 |
|14.95000 |
|17.95000 |
+---------+
only showing top 20 rows

25/04/01 11:14:17 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:14:17 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:14:17 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:14:17 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:14:17 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:14:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:14:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:14:17 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:14:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:14:17 INFO CodeGenerator: Code generated in 8.917143 ms
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 345.6 KiB, free 364.3 MiB)
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.3 MiB)
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:45637 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:14:17 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:14:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:14:17 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:14:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:14:17 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:14:17 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:14:17 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:14:17 INFO DAGScheduler: Missing parents: List()
25/04/01 11:14:17 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 29.9 KiB, free 364.3 MiB)
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.2 MiB)
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:45637 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:14:17 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 11:14:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:14:17 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 349.8 KiB, free 363.9 MiB)
25/04/01 11:14:17 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.9 MiB)
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:45637 (size: 33.4 KiB, free: 366.0 MiB)
25/04/01 11:14:17 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:14:17 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:14:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:33083 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:14:17 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:14:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:14:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:14:17 INFO DAGScheduler: Registering RDD 31 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 3
25/04/01 11:14:17 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:14:17 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:14:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:14:17 INFO DAGScheduler: Missing parents: List()
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:33083 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:14:17 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[34] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 33.2 KiB, free 363.8 MiB)
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 363.8 MiB)
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:45637 (size: 15.1 KiB, free: 366.0 MiB)
25/04/01 11:14:17 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:14:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[34] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:14:17 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:14:17 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.18.0.6, executor 2, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:33083 (size: 15.1 KiB, free: 366.2 MiB)
25/04/01 11:14:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:37398
25/04/01 11:14:17 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 27 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:14:17 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:14:17 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.032 s
25/04/01 11:14:17 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:14:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:14:17 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.035527 s
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 24.0 B, free 363.8 MiB)
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 120.0 B, free 363.8 MiB)
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:45637 (size: 120.0 B, free: 366.0 MiB)
25/04/01 11:14:17 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:14:17 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 105 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:14:17 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:14:17 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.112 s
25/04/01 11:14:17 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:14:17 INFO DAGScheduler: running: Set()
25/04/01 11:14:17 INFO DAGScheduler: waiting: Set()
25/04/01 11:14:17 INFO DAGScheduler: failed: Set()
25/04/01 11:14:17 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:14:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:14:17 INFO CodeGenerator: Code generated in 11.419999 ms
25/04/01 11:14:17 INFO DAGScheduler: Registering RDD 37 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 11:14:17 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:14:17 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:14:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 11:14:17 INFO DAGScheduler: Missing parents: List()
25/04/01 11:14:17 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 37.9 KiB, free 363.8 MiB)
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 363.8 MiB)
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:45637 (size: 17.9 KiB, free: 366.0 MiB)
25/04/01 11:14:17 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:14:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:14:17 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:14:17 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 6) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:33083 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 11:14:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:37398
25/04/01 11:14:17 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 6) in 48 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:14:17 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:14:17 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.056 s
25/04/01 11:14:17 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:14:17 INFO DAGScheduler: running: Set()
25/04/01 11:14:17 INFO DAGScheduler: waiting: Set()
25/04/01 11:14:17 INFO DAGScheduler: failed: Set()
25/04/01 11:14:17 INFO CodeGenerator: Code generated in 5.568221 ms
25/04/01 11:14:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:14:17 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:14:17 INFO DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:14:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/04/01 11:14:17 INFO DAGScheduler: Missing parents: List()
25/04/01 11:14:17 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 363.8 MiB)
25/04/01 11:14:17 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.8 MiB)
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:45637 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:14:17 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:14:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:14:17 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/04/01 11:14:17 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 7) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:14:17 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.6:33083 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:14:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.6:37398
25/04/01 11:14:17 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 7) in 27 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:14:17 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/04/01 11:14:17 INFO DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
25/04/01 11:14:17 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:14:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/04/01 11:14:17 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.034649 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 70, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:14:17 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:14:17 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:14:17 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:14:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:14:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:14:17 INFO MemoryStore: MemoryStore cleared
25/04/01 11:14:17 INFO BlockManager: BlockManager stopped
25/04/01 11:14:17 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:14:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:14:17 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:14:17 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:14:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-02be8634-9311-4f0f-b4f7-7776292a783e/pyspark-6b9ed095-9fd8-4c3f-90be-c1d4b16cddfb
25/04/01 11:14:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-02be8634-9311-4f0f-b4f7-7776292a783e
25/04/01 11:14:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-0642a5c3-a180-43ba-94d1-6b78762fb940
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:15:04 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:15:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:15:04 INFO ResourceUtils: ==============================================================
25/04/01 11:15:04 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:15:04 INFO ResourceUtils: ==============================================================
25/04/01 11:15:04 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:15:04 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:15:04 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:15:04 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:15:04 INFO SecurityManager: Changing view acls to: root
25/04/01 11:15:04 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:15:04 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:15:04 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:15:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:15:04 INFO Utils: Successfully started service 'sparkDriver' on port 37559.
25/04/01 11:15:04 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:15:04 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:15:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:15:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:15:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:15:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-556ddf48-c706-4c0a-bf45-dadcad53852a
25/04/01 11:15:05 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:15:05 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:15:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:15:05 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:15:05 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:15:05 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:15:05 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401111505-0013
25/04/01 11:15:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111505-0013/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:15:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111505-0013/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:15:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111505-0013/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:15:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111505-0013/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:15:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111505-0013/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:15:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111505-0013/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:15:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43141.
25/04/01 11:15:05 INFO NettyBlockTransferService: Server created on 7796893c36d7:43141
25/04/01 11:15:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:15:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111505-0013/2 is now RUNNING
25/04/01 11:15:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111505-0013/1 is now RUNNING
25/04/01 11:15:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 43141, None)
25/04/01 11:15:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111505-0013/0 is now RUNNING
25/04/01 11:15:05 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:43141 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 43141, None)
25/04/01 11:15:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 43141, None)
25/04/01 11:15:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 43141, None)
25/04/01 11:15:05 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:15:05 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:15:05 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:15:07 INFO InMemoryFileIndex: It took 61 ms to list leaf files for 1 paths.
25/04/01 11:15:07 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:15:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:58732) with ID 2,  ResourceProfileId 0
25/04/01 11:15:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:54212) with ID 1,  ResourceProfileId 0
25/04/01 11:15:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:60920) with ID 0,  ResourceProfileId 0
25/04/01 11:15:07 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42581 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 42581, None)
25/04/01 11:15:07 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:45429 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 45429, None)
25/04/01 11:15:07 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:36113 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 36113, None)
25/04/01 11:15:08 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:15:08 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:15:08 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:15:09 INFO CodeGenerator: Code generated in 130.384575 ms
25/04/01 11:15:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:15:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:15:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:43141 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:15:09 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:15:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:15:09 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:15:09 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:15:09 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:15:09 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:15:09 INFO DAGScheduler: Missing parents: List()
25/04/01 11:15:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:15:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:15:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:15:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:43141 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:15:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:15:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:15:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:15:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:15:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:42581 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:15:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:42581 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:15:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1391 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:15:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:15:10 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.454 s
25/04/01 11:15:10 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:15:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:15:10 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.485406 s
25/04/01 11:15:10 INFO CodeGenerator: Code generated in 7.558089 ms
25/04/01 11:15:10 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:15:10 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:15:10 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:15:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:15:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:15:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:43141 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:15:10 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:15:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:15:11 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:15:11 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:15:11 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:15:11 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:15:11 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:15:11 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:15:11 INFO metastore: Connected to metastore.
25/04/01 11:15:11 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=185ed9f8-8304-40a5-96ce-db12610432f1, clientType=HIVECLI]
25/04/01 11:15:11 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:15:11 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:15:11 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:15:11 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:15:11 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:15:11 INFO metastore: Connected to metastore.
25/04/01 11:15:11 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:15:11 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:15:11 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 11:15:11 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:15:11 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:15:11 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string, UnitPrice: string ... 1 more fields>
25/04/01 11:15:11 INFO CodeGenerator: Code generated in 57.527305 ms
25/04/01 11:15:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:15:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:15:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:43141 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:15:11 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:15:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:15:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:43141 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:15:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:42581 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:15:11 INFO DAGScheduler: Registering RDD 13 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:15:11 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:15:11 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:15:11 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:15:11 INFO DAGScheduler: Missing parents: List()
25/04/01 11:15:11 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:15:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 39.6 KiB, free 365.2 MiB)
25/04/01 11:15:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 365.1 MiB)
25/04/01 11:15:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:43141 (size: 18.6 KiB, free: 366.2 MiB)
25/04/01 11:15:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:15:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:15:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:15:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:15:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:45429 (size: 18.6 KiB, free: 366.3 MiB)
25/04/01 11:15:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:45429 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:15:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1596 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:15:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:15:13 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.609 s
25/04/01 11:15:13 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:15:13 INFO DAGScheduler: running: Set()
25/04/01 11:15:13 INFO DAGScheduler: waiting: Set()
25/04/01 11:15:13 INFO DAGScheduler: failed: Set()
25/04/01 11:15:13 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:15:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:15:13 INFO CodeGenerator: Code generated in 15.37236 ms
25/04/01 11:15:13 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:15:13 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:15:13 INFO DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:15:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:15:13 INFO DAGScheduler: Missing parents: List()
25/04/01 11:15:13 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:15:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 40.4 KiB, free 365.1 MiB)
25/04/01 11:15:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 365.1 MiB)
25/04/01 11:15:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:43141 (size: 19.1 KiB, free: 366.2 MiB)
25/04/01 11:15:13 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 11:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:15:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:15:13 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:15:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:45429 (size: 19.1 KiB, free: 366.2 MiB)
25/04/01 11:15:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:58732
25/04/01 11:15:13 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 189 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:15:13 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:15:13 INFO DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.197 s
25/04/01 11:15:13 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:15:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:15:13 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0.205796 s
25/04/01 11:15:13 INFO CodeGenerator: Code generated in 5.337254 ms
+---------+
|unitprice|
+---------+
|4.95000  |
|29.95000 |
|12.95000 |
|17.95000 |
|17.95000 |
|17.95000 |
|17.95000 |
|14.95000 |
|12.95000 |
|17.95000 |
|15.95000 |
|11.95000 |
|14.95000 |
|17.95000 |
|17.95000 |
|14.95000 |
|23.95000 |
|16.95000 |
|14.95000 |
|17.95000 |
+---------+
only showing top 20 rows

25/04/01 11:15:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:15:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:15:13 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:15:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:15:13 INFO CodeGenerator: Code generated in 10.425173 ms
25/04/01 11:15:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/01 11:15:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/01 11:15:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:43141 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:15:13 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:15:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:15:13 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:15:13 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:15:13 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:15:13 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:15:13 INFO DAGScheduler: Missing parents: List()
25/04/01 11:15:13 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:15:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 29.9 KiB, free 364.7 MiB)
25/04/01 11:15:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.7 MiB)
25/04/01 11:15:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:43141 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:15:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:15:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:15:13 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:15:13 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:15:14 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:36113 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:15:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:36113 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:15:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 1537 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:15:15 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:15:15 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 1.542 s
25/04/01 11:15:15 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:15:15 INFO DAGScheduler: running: Set()
25/04/01 11:15:15 INFO DAGScheduler: waiting: Set()
25/04/01 11:15:15 INFO DAGScheduler: failed: Set()
25/04/01 11:15:15 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:15:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:15:15 INFO CodeGenerator: Code generated in 9.266355 ms
25/04/01 11:15:15 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:15:15 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:15:15 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:15:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:15:15 INFO DAGScheduler: Missing parents: List()
25/04/01 11:15:15 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:15:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.6 KiB, free 364.6 MiB)
25/04/01 11:15:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 364.6 MiB)
25/04/01 11:15:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:43141 (size: 17.8 KiB, free: 366.1 MiB)
25/04/01 11:15:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:15:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:15:15 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:15:15 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:15:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:36113 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 11:15:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:60920
25/04/01 11:15:15 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 115 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:15:15 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:15:15 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.121 s
25/04/01 11:15:15 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:15:15 INFO DAGScheduler: running: Set()
25/04/01 11:15:15 INFO DAGScheduler: waiting: Set()
25/04/01 11:15:15 INFO DAGScheduler: failed: Set()
25/04/01 11:15:15 INFO CodeGenerator: Code generated in 5.636457 ms
25/04/01 11:15:15 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:15:15 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:15:15 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:15:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 11:15:15 INFO DAGScheduler: Missing parents: List()
25/04/01 11:15:15 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:15:15 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.6 MiB)
25/04/01 11:15:15 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.6 MiB)
25/04/01 11:15:15 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:43141 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:15:15 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:15:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:15:15 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 11:15:15 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:15:15 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:36113 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:15:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:60920
25/04/01 11:15:15 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 91 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:15:15 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:15:15 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.095 s
25/04/01 11:15:15 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:15:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 11:15:15 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0.098159 s
25/04/01 11:15:15 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:15:15 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:15:15 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:15:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:15:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:15:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:15:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:15:15 INFO CodeGenerator: Code generated in 9.526098 ms
25/04/01 11:15:15 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 364.3 MiB)
25/04/01 11:15:15 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.2 MiB)
25/04/01 11:15:15 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:43141 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:15:15 INFO SparkContext: Created broadcast 10 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:15:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:15:15 INFO DAGScheduler: Registering RDD 31 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 11:15:15 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:15:15 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:15:15 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:15:15 INFO DAGScheduler: Missing parents: List()
25/04/01 11:15:15 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:15:15 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 31.8 KiB, free 364.2 MiB)
25/04/01 11:15:15 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.2 MiB)
25/04/01 11:15:15 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:43141 (size: 14.7 KiB, free: 366.1 MiB)
25/04/01 11:15:15 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:15:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[31] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:15:15 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:15:15 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 6) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:15:15 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:42581 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 11:15:16 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:42581 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:15:16 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 6) in 463 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:15:16 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:15:16 INFO DAGScheduler: ShuffleMapStage 10 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.472 s
25/04/01 11:15:16 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:15:16 INFO DAGScheduler: running: Set()
25/04/01 11:15:16 INFO DAGScheduler: waiting: Set()
25/04/01 11:15:16 INFO DAGScheduler: failed: Set()
25/04/01 11:15:16 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:15:16 INFO CodeGenerator: Code generated in 7.230811 ms
25/04/01 11:15:16 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:15:16 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:15:16 INFO DAGScheduler: Final stage: ResultStage 12 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:15:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
25/04/01 11:15:16 INFO DAGScheduler: Missing parents: List()
25/04/01 11:15:16 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[36] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:15:16 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 234.4 KiB, free 364.0 MiB)
25/04/01 11:15:16 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 86.3 KiB, free 363.9 MiB)
25/04/01 11:15:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:43141 (size: 86.3 KiB, free: 366.0 MiB)
25/04/01 11:15:16 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:15:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[36] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:15:16 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/04/01 11:15:16 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 7) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:15:16 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:42581 (size: 86.3 KiB, free: 366.1 MiB)
25/04/01 11:15:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:54212
25/04/01 11:15:17 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 7) in 909 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:15:17 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/04/01 11:15:17 INFO DAGScheduler: ResultStage 12 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.935 s
25/04/01 11:15:17 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:15:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
25/04/01 11:15:17 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.940816 s
25/04/01 11:15:17 INFO FileFormatWriter: Start to commit write Job a0e2aa76-6958-4018-95b2-c52fc0792728.
25/04/01 11:15:17 INFO FileFormatWriter: Write Job a0e2aa76-6958-4018-95b2-c52fc0792728 committed. Elapsed time: 42 ms.
25/04/01 11:15:17 INFO FileFormatWriter: Finished processing stats for write job a0e2aa76-6958-4018-95b2-c52fc0792728.
25/04/01 11:15:17 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:15:17 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:15:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:15:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:15:17 INFO MemoryStore: MemoryStore cleared
25/04/01 11:15:17 INFO BlockManager: BlockManager stopped
25/04/01 11:15:17 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:15:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:15:17 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:15:18 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:15:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-fb8f103e-0f3c-4913-a647-cd26b4b617a9/pyspark-86967e33-528d-4a2f-84c1-964d589b80b1
25/04/01 11:15:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-fb8f103e-0f3c-4913-a647-cd26b4b617a9
25/04/01 11:15:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-8c4da434-b809-4db1-b372-53c5e047ca2b
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:15:56 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:15:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:15:56 INFO ResourceUtils: ==============================================================
25/04/01 11:15:56 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:15:56 INFO ResourceUtils: ==============================================================
25/04/01 11:15:56 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:15:56 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:15:56 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:15:56 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:15:56 INFO SecurityManager: Changing view acls to: root
25/04/01 11:15:56 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:15:56 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:15:56 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:15:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:15:56 INFO Utils: Successfully started service 'sparkDriver' on port 39115.
25/04/01 11:15:56 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:15:56 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:15:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:15:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:15:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:15:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1bc156e1-e5b3-4b4a-9dcd-0c0b41b48ce6
25/04/01 11:15:56 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:15:56 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:15:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:15:57 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:15:57 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:15:57 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:15:57 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401111557-0014
25/04/01 11:15:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111557-0014/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:15:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111557-0014/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:15:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111557-0014/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:15:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111557-0014/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:15:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111557-0014/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:15:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111557-0014/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:15:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44587.
25/04/01 11:15:57 INFO NettyBlockTransferService: Server created on 7796893c36d7:44587
25/04/01 11:15:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:15:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 44587, None)
25/04/01 11:15:57 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:44587 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 44587, None)
25/04/01 11:15:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111557-0014/2 is now RUNNING
25/04/01 11:15:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111557-0014/1 is now RUNNING
25/04/01 11:15:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 44587, None)
25/04/01 11:15:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 44587, None)
25/04/01 11:15:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111557-0014/0 is now RUNNING
25/04/01 11:15:57 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:15:57 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:15:57 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:15:58 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.
25/04/01 11:15:59 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:15:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:42668) with ID 2,  ResourceProfileId 0
25/04/01 11:15:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:52900) with ID 1,  ResourceProfileId 0
25/04/01 11:15:59 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:36250) with ID 0,  ResourceProfileId 0
25/04/01 11:15:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:36991 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 36991, None)
25/04/01 11:15:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:38527 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 38527, None)
25/04/01 11:15:59 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:40107 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 40107, None)
25/04/01 11:16:00 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:16:00 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:16:00 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:16:00 INFO CodeGenerator: Code generated in 138.681416 ms
25/04/01 11:16:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:16:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:16:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:44587 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:16:01 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:16:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:01 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:16:01 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:01 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:01 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:01 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:16:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:16:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:44587 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:16:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:16:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:16:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:36991 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:16:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:36991 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:16:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1367 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:16:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:16:02 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.431 s
25/04/01 11:16:02 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:16:02 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.463924 s
25/04/01 11:16:02 INFO CodeGenerator: Code generated in 8.642877 ms
25/04/01 11:16:02 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:16:02 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:16:02 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:16:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:16:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:16:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:44587 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:16:02 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:16:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:02 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:16:02 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:16:02 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:16:03 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:16:03 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:16:03 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:16:03 INFO metastore: Connected to metastore.
25/04/01 11:16:03 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=872f2c16-3032-47a7-be53-477ea1bc5bae, clientType=HIVECLI]
25/04/01 11:16:03 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:16:03 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:16:03 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:16:03 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:16:03 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:16:03 INFO metastore: Connected to metastore.
25/04/01 11:16:03 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:16:03 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:16:03 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:16:03 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 11:16:03 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:16:03 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:16:03 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string, UnitPrice: string ... 1 more fields>
25/04/01 11:16:03 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:16:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:16:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:16:03 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:16:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:44587 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:16:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:36991 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:16:03 INFO CodeGenerator: Code generated in 17.184065 ms
25/04/01 11:16:03 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:16:03 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 11:16:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:44587 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:16:03 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:03 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:16:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:03 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:03 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:16:03 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:16:03 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:03 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:03 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:16:03 INFO CodeGenerator: Code generated in 57.220154 ms
25/04/01 11:16:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 11:16:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 11:16:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:44587 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:16:03 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 11:16:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:16:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:16:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:16:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:44587 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:16:03 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:16:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:36991 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:16:03 INFO DAGScheduler: Registering RDD 17 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:16:03 INFO DAGScheduler: Got map stage job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:03 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:03 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:03 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:03 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:03 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.6 KiB, free 364.8 MiB)
25/04/01 11:16:03 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 364.7 MiB)
25/04/01 11:16:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:44587 (size: 18.6 KiB, free: 366.1 MiB)
25/04/01 11:16:03 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:36991 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:16:03 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:16:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:16:04 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:40107 (size: 18.6 KiB, free: 366.3 MiB)
25/04/01 11:16:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 695 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:16:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:16:04 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.701 s
25/04/01 11:16:04 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 11:16:04 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.705086 s
25/04/01 11:16:04 INFO CodeGenerator: Code generated in 5.783476 ms
25/04/01 11:16:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1028.0 KiB, free 363.7 MiB)
25/04/01 11:16:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 363.7 MiB)
25/04/01 11:16:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:44587 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:16:04 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:40107 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:16:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1701 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:16:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:16:05 INFO DAGScheduler: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 1.719 s
25/04/01 11:16:05 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:16:05 INFO DAGScheduler: running: Set()
25/04/01 11:16:05 INFO DAGScheduler: waiting: Set()
25/04/01 11:16:05 INFO DAGScheduler: failed: Set()
25/04/01 11:16:05 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:16:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:16:05 INFO CodeGenerator: Code generated in 14.65781 ms
25/04/01 11:16:05 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:16:05 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:05 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:16:05 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:05 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 49.4 KiB, free 363.7 MiB)
25/04/01 11:16:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.7 MiB)
25/04/01 11:16:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:44587 (size: 23.0 KiB, free: 366.1 MiB)
25/04/01 11:16:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:05 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:16:05 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:16:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:40107 (size: 23.0 KiB, free: 366.2 MiB)
25/04/01 11:16:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:36250
25/04/01 11:16:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:40107 (size: 2.4 KiB, free: 366.2 MiB)
25/04/01 11:16:05 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 253 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:16:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:16:05 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0.260 s
25/04/01 11:16:05 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 11:16:05 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.269947 s
+---------+
|unitprice|
+---------+
+---------+

25/04/01 11:16:06 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/04/01 11:16:06 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:16:06 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:16:06 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:16:06 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:16:06 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:16:06 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:16:06 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:16:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 363.3 MiB)
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.3 MiB)
25/04/01 11:16:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:44587 (size: 33.4 KiB, free: 366.1 MiB)
25/04/01 11:16:06 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:06 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:16:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:06 INFO CodeGenerator: Code generated in 14.548508 ms
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 363.0 MiB)
25/04/01 11:16:06 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:06 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:16:06 INFO DAGScheduler: Final stage: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:16:06 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:06 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:06 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 362.9 MiB)
25/04/01 11:16:06 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:44587 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:16:06 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 362.9 MiB)
25/04/01 11:16:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 362.9 MiB)
25/04/01 11:16:06 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:44587 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 11:16:06 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:16:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.18.0.2, executor 0, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:16:06 INFO DAGScheduler: Registering RDD 28 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:16:06 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:06 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:06 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:06 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:06 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[28] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 29.9 KiB, free 362.9 MiB)
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 362.9 MiB)
25/04/01 11:16:06 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:44587 (size: 14.1 KiB, free: 366.0 MiB)
25/04/01 11:16:06 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[28] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:06 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:16:06 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:16:06 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:40107 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:16:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:40107 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:16:06 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:38527 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:16:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 696 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:16:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:16:06 INFO DAGScheduler: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.702 s
25/04/01 11:16:06 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/01 11:16:06 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.705492 s
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 1028.0 KiB, free 361.9 MiB)
25/04/01 11:16:06 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 361.9 MiB)
25/04/01 11:16:06 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:44587 (size: 2.4 KiB, free: 366.0 MiB)
25/04/01 11:16:06 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:07 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:38527 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:16:07 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 1639 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:16:07 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:16:07 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 1.647 s
25/04/01 11:16:07 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:16:07 INFO DAGScheduler: running: Set()
25/04/01 11:16:07 INFO DAGScheduler: waiting: Set()
25/04/01 11:16:07 INFO DAGScheduler: failed: Set()
25/04/01 11:16:07 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:16:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:16:07 INFO CodeGenerator: Code generated in 10.572961 ms
25/04/01 11:16:07 INFO DAGScheduler: Registering RDD 31 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:16:07 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:07 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:16:07 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:07 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.3 KiB, free 361.8 MiB)
25/04/01 11:16:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 361.8 MiB)
25/04/01 11:16:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:44587 (size: 22.1 KiB, free: 366.0 MiB)
25/04/01 11:16:07 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:07 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:16:07 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:16:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:38527 (size: 22.1 KiB, free: 366.2 MiB)
25/04/01 11:16:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:52900
25/04/01 11:16:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:38527 (size: 2.4 KiB, free: 366.2 MiB)
25/04/01 11:16:07 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 182 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:16:07 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:16:07 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.190 s
25/04/01 11:16:07 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:16:07 INFO DAGScheduler: running: Set()
25/04/01 11:16:07 INFO DAGScheduler: waiting: Set()
25/04/01 11:16:07 INFO DAGScheduler: failed: Set()
25/04/01 11:16:08 INFO CodeGenerator: Code generated in 6.141137 ms
25/04/01 11:16:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:16:08 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:08 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 11:16:08 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:08 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:08 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 361.8 MiB)
25/04/01 11:16:08 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 361.8 MiB)
25/04/01 11:16:08 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:44587 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:16:08 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:08 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 11:16:08 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:16:08 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:38527 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:16:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:52900
25/04/01 11:16:08 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 85 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:16:08 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 11:16:08 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.090 s
25/04/01 11:16:08 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 11:16:08 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.092605 s
25/04/01 11:16:08 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:16:08 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:16:08 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:16:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:16:08 INFO MemoryStore: MemoryStore cleared
25/04/01 11:16:08 INFO BlockManager: BlockManager stopped
25/04/01 11:16:08 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:16:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:16:08 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:16:08 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:16:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-3e1cd8e3-2cd6-4c38-9d07-284169e9af80/pyspark-b0ca82d6-92ba-4296-ab07-fd8a334c24cb
25/04/01 11:16:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-3e1cd8e3-2cd6-4c38-9d07-284169e9af80
25/04/01 11:16:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-ed4a1fa1-efd3-471d-9aa6-45bb0a856888
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:16:43 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:16:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:16:43 INFO ResourceUtils: ==============================================================
25/04/01 11:16:43 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:16:43 INFO ResourceUtils: ==============================================================
25/04/01 11:16:43 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:16:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:16:43 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:16:43 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:16:43 INFO SecurityManager: Changing view acls to: root
25/04/01 11:16:43 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:16:43 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:16:43 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:16:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:16:43 INFO Utils: Successfully started service 'sparkDriver' on port 39509.
25/04/01 11:16:43 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:16:43 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:16:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:16:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:16:43 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:16:43 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a7941764-c8cf-457d-b9cb-f5c6249c23e7
25/04/01 11:16:43 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:16:43 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:16:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:16:43 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:16:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:16:43 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:16:44 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401111644-0015
25/04/01 11:16:44 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111644-0015/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:16:44 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111644-0015/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:16:44 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111644-0015/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:16:44 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111644-0015/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:16:44 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111644-0015/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:16:44 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111644-0015/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:16:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36635.
25/04/01 11:16:44 INFO NettyBlockTransferService: Server created on 7796893c36d7:36635
25/04/01 11:16:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:16:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 36635, None)
25/04/01 11:16:44 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:36635 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 36635, None)
25/04/01 11:16:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 36635, None)
25/04/01 11:16:44 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111644-0015/0 is now RUNNING
25/04/01 11:16:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 36635, None)
25/04/01 11:16:44 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111644-0015/1 is now RUNNING
25/04/01 11:16:44 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111644-0015/2 is now RUNNING
25/04/01 11:16:44 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:16:44 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:16:44 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:16:45 INFO InMemoryFileIndex: It took 62 ms to list leaf files for 1 paths.
25/04/01 11:16:45 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:16:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:45486) with ID 0,  ResourceProfileId 0
25/04/01 11:16:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:35466) with ID 2,  ResourceProfileId 0
25/04/01 11:16:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:43222) with ID 1,  ResourceProfileId 0
25/04/01 11:16:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:44079 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 44079, None)
25/04/01 11:16:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:45599 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 45599, None)
25/04/01 11:16:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:34717 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 34717, None)
25/04/01 11:16:47 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:16:47 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:16:47 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:16:47 INFO CodeGenerator: Code generated in 136.40487 ms
25/04/01 11:16:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:16:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:16:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:36635 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:16:47 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:16:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:47 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:16:47 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:47 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:47 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:47 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:47 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:16:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:16:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:36635 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:16:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:16:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:16:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:34717 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:16:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:34717 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:16:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1409 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:16:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:16:49 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.480 s
25/04/01 11:16:49 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:16:49 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.511382 s
25/04/01 11:16:49 INFO CodeGenerator: Code generated in 7.756374 ms
25/04/01 11:16:49 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:16:49 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:16:49 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:16:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:16:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:16:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:36635 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:16:49 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:16:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:49 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:16:49 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:16:49 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:16:49 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:16:49 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:16:49 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:16:49 INFO metastore: Connected to metastore.
25/04/01 11:16:50 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=e3b8c842-88db-4e76-82ce-fe92579571cb, clientType=HIVECLI]
25/04/01 11:16:50 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:16:50 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:16:50 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:16:50 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:16:50 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:16:50 INFO metastore: Connected to metastore.
25/04/01 11:16:50 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:16:50 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:16:50 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:16:50 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 11:16:50 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:16:50 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:16:50 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string, UnitPrice: string ... 1 more fields>
25/04/01 11:16:50 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:16:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:16:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:16:50 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:16:50 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:36635 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:16:50 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:34717 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:16:50 INFO CodeGenerator: Code generated in 15.668008 ms
25/04/01 11:16:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:16:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 11:16:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:36635 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:16:50 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:50 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:16:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:50 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:50 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:16:50 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:16:50 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:50 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:50 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:16:50 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 11:16:50 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 11:16:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:36635 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:16:50 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:16:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:16:50 INFO CodeGenerator: Code generated in 59.692361 ms
25/04/01 11:16:50 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 11:16:50 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:16:50 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:36635 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:16:50 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:16:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:50 INFO DAGScheduler: Registering RDD 17 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:16:50 INFO DAGScheduler: Got map stage job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:50 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:50 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:50 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:50 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.6 KiB, free 364.8 MiB)
25/04/01 11:16:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 364.7 MiB)
25/04/01 11:16:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:36635 (size: 18.6 KiB, free: 366.1 MiB)
25/04/01 11:16:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:16:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:16:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:45599 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:16:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:45599 (size: 18.6 KiB, free: 366.3 MiB)
25/04/01 11:16:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:45599 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:16:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:45599 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:16:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1331 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:16:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:16:52 INFO DAGScheduler: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 1.346 s
25/04/01 11:16:52 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:16:52 INFO DAGScheduler: running: Set(ResultStage 1)
25/04/01 11:16:52 INFO DAGScheduler: waiting: Set()
25/04/01 11:16:52 INFO DAGScheduler: failed: Set()
25/04/01 11:16:52 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1799 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:16:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:16:52 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.805 s
25/04/01 11:16:52 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 11:16:52 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.808516 s
25/04/01 11:16:52 INFO CodeGenerator: Code generated in 4.768324 ms
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1028.0 KiB, free 363.7 MiB)
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 363.7 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:36635 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:16:52 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:52 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:16:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:16:52 INFO CodeGenerator: Code generated in 16.613529 ms
25/04/01 11:16:52 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:16:52 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:52 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:16:52 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:52 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 49.4 KiB, free 363.7 MiB)
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.7 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:36635 (size: 23.0 KiB, free: 366.1 MiB)
25/04/01 11:16:52 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:52 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:16:52 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:45599 (size: 23.0 KiB, free: 366.2 MiB)
25/04/01 11:16:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:35466
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:45599 (size: 2.4 KiB, free: 366.2 MiB)
25/04/01 11:16:52 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 191 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:16:52 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:16:52 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0.201 s
25/04/01 11:16:52 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 11:16:52 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.211772 s
+---------+
|unitprice|
+---------+
+---------+

25/04/01 11:16:52 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/04/01 11:16:52 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:16:52 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:16:52 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:16:52 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:16:52 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:16:52 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:16:52 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:16:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 363.3 MiB)
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.3 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:36635 (size: 33.4 KiB, free: 366.1 MiB)
25/04/01 11:16:52 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:52 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:16:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:52 INFO CodeGenerator: Code generated in 12.461002 ms
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 363.0 MiB)
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 362.9 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:36635 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:16:52 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:16:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:16:52 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:52 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:16:52 INFO DAGScheduler: Final stage: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:16:52 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:52 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:52 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 362.9 MiB)
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 362.9 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:36635 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 11:16:52 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:52 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:16:52 INFO DAGScheduler: Registering RDD 28 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:16:52 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.18.0.8, executor 1, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:16:52 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:52 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:52 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:16:52 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:52 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[28] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 29.9 KiB, free 362.9 MiB)
25/04/01 11:16:52 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 362.9 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:36635 (size: 14.1 KiB, free: 366.0 MiB)
25/04/01 11:16:52 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[28] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:52 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:16:52 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:45599 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:34717 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:45599 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:16:52 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:34717 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:16:52 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 139 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:16:52 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:16:52 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.146 s
25/04/01 11:16:52 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:16:52 INFO DAGScheduler: running: Set(ResultStage 5)
25/04/01 11:16:52 INFO DAGScheduler: waiting: Set()
25/04/01 11:16:52 INFO DAGScheduler: failed: Set()
25/04/01 11:16:53 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 661 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:16:53 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:16:53 INFO DAGScheduler: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.668 s
25/04/01 11:16:53 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/01 11:16:53 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.670048 s
25/04/01 11:16:53 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 1028.0 KiB, free 361.9 MiB)
25/04/01 11:16:53 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 361.9 MiB)
25/04/01 11:16:53 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:36635 (size: 2.4 KiB, free: 366.0 MiB)
25/04/01 11:16:53 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:16:53 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:16:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:16:53 INFO CodeGenerator: Code generated in 12.024839 ms
25/04/01 11:16:53 INFO DAGScheduler: Registering RDD 31 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:16:53 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:53 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:16:53 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:53 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:53 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.3 KiB, free 361.8 MiB)
25/04/01 11:16:53 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 361.8 MiB)
25/04/01 11:16:53 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:36635 (size: 22.1 KiB, free: 366.0 MiB)
25/04/01 11:16:53 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:53 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:16:53 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:16:53 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:45599 (size: 22.1 KiB, free: 366.1 MiB)
25/04/01 11:16:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:35466
25/04/01 11:16:53 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:45599 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:16:53 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 61 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:16:53 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:16:53 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.069 s
25/04/01 11:16:53 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:16:53 INFO DAGScheduler: running: Set()
25/04/01 11:16:53 INFO DAGScheduler: waiting: Set()
25/04/01 11:16:53 INFO DAGScheduler: failed: Set()
25/04/01 11:16:53 INFO CodeGenerator: Code generated in 6.850104 ms
25/04/01 11:16:53 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:16:53 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:16:53 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:16:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 11:16:53 INFO DAGScheduler: Missing parents: List()
25/04/01 11:16:53 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:16:53 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 361.8 MiB)
25/04/01 11:16:53 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 361.8 MiB)
25/04/01 11:16:53 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:36635 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:16:53 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:16:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:16:53 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 11:16:53 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:16:53 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.6:45599 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:16:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:35466
25/04/01 11:16:53 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 29 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:16:53 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 11:16:53 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s
25/04/01 11:16:53 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:16:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 11:16:53 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.036604 s
25/04/01 11:16:53 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:16:53 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:16:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:16:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:16:53 INFO MemoryStore: MemoryStore cleared
25/04/01 11:16:53 INFO BlockManager: BlockManager stopped
25/04/01 11:16:53 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:16:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:16:53 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:16:53 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:16:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-4b5ca931-c1be-43b0-993c-30ee913482b5
25/04/01 11:16:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-4b5ca931-c1be-43b0-993c-30ee913482b5/pyspark-3fa7effe-93bf-4a91-8f4c-7b86d48409f3
25/04/01 11:16:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-d1d6421e-46b6-48a2-917a-e260667575e1
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:17:55 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:17:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:17:55 INFO ResourceUtils: ==============================================================
25/04/01 11:17:55 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:17:55 INFO ResourceUtils: ==============================================================
25/04/01 11:17:55 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:17:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:17:55 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:17:55 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:17:55 INFO SecurityManager: Changing view acls to: root
25/04/01 11:17:55 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:17:55 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:17:55 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:17:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:17:55 INFO Utils: Successfully started service 'sparkDriver' on port 37823.
25/04/01 11:17:55 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:17:55 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:17:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:17:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:17:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:17:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-13f7364e-b7a2-4df3-b43f-acac82ff5230
25/04/01 11:17:55 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:17:55 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:17:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:17:55 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:17:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:17:56 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:17:56 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401111756-0016
25/04/01 11:17:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111756-0016/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:17:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111756-0016/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:17:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111756-0016/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:17:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111756-0016/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:17:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111756-0016/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:17:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111756-0016/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:17:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45161.
25/04/01 11:17:56 INFO NettyBlockTransferService: Server created on 7796893c36d7:45161
25/04/01 11:17:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:17:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 45161, None)
25/04/01 11:17:56 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:45161 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 45161, None)
25/04/01 11:17:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111756-0016/0 is now RUNNING
25/04/01 11:17:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 45161, None)
25/04/01 11:17:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111756-0016/2 is now RUNNING
25/04/01 11:17:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 45161, None)
25/04/01 11:17:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111756-0016/1 is now RUNNING
25/04/01 11:17:56 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:17:56 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:17:56 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:17:57 INFO InMemoryFileIndex: It took 62 ms to list leaf files for 1 paths.
25/04/01 11:17:57 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:17:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:39716) with ID 0,  ResourceProfileId 0
25/04/01 11:17:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:33598) with ID 2,  ResourceProfileId 0
25/04/01 11:17:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:48458) with ID 1,  ResourceProfileId 0
25/04/01 11:17:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:42635 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 42635, None)
25/04/01 11:17:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:44783 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 44783, None)
25/04/01 11:17:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:34877 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 34877, None)
25/04/01 11:17:59 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:17:59 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:17:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:17:59 INFO CodeGenerator: Code generated in 135.304538 ms
25/04/01 11:17:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:17:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:17:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:45161 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:17:59 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:17:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:18:00 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:18:00 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:18:00 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:18:00 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:18:00 INFO DAGScheduler: Missing parents: List()
25/04/01 11:18:00 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:18:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:18:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:18:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:45161 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:18:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:18:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:18:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:18:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:18:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:42635 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:18:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:42635 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:18:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1400 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:18:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:18:01 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.474 s
25/04/01 11:18:01 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:18:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:18:01 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.506842 s
25/04/01 11:18:01 INFO CodeGenerator: Code generated in 9.1162 ms
25/04/01 11:18:01 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:18:01 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:18:01 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:18:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:18:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:18:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:45161 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:18:01 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:18:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:18:01 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:18:01 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:18:01 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:18:02 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:18:02 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:18:02 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:18:02 INFO metastore: Connected to metastore.
25/04/01 11:18:02 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=8ddba06b-b57f-43c5-8949-9b232e9fba9d, clientType=HIVECLI]
25/04/01 11:18:02 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:18:02 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:18:02 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:18:02 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:18:02 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:18:02 INFO metastore: Connected to metastore.
25/04/01 11:18:02 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:18:02 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:18:02 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:18:02 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 11:18:02 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:18:02 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:18:02 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string, UnitPrice: string ... 1 more fields>
25/04/01 11:18:02 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:18:02 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:18:02 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:18:02 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:18:02 INFO CodeGenerator: Code generated in 37.266448 ms
25/04/01 11:18:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:45161 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:18:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:42635 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:18:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:18:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 11:18:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:45161 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:18:02 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:18:02 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:18:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:18:02 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:18:02 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:18:02 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:18:02 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:18:02 INFO DAGScheduler: Missing parents: List()
25/04/01 11:18:02 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:18:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KiB, free 365.2 MiB)
25/04/01 11:18:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 365.2 MiB)
25/04/01 11:18:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:45161 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:18:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:18:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:18:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:18:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:18:02 INFO CodeGenerator: Code generated in 68.208072 ms
25/04/01 11:18:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 11:18:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:18:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:45161 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:18:02 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:18:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:18:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:42635 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:18:02 INFO DAGScheduler: Registering RDD 17 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:18:02 INFO DAGScheduler: Got map stage job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:18:02 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:18:02 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:18:02 INFO DAGScheduler: Missing parents: List()
25/04/01 11:18:02 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:18:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:42635 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:18:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.6 KiB, free 364.8 MiB)
25/04/01 11:18:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 364.7 MiB)
25/04/01 11:18:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:45161 (size: 18.6 KiB, free: 366.1 MiB)
25/04/01 11:18:02 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:18:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:18:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:18:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:18:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:44783 (size: 18.6 KiB, free: 366.3 MiB)
25/04/01 11:18:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 682 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:18:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:18:03 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.689 s
25/04/01 11:18:03 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:18:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 11:18:03 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.693056 s
25/04/01 11:18:03 INFO CodeGenerator: Code generated in 5.871829 ms
25/04/01 11:18:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1028.0 KiB, free 363.7 MiB)
25/04/01 11:18:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 363.7 MiB)
25/04/01 11:18:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:45161 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:18:03 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:18:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:44783 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:18:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1689 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:18:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:18:04 INFO DAGScheduler: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 1.704 s
25/04/01 11:18:04 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:18:04 INFO DAGScheduler: running: Set()
25/04/01 11:18:04 INFO DAGScheduler: waiting: Set()
25/04/01 11:18:04 INFO DAGScheduler: failed: Set()
25/04/01 11:18:04 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:18:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:18:04 INFO CodeGenerator: Code generated in 16.3892 ms
25/04/01 11:18:04 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:18:04 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:18:04 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:18:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:18:04 INFO DAGScheduler: Missing parents: List()
25/04/01 11:18:04 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:18:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 49.4 KiB, free 363.7 MiB)
25/04/01 11:18:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 363.7 MiB)
25/04/01 11:18:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:45161 (size: 23.0 KiB, free: 366.1 MiB)
25/04/01 11:18:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:18:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:18:04 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:18:04 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:18:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:44783 (size: 23.0 KiB, free: 366.2 MiB)
25/04/01 11:18:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:33598
25/04/01 11:18:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:44783 (size: 2.4 KiB, free: 366.2 MiB)
25/04/01 11:18:05 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 245 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:18:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:18:05 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0.254 s
25/04/01 11:18:05 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:18:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 11:18:05 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.263053 s
25/04/01 11:18:05 INFO CodeGenerator: Code generated in 5.351296 ms
+---------+
|unitprice|
+---------+
|16.95000 |
+---------+

25/04/01 11:18:05 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/04/01 11:18:05 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:18:05 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:18:05 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:18:05 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:18:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:18:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:18:05 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:18:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 363.3 MiB)
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.3 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:45161 (size: 33.4 KiB, free: 366.1 MiB)
25/04/01 11:18:05 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:18:05 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:18:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:18:05 INFO CodeGenerator: Code generated in 13.146574 ms
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 363.0 MiB)
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 362.9 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:45161 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:18:05 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:18:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:18:05 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:18:05 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:18:05 INFO DAGScheduler: Final stage: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:18:05 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:18:05 INFO DAGScheduler: Missing parents: List()
25/04/01 11:18:05 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 362.9 MiB)
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 362.9 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:45161 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 11:18:05 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:18:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:18:05 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:18:05 INFO DAGScheduler: Registering RDD 28 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:18:05 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:18:05 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:18:05 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:18:05 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.18.0.2, executor 0, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:18:05 INFO DAGScheduler: Missing parents: List()
25/04/01 11:18:05 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[28] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 29.9 KiB, free 362.9 MiB)
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 362.9 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:45161 (size: 14.1 KiB, free: 366.0 MiB)
25/04/01 11:18:05 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:18:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[28] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:18:05 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:18:05 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:42635 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:42635 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:42635 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:18:05 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 67 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:18:05 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:18:05 INFO DAGScheduler: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.074 s
25/04/01 11:18:05 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:18:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/01 11:18:05 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.076825 s
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 1028.0 KiB, free 361.9 MiB)
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 361.9 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:45161 (size: 2.4 KiB, free: 366.0 MiB)
25/04/01 11:18:05 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:42635 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:18:05 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 318 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:18:05 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:18:05 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.326 s
25/04/01 11:18:05 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:18:05 INFO DAGScheduler: running: Set()
25/04/01 11:18:05 INFO DAGScheduler: waiting: Set()
25/04/01 11:18:05 INFO DAGScheduler: failed: Set()
25/04/01 11:18:05 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:18:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:18:05 INFO CodeGenerator: Code generated in 12.530219 ms
25/04/01 11:18:05 INFO DAGScheduler: Registering RDD 31 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:18:05 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:18:05 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:18:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:18:05 INFO DAGScheduler: Missing parents: List()
25/04/01 11:18:05 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.3 KiB, free 361.8 MiB)
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 361.8 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:45161 (size: 22.1 KiB, free: 366.0 MiB)
25/04/01 11:18:05 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:18:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:18:05 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:18:05 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:42635 (size: 22.1 KiB, free: 366.1 MiB)
25/04/01 11:18:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:39716
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:42635 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:18:05 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 162 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:18:05 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:18:05 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.169 s
25/04/01 11:18:05 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:18:05 INFO DAGScheduler: running: Set()
25/04/01 11:18:05 INFO DAGScheduler: waiting: Set()
25/04/01 11:18:05 INFO DAGScheduler: failed: Set()
25/04/01 11:18:05 INFO CodeGenerator: Code generated in 5.922674 ms
25/04/01 11:18:05 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:18:05 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:18:05 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:18:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 11:18:05 INFO DAGScheduler: Missing parents: List()
25/04/01 11:18:05 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 361.8 MiB)
25/04/01 11:18:05 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 361.8 MiB)
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:45161 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:18:05 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:18:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:18:05 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 11:18:05 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:18:05 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.2:42635 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:18:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:39716
25/04/01 11:18:05 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 27 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:18:05 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 11:18:05 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
25/04/01 11:18:05 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:18:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 11:18:05 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.033126 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 62, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:18:05 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:18:05 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:18:05 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:18:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:18:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:18:05 INFO MemoryStore: MemoryStore cleared
25/04/01 11:18:05 INFO BlockManager: BlockManager stopped
25/04/01 11:18:05 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:18:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:18:05 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:18:05 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:18:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-14e4dbbb-c252-4a03-a2e8-c4d9e8682bc1/pyspark-5d9813da-3704-436a-9295-a03071c30604
25/04/01 11:18:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-14e4dbbb-c252-4a03-a2e8-c4d9e8682bc1
25/04/01 11:18:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-a6f5f139-f069-4e10-986c-8c90d5b77bab
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:19:07 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:19:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:19:07 INFO ResourceUtils: ==============================================================
25/04/01 11:19:07 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:19:07 INFO ResourceUtils: ==============================================================
25/04/01 11:19:07 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:19:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:19:07 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:19:07 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:19:07 INFO SecurityManager: Changing view acls to: root
25/04/01 11:19:07 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:19:07 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:19:07 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:19:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:19:07 INFO Utils: Successfully started service 'sparkDriver' on port 33103.
25/04/01 11:19:07 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:19:07 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:19:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:19:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:19:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:19:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8a33b478-2dad-43d4-89ba-7e864c7eaf75
25/04/01 11:19:07 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:19:07 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:19:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:19:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:19:08 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:19:08 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:19:08 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401111908-0017
25/04/01 11:19:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111908-0017/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:19:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111908-0017/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:19:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111908-0017/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:19:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111908-0017/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:19:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401111908-0017/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:19:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401111908-0017/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:19:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40961.
25/04/01 11:19:08 INFO NettyBlockTransferService: Server created on 7796893c36d7:40961
25/04/01 11:19:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:19:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 40961, None)
25/04/01 11:19:08 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:40961 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 40961, None)
25/04/01 11:19:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 40961, None)
25/04/01 11:19:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111908-0017/0 is now RUNNING
25/04/01 11:19:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111908-0017/1 is now RUNNING
25/04/01 11:19:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 40961, None)
25/04/01 11:19:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401111908-0017/2 is now RUNNING
25/04/01 11:19:08 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:19:08 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:19:08 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:19:09 INFO InMemoryFileIndex: It took 61 ms to list leaf files for 1 paths.
25/04/01 11:19:09 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:19:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:60542) with ID 1,  ResourceProfileId 0
25/04/01 11:19:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:48852) with ID 2,  ResourceProfileId 0
25/04/01 11:19:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:50578) with ID 0,  ResourceProfileId 0
25/04/01 11:19:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:33063 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 33063, None)
25/04/01 11:19:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:45425 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 45425, None)
25/04/01 11:19:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:33969 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 33969, None)
25/04/01 11:19:11 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:19:11 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:19:11 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:19:11 INFO CodeGenerator: Code generated in 136.221656 ms
25/04/01 11:19:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:19:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:19:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:40961 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:19:12 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:19:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:19:12 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:19:12 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:19:12 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:19:12 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:19:12 INFO DAGScheduler: Missing parents: List()
25/04/01 11:19:12 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:19:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:19:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:19:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:40961 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:19:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:19:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:19:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:19:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:19:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:45425 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:19:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:45425 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:19:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1370 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:19:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:19:13 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.433 s
25/04/01 11:19:13 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:19:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:19:13 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.464622 s
25/04/01 11:19:13 INFO CodeGenerator: Code generated in 8.150426 ms
25/04/01 11:19:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:19:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:19:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:19:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:19:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:19:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:40961 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:19:13 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:19:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:19:13 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:19:13 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:19:13 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:19:14 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:19:14 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:19:14 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:19:14 INFO metastore: Connected to metastore.
25/04/01 11:19:14 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4639762b-6007-4ce9-bc07-6027d3de4fd1, clientType=HIVECLI]
25/04/01 11:19:14 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:19:14 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:19:14 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:19:14 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:19:14 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:19:14 INFO metastore: Connected to metastore.
25/04/01 11:19:14 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:19:14 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:19:14 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 11:19:14 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 11:19:14 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:19:14 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:19:14 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:19:14 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:19:14 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:19:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:19:14 INFO CodeGenerator: Code generated in 39.437006 ms
25/04/01 11:19:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:40961 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:19:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:45425 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:19:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:19:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 11:19:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:40961 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:19:14 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:19:14 INFO CodeGenerator: Code generated in 37.614617 ms
25/04/01 11:19:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 11:19:14 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:19:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:19:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:19:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:40961 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:19:14 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:19:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:19:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:19:14 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:19:14 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:19:14 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:19:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:19:14 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:19:14 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.5 KiB, free 364.8 MiB)
25/04/01 11:19:14 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 364.8 MiB)
25/04/01 11:19:14 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:40961 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:19:14 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 11:19:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:19:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:19:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:19:14 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:19:14 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:19:14 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:19:14 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:19:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:19:14 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:19:14 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 29.9 KiB, free 364.8 MiB)
25/04/01 11:19:14 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.8 MiB)
25/04/01 11:19:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:40961 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:19:14 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:19:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:19:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:19:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:19:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:33969 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:19:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:33063 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:19:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:33969 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 11:19:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:33063 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:19:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1796 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:19:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:19:16 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 1.810 s
25/04/01 11:19:16 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:19:16 INFO DAGScheduler: running: Set(ResultStage 1)
25/04/01 11:19:16 INFO DAGScheduler: waiting: Set()
25/04/01 11:19:16 INFO DAGScheduler: failed: Set()
25/04/01 11:19:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2089 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:19:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:19:16 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.095 s
25/04/01 11:19:16 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:19:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 11:19:16 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.098458 s
25/04/01 11:19:16 INFO CodeGenerator: Code generated in 6.051254 ms
25/04/01 11:19:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1028.0 KiB, free 363.8 MiB)
25/04/01 11:19:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 363.7 MiB)
25/04/01 11:19:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:40961 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:19:16 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:19:16 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:19:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:19:17 INFO CodeGenerator: Code generated in 15.331305 ms
25/04/01 11:19:17 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:19:17 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:19:17 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:19:17 INFO DAGScheduler: Missing parents: List()
25/04/01 11:19:17 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:19:17 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 47.3 KiB, free 363.7 MiB)
25/04/01 11:19:17 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 363.7 MiB)
25/04/01 11:19:17 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:40961 (size: 22.0 KiB, free: 366.1 MiB)
25/04/01 11:19:17 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:19:17 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:19:17 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:19:17 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:33063 (size: 22.0 KiB, free: 366.2 MiB)
25/04/01 11:19:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:60542
25/04/01 11:19:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:33063 (size: 2.4 KiB, free: 366.2 MiB)
25/04/01 11:19:17 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 216 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:19:17 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:19:17 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.228 s
25/04/01 11:19:17 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:19:17 INFO DAGScheduler: running: Set()
25/04/01 11:19:17 INFO DAGScheduler: waiting: Set()
25/04/01 11:19:17 INFO DAGScheduler: failed: Set()
25/04/01 11:19:17 INFO CodeGenerator: Code generated in 7.213984 ms
25/04/01 11:19:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:19:17 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:19:17 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 11:19:17 INFO DAGScheduler: Missing parents: List()
25/04/01 11:19:17 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:19:17 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 11:19:17 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 11:19:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:40961 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:19:17 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:19:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:19:17 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:19:17 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:19:17 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:33063 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:19:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:60542
25/04/01 11:19:17 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 90 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:19:17 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:19:17 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.096 s
25/04/01 11:19:17 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:19:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 11:19:17 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.098889 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 61, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:19:17 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:19:17 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:19:17 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:19:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:19:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:19:17 INFO MemoryStore: MemoryStore cleared
25/04/01 11:19:17 INFO BlockManager: BlockManager stopped
25/04/01 11:19:17 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:19:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:19:17 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:19:17 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:19:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-24f4ce4f-534b-499b-9fe7-45dae0c1026f/pyspark-1a94efdc-0196-40d5-834a-dfc814a8d0a8
25/04/01 11:19:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-24f4ce4f-534b-499b-9fe7-45dae0c1026f
25/04/01 11:19:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-5ea16a84-1a59-43e2-9204-8d03bebc75e8
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:22:31 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:22:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:22:31 INFO ResourceUtils: ==============================================================
25/04/01 11:22:31 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:22:31 INFO ResourceUtils: ==============================================================
25/04/01 11:22:31 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:22:31 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:22:31 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:22:31 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:22:31 INFO SecurityManager: Changing view acls to: root
25/04/01 11:22:31 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:22:31 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:22:31 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:22:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:22:31 INFO Utils: Successfully started service 'sparkDriver' on port 45197.
25/04/01 11:22:31 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:22:31 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:22:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:22:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:22:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:22:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8d2a220f-87ea-44da-bfe4-c0f3546f9192
25/04/01 11:22:31 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:22:31 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:22:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:22:32 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:22:32 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:22:32 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:22:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401112232-0018
25/04/01 11:22:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112232-0018/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:22:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112232-0018/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:22:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112232-0018/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:22:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112232-0018/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:22:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112232-0018/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:22:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112232-0018/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:22:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42177.
25/04/01 11:22:32 INFO NettyBlockTransferService: Server created on 7796893c36d7:42177
25/04/01 11:22:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:22:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 42177, None)
25/04/01 11:22:32 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:42177 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 42177, None)
25/04/01 11:22:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112232-0018/0 is now RUNNING
25/04/01 11:22:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 42177, None)
25/04/01 11:22:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112232-0018/1 is now RUNNING
25/04/01 11:22:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 42177, None)
25/04/01 11:22:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112232-0018/2 is now RUNNING
25/04/01 11:22:32 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:22:32 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:22:32 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:22:33 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.
25/04/01 11:22:34 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:22:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:54754) with ID 2,  ResourceProfileId 0
25/04/01 11:22:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:34504) with ID 1,  ResourceProfileId 0
25/04/01 11:22:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:36406) with ID 0,  ResourceProfileId 0
25/04/01 11:22:34 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:33039 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 33039, None)
25/04/01 11:22:34 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:42611 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 42611, None)
25/04/01 11:22:34 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:39009 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 39009, None)
25/04/01 11:22:35 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:22:35 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:22:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:22:35 INFO CodeGenerator: Code generated in 135.12622 ms
25/04/01 11:22:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:22:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:22:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:42177 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:22:36 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:22:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:22:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:22:36 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:22:36 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:22:36 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:22:36 INFO DAGScheduler: Missing parents: List()
25/04/01 11:22:36 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:22:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:22:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:22:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:42177 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:22:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:22:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:22:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:22:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:22:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:33039 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:22:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:33039 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:22:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1347 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:22:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:22:37 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.411 s
25/04/01 11:22:37 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:22:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:22:37 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.443673 s
25/04/01 11:22:37 INFO CodeGenerator: Code generated in 7.902559 ms
25/04/01 11:22:37 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:22:37 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:22:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:22:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:22:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:22:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:42177 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:22:37 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:22:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:22:37 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:22:37 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:22:37 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:22:37 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:22:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:22:38 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:22:38 INFO metastore: Connected to metastore.
25/04/01 11:22:38 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=9cbf940e-65ba-438d-aadc-95fd4f9e2ded, clientType=HIVECLI]
25/04/01 11:22:38 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:22:38 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:22:38 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:22:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:22:38 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:22:38 INFO metastore: Connected to metastore.
25/04/01 11:22:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:22:38 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:22:38 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 11:22:38 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 11:22:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:22:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:22:38 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:22:38 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:22:38 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:22:38 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:22:38 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:22:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:42177 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:22:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:33039 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:22:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:22:38 INFO CodeGenerator: Code generated in 18.806441 ms
25/04/01 11:22:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:22:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 11:22:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:42177 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:22:38 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:22:38 INFO CodeGenerator: Code generated in 29.029991 ms
25/04/01 11:22:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 11:22:38 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:22:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:22:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:22:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:42177 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:22:38 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:22:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:22:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:22:38 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:22:38 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:22:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:22:38 INFO DAGScheduler: Missing parents: List()
25/04/01 11:22:38 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:22:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.5 KiB, free 364.8 MiB)
25/04/01 11:22:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 364.8 MiB)
25/04/01 11:22:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:42177 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:22:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 11:22:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:22:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:22:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:22:38 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:22:38 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:22:38 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:22:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:22:38 INFO DAGScheduler: Missing parents: List()
25/04/01 11:22:38 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:22:38 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 29.9 KiB, free 364.8 MiB)
25/04/01 11:22:38 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.8 MiB)
25/04/01 11:22:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:42177 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:22:38 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:22:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:22:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:22:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:22:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:42611 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:22:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:39009 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:22:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:42611 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 11:22:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:39009 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:22:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1732 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:22:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:22:40 INFO DAGScheduler: ShuffleMapStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 1.745 s
25/04/01 11:22:40 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:22:40 INFO DAGScheduler: running: Set(ResultStage 1)
25/04/01 11:22:40 INFO DAGScheduler: waiting: Set()
25/04/01 11:22:40 INFO DAGScheduler: failed: Set()
25/04/01 11:22:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2017 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:22:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:22:40 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 2.022 s
25/04/01 11:22:40 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:22:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 11:22:40 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 2.024886 s
25/04/01 11:22:40 INFO CodeGenerator: Code generated in 5.742763 ms
25/04/01 11:22:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1028.0 KiB, free 363.8 MiB)
25/04/01 11:22:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 363.7 MiB)
25/04/01 11:22:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:42177 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:22:40 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:22:40 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:22:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:22:40 INFO CodeGenerator: Code generated in 15.175213 ms
25/04/01 11:22:40 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:22:40 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:22:40 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:22:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:22:40 INFO DAGScheduler: Missing parents: List()
25/04/01 11:22:40 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:22:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 47.3 KiB, free 363.7 MiB)
25/04/01 11:22:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 363.7 MiB)
25/04/01 11:22:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:42177 (size: 22.0 KiB, free: 366.1 MiB)
25/04/01 11:22:40 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:22:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:22:40 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:22:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:22:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:39009 (size: 22.0 KiB, free: 366.2 MiB)
25/04/01 11:22:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:34504
25/04/01 11:22:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:39009 (size: 2.4 KiB, free: 366.2 MiB)
25/04/01 11:22:41 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 202 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:22:41 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:22:41 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.212 s
25/04/01 11:22:41 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:22:41 INFO DAGScheduler: running: Set()
25/04/01 11:22:41 INFO DAGScheduler: waiting: Set()
25/04/01 11:22:41 INFO DAGScheduler: failed: Set()
25/04/01 11:22:41 INFO CodeGenerator: Code generated in 6.71699 ms
25/04/01 11:22:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:22:41 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:22:41 INFO DAGScheduler: Final stage: ResultStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:22:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 11:22:41 INFO DAGScheduler: Missing parents: List()
25/04/01 11:22:41 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:22:41 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 363.7 MiB)
25/04/01 11:22:41 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.7 MiB)
25/04/01 11:22:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:42177 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:22:41 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:22:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:22:41 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:22:41 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:22:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:39009 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:22:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:34504
25/04/01 11:22:41 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 88 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:22:41 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:22:41 INFO DAGScheduler: ResultStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.094 s
25/04/01 11:22:41 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:22:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/04/01 11:22:41 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.097162 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 62, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:22:41 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:22:41 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:22:41 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:22:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:22:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:22:41 INFO MemoryStore: MemoryStore cleared
25/04/01 11:22:41 INFO BlockManager: BlockManager stopped
25/04/01 11:22:41 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:22:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:22:41 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:22:41 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:22:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-7b8d05d7-4fae-4bb0-98bd-7d5cb848f291
25/04/01 11:22:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-d0395f0a-8858-4aed-b74c-4a25a24fa431
25/04/01 11:22:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-7b8d05d7-4fae-4bb0-98bd-7d5cb848f291/pyspark-ce0bdca3-6131-4eb4-933e-55161537200e
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:23:19 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:23:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:23:19 INFO ResourceUtils: ==============================================================
25/04/01 11:23:19 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:23:19 INFO ResourceUtils: ==============================================================
25/04/01 11:23:19 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:23:19 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:23:19 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:23:19 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:23:19 INFO SecurityManager: Changing view acls to: root
25/04/01 11:23:19 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:23:19 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:23:19 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:23:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:23:19 INFO Utils: Successfully started service 'sparkDriver' on port 41961.
25/04/01 11:23:19 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:23:19 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:23:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:23:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:23:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:23:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5460b859-5f4d-4fd1-b2c9-303a2c29e6c6
25/04/01 11:23:19 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:23:19 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:23:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:23:19 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:23:19 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:23:19 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:23:20 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401112320-0019
25/04/01 11:23:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112320-0019/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:23:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112320-0019/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:23:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112320-0019/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:23:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112320-0019/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:23:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112320-0019/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:23:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112320-0019/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:23:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34815.
25/04/01 11:23:20 INFO NettyBlockTransferService: Server created on 7796893c36d7:34815
25/04/01 11:23:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:23:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 34815, None)
25/04/01 11:23:20 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:34815 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 34815, None)
25/04/01 11:23:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 34815, None)
25/04/01 11:23:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112320-0019/1 is now RUNNING
25/04/01 11:23:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 34815, None)
25/04/01 11:23:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112320-0019/0 is now RUNNING
25/04/01 11:23:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112320-0019/2 is now RUNNING
25/04/01 11:23:20 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:23:20 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:23:20 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:23:21 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.
25/04/01 11:23:21 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:23:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:56084) with ID 2,  ResourceProfileId 0
25/04/01 11:23:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:53668) with ID 0,  ResourceProfileId 0
25/04/01 11:23:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:37770) with ID 1,  ResourceProfileId 0
25/04/01 11:23:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:39833 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 39833, None)
25/04/01 11:23:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:40313 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 40313, None)
25/04/01 11:23:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42015 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 42015, None)
25/04/01 11:23:23 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:23:23 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:23:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:23:23 INFO CodeGenerator: Code generated in 136.01797 ms
25/04/01 11:23:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:23:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:23:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:34815 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:23:23 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:23:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:23:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:23:23 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:23:23 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:23:23 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:23:23 INFO DAGScheduler: Missing parents: List()
25/04/01 11:23:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:23:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:23:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:23:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:34815 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:23:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:23:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:23:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:23:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:23:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:39833 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:23:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:39833 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:23:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1367 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:23:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:23:25 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.432 s
25/04/01 11:23:25 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:23:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:23:25 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.465227 s
25/04/01 11:23:25 INFO CodeGenerator: Code generated in 8.621583 ms
25/04/01 11:23:25 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:23:25 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:23:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:23:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:23:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:23:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:34815 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:23:25 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:23:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:23:25 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:23:25 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:23:25 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:23:25 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:23:25 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:23:25 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:23:25 INFO metastore: Connected to metastore.
25/04/01 11:23:25 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4fc41265-ca13-4c55-902e-49ffd4a91fec, clientType=HIVECLI]
25/04/01 11:23:25 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:23:25 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:23:25 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:23:25 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:23:25 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:23:25 INFO metastore: Connected to metastore.
25/04/01 11:23:26 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:23:26 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:23:26 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)
 |-- date: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:23:26 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 11:23:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:23:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:23:26 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:23:26 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:23:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:23:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:23:26 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:23:26 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:34815 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:23:26 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:39833 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:23:26 INFO CodeGenerator: Code generated in 24.848897 ms
25/04/01 11:23:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:23:26 INFO CodeGenerator: Code generated in 31.761026 ms
25/04/01 11:23:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.6 KiB, free 364.9 MiB)
25/04/01 11:23:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:23:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:34815 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:23:26 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:23:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:23:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:34815 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:23:26 INFO SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:23:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:23:26 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:23:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:23:26 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:23:26 INFO DAGScheduler: Got job 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:23:26 INFO DAGScheduler: Final stage: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:23:26 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:23:26 INFO DAGScheduler: Missing parents: List()
25/04/01 11:23:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[15] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:23:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.5 KiB, free 364.8 MiB)
25/04/01 11:23:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 364.8 MiB)
25/04/01 11:23:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:34815 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:23:26 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 11:23:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[15] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:23:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:23:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:23:26 INFO DAGScheduler: Registering RDD 18 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:23:26 INFO DAGScheduler: Got map stage job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:23:26 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:23:26 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:23:26 INFO DAGScheduler: Missing parents: List()
25/04/01 11:23:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:39833 (size: 6.0 KiB, free: 366.3 MiB)
25/04/01 11:23:26 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:23:26 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 31.8 KiB, free 364.8 MiB)
25/04/01 11:23:26 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.8 MiB)
25/04/01 11:23:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:34815 (size: 14.7 KiB, free: 366.2 MiB)
25/04/01 11:23:26 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:23:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:23:26 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:23:26 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:23:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:39833 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:23:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:42015 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 11:23:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 643 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:23:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:23:27 INFO DAGScheduler: ResultStage 1 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.648 s
25/04/01 11:23:27 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:23:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/04/01 11:23:27 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.651194 s
25/04/01 11:23:27 INFO CodeGenerator: Code generated in 8.68912 ms
25/04/01 11:23:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1028.0 KiB, free 363.7 MiB)
25/04/01 11:23:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 363.7 MiB)
25/04/01 11:23:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:34815 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:23:27 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:23:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:42015 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:23:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1703 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:23:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:23:28 INFO DAGScheduler: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 1.721 s
25/04/01 11:23:28 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:23:28 INFO DAGScheduler: running: Set()
25/04/01 11:23:28 INFO DAGScheduler: waiting: Set()
25/04/01 11:23:28 INFO DAGScheduler: failed: Set()
25/04/01 11:23:28 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:23:28 INFO CodeGenerator: Code generated in 12.64253 ms
25/04/01 11:23:28 INFO CodeGenerator: Code generated in 7.496916 ms
25/04/01 11:23:28 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:23:28 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:23:28 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:23:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:23:28 INFO DAGScheduler: Missing parents: List()
25/04/01 11:23:28 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 41.3 KiB, free 363.7 MiB)
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 363.7 MiB)
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:34815 (size: 18.8 KiB, free: 366.1 MiB)
25/04/01 11:23:28 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:23:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:23:28 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:23:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:42015 (size: 18.8 KiB, free: 366.2 MiB)
25/04/01 11:23:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:37770
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:42015 (size: 2.4 KiB, free: 366.2 MiB)
25/04/01 11:23:28 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 273 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:23:28 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:23:28 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0.282 s
25/04/01 11:23:28 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:23:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 11:23:28 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.291881 s
25/04/01 11:23:28 INFO CodeGenerator: Code generated in 8.979105 ms
+---------+----------+----------------+--------------------+---------+
|stockcode|      date|     productname|  productdescription|unitprice|
+---------+----------+----------------+--------------------+---------+
|    11333|2025-03-27|Valhalla Knights|Action,Role-Playi...| 16.95000|
+---------+----------+----------------+--------------------+---------+

25/04/01 11:23:28 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/04/01 11:23:28 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:23:28 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:23:28 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:23:28 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:23:28 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:23:28 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:23:28 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:23:28 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 363.3 MiB)
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.3 MiB)
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:34815 (size: 33.4 KiB, free: 366.1 MiB)
25/04/01 11:23:28 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:23:28 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:23:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:23:28 INFO CodeGenerator: Code generated in 16.173815 ms
25/04/01 11:23:28 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:23:28 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:23:28 INFO DAGScheduler: Final stage: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:23:28 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:23:28 INFO DAGScheduler: Missing parents: List()
25/04/01 11:23:28 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 363.0 MiB)
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.5 KiB, free 363.0 MiB)
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 363.0 MiB)
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:34815 (size: 6.0 KiB, free: 366.1 MiB)
25/04/01 11:23:28 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:23:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:23:28 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:23:28 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 362.9 MiB)
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:34815 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:23:28 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:23:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:23:28 INFO DAGScheduler: Registering RDD 31 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:23:28 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:23:28 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:23:28 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:23:28 INFO DAGScheduler: Missing parents: List()
25/04/01 11:23:28 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:39833 (size: 6.0 KiB, free: 366.2 MiB)
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 29.9 KiB, free 362.9 MiB)
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 362.9 MiB)
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:34815 (size: 14.1 KiB, free: 366.0 MiB)
25/04/01 11:23:28 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:23:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:23:28 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:23:28 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:39833 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:39833 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:23:28 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 66 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:23:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:23:28 INFO DAGScheduler: ResultStage 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.072 s
25/04/01 11:23:28 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:23:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/01 11:23:28 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.074408 s
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 1028.0 KiB, free 361.9 MiB)
25/04/01 11:23:28 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 361.9 MiB)
25/04/01 11:23:28 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:34815 (size: 2.4 KiB, free: 366.0 MiB)
25/04/01 11:23:28 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:23:29 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:39833 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:23:29 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 318 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:23:29 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:23:29 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.327 s
25/04/01 11:23:29 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:23:29 INFO DAGScheduler: running: Set()
25/04/01 11:23:29 INFO DAGScheduler: waiting: Set()
25/04/01 11:23:29 INFO DAGScheduler: failed: Set()
25/04/01 11:23:29 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:23:29 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:23:29 INFO CodeGenerator: Code generated in 12.1118 ms
25/04/01 11:23:29 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:23:29 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:23:29 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:23:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:23:29 INFO DAGScheduler: Missing parents: List()
25/04/01 11:23:29 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:23:29 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.3 KiB, free 361.8 MiB)
25/04/01 11:23:29 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 361.8 MiB)
25/04/01 11:23:29 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:34815 (size: 22.0 KiB, free: 366.0 MiB)
25/04/01 11:23:29 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:23:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:23:29 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:23:29 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:23:29 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:39833 (size: 22.0 KiB, free: 366.1 MiB)
25/04/01 11:23:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:56084
25/04/01 11:23:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:39833 (size: 2.4 KiB, free: 366.1 MiB)
25/04/01 11:23:29 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 153 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:23:29 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:23:29 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.160 s
25/04/01 11:23:29 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:23:29 INFO DAGScheduler: running: Set()
25/04/01 11:23:29 INFO DAGScheduler: waiting: Set()
25/04/01 11:23:29 INFO DAGScheduler: failed: Set()
25/04/01 11:23:29 INFO CodeGenerator: Code generated in 6.05803 ms
25/04/01 11:23:29 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:23:29 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:23:29 INFO DAGScheduler: Final stage: ResultStage 11 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:23:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 11:23:29 INFO DAGScheduler: Missing parents: List()
25/04/01 11:23:29 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:23:29 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 361.8 MiB)
25/04/01 11:23:29 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 361.8 MiB)
25/04/01 11:23:29 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:34815 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:23:29 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:23:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:23:29 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 11:23:29 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:23:29 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.6:39833 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:23:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:56084
25/04/01 11:23:29 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 28 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:23:29 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 11:23:29 INFO DAGScheduler: ResultStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/01 11:23:29 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:23:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 11:23:29 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.035658 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 65, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:23:29 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:23:29 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:23:29 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:23:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:23:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:23:29 INFO MemoryStore: MemoryStore cleared
25/04/01 11:23:29 INFO BlockManager: BlockManager stopped
25/04/01 11:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:23:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:23:29 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:23:29 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:23:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-11899f59-84bc-4d62-9989-a4fd43ad4782/pyspark-c2c592bb-c3e6-4867-84b2-13434fd782fb
25/04/01 11:23:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-4e9ba598-9afb-4050-bff1-e580fd1866fe
25/04/01 11:23:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-11899f59-84bc-4d62-9989-a4fd43ad4782
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:27:03 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:27:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:27:03 INFO ResourceUtils: ==============================================================
25/04/01 11:27:03 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:27:03 INFO ResourceUtils: ==============================================================
25/04/01 11:27:03 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:27:03 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:27:03 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:27:03 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:27:03 INFO SecurityManager: Changing view acls to: root
25/04/01 11:27:03 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:27:03 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:27:03 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:27:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:27:03 INFO Utils: Successfully started service 'sparkDriver' on port 43281.
25/04/01 11:27:03 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:27:03 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:27:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:27:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:27:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:27:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8221ef3-b819-4d13-a84d-28e4ae55263d
25/04/01 11:27:03 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:27:03 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:27:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:27:03 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:27:03 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:27:03 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 11:27:03 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401112703-0020
25/04/01 11:27:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112703-0020/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:27:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112703-0020/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:27:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112703-0020/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:27:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112703-0020/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:27:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401112703-0020/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:27:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401112703-0020/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:27:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42851.
25/04/01 11:27:03 INFO NettyBlockTransferService: Server created on 7796893c36d7:42851
25/04/01 11:27:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:27:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 42851, None)
25/04/01 11:27:03 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:42851 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 42851, None)
25/04/01 11:27:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112703-0020/2 is now RUNNING
25/04/01 11:27:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112703-0020/1 is now RUNNING
25/04/01 11:27:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 42851, None)
25/04/01 11:27:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 42851, None)
25/04/01 11:27:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401112703-0020/0 is now RUNNING
25/04/01 11:27:04 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:27:04 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:27:04 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:27:05 INFO InMemoryFileIndex: It took 58 ms to list leaf files for 1 paths.
25/04/01 11:27:05 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:27:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:34130) with ID 0,  ResourceProfileId 0
25/04/01 11:27:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:37134) with ID 1,  ResourceProfileId 0
25/04/01 11:27:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:34526) with ID 2,  ResourceProfileId 0
25/04/01 11:27:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:43959 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 43959, None)
25/04/01 11:27:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:36361 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 36361, None)
25/04/01 11:27:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35809 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 35809, None)
25/04/01 11:27:07 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:27:07 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:27:07 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:27:07 INFO CodeGenerator: Code generated in 131.560733 ms
25/04/01 11:27:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:27:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:27:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:42851 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:27:07 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:27:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:27:07 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:27:07 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:27:07 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:27:07 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:27:07 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:27:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:27:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:27:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:42851 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:27:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:27:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:27:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:35809 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:27:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:35809 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:27:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1353 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:27:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:27:09 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.416 s
25/04/01 11:27:09 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:27:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:27:09 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.448264 s
25/04/01 11:27:09 INFO CodeGenerator: Code generated in 7.848921 ms
25/04/01 11:27:09 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:27:09 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:27:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:27:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:27:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:27:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:42851 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:27:09 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:27:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:27:09 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:27:09 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:27:09 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:27:09 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:27:09 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:27:09 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:27:09 INFO metastore: Connected to metastore.
25/04/01 11:27:09 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=7b548cd4-2a6b-41d7-8945-abde79237e75, clientType=HIVECLI]
25/04/01 11:27:09 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:27:09 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:27:09 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:27:09 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:27:09 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:27:09 INFO metastore: Connected to metastore.
25/04/01 11:27:09 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:27:09 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:27:09 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)
 |-- date: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:27:10 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 11:27:10 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:27:10 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:27:10 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:27:10 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:27:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:27:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 11:27:10 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:27:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:42851 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:27:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:35809 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:27:10 INFO CodeGenerator: Code generated in 17.687085 ms
25/04/01 11:27:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:27:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:27:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:42851 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:27:10 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:27:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:27:10 INFO DAGScheduler: Registering RDD 14 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:27:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:27:10 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:27:10 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:27:10 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:27:10 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:10 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:27:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 31.8 KiB, free 365.2 MiB)
25/04/01 11:27:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 365.1 MiB)
25/04/01 11:27:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:42851 (size: 14.7 KiB, free: 366.2 MiB)
25/04/01 11:27:10 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:27:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:27:10 INFO CodeGenerator: Code generated in 25.335629 ms
25/04/01 11:27:10 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:27:10 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:27:10 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:42851 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:27:10 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:27:10 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:27:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:27:10 INFO DAGScheduler: Registering RDD 18 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:27:10 INFO DAGScheduler: Got map stage job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:27:10 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:27:10 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:27:10 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:10 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:27:10 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 32.3 KiB, free 364.7 MiB)
25/04/01 11:27:10 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 364.7 MiB)
25/04/01 11:27:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:42851 (size: 14.3 KiB, free: 366.1 MiB)
25/04/01 11:27:10 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:27:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.2, executor 0, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 11:27:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:43959 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 11:27:10 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:36361 (size: 14.3 KiB, free: 366.3 MiB)
25/04/01 11:27:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:43959 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:27:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:36361 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 11:27:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1867 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:27:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:27:12 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.889 s
25/04/01 11:27:12 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:27:12 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
25/04/01 11:27:12 INFO DAGScheduler: waiting: Set()
25/04/01 11:27:12 INFO DAGScheduler: failed: Set()
25/04/01 11:27:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2170 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:27:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:27:12 INFO DAGScheduler: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 2.177 s
25/04/01 11:27:12 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:27:12 INFO DAGScheduler: running: Set()
25/04/01 11:27:12 INFO DAGScheduler: waiting: Set()
25/04/01 11:27:12 INFO DAGScheduler: failed: Set()
25/04/01 11:27:12 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:27:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:27:12 INFO CodeGenerator: Code generated in 13.541678 ms
25/04/01 11:27:12 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:27:12 INFO DAGScheduler: Got job 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:27:12 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:27:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:27:12 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:12 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:27:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 34.4 KiB, free 364.7 MiB)
25/04/01 11:27:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 364.7 MiB)
25/04/01 11:27:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:42851 (size: 15.8 KiB, free: 366.1 MiB)
25/04/01 11:27:12 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:12 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:27:12 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:27:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:36361 (size: 15.8 KiB, free: 366.2 MiB)
25/04/01 11:27:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:34130
25/04/01 11:27:12 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 181 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:27:12 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:27:12 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.187 s
25/04/01 11:27:12 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:27:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 11:27:12 INFO DAGScheduler: Job 3 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.197085 s
25/04/01 11:27:12 INFO CodeGenerator: Code generated in 5.807926 ms
25/04/01 11:27:12 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1028.0 KiB, free 363.7 MiB)
25/04/01 11:27:12 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 363.7 MiB)
25/04/01 11:27:12 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:42851 (size: 2.3 KiB, free: 366.1 MiB)
25/04/01 11:27:12 INFO SparkContext: Created broadcast 8 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:27:12 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:27:12 INFO CodeGenerator: Code generated in 9.330411 ms
25/04/01 11:27:12 INFO CodeGenerator: Code generated in 7.039801 ms
25/04/01 11:27:12 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:27:12 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:27:12 INFO DAGScheduler: Final stage: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:27:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:27:12 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:12 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:27:12 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 41.3 KiB, free 363.6 MiB)
25/04/01 11:27:12 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 363.6 MiB)
25/04/01 11:27:12 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:42851 (size: 18.8 KiB, free: 366.1 MiB)
25/04/01 11:27:12 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:12 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:27:12 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:27:12 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:43959 (size: 18.8 KiB, free: 366.2 MiB)
25/04/01 11:27:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:37134
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:43959 (size: 2.3 KiB, free: 366.2 MiB)
25/04/01 11:27:13 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 259 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:27:13 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:27:13 INFO DAGScheduler: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0) finished in 0.268 s
25/04/01 11:27:13 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:27:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 11:27:13 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.274098 s
25/04/01 11:27:13 INFO CodeGenerator: Code generated in 7.717199 ms
+---------+----------+----------------+--------------------+---------+
|stockcode|      date|     productname|  productdescription|unitprice|
+---------+----------+----------------+--------------------+---------+
|    11333|2025-03-27|Valhalla Knights|Action,Role-Playi...| 16.95000|
+---------+----------+----------------+--------------------+---------+

25/04/01 11:27:13 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/04/01 11:27:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:27:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:27:13 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:27:13 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:27:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:27:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 11:27:13 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:27:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:27:13 INFO CodeGenerator: Code generated in 9.658808 ms
25/04/01 11:27:13 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 363.3 MiB)
25/04/01 11:27:13 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.2 MiB)
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:42851 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:27:13 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:27:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:27:13 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:27:13 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:27:13 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:27:13 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:27:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:27:13 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:13 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:27:13 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 29.9 KiB, free 363.2 MiB)
25/04/01 11:27:13 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 363.2 MiB)
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:42851 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:27:13 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:13 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:27:13 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:27:13 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 349.8 KiB, free 362.9 MiB)
25/04/01 11:27:13 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 362.8 MiB)
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:42851 (size: 33.4 KiB, free: 366.0 MiB)
25/04/01 11:27:13 INFO SparkContext: Created broadcast 12 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:27:13 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:27:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:27:13 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 11:27:13 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:27:13 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:27:13 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:27:13 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:13 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:27:13 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 32.3 KiB, free 362.8 MiB)
25/04/01 11:27:13 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 362.8 MiB)
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:42851 (size: 14.3 KiB, free: 366.0 MiB)
25/04/01 11:27:13 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:13 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:27:13 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.18.0.8, executor 1, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:35809 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:43959 (size: 14.3 KiB, free: 366.2 MiB)
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:43959 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:27:13 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:35809 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:27:13 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 349 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:27:13 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:27:13 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.356 s
25/04/01 11:27:13 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:27:13 INFO DAGScheduler: running: Set(ShuffleMapStage 8)
25/04/01 11:27:13 INFO DAGScheduler: waiting: Set()
25/04/01 11:27:13 INFO DAGScheduler: failed: Set()
25/04/01 11:27:14 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 670 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:27:14 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:27:14 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.674 s
25/04/01 11:27:14 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:27:14 INFO DAGScheduler: running: Set()
25/04/01 11:27:14 INFO DAGScheduler: waiting: Set()
25/04/01 11:27:14 INFO DAGScheduler: failed: Set()
25/04/01 11:27:14 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:27:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:27:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:27:14 INFO DAGScheduler: Got job 7 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:27:14 INFO DAGScheduler: Final stage: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:27:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 11:27:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:14 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:27:14 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 34.4 KiB, free 362.7 MiB)
25/04/01 11:27:14 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 362.7 MiB)
25/04/01 11:27:14 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:42851 (size: 15.8 KiB, free: 366.0 MiB)
25/04/01 11:27:14 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:14 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:27:14 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:27:14 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.8:43959 (size: 15.8 KiB, free: 366.2 MiB)
25/04/01 11:27:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:37134
25/04/01 11:27:14 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 34 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:27:14 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:27:14 INFO DAGScheduler: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.039 s
25/04/01 11:27:14 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:27:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/04/01 11:27:14 INFO DAGScheduler: Job 7 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.042744 s
25/04/01 11:27:14 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1028.0 KiB, free 361.7 MiB)
25/04/01 11:27:14 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 361.7 MiB)
25/04/01 11:27:14 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:42851 (size: 2.3 KiB, free: 366.0 MiB)
25/04/01 11:27:14 INFO SparkContext: Created broadcast 15 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:27:14 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:27:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:27:14 INFO CodeGenerator: Code generated in 10.237171 ms
25/04/01 11:27:14 INFO DAGScheduler: Registering RDD 40 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 11:27:14 INFO DAGScheduler: Got map stage job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:27:14 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:27:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
25/04/01 11:27:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:14 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:27:14 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 53.4 KiB, free 361.7 MiB)
25/04/01 11:27:14 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.5 KiB, free 361.7 MiB)
25/04/01 11:27:14 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7796893c36d7:42851 (size: 23.5 KiB, free: 366.0 MiB)
25/04/01 11:27:14 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:14 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/04/01 11:27:14 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:27:14 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.6:35809 (size: 23.5 KiB, free: 366.2 MiB)
25/04/01 11:27:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:34526
25/04/01 11:27:14 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.6:35809 (size: 2.3 KiB, free: 366.2 MiB)
25/04/01 11:27:14 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 173 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:27:14 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/04/01 11:27:14 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.179 s
25/04/01 11:27:14 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:27:14 INFO DAGScheduler: running: Set()
25/04/01 11:27:14 INFO DAGScheduler: waiting: Set()
25/04/01 11:27:14 INFO DAGScheduler: failed: Set()
25/04/01 11:27:14 INFO CodeGenerator: Code generated in 6.001529 ms
25/04/01 11:27:14 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:27:14 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:27:14 INFO DAGScheduler: Final stage: ResultStage 15 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:27:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
25/04/01 11:27:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:27:14 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:27:14 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.0 KiB, free 361.6 MiB)
25/04/01 11:27:14 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 361.6 MiB)
25/04/01 11:27:14 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7796893c36d7:42851 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:27:14 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1478
25/04/01 11:27:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:27:14 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/04/01 11:27:14 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 9) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:27:14 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.6:35809 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:27:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.6:34526
25/04/01 11:27:14 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 9) in 29 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:27:14 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/04/01 11:27:14 INFO DAGScheduler: ResultStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.032 s
25/04/01 11:27:14 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:27:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/04/01 11:27:14 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.033997 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 73, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:27:14 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:27:14 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:27:14 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:27:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:27:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:27:14 INFO MemoryStore: MemoryStore cleared
25/04/01 11:27:14 INFO BlockManager: BlockManager stopped
25/04/01 11:27:14 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:27:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:27:14 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:27:14 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:27:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-95df2682-b2b1-476d-9694-3a54697a4721/pyspark-740f2702-9803-44c9-a04f-27a4af2929e9
25/04/01 11:27:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-6cdd5290-f1ec-47cf-a477-62867346b295
25/04/01 11:27:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-95df2682-b2b1-476d-9694-3a54697a4721
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:30:29 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:30:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:30:29 INFO ResourceUtils: ==============================================================
25/04/01 11:30:29 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:30:29 INFO ResourceUtils: ==============================================================
25/04/01 11:30:29 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:30:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:30:29 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:30:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:30:29 INFO SecurityManager: Changing view acls to: root
25/04/01 11:30:29 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:30:29 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:30:29 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:30:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:30:30 INFO Utils: Successfully started service 'sparkDriver' on port 38263.
25/04/01 11:30:30 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:30:30 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:30:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:30:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:30:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:30:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-87a1af92-044e-411c-8c66-d348303e9e6f
25/04/01 11:30:30 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:30:30 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:30:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:30:30 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:30:30 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:30:30 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 11:30:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401113030-0021
25/04/01 11:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113030-0021/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113030-0021/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113030-0021/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113030-0021/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113030-0021/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113030-0021/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:30:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33367.
25/04/01 11:30:30 INFO NettyBlockTransferService: Server created on 7796893c36d7:33367
25/04/01 11:30:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:30:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 33367, None)
25/04/01 11:30:30 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:33367 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 33367, None)
25/04/01 11:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113030-0021/2 is now RUNNING
25/04/01 11:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113030-0021/0 is now RUNNING
25/04/01 11:30:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 33367, None)
25/04/01 11:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113030-0021/1 is now RUNNING
25/04/01 11:30:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 33367, None)
25/04/01 11:30:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:30:30 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:30:30 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:30:32 INFO InMemoryFileIndex: It took 59 ms to list leaf files for 1 paths.
25/04/01 11:30:32 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:30:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:33574) with ID 1,  ResourceProfileId 0
25/04/01 11:30:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:50374) with ID 2,  ResourceProfileId 0
25/04/01 11:30:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:42936) with ID 0,  ResourceProfileId 0
25/04/01 11:30:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:35175 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 35175, None)
25/04/01 11:30:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:33921 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 33921, None)
25/04/01 11:30:32 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:45763 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 45763, None)
25/04/01 11:30:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:30:33 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:30:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:30:34 INFO CodeGenerator: Code generated in 131.036085 ms
25/04/01 11:30:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:30:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:30:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:33367 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:30:34 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:30:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:30:34 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:30:34 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:30:34 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:30:34 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:30:34 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:30:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:30:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:30:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:33367 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:30:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:30:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:30:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:35175 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:30:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:35175 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:30:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1365 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:30:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:30:35 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.432 s
25/04/01 11:30:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:30:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:30:35 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.462962 s
25/04/01 11:30:35 INFO CodeGenerator: Code generated in 8.542105 ms
25/04/01 11:30:35 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:30:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:30:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:30:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:30:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:30:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:33367 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:30:35 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:30:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:30:35 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:30:35 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:30:36 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:30:36 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:30:36 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:30:36 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:30:36 INFO metastore: Connected to metastore.
25/04/01 11:30:36 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=fbff26a9-0e69-44e5-8244-4fbda580b5ec, clientType=HIVECLI]
25/04/01 11:30:36 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:30:36 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:30:36 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:30:36 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:30:36 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:30:36 INFO metastore: Connected to metastore.
25/04/01 11:30:36 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:30:36 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:30:36 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)
 |-- date: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:30:36 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 11:30:36 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:30:36 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:30:36 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:30:36 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:30:36 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:30:36 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:30:36 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:30:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:33367 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:30:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:35175 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:30:36 INFO CodeGenerator: Code generated in 20.661798 ms
25/04/01 11:30:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:30:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:30:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:33367 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:30:36 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:30:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:30:36 INFO DAGScheduler: Registering RDD 14 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:30:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:30:36 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:30:36 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:30:36 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:30:36 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:36 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:30:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 31.8 KiB, free 365.2 MiB)
25/04/01 11:30:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 365.1 MiB)
25/04/01 11:30:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:33367 (size: 14.7 KiB, free: 366.2 MiB)
25/04/01 11:30:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:30:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:30:37 INFO CodeGenerator: Code generated in 29.835764 ms
25/04/01 11:30:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:35175 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 11:30:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:30:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:30:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:33367 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:30:37 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:30:37 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:30:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:30:37 INFO DAGScheduler: Registering RDD 18 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:30:37 INFO DAGScheduler: Got map stage job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:30:37 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:30:37 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:30:37 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:37 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:30:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 31.2 KiB, free 364.7 MiB)
25/04/01 11:30:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 364.7 MiB)
25/04/01 11:30:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:33367 (size: 13.8 KiB, free: 366.1 MiB)
25/04/01 11:30:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:30:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.2, executor 0, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 11:30:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:33921 (size: 13.8 KiB, free: 366.3 MiB)
25/04/01 11:30:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:35175 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:30:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 513 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:30:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:30:37 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.534 s
25/04/01 11:30:37 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:30:37 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
25/04/01 11:30:37 INFO DAGScheduler: waiting: Set()
25/04/01 11:30:37 INFO DAGScheduler: failed: Set()
25/04/01 11:30:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:33921 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 11:30:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2010 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:30:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:30:39 INFO DAGScheduler: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 2.016 s
25/04/01 11:30:39 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:30:39 INFO DAGScheduler: running: Set()
25/04/01 11:30:39 INFO DAGScheduler: waiting: Set()
25/04/01 11:30:39 INFO DAGScheduler: failed: Set()
25/04/01 11:30:39 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:30:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:30:39 INFO CodeGenerator: Code generated in 13.858901 ms
25/04/01 11:30:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:30:39 INFO DAGScheduler: Got job 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:30:39 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:30:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:30:39 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.3 KiB, free 364.7 MiB)
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 364.7 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:33367 (size: 15.2 KiB, free: 366.1 MiB)
25/04/01 11:30:39 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:30:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:33921 (size: 15.2 KiB, free: 366.2 MiB)
25/04/01 11:30:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:42936
25/04/01 11:30:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 189 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:30:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:30:39 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.197 s
25/04/01 11:30:39 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:30:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 11:30:39 INFO DAGScheduler: Job 3 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.208819 s
25/04/01 11:30:39 INFO CodeGenerator: Code generated in 5.407452 ms
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1028.0 KiB, free 363.7 MiB)
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 363.7 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:33367 (size: 2.3 KiB, free: 366.1 MiB)
25/04/01 11:30:39 INFO SparkContext: Created broadcast 8 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:30:39 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:30:39 INFO CodeGenerator: Code generated in 11.912822 ms
25/04/01 11:30:39 INFO CodeGenerator: Code generated in 7.610271 ms
25/04/01 11:30:39 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:30:39 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:30:39 INFO DAGScheduler: Final stage: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:30:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:30:39 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:39 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 41.3 KiB, free 363.6 MiB)
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 363.6 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:33367 (size: 18.8 KiB, free: 366.1 MiB)
25/04/01 11:30:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:39 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:30:39 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:35175 (size: 18.8 KiB, free: 366.2 MiB)
25/04/01 11:30:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:50374
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:35175 (size: 2.3 KiB, free: 366.2 MiB)
25/04/01 11:30:39 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 188 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:30:39 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:30:39 INFO DAGScheduler: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0) finished in 0.196 s
25/04/01 11:30:39 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:30:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 11:30:39 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.202553 s
25/04/01 11:30:39 INFO CodeGenerator: Code generated in 8.064455 ms
+---------+----------+----------------+--------------------+---------+
|stockcode|      date|     productname|  productdescription|unitprice|
+---------+----------+----------------+--------------------+---------+
|    11333|2025-03-27|Valhalla Knights|Action,Role-Playi...| 16.95000|
+---------+----------+----------------+--------------------+---------+

25/04/01 11:30:39 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/04/01 11:30:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:30:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:30:39 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:30:39 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:30:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:30:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:30:39 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:30:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:30:39 INFO CodeGenerator: Code generated in 9.146867 ms
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 363.3 MiB)
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.2 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:33367 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:30:39 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:30:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:30:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:30:39 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:30:39 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:30:39 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:30:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:30:39 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:39 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 29.9 KiB, free 363.2 MiB)
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 363.2 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:33367 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:30:39 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:39 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 349.8 KiB, free 362.9 MiB)
25/04/01 11:30:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 362.8 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:33367 (size: 33.4 KiB, free: 366.0 MiB)
25/04/01 11:30:39 INFO SparkContext: Created broadcast 12 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:30:39 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:30:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:33921 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:30:39 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 11:30:39 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:30:39 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:30:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:30:39 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:39 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.2 KiB, free 362.8 MiB)
25/04/01 11:30:39 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 362.8 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:33367 (size: 13.8 KiB, free: 366.0 MiB)
25/04/01 11:30:39 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:39 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:30:39 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.18.0.6, executor 2, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:35175 (size: 13.8 KiB, free: 366.2 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:33921 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:30:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:35175 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:30:39 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 178 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:30:39 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:30:39 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.184 s
25/04/01 11:30:39 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:30:39 INFO DAGScheduler: running: Set(ShuffleMapStage 8)
25/04/01 11:30:39 INFO DAGScheduler: waiting: Set()
25/04/01 11:30:39 INFO DAGScheduler: failed: Set()
25/04/01 11:30:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 647 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:30:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:30:40 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.651 s
25/04/01 11:30:40 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:30:40 INFO DAGScheduler: running: Set()
25/04/01 11:30:40 INFO DAGScheduler: waiting: Set()
25/04/01 11:30:40 INFO DAGScheduler: failed: Set()
25/04/01 11:30:40 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:30:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:30:40 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:30:40 INFO DAGScheduler: Got job 7 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:30:40 INFO DAGScheduler: Final stage: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:30:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 11:30:40 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:40 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:30:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 33.3 KiB, free 362.8 MiB)
25/04/01 11:30:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 362.7 MiB)
25/04/01 11:30:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:33367 (size: 15.2 KiB, free: 366.0 MiB)
25/04/01 11:30:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:40 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:30:40 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:30:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:35175 (size: 15.2 KiB, free: 366.1 MiB)
25/04/01 11:30:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:50374
25/04/01 11:30:40 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 34 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:30:40 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:30:40 INFO DAGScheduler: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.038 s
25/04/01 11:30:40 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:30:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/04/01 11:30:40 INFO DAGScheduler: Job 7 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.042771 s
25/04/01 11:30:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1028.0 KiB, free 361.7 MiB)
25/04/01 11:30:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 361.7 MiB)
25/04/01 11:30:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:33367 (size: 2.3 KiB, free: 366.0 MiB)
25/04/01 11:30:40 INFO SparkContext: Created broadcast 15 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:30:40 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:30:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:30:40 INFO CodeGenerator: Code generated in 9.886424 ms
25/04/01 11:30:40 INFO DAGScheduler: Registering RDD 40 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 11:30:40 INFO DAGScheduler: Got map stage job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:30:40 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:30:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
25/04/01 11:30:40 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:40 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:30:40 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 52.6 KiB, free 361.7 MiB)
25/04/01 11:30:40 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 361.7 MiB)
25/04/01 11:30:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7796893c36d7:33367 (size: 23.4 KiB, free: 366.0 MiB)
25/04/01 11:30:40 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:40 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/04/01 11:30:40 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:30:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.2:33921 (size: 23.4 KiB, free: 366.2 MiB)
25/04/01 11:30:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:42936
25/04/01 11:30:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.2:33921 (size: 2.3 KiB, free: 366.2 MiB)
25/04/01 11:30:40 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 85 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:30:40 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/04/01 11:30:40 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.091 s
25/04/01 11:30:40 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:30:40 INFO DAGScheduler: running: Set()
25/04/01 11:30:40 INFO DAGScheduler: waiting: Set()
25/04/01 11:30:40 INFO DAGScheduler: failed: Set()
25/04/01 11:30:40 INFO CodeGenerator: Code generated in 6.078425 ms
25/04/01 11:30:40 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:30:40 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:30:40 INFO DAGScheduler: Final stage: ResultStage 15 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:30:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
25/04/01 11:30:40 INFO DAGScheduler: Missing parents: List()
25/04/01 11:30:40 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:30:40 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.0 KiB, free 361.6 MiB)
25/04/01 11:30:40 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 361.6 MiB)
25/04/01 11:30:40 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7796893c36d7:33367 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:30:40 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1478
25/04/01 11:30:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:30:40 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/04/01 11:30:40 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 9) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:30:40 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.2:33921 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:30:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.2:42936
25/04/01 11:30:40 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 9) in 23 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:30:40 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/04/01 11:30:40 INFO DAGScheduler: ResultStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.025 s
25/04/01 11:30:40 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:30:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/04/01 11:30:40 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.027973 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 73, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:30:40 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:30:40 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:30:40 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:30:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:30:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:30:40 INFO MemoryStore: MemoryStore cleared
25/04/01 11:30:40 INFO BlockManager: BlockManager stopped
25/04/01 11:30:40 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:30:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:30:40 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:30:40 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:30:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-5976938b-45ec-41c5-84a4-e12a635a7f6b
25/04/01 11:30:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-13e1e95c-9344-48b4-82ce-2366ac13b019
25/04/01 11:30:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-5976938b-45ec-41c5-84a4-e12a635a7f6b/pyspark-7ecce674-be14-486b-85ba-8ef8cebb40c6
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:36:00 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:36:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:36:00 INFO ResourceUtils: ==============================================================
25/04/01 11:36:00 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:36:00 INFO ResourceUtils: ==============================================================
25/04/01 11:36:00 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:36:01 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:36:01 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:36:01 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:36:01 INFO SecurityManager: Changing view acls to: root
25/04/01 11:36:01 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:36:01 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:36:01 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:36:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:36:01 INFO Utils: Successfully started service 'sparkDriver' on port 37579.
25/04/01 11:36:01 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:36:01 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:36:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:36:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:36:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:36:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9c517169-73e7-4abb-bf3a-eeff00fc1b44
25/04/01 11:36:01 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:36:01 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:36:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:36:01 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:36:01 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:36:01 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:36:01 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401113601-0022
25/04/01 11:36:01 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113601-0022/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:36:01 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113601-0022/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:36:01 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113601-0022/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:36:01 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113601-0022/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:36:01 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113601-0022/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:36:01 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113601-0022/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:36:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42359.
25/04/01 11:36:01 INFO NettyBlockTransferService: Server created on 7796893c36d7:42359
25/04/01 11:36:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:36:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 42359, None)
25/04/01 11:36:01 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:42359 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 42359, None)
25/04/01 11:36:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113601-0022/1 is now RUNNING
25/04/01 11:36:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113601-0022/0 is now RUNNING
25/04/01 11:36:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 42359, None)
25/04/01 11:36:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 42359, None)
25/04/01 11:36:01 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113601-0022/2 is now RUNNING
25/04/01 11:36:01 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:36:02 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:36:02 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:36:03 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/01 11:36:03 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:36:03 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:53076) with ID 2,  ResourceProfileId 0
25/04/01 11:36:03 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:38270) with ID 1,  ResourceProfileId 0
25/04/01 11:36:03 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:49620) with ID 0,  ResourceProfileId 0
25/04/01 11:36:03 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:36191 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 36191, None)
25/04/01 11:36:03 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:33861 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 33861, None)
25/04/01 11:36:03 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:35807 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 35807, None)
25/04/01 11:36:04 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:36:04 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:36:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:36:05 INFO CodeGenerator: Code generated in 131.925667 ms
25/04/01 11:36:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:36:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:36:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:42359 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:36:05 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:36:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:36:05 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:36:05 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:36:05 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:36:05 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:36:05 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:05 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:36:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:36:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:36:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:42359 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:36:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:36:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:36:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:35807 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:36:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:35807 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:36:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1353 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:36:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:36:06 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.418 s
25/04/01 11:36:06 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:36:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:36:06 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.449550 s
25/04/01 11:36:06 INFO CodeGenerator: Code generated in 7.741574 ms
25/04/01 11:36:06 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:36:06 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:36:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:36:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:36:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:36:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:42359 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:36:06 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:36:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:36:07 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:36:07 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:36:07 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:36:07 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:36:07 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:36:07 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:36:07 INFO metastore: Connected to metastore.
25/04/01 11:36:07 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=d414508b-7979-4d98-8798-c5ee750131d7, clientType=HIVECLI]
25/04/01 11:36:07 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:36:07 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:36:07 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:36:07 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:36:07 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:36:07 INFO metastore: Connected to metastore.
25/04/01 11:36:07 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:36:07 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:36:07 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)
 |-- date: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:36:08 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
25/04/01 11:36:08 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:36:08 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:36:08 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:36:08 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:36:08 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:36:08 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:36:08 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:36:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:42359 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:36:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:35807 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:36:08 INFO CodeGenerator: Code generated in 20.575614 ms
25/04/01 11:36:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:36:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:36:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:42359 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:36:08 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:36:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:36:08 INFO DAGScheduler: Registering RDD 14 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:36:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:36:08 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:36:08 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:36:08 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:36:08 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:08 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:36:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 33.0 KiB, free 365.2 MiB)
25/04/01 11:36:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 365.1 MiB)
25/04/01 11:36:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:42359 (size: 15.5 KiB, free: 366.2 MiB)
25/04/01 11:36:08 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:36:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:36:08 INFO CodeGenerator: Code generated in 28.194755 ms
25/04/01 11:36:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:35807 (size: 15.5 KiB, free: 366.3 MiB)
25/04/01 11:36:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:36:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:36:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:42359 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:36:08 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:36:08 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:36:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:36:08 INFO DAGScheduler: Registering RDD 18 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:36:08 INFO DAGScheduler: Got map stage job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:36:08 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:36:08 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:36:08 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:08 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:36:08 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 31.2 KiB, free 364.7 MiB)
25/04/01 11:36:08 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 364.7 MiB)
25/04/01 11:36:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:42359 (size: 13.8 KiB, free: 366.1 MiB)
25/04/01 11:36:08 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:08 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 11:36:08 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.8, executor 1, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 11:36:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:33861 (size: 13.8 KiB, free: 366.3 MiB)
25/04/01 11:36:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:35807 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:36:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 551 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:36:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:36:08 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.571 s
25/04/01 11:36:08 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:36:08 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
25/04/01 11:36:08 INFO DAGScheduler: waiting: Set()
25/04/01 11:36:08 INFO DAGScheduler: failed: Set()
25/04/01 11:36:09 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:33861 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 11:36:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2033 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:36:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 11:36:10 INFO DAGScheduler: ShuffleMapStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 2.040 s
25/04/01 11:36:10 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:36:10 INFO DAGScheduler: running: Set()
25/04/01 11:36:10 INFO DAGScheduler: waiting: Set()
25/04/01 11:36:10 INFO DAGScheduler: failed: Set()
25/04/01 11:36:10 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:36:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:36:10 INFO CodeGenerator: Code generated in 12.766991 ms
25/04/01 11:36:10 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:36:10 INFO DAGScheduler: Got job 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:36:10 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:36:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/04/01 11:36:10 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:10 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:36:10 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.3 KiB, free 364.7 MiB)
25/04/01 11:36:10 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 364.7 MiB)
25/04/01 11:36:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:42359 (size: 15.2 KiB, free: 366.1 MiB)
25/04/01 11:36:10 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:10 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:36:10 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:36:10 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:33861 (size: 15.2 KiB, free: 366.2 MiB)
25/04/01 11:36:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:38270
25/04/01 11:36:10 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 183 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:36:10 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:36:10 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.189 s
25/04/01 11:36:10 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:36:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 11:36:10 INFO DAGScheduler: Job 3 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.197818 s
25/04/01 11:36:10 INFO CodeGenerator: Code generated in 5.100916 ms
25/04/01 11:36:10 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 1028.0 KiB, free 363.7 MiB)
25/04/01 11:36:10 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 363.7 MiB)
25/04/01 11:36:10 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:42359 (size: 2.3 KiB, free: 366.1 MiB)
25/04/01 11:36:10 INFO SparkContext: Created broadcast 8 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:36:10 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:36:10 INFO CodeGenerator: Code generated in 9.722645 ms
25/04/01 11:36:10 INFO CodeGenerator: Code generated in 7.961577 ms
25/04/01 11:36:10 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:36:10 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:36:10 INFO DAGScheduler: Final stage: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:36:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:36:10 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:10 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:36:10 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 42.0 KiB, free 363.6 MiB)
25/04/01 11:36:10 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 363.6 MiB)
25/04/01 11:36:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:42359 (size: 19.1 KiB, free: 366.1 MiB)
25/04/01 11:36:10 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:10 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:36:10 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:36:10 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:35807 (size: 19.1 KiB, free: 366.2 MiB)
25/04/01 11:36:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:49620
25/04/01 11:36:10 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:35807 (size: 2.3 KiB, free: 366.2 MiB)
25/04/01 11:36:10 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 183 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:36:10 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:36:10 INFO DAGScheduler: ResultStage 6 (showString at NativeMethodAccessorImpl.java:0) finished in 0.191 s
25/04/01 11:36:10 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:36:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 11:36:10 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.196003 s
25/04/01 11:36:10 INFO CodeGenerator: Code generated in 8.313371 ms
+---------+----------+----------------+--------------------+---------+
|stockcode|      date|     productname|  productdescription|unitprice|
+---------+----------+----------------+--------------------+---------+
|    11333|2025-03-27|Valhalla Knights|Action,Role-Playi...| 16.95000|
+---------+----------+----------------+--------------------+---------+

25/04/01 11:36:11 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/04/01 11:36:11 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:36:11 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:36:11 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:36:11 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:36:11 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:36:11 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:36:11 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:36:11 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:36:11 INFO CodeGenerator: Code generated in 10.191006 ms
25/04/01 11:36:11 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 363.3 MiB)
25/04/01 11:36:11 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.2 MiB)
25/04/01 11:36:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:42359 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:36:11 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:36:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:36:11 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:36:11 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:36:11 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:36:11 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:36:11 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:11 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:36:11 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:36:11 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 29.9 KiB, free 363.2 MiB)
25/04/01 11:36:11 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 363.2 MiB)
25/04/01 11:36:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:42359 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:36:11 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:11 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:36:11 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:36:11 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 349.8 KiB, free 362.9 MiB)
25/04/01 11:36:11 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 362.8 MiB)
25/04/01 11:36:11 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:42359 (size: 33.4 KiB, free: 366.0 MiB)
25/04/01 11:36:11 INFO SparkContext: Created broadcast 12 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:36:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:33861 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:36:11 INFO InMemoryFileIndex: Selected 1 partitions out of 1, pruned 0.0% partitions.
25/04/01 11:36:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:36:11 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 11:36:11 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:36:11 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:36:11 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:36:11 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:11 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:36:11 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.2 KiB, free 362.8 MiB)
25/04/01 11:36:11 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.8 KiB, free 362.8 MiB)
25/04/01 11:36:11 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:42359 (size: 13.8 KiB, free: 366.0 MiB)
25/04/01 11:36:11 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:11 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:36:11 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.18.0.6, executor 2, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 11:36:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:33861 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:36:11 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 194 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:36:11 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:36:11 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.199 s
25/04/01 11:36:11 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:36:11 INFO DAGScheduler: running: Set(ShuffleMapStage 8)
25/04/01 11:36:11 INFO DAGScheduler: waiting: Set()
25/04/01 11:36:11 INFO DAGScheduler: failed: Set()
25/04/01 11:36:11 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:36191 (size: 13.8 KiB, free: 366.3 MiB)
25/04/01 11:36:12 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:36191 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 11:36:13 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 2010 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:36:13 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:36:13 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 2.015 s
25/04/01 11:36:13 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:36:13 INFO DAGScheduler: running: Set()
25/04/01 11:36:13 INFO DAGScheduler: waiting: Set()
25/04/01 11:36:13 INFO DAGScheduler: failed: Set()
25/04/01 11:36:13 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:36:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:36:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:36:13 INFO DAGScheduler: Got job 7 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:36:13 INFO DAGScheduler: Final stage: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:36:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 11:36:13 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:13 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:36:13 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 33.3 KiB, free 362.8 MiB)
25/04/01 11:36:13 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 362.7 MiB)
25/04/01 11:36:13 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:42359 (size: 15.2 KiB, free: 366.0 MiB)
25/04/01 11:36:13 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:13 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:36:13 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:36:13 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:36191 (size: 15.2 KiB, free: 366.2 MiB)
25/04/01 11:36:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:53076
25/04/01 11:36:13 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 172 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:36:13 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:36:13 INFO DAGScheduler: ResultStage 10 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.176 s
25/04/01 11:36:13 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:36:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/04/01 11:36:13 INFO DAGScheduler: Job 7 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.180539 s
25/04/01 11:36:13 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1028.0 KiB, free 361.7 MiB)
25/04/01 11:36:13 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 361.7 MiB)
25/04/01 11:36:13 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:42359 (size: 2.3 KiB, free: 366.0 MiB)
25/04/01 11:36:13 INFO SparkContext: Created broadcast 15 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:36:13 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:36:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:36:13 INFO CodeGenerator: Code generated in 10.833553 ms
25/04/01 11:36:13 INFO DAGScheduler: Registering RDD 40 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 11:36:13 INFO DAGScheduler: Got map stage job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:36:13 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:36:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
25/04/01 11:36:13 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:13 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:36:13 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 52.6 KiB, free 361.7 MiB)
25/04/01 11:36:13 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 361.7 MiB)
25/04/01 11:36:13 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7796893c36d7:42359 (size: 23.4 KiB, free: 366.0 MiB)
25/04/01 11:36:13 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:13 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/04/01 11:36:13 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:36:13 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.8:33861 (size: 23.4 KiB, free: 366.2 MiB)
25/04/01 11:36:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:38270
25/04/01 11:36:13 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:33861 (size: 2.3 KiB, free: 366.2 MiB)
25/04/01 11:36:13 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 91 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:36:13 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/04/01 11:36:13 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.098 s
25/04/01 11:36:13 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:36:13 INFO DAGScheduler: running: Set()
25/04/01 11:36:13 INFO DAGScheduler: waiting: Set()
25/04/01 11:36:13 INFO DAGScheduler: failed: Set()
25/04/01 11:36:13 INFO CodeGenerator: Code generated in 6.35032 ms
25/04/01 11:36:13 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:36:13 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:36:13 INFO DAGScheduler: Final stage: ResultStage 15 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:36:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
25/04/01 11:36:13 INFO DAGScheduler: Missing parents: List()
25/04/01 11:36:13 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:36:13 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.0 KiB, free 361.6 MiB)
25/04/01 11:36:13 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 361.6 MiB)
25/04/01 11:36:13 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7796893c36d7:42359 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:36:13 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1478
25/04/01 11:36:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:36:13 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/04/01 11:36:13 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 9) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:36:13 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.8:33861 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:36:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.8:38270
25/04/01 11:36:13 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 9) in 25 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:36:13 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/04/01 11:36:13 INFO DAGScheduler: ResultStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.029 s
25/04/01 11:36:13 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:36:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/04/01 11:36:13 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0.031196 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 73, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:36:13 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:36:13 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:36:13 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:36:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:36:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:36:13 INFO MemoryStore: MemoryStore cleared
25/04/01 11:36:13 INFO BlockManager: BlockManager stopped
25/04/01 11:36:13 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:36:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:36:13 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:36:13 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:36:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-b64d543f-1124-4cf7-b393-13586fde3f3b/pyspark-1b92ff39-18fd-4958-86f6-98258b0fdc40
25/04/01 11:36:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-de600e31-3cf7-4cd1-b190-8528870dce0c
25/04/01 11:36:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-b64d543f-1124-4cf7-b393-13586fde3f3b
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:37:35 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:37:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:37:35 INFO ResourceUtils: ==============================================================
25/04/01 11:37:35 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:37:35 INFO ResourceUtils: ==============================================================
25/04/01 11:37:35 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:37:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:37:35 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:37:35 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:37:35 INFO SecurityManager: Changing view acls to: root
25/04/01 11:37:35 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:37:35 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:37:35 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:37:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:37:35 INFO Utils: Successfully started service 'sparkDriver' on port 46443.
25/04/01 11:37:35 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:37:35 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:37:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:37:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:37:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:37:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8c23430-a18e-4c4c-89cb-2d79e9f656b1
25/04/01 11:37:35 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:37:35 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:37:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:37:36 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:37:36 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:37:36 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:37:36 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401113736-0023
25/04/01 11:37:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113736-0023/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:37:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113736-0023/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:37:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113736-0023/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:37:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113736-0023/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:37:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113736-0023/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:37:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113736-0023/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:37:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40009.
25/04/01 11:37:36 INFO NettyBlockTransferService: Server created on 7796893c36d7:40009
25/04/01 11:37:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:37:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 40009, None)
25/04/01 11:37:36 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:40009 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 40009, None)
25/04/01 11:37:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113736-0023/0 is now RUNNING
25/04/01 11:37:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113736-0023/2 is now RUNNING
25/04/01 11:37:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 40009, None)
25/04/01 11:37:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113736-0023/1 is now RUNNING
25/04/01 11:37:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 40009, None)
25/04/01 11:37:36 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:37:36 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:37:36 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:37:37 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/01 11:37:38 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:37:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:56352) with ID 2,  ResourceProfileId 0
25/04/01 11:37:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:35922) with ID 0,  ResourceProfileId 0
25/04/01 11:37:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:45696) with ID 1,  ResourceProfileId 0
25/04/01 11:37:38 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:41431 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 41431, None)
25/04/01 11:37:38 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:33711 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 33711, None)
25/04/01 11:37:38 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:40011 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 40011, None)
25/04/01 11:37:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:37:39 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:37:39 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:37:40 INFO CodeGenerator: Code generated in 136.705078 ms
25/04/01 11:37:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:37:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:37:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:40009 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:37:40 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:37:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:37:40 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:37:40 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:37:40 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:37:40 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:37:40 INFO DAGScheduler: Missing parents: List()
25/04/01 11:37:40 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:37:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:37:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:37:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:40009 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:37:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:37:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:37:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:37:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:37:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:40011 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:37:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:40011 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:37:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1377 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:37:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:37:41 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.441 s
25/04/01 11:37:41 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:37:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:37:41 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.471475 s
25/04/01 11:37:41 INFO CodeGenerator: Code generated in 7.940866 ms
25/04/01 11:37:41 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:37:41 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:37:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:37:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:37:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:37:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:40009 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:37:41 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:37:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:37:41 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:37:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:37:41 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:37:42 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:37:42 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:37:42 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:37:42 INFO metastore: Connected to metastore.
25/04/01 11:37:42 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=b7543f13-0683-483c-8e09-8025bb58c1ba, clientType=HIVECLI]
25/04/01 11:37:42 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:37:42 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:37:42 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:37:42 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:37:42 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:37:42 INFO metastore: Connected to metastore.
25/04/01 11:37:42 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:37:42 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:37:42 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,7) (nullable = true)
 |-- date: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,7) (nullable = true)

25/04/01 11:37:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:37:42 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:40009 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:37:42 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:40011 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:37:42 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:37:42 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:37:42 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:37:42 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:37:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:37:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:37:42 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:37:43 INFO CodeGenerator: Code generated in 22.663157 ms
25/04/01 11:37:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:37:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:37:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:40009 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:37:43 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:37:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:37:43 INFO DAGScheduler: Registering RDD 14 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:37:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:37:43 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:37:43 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:37:43 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:37:43 INFO DAGScheduler: Missing parents: List()
25/04/01 11:37:43 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:37:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 33.0 KiB, free 365.2 MiB)
25/04/01 11:37:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 365.1 MiB)
25/04/01 11:37:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:40009 (size: 15.5 KiB, free: 366.2 MiB)
25/04/01 11:37:43 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:37:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:37:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:37:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:37:43 INFO CodeGenerator: Code generated in 28.129112 ms
25/04/01 11:37:43 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:37:43 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:37:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:40009 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:37:43 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:37:43 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:37:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:37:43 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:37:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:37:43 INFO CodeGenerator: Code generated in 18.452747 ms
25/04/01 11:37:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:37:43 INFO DAGScheduler: Registering RDD 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 11:37:43 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:37:43 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:37:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:37:43 INFO DAGScheduler: Missing parents: List()
25/04/01 11:37:43 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:37:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 33.2 KiB, free 364.7 MiB)
25/04/01 11:37:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 364.7 MiB)
25/04/01 11:37:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:40009 (size: 15.1 KiB, free: 366.1 MiB)
25/04/01 11:37:43 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:37:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:37:43 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:37:43 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:37:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:33711 (size: 15.5 KiB, free: 366.3 MiB)
25/04/01 11:37:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:41431 (size: 15.1 KiB, free: 366.3 MiB)
25/04/01 11:37:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:56352
25/04/01 11:37:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:33711 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:37:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 1080 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:37:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:37:44 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.088 s
25/04/01 11:37:44 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:37:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:37:44 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.092853 s
25/04/01 11:37:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 11:37:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 11:37:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:40009 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:37:44 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:37:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1860 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:37:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:37:44 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.878 s
25/04/01 11:37:44 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:37:44 INFO DAGScheduler: running: Set()
25/04/01 11:37:44 INFO DAGScheduler: waiting: Set()
25/04/01 11:37:44 INFO DAGScheduler: failed: Set()
25/04/01 11:37:44 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:37:44 INFO CodeGenerator: Code generated in 7.575944 ms
25/04/01 11:37:44 INFO CodeGenerator: Code generated in 7.690833 ms
25/04/01 11:37:44 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:37:44 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:37:44 INFO DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:37:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 11:37:44 INFO DAGScheduler: Missing parents: List()
25/04/01 11:37:44 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 40.2 KiB, free 364.7 MiB)
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 18.4 KiB, free 364.7 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:40009 (size: 18.4 KiB, free: 366.1 MiB)
25/04/01 11:37:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:37:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:37:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:37:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:33711 (size: 18.4 KiB, free: 366.2 MiB)
25/04/01 11:37:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:35922
25/04/01 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 230 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:37:45 INFO DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 0.240 s
25/04/01 11:37:45 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:37:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/01 11:37:45 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.250162 s
25/04/01 11:37:45 INFO CodeGenerator: Code generated in 10.235518 ms
+---------+----------+--------------------+--------------------+----------+
|stockcode|      date|         productname|  productdescription| unitprice|
+---------+----------+--------------------+--------------------+----------+
|     1005|2025-03-27|The Urbz: Sims in...|          Simulation|12.9500000|
|     1025|2025-03-27|Brain Agey: More ...|              Action|17.9500000|
|     1026|2025-03-27|Grand Theft Auto:...|Action,Racing / D...|17.9500000|
|     1039|2025-03-27|Mario & Luigi: Pa...|Action,Role-Playi...|29.9500000|
|     1040|2025-03-27|       Madden NFL 06|              Sports| 7.9500000|
|     1056|2025-03-27|     Dead or Alive 4|              Action|17.9500000|
|     1062|2025-03-27|    Yoshi Touch & Go|              Action|17.9500000|
|     1077|2025-03-27|          Madagascar|           Adventure|14.9500000|
|     1088|2025-03-27|Harry Potter and ...|              Action|17.9500000|
|     1108|2025-03-27| Kingdom of Paradise|Action,Role-Playi...|12.9500000|
|     1125|2025-03-27|The Lord of the R...|Role-Playing (RPG...|19.9500000|
|    11333|2025-03-27|    Valhalla Knights|Action,Role-Playi...|16.9500000|
|     1166|2025-03-27|       Madden NFL 07|              Sports| 4.9500000|
|     1175|2025-03-27|Rayman Raving Rab...|              Action|17.9500000|
|     1179|2025-03-27|      Call of Duty 3|              Action|19.9500000|
|     1200|2025-03-27|Mortal Kombat: Un...|              Action|17.9500000|
|     1224|2025-03-27|        Excite Truck|    Racing / Driving|19.9500000|
|     1227|2025-03-27|Metal Gear Solid:...|     Action,Strategy|17.9500000|
|     1229|2025-03-27|Blazing Angels: S...|              Action|16.9500000|
|     1234|2025-03-27|WWE SmackDown vs....|              Sports|14.9500000|
+---------+----------+--------------------+--------------------+----------+
only showing top 20 rows

25/04/01 11:37:45 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:37:45 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:37:45 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:37:45 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:37:45 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:37:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:37:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:37:45 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:37:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:37:45 INFO CodeGenerator: Code generated in 10.926322 ms
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 345.6 KiB, free 364.3 MiB)
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.3 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:40009 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:37:45 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:37:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:37:45 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:37:45 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:37:45 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:37:45 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:37:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:37:45 INFO DAGScheduler: Missing parents: List()
25/04/01 11:37:45 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 29.9 KiB, free 364.3 MiB)
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.3 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:40009 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:37:45 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 11:37:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:37:45 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:37:45 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 349.8 KiB, free 363.9 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:33711 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.9 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:40009 (size: 33.4 KiB, free: 366.0 MiB)
25/04/01 11:37:45 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:37:45 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:37:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:37:45 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:37:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:37:45 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:37:45 INFO DAGScheduler: Registering RDD 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 3
25/04/01 11:37:45 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:37:45 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:37:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:37:45 INFO DAGScheduler: Missing parents: List()
25/04/01 11:37:45 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 33.2 KiB, free 363.8 MiB)
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 363.8 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:40009 (size: 15.1 KiB, free: 366.0 MiB)
25/04/01 11:37:45 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:37:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:37:45 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:37:45 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:33711 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:40011 (size: 15.1 KiB, free: 366.3 MiB)
25/04/01 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 141 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:37:45 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.146 s
25/04/01 11:37:45 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:37:45 INFO DAGScheduler: running: Set(ResultStage 8)
25/04/01 11:37:45 INFO DAGScheduler: waiting: Set()
25/04/01 11:37:45 INFO DAGScheduler: failed: Set()
25/04/01 11:37:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:45696
25/04/01 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 235 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:37:45 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.242 s
25/04/01 11:37:45 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:37:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:37:45 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.245241 s
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 24.0 B, free 363.8 MiB)
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 120.0 B, free 363.8 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:40009 (size: 120.0 B, free: 366.0 MiB)
25/04/01 11:37:45 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:37:45 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:37:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:37:45 INFO CodeGenerator: Code generated in 9.495475 ms
25/04/01 11:37:45 INFO DAGScheduler: Registering RDD 40 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 11:37:45 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:37:45 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:37:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 11:37:45 INFO DAGScheduler: Missing parents: List()
25/04/01 11:37:45 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 37.9 KiB, free 363.8 MiB)
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 363.8 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:40009 (size: 17.9 KiB, free: 366.0 MiB)
25/04/01 11:37:45 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:37:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:37:45 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:37:45 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 6) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:33711 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:37:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:35922
25/04/01 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 6) in 47 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:37:45 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.055 s
25/04/01 11:37:45 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:37:45 INFO DAGScheduler: running: Set()
25/04/01 11:37:45 INFO DAGScheduler: waiting: Set()
25/04/01 11:37:45 INFO DAGScheduler: failed: Set()
25/04/01 11:37:45 INFO CodeGenerator: Code generated in 5.86552 ms
25/04/01 11:37:45 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:37:45 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:37:45 INFO DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:37:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/04/01 11:37:45 INFO DAGScheduler: Missing parents: List()
25/04/01 11:37:45 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 363.8 MiB)
25/04/01 11:37:45 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.8 MiB)
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:40009 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:37:45 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:37:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:37:45 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/04/01 11:37:45 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 7) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:37:45 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.2:33711 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:37:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.2:35922
25/04/01 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 7) in 25 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/04/01 11:37:45 INFO DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.030 s
25/04/01 11:37:45 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:37:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/04/01 11:37:45 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.032800 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 73, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,7)
25/04/01 11:37:45 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:37:45 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:37:45 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:37:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:37:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:37:45 INFO MemoryStore: MemoryStore cleared
25/04/01 11:37:45 INFO BlockManager: BlockManager stopped
25/04/01 11:37:45 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:37:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:37:45 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:37:45 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:37:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-eb0a4a6a-a65e-4ae6-b17c-25f6235c671a/pyspark-9a2e5054-f4b4-48ba-b135-261daa90e091
25/04/01 11:37:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-eb0a4a6a-a65e-4ae6-b17c-25f6235c671a
25/04/01 11:37:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-7033a4cd-5447-49b2-8483-629b24b47b7d
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:38:22 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:38:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:38:22 INFO ResourceUtils: ==============================================================
25/04/01 11:38:22 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:38:22 INFO ResourceUtils: ==============================================================
25/04/01 11:38:22 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:38:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:38:22 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:38:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:38:22 INFO SecurityManager: Changing view acls to: root
25/04/01 11:38:22 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:38:22 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:38:22 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:38:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:38:22 INFO Utils: Successfully started service 'sparkDriver' on port 42401.
25/04/01 11:38:23 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:38:23 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:38:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:38:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:38:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:38:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0a620549-f0ac-4cb3-b73e-bfab7d8de579
25/04/01 11:38:23 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:38:23 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:38:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:38:23 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:38:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:38:23 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 24 ms (0 ms spent in bootstraps)
25/04/01 11:38:23 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401113823-0024
25/04/01 11:38:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113823-0024/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:38:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113823-0024/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:38:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113823-0024/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:38:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113823-0024/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:38:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401113823-0024/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:38:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401113823-0024/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:38:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46773.
25/04/01 11:38:23 INFO NettyBlockTransferService: Server created on 7796893c36d7:46773
25/04/01 11:38:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:38:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 46773, None)
25/04/01 11:38:23 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:46773 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 46773, None)
25/04/01 11:38:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113823-0024/1 is now RUNNING
25/04/01 11:38:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113823-0024/2 is now RUNNING
25/04/01 11:38:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 46773, None)
25/04/01 11:38:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401113823-0024/0 is now RUNNING
25/04/01 11:38:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 46773, None)
25/04/01 11:38:23 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:38:23 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:38:23 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:38:25 INFO InMemoryFileIndex: It took 61 ms to list leaf files for 1 paths.
25/04/01 11:38:25 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:38:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:41676) with ID 1,  ResourceProfileId 0
25/04/01 11:38:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:51116) with ID 0,  ResourceProfileId 0
25/04/01 11:38:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:58332) with ID 2,  ResourceProfileId 0
25/04/01 11:38:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:45035 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 45035, None)
25/04/01 11:38:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:39839 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 39839, None)
25/04/01 11:38:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:45575 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 45575, None)
25/04/01 11:38:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:38:26 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:38:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:38:27 INFO CodeGenerator: Code generated in 133.495315 ms
25/04/01 11:38:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:38:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:38:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:46773 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:38:27 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:38:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:38:27 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:38:27 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:38:27 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:38:27 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:38:27 INFO DAGScheduler: Missing parents: List()
25/04/01 11:38:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:38:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:38:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:38:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:46773 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:38:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:38:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:38:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:38:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:38:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:39839 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:38:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:39839 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:38:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1357 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:38:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:38:28 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.425 s
25/04/01 11:38:28 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:38:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:38:28 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.457775 s
25/04/01 11:38:28 INFO CodeGenerator: Code generated in 8.74957 ms
25/04/01 11:38:28 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:38:28 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:38:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:38:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:38:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:38:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:46773 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:38:28 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:38:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:38:28 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:38:28 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:38:29 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:38:29 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:38:29 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:38:29 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:38:29 INFO metastore: Connected to metastore.
25/04/01 11:38:29 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=231cc3c4-3d19-449a-bdc3-5f2bdedba8a1, clientType=HIVECLI]
25/04/01 11:38:29 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:38:29 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:38:29 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:38:29 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:38:29 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:38:29 INFO metastore: Connected to metastore.
25/04/01 11:38:29 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:38:29 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:38:29 INFO metastore: Connected to metastore.
root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)
 |-- date: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- date: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(15,5) (nullable = true)

25/04/01 11:38:29 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:38:29 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:38:29 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:38:29 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:38:29 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:38:29 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:38:29 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:38:29 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:38:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:46773 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:38:29 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:39839 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:38:30 INFO CodeGenerator: Code generated in 19.391574 ms
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:38:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:46773 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:38:30 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:38:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:38:30 INFO DAGScheduler: Registering RDD 14 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:38:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:38:30 INFO DAGScheduler: Got map stage job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:38:30 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:38:30 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:38:30 INFO DAGScheduler: Missing parents: List()
25/04/01 11:38:30 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 31.8 KiB, free 365.2 MiB)
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 365.1 MiB)
25/04/01 11:38:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:46773 (size: 14.7 KiB, free: 366.2 MiB)
25/04/01 11:38:30 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:38:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:38:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:38:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:38:30 INFO CodeGenerator: Code generated in 29.279076 ms
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:38:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:46773 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:38:30 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:38:30 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:38:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:38:30 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:38:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:38:30 INFO CodeGenerator: Code generated in 17.213068 ms
25/04/01 11:38:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:38:30 INFO DAGScheduler: Registering RDD 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 11:38:30 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:38:30 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:38:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:38:30 INFO DAGScheduler: Missing parents: List()
25/04/01 11:38:30 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 33.2 KiB, free 364.7 MiB)
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 364.7 MiB)
25/04/01 11:38:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:46773 (size: 15.1 KiB, free: 366.1 MiB)
25/04/01 11:38:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:38:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:38:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:38:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:38:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:45035 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 11:38:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:39839 (size: 15.1 KiB, free: 366.3 MiB)
25/04/01 11:38:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:51116
25/04/01 11:38:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 249 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:38:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:38:30 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.256 s
25/04/01 11:38:30 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:38:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:38:30 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.260315 s
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 11:38:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 11:38:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:46773 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:38:30 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:38:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:45035 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:38:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1721 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:38:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:38:31 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.742 s
25/04/01 11:38:31 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:38:31 INFO DAGScheduler: running: Set()
25/04/01 11:38:31 INFO DAGScheduler: waiting: Set()
25/04/01 11:38:31 INFO DAGScheduler: failed: Set()
25/04/01 11:38:31 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:38:31 INFO CodeGenerator: Code generated in 7.869424 ms
25/04/01 11:38:31 INFO CodeGenerator: Code generated in 7.831081 ms
25/04/01 11:38:31 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:38:31 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:38:31 INFO DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:38:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 11:38:31 INFO DAGScheduler: Missing parents: List()
25/04/01 11:38:31 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:38:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 39.5 KiB, free 364.7 MiB)
25/04/01 11:38:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 18.0 KiB, free 364.7 MiB)
25/04/01 11:38:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:46773 (size: 18.0 KiB, free: 366.1 MiB)
25/04/01 11:38:31 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:38:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:38:31 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:38:31 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:38:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:45035 (size: 18.0 KiB, free: 366.2 MiB)
25/04/01 11:38:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:41676
25/04/01 11:38:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 229 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:38:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:38:32 INFO DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 0.238 s
25/04/01 11:38:32 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:38:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/04/01 11:38:32 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.248149 s
25/04/01 11:38:32 INFO CodeGenerator: Code generated in 11.428283 ms
+---------+----------+--------------------+--------------------+---------+
|stockcode|      date|         productname|  productdescription|unitprice|
+---------+----------+--------------------+--------------------+---------+
|     1005|2025-03-27|The Urbz: Sims in...|          Simulation| 12.95000|
|     1025|2025-03-27|Brain Agey: More ...|              Action| 17.95000|
|     1026|2025-03-27|Grand Theft Auto:...|Action,Racing / D...| 17.95000|
|     1039|2025-03-27|Mario & Luigi: Pa...|Action,Role-Playi...| 29.95000|
|     1040|2025-03-27|       Madden NFL 06|              Sports|  7.95000|
|     1056|2025-03-27|     Dead or Alive 4|              Action| 17.95000|
|     1062|2025-03-27|    Yoshi Touch & Go|              Action| 17.95000|
|     1077|2025-03-27|          Madagascar|           Adventure| 14.95000|
|     1088|2025-03-27|Harry Potter and ...|              Action| 17.95000|
|     1108|2025-03-27| Kingdom of Paradise|Action,Role-Playi...| 12.95000|
|     1125|2025-03-27|The Lord of the R...|Role-Playing (RPG...| 19.95000|
|    11333|2025-03-27|    Valhalla Knights|Action,Role-Playi...| 16.95000|
|     1166|2025-03-27|       Madden NFL 07|              Sports|  4.95000|
|     1175|2025-03-27|Rayman Raving Rab...|              Action| 17.95000|
|     1179|2025-03-27|      Call of Duty 3|              Action| 19.95000|
|     1200|2025-03-27|Mortal Kombat: Un...|              Action| 17.95000|
|     1224|2025-03-27|        Excite Truck|    Racing / Driving| 19.95000|
|     1227|2025-03-27|Metal Gear Solid:...|     Action,Strategy| 17.95000|
|     1229|2025-03-27|Blazing Angels: S...|              Action| 16.95000|
|     1234|2025-03-27|WWE SmackDown vs....|              Sports| 14.95000|
+---------+----------+--------------------+--------------------+---------+
only showing top 20 rows

25/04/01 11:38:32 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:38:32 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:38:32 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:38:32 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:38:32 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:38:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:38:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:38:32 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:38:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:38:32 INFO CodeGenerator: Code generated in 11.191169 ms
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 345.6 KiB, free 364.3 MiB)
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.3 MiB)
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:46773 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:38:32 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:38:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:38:32 INFO DAGScheduler: Registering RDD 30 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:38:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:38:32 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:38:32 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:38:32 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:38:32 INFO DAGScheduler: Missing parents: List()
25/04/01 11:38:32 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 29.9 KiB, free 364.3 MiB)
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.3 MiB)
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:46773 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:38:32 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 11:38:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:38:32 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:38:32 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 349.8 KiB, free 363.9 MiB)
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.9 MiB)
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:46773 (size: 33.4 KiB, free: 366.0 MiB)
25/04/01 11:38:32 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:38:32 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:38:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:39839 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:38:32 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:38:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:38:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:38:32 INFO DAGScheduler: Registering RDD 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 3
25/04/01 11:38:32 INFO DAGScheduler: Got job 5 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:38:32 INFO DAGScheduler: Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:38:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:38:32 INFO DAGScheduler: Missing parents: List()
25/04/01 11:38:32 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 33.2 KiB, free 363.8 MiB)
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.1 KiB, free 363.8 MiB)
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:46773 (size: 15.1 KiB, free: 366.0 MiB)
25/04/01 11:38:32 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:38:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:38:32 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:38:32 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:45035 (size: 15.1 KiB, free: 366.2 MiB)
25/04/01 11:38:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:41676
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:39839 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:38:32 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 111 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:38:32 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:38:32 INFO DAGScheduler: ResultStage 8 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.117 s
25/04/01 11:38:32 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:38:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:38:32 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.119956 s
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 24.0 B, free 363.8 MiB)
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 120.0 B, free 363.8 MiB)
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:46773 (size: 120.0 B, free: 366.0 MiB)
25/04/01 11:38:32 INFO SparkContext: Created broadcast 13 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:38:32 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 276 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:38:32 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:38:32 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.283 s
25/04/01 11:38:32 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:38:32 INFO DAGScheduler: running: Set()
25/04/01 11:38:32 INFO DAGScheduler: waiting: Set()
25/04/01 11:38:32 INFO DAGScheduler: failed: Set()
25/04/01 11:38:32 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:38:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:38:32 INFO CodeGenerator: Code generated in 10.845313 ms
25/04/01 11:38:32 INFO DAGScheduler: Registering RDD 40 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
25/04/01 11:38:32 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:38:32 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:38:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 11:38:32 INFO DAGScheduler: Missing parents: List()
25/04/01 11:38:32 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 37.9 KiB, free 363.8 MiB)
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 363.8 MiB)
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:46773 (size: 17.9 KiB, free: 366.0 MiB)
25/04/01 11:38:32 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 11:38:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:38:32 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:38:32 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 6) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:39839 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:38:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:51116
25/04/01 11:38:32 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 6) in 71 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:38:32 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:38:32 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.078 s
25/04/01 11:38:32 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:38:32 INFO DAGScheduler: running: Set()
25/04/01 11:38:32 INFO DAGScheduler: waiting: Set()
25/04/01 11:38:32 INFO DAGScheduler: failed: Set()
25/04/01 11:38:32 INFO CodeGenerator: Code generated in 7.264664 ms
25/04/01 11:38:32 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:38:32 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:38:32 INFO DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:38:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/04/01 11:38:32 INFO DAGScheduler: Missing parents: List()
25/04/01 11:38:32 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 11.0 KiB, free 363.8 MiB)
25/04/01 11:38:32 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.8 MiB)
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:46773 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:38:32 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1478
25/04/01 11:38:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:38:32 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/04/01 11:38:32 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 7) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:38:32 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.2:39839 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:38:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.2:51116
25/04/01 11:38:32 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 7) in 33 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:38:32 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/04/01 11:38:32 INFO DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.036 s
25/04/01 11:38:32 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:38:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/04/01 11:38:32 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.039768 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 73, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'unitprice': string to decimal(15,5)
25/04/01 11:38:32 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:38:32 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:38:32 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:38:32 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:38:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:38:32 INFO MemoryStore: MemoryStore cleared
25/04/01 11:38:32 INFO BlockManager: BlockManager stopped
25/04/01 11:38:32 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:38:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:38:32 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:38:32 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:38:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-95b39ecb-0b4f-46e1-9dea-8fec7c6315de
25/04/01 11:38:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-5771877f-1613-445f-b943-73a30415eab3
25/04/01 11:38:32 INFO ShutdownHookManager: Deleting directory /tmp/spark-95b39ecb-0b4f-46e1-9dea-8fec7c6315de/pyspark-fd197af3-0b9e-4a66-a8db-827e1ad2c632
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:42:06 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:42:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:42:06 INFO ResourceUtils: ==============================================================
25/04/01 11:42:06 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:42:06 INFO ResourceUtils: ==============================================================
25/04/01 11:42:06 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:42:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:42:06 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:42:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:42:06 INFO SecurityManager: Changing view acls to: root
25/04/01 11:42:06 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:42:06 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:42:06 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:42:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:42:06 INFO Utils: Successfully started service 'sparkDriver' on port 34583.
25/04/01 11:42:06 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:42:06 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:42:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:42:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:42:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:42:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9016fa85-42bf-40b8-9b56-2355cbb2016b
25/04/01 11:42:06 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:42:06 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:42:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:42:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:42:07 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:42:07 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:42:07 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401114207-0025
25/04/01 11:42:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114207-0025/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:42:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114207-0025/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:42:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114207-0025/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:42:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114207-0025/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:42:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114207-0025/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:42:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114207-0025/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:42:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37161.
25/04/01 11:42:07 INFO NettyBlockTransferService: Server created on 7796893c36d7:37161
25/04/01 11:42:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:42:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 37161, None)
25/04/01 11:42:07 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:37161 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 37161, None)
25/04/01 11:42:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 37161, None)
25/04/01 11:42:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 37161, None)
25/04/01 11:42:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114207-0025/2 is now RUNNING
25/04/01 11:42:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114207-0025/1 is now RUNNING
25/04/01 11:42:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114207-0025/0 is now RUNNING
25/04/01 11:42:07 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:42:07 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:42:07 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:42:08 INFO InMemoryFileIndex: It took 58 ms to list leaf files for 1 paths.
25/04/01 11:42:09 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:42:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:35696) with ID 2,  ResourceProfileId 0
25/04/01 11:42:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:59512) with ID 1,  ResourceProfileId 0
25/04/01 11:42:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:49838) with ID 0,  ResourceProfileId 0
25/04/01 11:42:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:38915 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 38915, None)
25/04/01 11:42:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:45467 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 45467, None)
25/04/01 11:42:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:38791 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 38791, None)
25/04/01 11:42:10 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:42:10 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:42:10 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:42:10 INFO CodeGenerator: Code generated in 131.797932 ms
25/04/01 11:42:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:42:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:42:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:37161 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:42:10 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:42:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:42:11 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:42:11 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:42:11 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:42:11 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:42:11 INFO DAGScheduler: Missing parents: List()
25/04/01 11:42:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:42:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:42:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:42:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:37161 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:42:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:42:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:42:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:42:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:38791 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:42:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:38791 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:42:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1347 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:42:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:42:12 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.411 s
25/04/01 11:42:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:42:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:42:12 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.442390 s
25/04/01 11:42:12 INFO CodeGenerator: Code generated in 8.037619 ms
25/04/01 11:42:12 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:42:12 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:42:12 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:42:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:42:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:42:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:37161 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:42:12 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:42:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:42:12 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:42:12 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:42:12 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:42:12 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:42:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:42:13 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:42:13 INFO metastore: Connected to metastore.
25/04/01 11:42:13 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=2228a26f-afce-4557-809a-07ad72f4510f, clientType=HIVECLI]
25/04/01 11:42:13 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:42:13 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:42:13 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:42:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:42:13 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:42:13 INFO metastore: Connected to metastore.
25/04/01 11:42:13 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:42:13 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:42:13 INFO metastore: Connected to metastore.
25/04/01 11:42:13 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:42:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:42:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:42:13 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:42:13 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:42:13 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:42:13 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:42:13 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:42:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:42:13 INFO CodeGenerator: Code generated in 35.273247 ms
25/04/01 11:42:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:42:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 11:42:13 INFO CodeGenerator: Code generated in 47.020589 ms
25/04/01 11:42:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:37161 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:42:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:37161 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:42:13 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:42:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 11:42:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:38791 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:42:13 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:42:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:42:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:42:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:37161 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:42:13 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:42:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:42:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:42:13 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000238 s
25/04/01 11:42:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 24.0 B, free 364.8 MiB)
25/04/01 11:42:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.8 MiB)
25/04/01 11:42:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:37161 (size: 120.0 B, free: 366.2 MiB)
25/04/01 11:42:13 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:42:13 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:42:13 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:42:13 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:42:13 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:42:13 INFO DAGScheduler: Missing parents: List()
25/04/01 11:42:13 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:42:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 29.9 KiB, free 364.8 MiB)
25/04/01 11:42:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.8 MiB)
25/04/01 11:42:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:37161 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:42:13 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:42:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:42:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:42:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:42:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:38791 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:38791 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:42:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 316 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:42:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:42:14 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.330 s
25/04/01 11:42:14 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:42:14 INFO DAGScheduler: running: Set()
25/04/01 11:42:14 INFO DAGScheduler: waiting: Set()
25/04/01 11:42:14 INFO DAGScheduler: failed: Set()
25/04/01 11:42:14 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:42:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:42:14 INFO CodeGenerator: Code generated in 13.110657 ms
25/04/01 11:42:14 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:42:14 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:42:14 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:42:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:42:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:42:14 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:37161 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 11:42:14 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:42:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:42:14 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:42:14 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:38791 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:42:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:49838
25/04/01 11:42:14 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 138 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:42:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:42:14 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.147 s
25/04/01 11:42:14 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:42:14 INFO DAGScheduler: running: Set()
25/04/01 11:42:14 INFO DAGScheduler: waiting: Set()
25/04/01 11:42:14 INFO DAGScheduler: failed: Set()
25/04/01 11:42:14 INFO CodeGenerator: Code generated in 6.507592 ms
25/04/01 11:42:14 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:42:14 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:42:14 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:42:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:42:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:42:14 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:37161 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:42:14 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:42:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:42:14 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:42:14 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:38791 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:42:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:49838
25/04/01 11:42:14 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 28 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:42:14 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:42:14 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/01 11:42:14 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:42:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 11:42:14 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.036086 s
25/04/01 11:42:14 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:42:14 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:42:14 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:42:14 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:42:14 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:42:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:42:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:42:14 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:42:14 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:42:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:42:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:42:14 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:42:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:42:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:42:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 364.4 MiB)
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.3 MiB)
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:37161 (size: 33.4 KiB, free: 366.1 MiB)
25/04/01 11:42:14 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:42:14 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:42:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:42:14 INFO CodeGenerator: Code generated in 12.623998 ms
25/04/01 11:42:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:42:14 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000152 s
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 364.0 MiB)
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 24.0 B, free 364.0 MiB)
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.0 MiB)
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:37161 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:42:14 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:37161 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:42:14 INFO SparkContext: Created broadcast 10 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:42:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:42:14 INFO DAGScheduler: Registering RDD 32 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:42:14 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:42:14 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:42:14 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:42:14 INFO DAGScheduler: Missing parents: List()
25/04/01 11:42:14 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[32] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 30.9 KiB, free 363.9 MiB)
25/04/01 11:42:14 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 363.9 MiB)
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:37161 (size: 14.3 KiB, free: 366.1 MiB)
25/04/01 11:42:14 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:42:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[32] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:42:14 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:42:14 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:42:14 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:38915 (size: 14.3 KiB, free: 366.3 MiB)
25/04/01 11:42:15 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:38915 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:42:16 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1609 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:42:16 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:42:16 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.619 s
25/04/01 11:42:16 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:42:16 INFO DAGScheduler: running: Set()
25/04/01 11:42:16 INFO DAGScheduler: waiting: Set()
25/04/01 11:42:16 INFO DAGScheduler: failed: Set()
25/04/01 11:42:16 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:42:16 INFO CodeGenerator: Code generated in 7.622688 ms
25/04/01 11:42:16 INFO CodeGenerator: Code generated in 8.45234 ms
25/04/01 11:42:16 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:42:16 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:42:16 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:42:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 11:42:16 INFO DAGScheduler: Missing parents: List()
25/04/01 11:42:16 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:42:16 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 241.9 KiB, free 363.7 MiB)
25/04/01 11:42:16 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 89.3 KiB, free 363.6 MiB)
25/04/01 11:42:16 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:37161 (size: 89.3 KiB, free: 366.0 MiB)
25/04/01 11:42:16 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 11:42:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:42:16 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 11:42:16 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:42:16 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:38915 (size: 89.3 KiB, free: 366.2 MiB)
25/04/01 11:42:16 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:35696
25/04/01 11:42:17 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 1141 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:42:17 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:42:17 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.168 s
25/04/01 11:42:17 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:42:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 11:42:17 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 1.173885 s
25/04/01 11:42:17 INFO FileFormatWriter: Start to commit write Job 993b2d76-bdc7-4dfc-a4c3-a4b91a7337dd.
25/04/01 11:42:17 INFO FileFormatWriter: Write Job 993b2d76-bdc7-4dfc-a4c3-a4b91a7337dd committed. Elapsed time: 58 ms.
25/04/01 11:42:17 INFO FileFormatWriter: Finished processing stats for write job 993b2d76-bdc7-4dfc-a4c3-a4b91a7337dd.
25/04/01 11:42:17 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:42:17 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:42:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:42:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:42:17 INFO MemoryStore: MemoryStore cleared
25/04/01 11:42:17 INFO BlockManager: BlockManager stopped
25/04/01 11:42:17 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:42:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:42:17 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:42:18 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:42:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-545a0acc-f287-4bd7-a3d5-b386d1002c84
25/04/01 11:42:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-7531166c-cb0e-4e64-993e-379329c6c73c/pyspark-8d1e0407-dc61-4919-bfeb-831ee21bfbde
25/04/01 11:42:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-7531166c-cb0e-4e64-993e-379329c6c73c
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:43:32 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:43:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:43:32 INFO ResourceUtils: ==============================================================
25/04/01 11:43:32 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:43:32 INFO ResourceUtils: ==============================================================
25/04/01 11:43:32 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:43:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:43:32 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:43:32 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:43:32 INFO SecurityManager: Changing view acls to: root
25/04/01 11:43:32 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:43:32 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:43:32 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:43:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:43:32 INFO Utils: Successfully started service 'sparkDriver' on port 43799.
25/04/01 11:43:32 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:43:32 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:43:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:43:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:43:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:43:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7e61b76f-1a71-4ce8-ad69-df095e2d1131
25/04/01 11:43:32 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:43:32 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:43:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:43:32 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:43:32 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:43:32 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 11:43:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401114332-0026
25/04/01 11:43:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114332-0026/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:43:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114332-0026/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:43:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114332-0026/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:43:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114332-0026/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:43:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114332-0026/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:43:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114332-0026/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:43:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45773.
25/04/01 11:43:32 INFO NettyBlockTransferService: Server created on 7796893c36d7:45773
25/04/01 11:43:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:43:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 45773, None)
25/04/01 11:43:32 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:45773 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 45773, None)
25/04/01 11:43:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114332-0026/0 is now RUNNING
25/04/01 11:43:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114332-0026/2 is now RUNNING
25/04/01 11:43:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 45773, None)
25/04/01 11:43:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 45773, None)
25/04/01 11:43:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114332-0026/1 is now RUNNING
25/04/01 11:43:33 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:43:33 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:43:33 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:43:34 INFO InMemoryFileIndex: It took 63 ms to list leaf files for 1 paths.
25/04/01 11:43:34 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:43:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:42694) with ID 2,  ResourceProfileId 0
25/04/01 11:43:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:34896) with ID 0,  ResourceProfileId 0
25/04/01 11:43:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:52346) with ID 1,  ResourceProfileId 0
25/04/01 11:43:34 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:35481 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 35481, None)
25/04/01 11:43:34 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:41757 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 41757, None)
25/04/01 11:43:34 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:46627 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 46627, None)
25/04/01 11:43:36 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:43:36 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:43:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:43:36 INFO CodeGenerator: Code generated in 135.567426 ms
25/04/01 11:43:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.5 KiB, free 366.0 MiB)
25/04/01 11:43:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.9 MiB)
25/04/01 11:43:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:45773 (size: 32.5 KiB, free: 366.3 MiB)
25/04/01 11:43:36 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:43:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:43:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:43:36 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:43:36 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:43:36 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:43:36 INFO DAGScheduler: Missing parents: List()
25/04/01 11:43:36 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:43:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:43:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:43:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:45773 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:43:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:43:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:43:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:43:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:43:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:35481 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:43:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:35481 (size: 32.5 KiB, free: 366.3 MiB)
25/04/01 11:43:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1355 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:43:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:43:38 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.420 s
25/04/01 11:43:38 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:43:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:43:38 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.450157 s
25/04/01 11:43:38 INFO CodeGenerator: Code generated in 8.027564 ms
25/04/01 11:43:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:43:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:43:38 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:43:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.5 KiB, free 365.6 MiB)
25/04/01 11:43:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.5 MiB)
25/04/01 11:43:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:45773 (size: 32.5 KiB, free: 366.2 MiB)
25/04/01 11:43:38 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:43:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:43:38 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:43:38 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:43:38 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:43:38 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:43:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:43:38 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:43:38 INFO metastore: Connected to metastore.
25/04/01 11:43:38 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=ed2ee38a-394e-4267-ae4c-73d8edc919d5, clientType=HIVECLI]
25/04/01 11:43:38 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:43:38 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:43:38 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:43:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:43:38 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:43:38 INFO metastore: Connected to metastore.
25/04/01 11:43:38 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:43:38 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:43:38 INFO metastore: Connected to metastore.
25/04/01 11:43:39 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:43:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:43:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:43:39 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:43:39 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:43:39 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:43:39 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:43:39 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:43:39 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:43:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:45773 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:43:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:35481 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:43:39 INFO CodeGenerator: Code generated in 23.45698 ms
25/04/01 11:43:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:43:39 INFO CodeGenerator: Code generated in 28.91869 ms
25/04/01 11:43:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 11:43:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:45773 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:43:39 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:43:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.4 KiB, free 364.9 MiB)
25/04/01 11:43:39 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:43:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:43:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:43:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:45773 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:43:39 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:43:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:43:39 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:43:39 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000252 s
25/04/01 11:43:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 24.0 B, free 364.8 MiB)
25/04/01 11:43:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.8 MiB)
25/04/01 11:43:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:45773 (size: 120.0 B, free: 366.2 MiB)
25/04/01 11:43:39 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:43:39 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:43:39 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:43:39 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:43:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:43:39 INFO DAGScheduler: Missing parents: List()
25/04/01 11:43:39 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:43:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 29.9 KiB, free 364.8 MiB)
25/04/01 11:43:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.8 MiB)
25/04/01 11:43:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:45773 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:43:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:43:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:43:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:43:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:43:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:46627 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:43:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:46627 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:43:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1531 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:43:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:43:40 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.546 s
25/04/01 11:43:40 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:43:40 INFO DAGScheduler: running: Set()
25/04/01 11:43:40 INFO DAGScheduler: waiting: Set()
25/04/01 11:43:40 INFO DAGScheduler: failed: Set()
25/04/01 11:43:40 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:43:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:43:41 INFO CodeGenerator: Code generated in 15.19768 ms
25/04/01 11:43:41 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:43:41 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:43:41 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:43:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:43:41 INFO DAGScheduler: Missing parents: List()
25/04/01 11:43:41 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:45773 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 11:43:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:43:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:43:41 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:43:41 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:46627 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:43:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:42694
25/04/01 11:43:41 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 147 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:43:41 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:43:41 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.157 s
25/04/01 11:43:41 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:43:41 INFO DAGScheduler: running: Set()
25/04/01 11:43:41 INFO DAGScheduler: waiting: Set()
25/04/01 11:43:41 INFO DAGScheduler: failed: Set()
25/04/01 11:43:41 INFO CodeGenerator: Code generated in 6.022053 ms
25/04/01 11:43:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:43:41 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:43:41 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:43:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:43:41 INFO DAGScheduler: Missing parents: List()
25/04/01 11:43:41 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:45773 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:43:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:43:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:43:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:43:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:46627 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:43:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:42694
25/04/01 11:43:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 86 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:43:41 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:43:41 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.091 s
25/04/01 11:43:41 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:43:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 11:43:41 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.093920 s
25/04/01 11:43:41 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:43:41 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:43:41 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:43:41 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:43:41 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:43:41 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:43:41 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:43:41 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:43:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:43:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:43:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:43:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:43:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:43:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:43:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 364.4 MiB)
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.3 MiB)
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:45773 (size: 33.4 KiB, free: 366.1 MiB)
25/04/01 11:43:41 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:43:41 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:43:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:43:41 INFO CodeGenerator: Code generated in 13.904486 ms
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.4 KiB, free 364.0 MiB)
25/04/01 11:43:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:43:41 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000178 s
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 24.0 B, free 364.0 MiB)
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.0 MiB)
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:45773 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:45773 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:43:41 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:43:41 INFO SparkContext: Created broadcast 10 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:43:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:43:41 INFO DAGScheduler: Registering RDD 32 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:43:41 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:43:41 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:43:41 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:43:41 INFO DAGScheduler: Missing parents: List()
25/04/01 11:43:41 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[32] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 30.9 KiB, free 363.9 MiB)
25/04/01 11:43:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 363.9 MiB)
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:45773 (size: 14.2 KiB, free: 366.1 MiB)
25/04/01 11:43:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:43:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[32] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:43:41 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:43:41 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:35481 (size: 14.2 KiB, free: 366.3 MiB)
25/04/01 11:43:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:35481 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:43:42 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 422 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:43:42 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:43:42 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.435 s
25/04/01 11:43:42 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:43:42 INFO DAGScheduler: running: Set()
25/04/01 11:43:42 INFO DAGScheduler: waiting: Set()
25/04/01 11:43:42 INFO DAGScheduler: failed: Set()
25/04/01 11:43:42 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:43:42 INFO CodeGenerator: Code generated in 7.162083 ms
25/04/01 11:43:42 INFO CodeGenerator: Code generated in 8.134214 ms
25/04/01 11:43:42 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:43:42 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:43:42 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:43:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 11:43:42 INFO DAGScheduler: Missing parents: List()
25/04/01 11:43:42 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:43:42 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 241.9 KiB, free 363.7 MiB)
25/04/01 11:43:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 89.3 KiB, free 363.6 MiB)
25/04/01 11:43:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:45773 (size: 89.3 KiB, free: 366.0 MiB)
25/04/01 11:43:42 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 11:43:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:43:42 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 11:43:42 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:43:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.8:35481 (size: 89.3 KiB, free: 366.1 MiB)
25/04/01 11:43:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:52346
25/04/01 11:43:43 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 1111 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:43:43 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:43:43 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.139 s
25/04/01 11:43:43 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:43:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 11:43:43 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 1.145674 s
25/04/01 11:43:43 INFO FileFormatWriter: Start to commit write Job 3ef21da1-db70-4495-802c-5bf0d64841de.
25/04/01 11:43:43 INFO FileFormatWriter: Write Job 3ef21da1-db70-4495-802c-5bf0d64841de committed. Elapsed time: 58 ms.
25/04/01 11:43:43 INFO FileFormatWriter: Finished processing stats for write job 3ef21da1-db70-4495-802c-5bf0d64841de.
25/04/01 11:43:43 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:43:43 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:43:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:43:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:43:43 INFO MemoryStore: MemoryStore cleared
25/04/01 11:43:43 INFO BlockManager: BlockManager stopped
25/04/01 11:43:43 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:43:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:43:43 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:43:43 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:43:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-797715d3-02cb-4366-82e9-6f1be4e6af0f
25/04/01 11:43:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-3a8e6a7e-5f65-4a43-b557-eec4db6fcef3
25/04/01 11:43:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-797715d3-02cb-4366-82e9-6f1be4e6af0f/pyspark-861fbd2b-a79e-44f2-89e2-5b3b18898bff
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:44:40 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:44:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:44:40 INFO ResourceUtils: ==============================================================
25/04/01 11:44:40 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:44:40 INFO ResourceUtils: ==============================================================
25/04/01 11:44:40 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:44:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:44:40 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:44:40 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:44:40 INFO SecurityManager: Changing view acls to: root
25/04/01 11:44:40 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:44:40 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:44:40 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:44:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:44:40 INFO Utils: Successfully started service 'sparkDriver' on port 41743.
25/04/01 11:44:41 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:44:41 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:44:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:44:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:44:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:44:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7e48435d-34fb-4915-8dc6-a17295808017
25/04/01 11:44:41 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:44:41 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:44:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:44:41 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:44:41 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:44:41 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:44:41 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401114441-0027
25/04/01 11:44:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114441-0027/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:44:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114441-0027/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:44:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114441-0027/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:44:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114441-0027/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:44:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114441-0027/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:44:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114441-0027/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:44:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39459.
25/04/01 11:44:41 INFO NettyBlockTransferService: Server created on 7796893c36d7:39459
25/04/01 11:44:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:44:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 39459, None)
25/04/01 11:44:41 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:39459 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 39459, None)
25/04/01 11:44:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114441-0027/2 is now RUNNING
25/04/01 11:44:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114441-0027/1 is now RUNNING
25/04/01 11:44:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 39459, None)
25/04/01 11:44:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 39459, None)
25/04/01 11:44:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114441-0027/0 is now RUNNING
25/04/01 11:44:41 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:44:41 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:44:42 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:44:43 INFO InMemoryFileIndex: It took 58 ms to list leaf files for 1 paths.
25/04/01 11:44:43 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:44:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:60594) with ID 1,  ResourceProfileId 0
25/04/01 11:44:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:57618) with ID 2,  ResourceProfileId 0
25/04/01 11:44:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:43968) with ID 0,  ResourceProfileId 0
25/04/01 11:44:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:46179 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 46179, None)
25/04/01 11:44:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:43119 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 43119, None)
25/04/01 11:44:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:39639 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 39639, None)
25/04/01 11:44:44 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:44:44 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:44:44 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:44:45 INFO CodeGenerator: Code generated in 133.904451 ms
25/04/01 11:44:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.5 KiB, free 366.0 MiB)
25/04/01 11:44:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.9 MiB)
25/04/01 11:44:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:39459 (size: 32.5 KiB, free: 366.3 MiB)
25/04/01 11:44:45 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:44:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:44:45 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:44:45 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:44:45 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:44:45 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:44:45 INFO DAGScheduler: Missing parents: List()
25/04/01 11:44:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:44:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:44:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:44:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:39459 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:44:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:44:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:44:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:44:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:44:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:39639 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:44:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:39639 (size: 32.5 KiB, free: 366.3 MiB)
25/04/01 11:44:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1391 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:44:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:44:46 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.456 s
25/04/01 11:44:46 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:44:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:44:46 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.487652 s
25/04/01 11:44:46 INFO CodeGenerator: Code generated in 8.407436 ms
25/04/01 11:44:46 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:44:46 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:44:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:44:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.5 KiB, free 365.6 MiB)
25/04/01 11:44:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 365.5 MiB)
25/04/01 11:44:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:39459 (size: 32.5 KiB, free: 366.2 MiB)
25/04/01 11:44:46 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:44:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:44:47 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:44:47 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:44:47 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:44:47 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:44:47 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:44:47 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:44:47 INFO metastore: Connected to metastore.
25/04/01 11:44:47 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=542fabf5-0f37-49a5-9cff-f9e2bdedd080, clientType=HIVECLI]
25/04/01 11:44:47 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:44:47 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:44:47 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:44:47 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:44:47 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:44:47 INFO metastore: Connected to metastore.
25/04/01 11:44:47 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:44:47 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:44:47 INFO metastore: Connected to metastore.
25/04/01 11:44:47 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:44:47 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:44:47 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:44:47 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:44:47 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:44:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:44:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:44:47 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:44:48 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:39459 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:44:48 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:39639 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:44:48 INFO CodeGenerator: Code generated in 21.89022 ms
25/04/01 11:44:48 INFO CodeGenerator: Code generated in 23.699616 ms
25/04/01 11:44:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 364.9 MiB)
25/04/01 11:44:48 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.4 KiB, free 364.9 MiB)
25/04/01 11:44:48 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.9 MiB)
25/04/01 11:44:48 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:39459 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:44:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.8 MiB)
25/04/01 11:44:48 INFO SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0
25/04/01 11:44:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:39459 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:44:48 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:44:48 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:44:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:44:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:48 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000230 s
25/04/01 11:44:48 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 24.0 B, free 364.8 MiB)
25/04/01 11:44:48 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.8 MiB)
25/04/01 11:44:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:39459 (size: 120.0 B, free: 366.2 MiB)
25/04/01 11:44:48 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:48 INFO DAGScheduler: Registering RDD 18 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:44:48 INFO DAGScheduler: Got map stage job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:44:48 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:44:48 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:44:48 INFO DAGScheduler: Missing parents: List()
25/04/01 11:44:48 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:44:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 30.9 KiB, free 364.8 MiB)
25/04/01 11:44:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 364.8 MiB)
25/04/01 11:44:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:39459 (size: 14.2 KiB, free: 366.2 MiB)
25/04/01 11:44:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:44:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[18] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:44:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:44:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:44:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:43119 (size: 14.2 KiB, free: 366.3 MiB)
25/04/01 11:44:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:43119 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:44:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1670 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:44:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:44:49 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.689 s
25/04/01 11:44:49 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:44:49 INFO DAGScheduler: running: Set()
25/04/01 11:44:49 INFO DAGScheduler: waiting: Set()
25/04/01 11:44:49 INFO DAGScheduler: failed: Set()
25/04/01 11:44:49 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:44:49 INFO CodeGenerator: Code generated in 8.416168 ms
25/04/01 11:44:49 INFO CodeGenerator: Code generated in 8.963728 ms
25/04/01 11:44:49 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 11:44:49 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:44:49 INFO DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 11:44:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:44:49 INFO DAGScheduler: Missing parents: List()
25/04/01 11:44:49 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:44:49 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 38.8 KiB, free 364.7 MiB)
25/04/01 11:44:49 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 17.5 KiB, free 364.7 MiB)
25/04/01 11:44:49 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:39459 (size: 17.5 KiB, free: 366.1 MiB)
25/04/01 11:44:49 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:44:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[23] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:44:49 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:44:49 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:44:49 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:43119 (size: 17.5 KiB, free: 366.2 MiB)
25/04/01 11:44:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:57618
25/04/01 11:44:50 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 278 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:44:50 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:44:50 INFO DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.288 s
25/04/01 11:44:50 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:44:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:44:50 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.299170 s
25/04/01 11:44:50 INFO CodeGenerator: Code generated in 9.879776 ms
+---------+----------+--------------------+--------------------+---------+
|stockcode|      date|         productname|  productdescription|unitprice|
+---------+----------+--------------------+--------------------+---------+
|     1005|2025-03-27|The Urbz: Sims in...|          Simulation|    12.95|
|     1025|2025-03-27|Brain Agey: More ...|              Action|    17.95|
|     1026|2025-03-27|Grand Theft Auto:...|Action,Racing / D...|    17.95|
|     1039|2025-03-27|Mario & Luigi: Pa...|Action,Role-Playi...|    29.95|
|     1040|2025-03-27|       Madden NFL 06|              Sports|     7.95|
|     1056|2025-03-27|     Dead or Alive 4|              Action|    17.95|
|     1062|2025-03-27|    Yoshi Touch & Go|              Action|    17.95|
|     1077|2025-03-27|          Madagascar|           Adventure|    14.95|
|     1088|2025-03-27|Harry Potter and ...|              Action|    17.95|
|     1108|2025-03-27| Kingdom of Paradise|Action,Role-Playi...|    12.95|
|     1125|2025-03-27|The Lord of the R...|Role-Playing (RPG...|    19.95|
|    11333|2025-03-27|    Valhalla Knights|Action,Role-Playi...|    16.95|
|     1166|2025-03-27|       Madden NFL 07|              Sports|     4.95|
|     1175|2025-03-27|Rayman Raving Rab...|              Action|    17.95|
|     1179|2025-03-27|      Call of Duty 3|              Action|    19.95|
|     1200|2025-03-27|Mortal Kombat: Un...|              Action|    17.95|
|     1224|2025-03-27|        Excite Truck|    Racing / Driving|    19.95|
|     1227|2025-03-27|Metal Gear Solid:...|     Action,Strategy|    17.95|
|     1229|2025-03-27|Blazing Angels: S...|              Action|    16.95|
|     1234|2025-03-27|WWE SmackDown vs....|              Sports|    14.95|
+---------+----------+--------------------+--------------------+---------+
only showing top 20 rows

25/04/01 11:44:50 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:44:50 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:44:50 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:44:50 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:44:50 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:44:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:44:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:44:50 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:44:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 349.8 KiB, free 364.4 MiB)
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.3 MiB)
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:39459 (size: 33.4 KiB, free: 366.1 MiB)
25/04/01 11:44:50 INFO SparkContext: Created broadcast 8 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:50 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:44:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:44:50 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:50 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000197 s
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 24.0 B, free 364.3 MiB)
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.3 MiB)
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:39459 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:44:50 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:50 INFO CodeGenerator: Code generated in 22.144306 ms
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.4 KiB, free 364.0 MiB)
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:39459 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:44:50 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:44:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:44:50 INFO DAGScheduler: Registering RDD 31 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:44:50 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:44:50 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:44:50 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:44:50 INFO DAGScheduler: Missing parents: List()
25/04/01 11:44:50 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 29.9 KiB, free 363.9 MiB)
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 363.9 MiB)
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:39459 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 11:44:50 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 11:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[31] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:44:50 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 11:44:50 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.2:39639 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.2:39639 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:44:50 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 327 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:44:50 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 11:44:50 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.333 s
25/04/01 11:44:50 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:44:50 INFO DAGScheduler: running: Set()
25/04/01 11:44:50 INFO DAGScheduler: waiting: Set()
25/04/01 11:44:50 INFO DAGScheduler: failed: Set()
25/04/01 11:44:50 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:44:50 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:44:50 INFO CodeGenerator: Code generated in 11.957644 ms
25/04/01 11:44:50 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:44:50 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:44:50 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:44:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:44:50 INFO DAGScheduler: Missing parents: List()
25/04/01 11:44:50 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 37.9 KiB, free 363.9 MiB)
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 363.9 MiB)
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:39459 (size: 17.9 KiB, free: 366.0 MiB)
25/04/01 11:44:50 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:44:50 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:44:50 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:39639 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:44:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:43968
25/04/01 11:44:50 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 110 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:44:50 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:44:50 INFO DAGScheduler: ShuffleMapStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.117 s
25/04/01 11:44:50 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:44:50 INFO DAGScheduler: running: Set()
25/04/01 11:44:50 INFO DAGScheduler: waiting: Set()
25/04/01 11:44:50 INFO DAGScheduler: failed: Set()
25/04/01 11:44:50 INFO CodeGenerator: Code generated in 6.607539 ms
25/04/01 11:44:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:44:50 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:44:50 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:44:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 11:44:50 INFO DAGScheduler: Missing parents: List()
25/04/01 11:44:50 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.0 KiB, free 363.9 MiB)
25/04/01 11:44:50 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 363.9 MiB)
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:39459 (size: 5.5 KiB, free: 366.0 MiB)
25/04/01 11:44:50 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 11:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:44:50 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 11:44:50 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:44:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:39639 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:44:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:43968
25/04/01 11:44:50 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 29 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:44:50 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:44:50 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/01 11:44:50 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:44:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 11:44:50 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0.036071 s
25/04/01 11:44:50 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:44:50 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:44:50 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:44:50 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:44:50 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:44:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:44:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:44:50 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:44:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:44:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:44:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:44:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:44:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:44:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:44:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:44:51 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 345.4 KiB, free 363.2 MiB)
25/04/01 11:44:51 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 349.8 KiB, free 363.2 MiB)
25/04/01 11:44:51 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.2 MiB)
25/04/01 11:44:51 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 7796893c36d7:39459 (size: 32.6 KiB, free: 366.0 MiB)
25/04/01 11:44:51 INFO SparkContext: Created broadcast 15 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:44:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:44:51 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 363.1 MiB)
25/04/01 11:44:51 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:39459 (size: 33.4 KiB, free: 366.0 MiB)
25/04/01 11:44:51 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:51 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:44:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:44:51 INFO DAGScheduler: Registering RDD 44 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 11:44:51 INFO DAGScheduler: Got map stage job 8 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:44:51 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:44:51 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:44:51 INFO DAGScheduler: Missing parents: List()
25/04/01 11:44:51 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[44] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:44:51 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 30.9 KiB, free 363.1 MiB)
25/04/01 11:44:51 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 363.1 MiB)
25/04/01 11:44:51 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 7796893c36d7:39459 (size: 14.2 KiB, free: 366.0 MiB)
25/04/01 11:44:51 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1478
25/04/01 11:44:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[44] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:44:51 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 11:44:51 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:51 INFO DAGScheduler: Job 9 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000178 s
25/04/01 11:44:51 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 6) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:44:51 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 24.0 B, free 363.1 MiB)
25/04/01 11:44:51 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 120.0 B, free 363.1 MiB)
25/04/01 11:44:51 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 7796893c36d7:39459 (size: 120.0 B, free: 366.0 MiB)
25/04/01 11:44:51 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:44:51 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.8:46179 (size: 14.2 KiB, free: 366.3 MiB)
25/04/01 11:44:52 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.8:46179 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:44:52 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 6) in 1701 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:44:52 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 11:44:52 INFO DAGScheduler: ShuffleMapStage 10 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.710 s
25/04/01 11:44:52 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:44:52 INFO DAGScheduler: running: Set()
25/04/01 11:44:52 INFO DAGScheduler: waiting: Set()
25/04/01 11:44:52 INFO DAGScheduler: failed: Set()
25/04/01 11:44:52 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:44:52 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:44:52 INFO DAGScheduler: Got job 10 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:44:52 INFO DAGScheduler: Final stage: ResultStage 12 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:44:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
25/04/01 11:44:52 INFO DAGScheduler: Missing parents: List()
25/04/01 11:44:52 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[52] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:44:52 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 241.9 KiB, free 362.8 MiB)
25/04/01 11:44:52 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 89.3 KiB, free 362.8 MiB)
25/04/01 11:44:52 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 7796893c36d7:39459 (size: 89.3 KiB, free: 365.9 MiB)
25/04/01 11:44:52 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1478
25/04/01 11:44:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[52] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:44:52 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/04/01 11:44:52 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 7) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:44:52 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.8:46179 (size: 89.3 KiB, free: 366.2 MiB)
25/04/01 11:44:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:60594
25/04/01 11:44:54 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 7) in 1187 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:44:54 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/04/01 11:44:54 INFO DAGScheduler: ResultStage 12 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.216 s
25/04/01 11:44:54 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:44:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
25/04/01 11:44:54 INFO DAGScheduler: Job 10 finished: insertInto at NativeMethodAccessorImpl.java:0, took 1.221387 s
25/04/01 11:44:54 INFO FileFormatWriter: Start to commit write Job eea1a27b-91c4-4c0a-a53b-90c01d711d6d.
25/04/01 11:44:54 INFO FileFormatWriter: Write Job eea1a27b-91c4-4c0a-a53b-90c01d711d6d committed. Elapsed time: 62 ms.
25/04/01 11:44:54 INFO FileFormatWriter: Finished processing stats for write job eea1a27b-91c4-4c0a-a53b-90c01d711d6d.
25/04/01 11:44:54 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:44:54 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:44:54 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:44:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:44:54 INFO MemoryStore: MemoryStore cleared
25/04/01 11:44:54 INFO BlockManager: BlockManager stopped
25/04/01 11:44:54 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:44:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:44:54 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:44:54 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:44:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-c4e45226-00c0-4cce-9924-344022c664f3/pyspark-7efb6308-c7f7-4d0e-a41c-3aeaffc63d41
25/04/01 11:44:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-c4e45226-00c0-4cce-9924-344022c664f3
25/04/01 11:44:54 INFO ShutdownHookManager: Deleting directory /tmp/spark-87df8d73-0f2b-4230-8e5b-e7082b20773e
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:48:55 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:48:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:48:55 INFO ResourceUtils: ==============================================================
25/04/01 11:48:55 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:48:55 INFO ResourceUtils: ==============================================================
25/04/01 11:48:55 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:48:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:48:55 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:48:55 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:48:55 INFO SecurityManager: Changing view acls to: root
25/04/01 11:48:55 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:48:55 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:48:55 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:48:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:48:55 INFO Utils: Successfully started service 'sparkDriver' on port 43507.
25/04/01 11:48:55 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:48:55 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:48:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:48:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:48:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:48:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fe028063-71a2-4743-99fd-cef3a200ea2b
25/04/01 11:48:55 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:48:55 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:48:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:48:55 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:48:55 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:48:55 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:48:55 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401114855-0028
25/04/01 11:48:55 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114855-0028/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:48:55 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114855-0028/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:48:55 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114855-0028/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:48:55 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114855-0028/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:48:55 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401114855-0028/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:48:55 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401114855-0028/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:48:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33803.
25/04/01 11:48:55 INFO NettyBlockTransferService: Server created on 7796893c36d7:33803
25/04/01 11:48:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:48:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 33803, None)
25/04/01 11:48:56 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:33803 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 33803, None)
25/04/01 11:48:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114855-0028/0 is now RUNNING
25/04/01 11:48:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114855-0028/2 is now RUNNING
25/04/01 11:48:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 33803, None)
25/04/01 11:48:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 33803, None)
25/04/01 11:48:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401114855-0028/1 is now RUNNING
25/04/01 11:48:56 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:48:56 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:48:56 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:48:57 INFO InMemoryFileIndex: It took 63 ms to list leaf files for 1 paths.
25/04/01 11:48:57 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:48:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:57640) with ID 1,  ResourceProfileId 0
25/04/01 11:48:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:45496) with ID 0,  ResourceProfileId 0
25/04/01 11:48:57 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:34704) with ID 2,  ResourceProfileId 0
25/04/01 11:48:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:36801 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 36801, None)
25/04/01 11:48:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:37529 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 37529, None)
25/04/01 11:48:57 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:44119 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 44119, None)
25/04/01 11:48:59 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:48:59 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:48:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:48:59 INFO CodeGenerator: Code generated in 135.171381 ms
25/04/01 11:48:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:48:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:48:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:33803 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:48:59 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:48:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:48:59 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:48:59 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:48:59 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:48:59 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:48:59 INFO DAGScheduler: Missing parents: List()
25/04/01 11:48:59 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:48:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:48:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:48:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:33803 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:48:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:48:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:48:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:48:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:49:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:36801 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:49:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:36801 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:49:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1362 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:49:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:49:01 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.427 s
25/04/01 11:49:01 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:49:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:49:01 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.459147 s
25/04/01 11:49:01 INFO CodeGenerator: Code generated in 8.13394 ms
25/04/01 11:49:01 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:49:01 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:49:01 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:49:01 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:49:01 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:49:01 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:33803 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:49:01 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:49:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:49:01 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:49:01 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:49:01 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:49:01 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:49:01 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:49:01 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:49:01 INFO metastore: Connected to metastore.
25/04/01 11:49:01 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=c3318c03-d8d4-494a-a5ab-e22d211a6dc5, clientType=HIVECLI]
25/04/01 11:49:01 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:49:01 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:49:01 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:49:01 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:49:01 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:49:01 INFO metastore: Connected to metastore.
25/04/01 11:49:01 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:49:01 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:49:01 INFO metastore: Connected to metastore.
25/04/01 11:49:02 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:49:02 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:49:02 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:49:02 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:49:02 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:49:02 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:49:02 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:49:02 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:49:02 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:49:02 INFO CodeGenerator: Code generated in 35.90815 ms
25/04/01 11:49:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.8 KiB, free 365.2 MiB)
25/04/01 11:49:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:33803 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:49:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 11:49:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:33803 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 11:49:02 INFO SparkContext: Created broadcast 3 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:49:02 INFO CodeGenerator: Code generated in 37.595044 ms
25/04/01 11:49:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 11:49:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:36801 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:49:02 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:49:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:49:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:49:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:33803 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:49:02 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:49:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:49:02 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:49:02 INFO DAGScheduler: Job 1 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000192 s
25/04/01 11:49:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 24.0 B, free 364.8 MiB)
25/04/01 11:49:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.8 MiB)
25/04/01 11:49:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:33803 (size: 120.0 B, free: 366.2 MiB)
25/04/01 11:49:02 INFO SparkContext: Created broadcast 5 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:49:02 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:49:02 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:49:02 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:49:02 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:49:02 INFO DAGScheduler: Missing parents: List()
25/04/01 11:49:02 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:49:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 29.9 KiB, free 364.8 MiB)
25/04/01 11:49:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.8 MiB)
25/04/01 11:49:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:33803 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:49:02 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:49:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:49:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:49:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:49:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:37529 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:49:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:37529 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:49:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1520 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:49:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:49:04 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.534 s
25/04/01 11:49:04 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:49:04 INFO DAGScheduler: running: Set()
25/04/01 11:49:04 INFO DAGScheduler: waiting: Set()
25/04/01 11:49:04 INFO DAGScheduler: failed: Set()
25/04/01 11:49:04 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:49:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:49:04 INFO CodeGenerator: Code generated in 14.658719 ms
25/04/01 11:49:04 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:49:04 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:49:04 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:49:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:49:04 INFO DAGScheduler: Missing parents: List()
25/04/01 11:49:04 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:33803 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 11:49:04 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 11:49:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:49:04 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:49:04 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:37529 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:49:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:45496
25/04/01 11:49:04 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 146 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:49:04 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:49:04 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.156 s
25/04/01 11:49:04 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:49:04 INFO DAGScheduler: running: Set()
25/04/01 11:49:04 INFO DAGScheduler: waiting: Set()
25/04/01 11:49:04 INFO DAGScheduler: failed: Set()
25/04/01 11:49:04 INFO CodeGenerator: Code generated in 5.984064 ms
25/04/01 11:49:04 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:49:04 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:49:04 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:49:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:49:04 INFO DAGScheduler: Missing parents: List()
25/04/01 11:49:04 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:33803 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:49:04 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:49:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:49:04 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:49:04 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:37529 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:49:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:45496
25/04/01 11:49:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 83 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:49:04 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:49:04 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.088 s
25/04/01 11:49:04 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:49:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 11:49:04 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.090698 s
25/04/01 11:49:04 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:49:04 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:49:04 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:49:04 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:49:04 INFO DataSourceStrategy: Pruning directories with: isnotnull(date#40)
25/04/01 11:49:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(stockcode)
25/04/01 11:49:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(stockcode#36)
25/04/01 11:49:04 INFO FileSourceStrategy: Output Data Schema: struct<stockcode: string>
25/04/01 11:49:04 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:49:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:49:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:49:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:49:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:49:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:49:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 349.8 KiB, free 364.4 MiB)
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 364.3 MiB)
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:33803 (size: 33.4 KiB, free: 366.1 MiB)
25/04/01 11:49:04 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:49:04 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:49:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:49:04 INFO CodeGenerator: Code generated in 13.65516 ms
25/04/01 11:49:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:49:04 INFO DAGScheduler: Job 5 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.000147 s
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 364.0 MiB)
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 24.0 B, free 364.0 MiB)
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.0 MiB)
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:33803 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:49:04 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.0 MiB)
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:33803 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:49:04 INFO SparkContext: Created broadcast 10 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:49:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:49:04 INFO DAGScheduler: Registering RDD 32 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:49:04 INFO DAGScheduler: Got map stage job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:49:04 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:49:04 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:49:04 INFO DAGScheduler: Missing parents: List()
25/04/01 11:49:04 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[32] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 30.9 KiB, free 363.9 MiB)
25/04/01 11:49:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 363.9 MiB)
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:33803 (size: 14.2 KiB, free: 366.1 MiB)
25/04/01 11:49:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 11:49:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[32] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:49:04 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:49:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:49:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:44119 (size: 14.2 KiB, free: 366.3 MiB)
25/04/01 11:49:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:44119 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:49:06 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1650 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:49:06 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:49:06 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.663 s
25/04/01 11:49:06 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:49:06 INFO DAGScheduler: running: Set()
25/04/01 11:49:06 INFO DAGScheduler: waiting: Set()
25/04/01 11:49:06 INFO DAGScheduler: failed: Set()
25/04/01 11:49:06 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:49:06 INFO CodeGenerator: Code generated in 7.595318 ms
25/04/01 11:49:06 INFO CodeGenerator: Code generated in 8.207553 ms
25/04/01 11:49:06 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:49:06 INFO DAGScheduler: Got job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:49:06 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:49:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 11:49:06 INFO DAGScheduler: Missing parents: List()
25/04/01 11:49:06 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:49:06 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 241.9 KiB, free 363.7 MiB)
25/04/01 11:49:06 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 89.3 KiB, free 363.6 MiB)
25/04/01 11:49:06 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:33803 (size: 89.3 KiB, free: 366.0 MiB)
25/04/01 11:49:06 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 11:49:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:49:06 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 11:49:06 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:49:06 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:44119 (size: 89.3 KiB, free: 366.2 MiB)
25/04/01 11:49:06 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:34704
25/04/01 11:49:07 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 1137 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:49:07 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:49:07 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.163 s
25/04/01 11:49:07 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:49:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 11:49:07 INFO DAGScheduler: Job 7 finished: insertInto at NativeMethodAccessorImpl.java:0, took 1.169123 s
25/04/01 11:49:07 INFO FileFormatWriter: Start to commit write Job a68ae4c7-b58f-4e3f-aaee-3cf1d0f5530b.
25/04/01 11:49:07 INFO FileFormatWriter: Write Job a68ae4c7-b58f-4e3f-aaee-3cf1d0f5530b committed. Elapsed time: 63 ms.
25/04/01 11:49:07 INFO FileFormatWriter: Finished processing stats for write job a68ae4c7-b58f-4e3f-aaee-3cf1d0f5530b.
25/04/01 11:49:07 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:49:07 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:49:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:49:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:49:07 INFO MemoryStore: MemoryStore cleared
25/04/01 11:49:07 INFO BlockManager: BlockManager stopped
25/04/01 11:49:07 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:49:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:49:07 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:49:08 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:49:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-1962bb53-7712-4dbd-90bc-006a0df26f2a/pyspark-d597997f-ed7b-4916-8229-5f40c1cf8f17
25/04/01 11:49:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-29e67abd-4402-456c-9f16-16258dbda708
25/04/01 11:49:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-1962bb53-7712-4dbd-90bc-006a0df26f2a
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:51:26 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:51:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:51:26 INFO ResourceUtils: ==============================================================
25/04/01 11:51:26 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:51:26 INFO ResourceUtils: ==============================================================
25/04/01 11:51:26 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:51:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:51:26 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:51:26 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:51:26 INFO SecurityManager: Changing view acls to: root
25/04/01 11:51:26 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:51:26 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:51:26 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:51:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:51:26 INFO Utils: Successfully started service 'sparkDriver' on port 34227.
25/04/01 11:51:26 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:51:26 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:51:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:51:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:51:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:51:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cb33756d-97a0-45d1-a320-1130590ea061
25/04/01 11:51:26 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:51:26 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:51:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:51:26 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:51:27 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:51:27 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 11:51:27 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401115127-0029
25/04/01 11:51:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115127-0029/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:51:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115127-0029/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:51:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115127-0029/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:51:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115127-0029/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:51:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115127-0029/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:51:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115127-0029/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:51:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36183.
25/04/01 11:51:27 INFO NettyBlockTransferService: Server created on 7796893c36d7:36183
25/04/01 11:51:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:51:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 36183, None)
25/04/01 11:51:27 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:36183 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 36183, None)
25/04/01 11:51:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115127-0029/0 is now RUNNING
25/04/01 11:51:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115127-0029/1 is now RUNNING
25/04/01 11:51:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115127-0029/2 is now RUNNING
25/04/01 11:51:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 36183, None)
25/04/01 11:51:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 36183, None)
25/04/01 11:51:27 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:51:27 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:51:27 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:51:28 INFO InMemoryFileIndex: It took 58 ms to list leaf files for 1 paths.
25/04/01 11:51:28 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:51:28 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:46844) with ID 1,  ResourceProfileId 0
25/04/01 11:51:28 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:58014) with ID 2,  ResourceProfileId 0
25/04/01 11:51:28 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:43774) with ID 0,  ResourceProfileId 0
25/04/01 11:51:29 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:38903 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 38903, None)
25/04/01 11:51:29 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:40433 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 40433, None)
25/04/01 11:51:29 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:44941 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 44941, None)
25/04/01 11:51:30 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:51:30 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:51:30 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:51:30 INFO CodeGenerator: Code generated in 135.076553 ms
25/04/01 11:51:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:51:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:51:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:36183 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:51:30 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:51:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:51:30 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:51:30 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:51:30 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:51:30 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:51:30 INFO DAGScheduler: Missing parents: List()
25/04/01 11:51:30 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:51:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:51:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:51:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:36183 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:51:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:51:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:51:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:51:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:51:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:44941 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:51:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:44941 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:51:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1394 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:51:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:51:32 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.456 s
25/04/01 11:51:32 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:51:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:51:32 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.487637 s
25/04/01 11:51:32 INFO CodeGenerator: Code generated in 8.471557 ms
25/04/01 11:51:32 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:51:32 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:51:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:51:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:51:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:51:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:36183 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:51:32 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:51:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 11:51:32 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:51:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:51:32 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:51:32 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:51:32 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:51:32 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:51:32 INFO metastore: Connected to metastore.
25/04/01 11:51:33 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=48382367-6e51-49e8-8382-b4b36b9589a5, clientType=HIVECLI]
25/04/01 11:51:33 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:51:33 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:51:33 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:51:33 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:51:33 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:51:33 INFO metastore: Connected to metastore.
25/04/01 11:51:33 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:51:33 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:51:33 INFO metastore: Connected to metastore.
25/04/01 11:51:33 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 11:51:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:51:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:51:33 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:51:33 INFO DataSourceStrategy: Pruning directories with: isnotnull(Date#40)
25/04/01 11:51:33 INFO FileSourceStrategy: Pushed Filters: IsNotNull(StockCode)
25/04/01 11:51:33 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(StockCode#36)
25/04/01 11:51:33 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string>
25/04/01 11:51:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:36183 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:51:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:51:33 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:44941 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:51:33 INFO CodeGenerator: Code generated in 22.476209 ms
25/04/01 11:51:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:51:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:51:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:36183 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:51:33 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:51:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:51:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:51:33 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:51:33 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:51:33 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:51:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:51:33 INFO DAGScheduler: Missing parents: List()
25/04/01 11:51:33 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:51:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 11:51:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 11:51:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:36183 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:51:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:51:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:51:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:51:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:51:33 INFO CodeGenerator: Code generated in 21.091171 ms
25/04/01 11:51:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 349.8 KiB, free 364.8 MiB)
25/04/01 11:51:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.5 KiB, free 364.8 MiB)
25/04/01 11:51:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:36183 (size: 33.5 KiB, free: 366.2 MiB)
25/04/01 11:51:33 INFO SparkContext: Created broadcast 5 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:51:33 INFO InMemoryFileIndex: Selected 0 partitions out of 0, pruned 0 partitions.
25/04/01 11:51:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:51:33 INFO ShufflePartitionsUtil: For shuffle(), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:51:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:51:33 INFO CodeGenerator: Code generated in 18.319561 ms
25/04/01 11:51:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:51:33 INFO DAGScheduler: Registering RDD 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) as input to shuffle 1
25/04/01 11:51:33 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 1 output partitions
25/04/01 11:51:33 INFO DAGScheduler: Final stage: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
25/04/01 11:51:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:51:33 INFO DAGScheduler: Missing parents: List()
25/04/01 11:51:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
25/04/01 11:51:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 34.2 KiB, free 364.7 MiB)
25/04/01 11:51:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 364.7 MiB)
25/04/01 11:51:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:36183 (size: 15.7 KiB, free: 366.1 MiB)
25/04/01 11:51:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:51:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0))
25/04/01 11:51:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:51:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:51:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:38903 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:51:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:38903 (size: 15.7 KiB, free: 366.3 MiB)
25/04/01 11:51:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:43774
25/04/01 11:51:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 687 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:51:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:51:34 INFO DAGScheduler: ResultStage 3 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 0.693 s
25/04/01 11:51:34 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:51:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 11:51:34 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 0.698610 s
25/04/01 11:51:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:38903 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:51:34 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.0 B, free 364.7 MiB)
25/04/01 11:51:34 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 120.0 B, free 364.7 MiB)
25/04/01 11:51:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:36183 (size: 120.0 B, free: 366.1 MiB)
25/04/01 11:51:34 INFO SparkContext: Created broadcast 7 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
25/04/01 11:51:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1510 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:51:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:51:35 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.524 s
25/04/01 11:51:35 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:51:35 INFO DAGScheduler: running: Set()
25/04/01 11:51:35 INFO DAGScheduler: waiting: Set()
25/04/01 11:51:35 INFO DAGScheduler: failed: Set()
25/04/01 11:51:35 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:51:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:51:35 INFO CodeGenerator: Code generated in 11.422592 ms
25/04/01 11:51:35 INFO DAGScheduler: Registering RDD 23 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:51:35 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:51:35 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:51:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 11:51:35 INFO DAGScheduler: Missing parents: List()
25/04/01 11:51:35 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:51:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.9 KiB, free 364.7 MiB)
25/04/01 11:51:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 364.7 MiB)
25/04/01 11:51:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:36183 (size: 17.9 KiB, free: 366.1 MiB)
25/04/01 11:51:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:51:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:51:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 11:51:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:51:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:38903 (size: 17.9 KiB, free: 366.2 MiB)
25/04/01 11:51:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:43774
25/04/01 11:51:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 79 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:51:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 11:51:35 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.088 s
25/04/01 11:51:35 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:51:35 INFO DAGScheduler: running: Set()
25/04/01 11:51:35 INFO DAGScheduler: waiting: Set()
25/04/01 11:51:35 INFO DAGScheduler: failed: Set()
25/04/01 11:51:35 INFO CodeGenerator: Code generated in 7.230954 ms
25/04/01 11:51:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:51:35 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:51:35 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:51:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 11:51:35 INFO DAGScheduler: Missing parents: List()
25/04/01 11:51:35 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:51:35 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.7 MiB)
25/04/01 11:51:35 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.7 MiB)
25/04/01 11:51:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:36183 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 11:51:35 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:51:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:51:35 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 11:51:35 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:51:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:38903 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:51:35 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:43774
25/04/01 11:51:35 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 26 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:51:35 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 11:51:35 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.031 s
25/04/01 11:51:35 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:51:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 11:51:35 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.034261 s
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 76, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: Cannot write incompatible data to table '`default`.`products`':
- Cannot safely cast 'UnitPrice': string to decimal(10,5)
25/04/01 11:51:35 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 11:51:35 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:51:35 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:51:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:51:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:51:35 INFO MemoryStore: MemoryStore cleared
25/04/01 11:51:35 INFO BlockManager: BlockManager stopped
25/04/01 11:51:35 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:51:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:51:35 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:51:35 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:51:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-399b8104-df5d-41bd-b2fa-c63012340df4
25/04/01 11:51:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-8355f84f-2189-4016-bbe9-f43bf034e641
25/04/01 11:51:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-8355f84f-2189-4016-bbe9-f43bf034e641/pyspark-9963aa35-def1-406d-b51c-7a5a0c0e689f
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:52:42 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:52:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:52:42 INFO ResourceUtils: ==============================================================
25/04/01 11:52:42 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:52:42 INFO ResourceUtils: ==============================================================
25/04/01 11:52:42 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:52:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:52:42 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:52:42 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:52:42 INFO SecurityManager: Changing view acls to: root
25/04/01 11:52:42 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:52:42 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:52:42 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:52:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:52:42 INFO Utils: Successfully started service 'sparkDriver' on port 41395.
25/04/01 11:52:42 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:52:42 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:52:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:52:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:52:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:52:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5f57e2e1-eaff-4330-a11b-b094acfe12e5
25/04/01 11:52:42 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:52:42 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:52:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:52:43 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:52:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:52:43 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 11:52:43 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401115243-0030
25/04/01 11:52:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115243-0030/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:52:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115243-0030/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:52:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115243-0030/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:52:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115243-0030/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:52:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115243-0030/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:52:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115243-0030/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:52:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35649.
25/04/01 11:52:43 INFO NettyBlockTransferService: Server created on 7796893c36d7:35649
25/04/01 11:52:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:52:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 35649, None)
25/04/01 11:52:43 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:35649 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 35649, None)
25/04/01 11:52:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115243-0030/0 is now RUNNING
25/04/01 11:52:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115243-0030/1 is now RUNNING
25/04/01 11:52:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 35649, None)
25/04/01 11:52:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115243-0030/2 is now RUNNING
25/04/01 11:52:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 35649, None)
25/04/01 11:52:43 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:52:43 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:52:43 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:52:44 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.
25/04/01 11:52:44 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:52:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:36550) with ID 1,  ResourceProfileId 0
25/04/01 11:52:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:42076) with ID 2,  ResourceProfileId 0
25/04/01 11:52:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:56184) with ID 0,  ResourceProfileId 0
25/04/01 11:52:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:45179 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 45179, None)
25/04/01 11:52:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:38393 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 38393, None)
25/04/01 11:52:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:41453 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 41453, None)
25/04/01 11:52:46 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:52:46 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:52:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:52:46 INFO CodeGenerator: Code generated in 133.423747 ms
25/04/01 11:52:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:52:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:52:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:35649 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:52:46 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:52:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:52:47 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:52:47 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:52:47 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:52:47 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:52:47 INFO DAGScheduler: Missing parents: List()
25/04/01 11:52:47 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:52:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:52:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:52:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:35649 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:52:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:52:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:52:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:52:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:52:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:41453 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:52:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:41453 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:52:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1366 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:52:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:52:48 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.428 s
25/04/01 11:52:48 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:52:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:52:48 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.458866 s
25/04/01 11:52:48 INFO CodeGenerator: Code generated in 7.715797 ms
25/04/01 11:52:48 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:52:48 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:52:48 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:52:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:52:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:52:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:35649 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:52:48 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:52:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 11:52:48 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:52:48 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:52:48 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:52:48 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:52:49 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:52:49 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:52:49 INFO metastore: Connected to metastore.
25/04/01 11:52:49 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=7a9d0912-7a4d-4baa-acf2-28c6a72f9c98, clientType=HIVECLI]
25/04/01 11:52:49 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:52:49 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:52:49 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:52:49 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:52:49 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:52:49 INFO metastore: Connected to metastore.
25/04/01 11:52:49 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:52:49 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:52:49 INFO metastore: Connected to metastore.
25/04/01 11:52:49 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:52:49 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:52:49 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:52:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:52:49 INFO CodeGenerator: Code generated in 21.304888 ms
25/04/01 11:52:49 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:52:49 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:52:49 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:35649 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:52:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:52:49 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:52:49 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:52:49 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:52:49 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:52:49 INFO DAGScheduler: Missing parents: List()
25/04/01 11:52:49 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:52:49 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.1 MiB)
25/04/01 11:52:49 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 11:52:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:35649 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:52:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:52:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:52:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:52:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:41453 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:41453 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 304 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:52:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:52:49 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.318 s
25/04/01 11:52:49 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:52:49 INFO DAGScheduler: running: Set()
25/04/01 11:52:49 INFO DAGScheduler: waiting: Set()
25/04/01 11:52:49 INFO DAGScheduler: failed: Set()
25/04/01 11:52:49 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:52:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:52:49 INFO CodeGenerator: Code generated in 23.899171 ms
25/04/01 11:52:49 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:35649 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:41453 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 7796893c36d7:35649 in memory (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.2:41453 in memory (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:52:49 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:52:49 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:52:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:52:49 INFO DAGScheduler: Missing parents: List()
25/04/01 11:52:49 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:52:49 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.2 MiB)
25/04/01 11:52:49 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 11:52:49 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:35649 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 11:52:49 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 11:52:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:52:49 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:52:49 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:52:49 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:41453 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 11:52:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:56184
25/04/01 11:52:50 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 130 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:52:50 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:52:50 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.140 s
25/04/01 11:52:50 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:52:50 INFO DAGScheduler: running: Set()
25/04/01 11:52:50 INFO DAGScheduler: waiting: Set()
25/04/01 11:52:50 INFO DAGScheduler: failed: Set()
25/04/01 11:52:50 INFO CodeGenerator: Code generated in 6.745272 ms
25/04/01 11:52:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:52:50 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:52:50 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:52:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:52:50 INFO DAGScheduler: Missing parents: List()
25/04/01 11:52:50 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:52:50 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 11:52:50 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 11:52:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:35649 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:52:50 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:52:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:52:50 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:52:50 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:52:50 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:41453 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:52:50 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:56184
25/04/01 11:52:50 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 31 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:52:50 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:52:50 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.036 s
25/04/01 11:52:50 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:52:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 11:52:50 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.038698 s
25/04/01 11:52:50 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:52:50 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:52:50 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:52:50 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:52:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:52:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:52:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:52:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:52:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:52:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:52:50 INFO CodeGenerator: Code generated in 12.09098 ms
25/04/01 11:52:50 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.8 MiB)
25/04/01 11:52:50 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.8 MiB)
25/04/01 11:52:50 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:35649 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:52:50 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:52:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:52:50 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:52:50 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:52:50 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:52:50 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:52:50 INFO DAGScheduler: Missing parents: List()
25/04/01 11:52:50 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:52:50 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/01 11:52:50 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/01 11:52:50 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:35649 (size: 14.7 KiB, free: 366.1 MiB)
25/04/01 11:52:50 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:52:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:52:50 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:52:50 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:52:50 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:45179 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 11:52:51 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:45179 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:52:52 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1630 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:52:52 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:52:52 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.641 s
25/04/01 11:52:52 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:52:52 INFO DAGScheduler: running: Set()
25/04/01 11:52:52 INFO DAGScheduler: waiting: Set()
25/04/01 11:52:52 INFO DAGScheduler: failed: Set()
25/04/01 11:52:52 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:52:52 INFO CodeGenerator: Code generated in 7.658107 ms
25/04/01 11:52:52 INFO CodeGenerator: Code generated in 7.51982 ms
25/04/01 11:52:52 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:52:52 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:52:52 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:52:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 11:52:52 INFO DAGScheduler: Missing parents: List()
25/04/01 11:52:52 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:52:52 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.5 MiB)
25/04/01 11:52:52 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.4 MiB)
25/04/01 11:52:52 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:35649 (size: 87.8 KiB, free: 366.0 MiB)
25/04/01 11:52:52 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:52:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:52:52 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 11:52:52 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:52:52 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:45179 (size: 87.8 KiB, free: 366.2 MiB)
25/04/01 11:52:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:36550
25/04/01 11:52:53 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 907 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 11:52:53 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:52:53 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.933 s
25/04/01 11:52:53 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:52:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 11:52:53 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.939578 s
25/04/01 11:52:53 INFO FileFormatWriter: Start to commit write Job f7ce5eb3-bbde-43e8-9cb8-2c3bf4e6370c.
25/04/01 11:52:53 INFO FileFormatWriter: Write Job f7ce5eb3-bbde-43e8-9cb8-2c3bf4e6370c committed. Elapsed time: 37 ms.
25/04/01 11:52:53 INFO FileFormatWriter: Finished processing stats for write job f7ce5eb3-bbde-43e8-9cb8-2c3bf4e6370c.
25/04/01 11:52:53 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:52:53 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:52:53 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:52:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:52:53 INFO MemoryStore: MemoryStore cleared
25/04/01 11:52:53 INFO BlockManager: BlockManager stopped
25/04/01 11:52:53 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:52:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:52:53 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:52:53 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:52:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-4cd6020d-6128-4a42-baad-fbf9586fb430
25/04/01 11:52:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-b69c2d92-32f4-46e0-be1c-6af0ea8b9bc2
25/04/01 11:52:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-b69c2d92-32f4-46e0-be1c-6af0ea8b9bc2/pyspark-a78cb5fa-2e8c-4f7d-a394-00af0a5a08d5
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 11:53:44 INFO SparkContext: Running Spark version 3.2.2
25/04/01 11:53:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 11:53:44 INFO ResourceUtils: ==============================================================
25/04/01 11:53:44 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 11:53:44 INFO ResourceUtils: ==============================================================
25/04/01 11:53:44 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 11:53:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 11:53:44 INFO ResourceProfile: Limiting resource is cpu
25/04/01 11:53:44 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 11:53:44 INFO SecurityManager: Changing view acls to: root
25/04/01 11:53:44 INFO SecurityManager: Changing modify acls to: root
25/04/01 11:53:44 INFO SecurityManager: Changing view acls groups to: 
25/04/01 11:53:44 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 11:53:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 11:53:44 INFO Utils: Successfully started service 'sparkDriver' on port 38325.
25/04/01 11:53:44 INFO SparkEnv: Registering MapOutputTracker
25/04/01 11:53:44 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 11:53:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 11:53:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 11:53:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 11:53:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2d979a83-d280-4a35-ad77-7b0e66e62d10
25/04/01 11:53:44 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 11:53:44 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 11:53:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 11:53:44 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 11:53:44 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 11:53:44 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 11:53:45 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401115345-0031
25/04/01 11:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115345-0031/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 11:53:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115345-0031/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115345-0031/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 11:53:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115345-0031/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401115345-0031/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 11:53:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401115345-0031/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 11:53:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38253.
25/04/01 11:53:45 INFO NettyBlockTransferService: Server created on 7796893c36d7:38253
25/04/01 11:53:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 11:53:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 38253, None)
25/04/01 11:53:45 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:38253 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 38253, None)
25/04/01 11:53:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 38253, None)
25/04/01 11:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115345-0031/2 is now RUNNING
25/04/01 11:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115345-0031/1 is now RUNNING
25/04/01 11:53:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 38253, None)
25/04/01 11:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401115345-0031/0 is now RUNNING
25/04/01 11:53:45 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 11:53:45 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 11:53:45 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 11:53:46 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.
25/04/01 11:53:46 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 11:53:46 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:42666) with ID 1,  ResourceProfileId 0
25/04/01 11:53:46 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:44398) with ID 0,  ResourceProfileId 0
25/04/01 11:53:46 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:59180) with ID 2,  ResourceProfileId 0
25/04/01 11:53:46 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:38297 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 38297, None)
25/04/01 11:53:46 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:35753 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 35753, None)
25/04/01 11:53:46 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:44659 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 44659, None)
25/04/01 11:53:48 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:53:48 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 11:53:48 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:53:48 INFO CodeGenerator: Code generated in 134.147523 ms
25/04/01 11:53:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 11:53:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 11:53:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:38253 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:53:48 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:53:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:53:48 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 11:53:48 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:53:48 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 11:53:48 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:53:48 INFO DAGScheduler: Missing parents: List()
25/04/01 11:53:48 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:53:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 11:53:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 11:53:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:38253 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:53:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 11:53:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:53:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 11:53:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 11:53:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:35753 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:53:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:35753 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:53:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1368 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:53:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 11:53:50 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.434 s
25/04/01 11:53:50 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:53:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 11:53:50 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.464189 s
25/04/01 11:53:50 INFO CodeGenerator: Code generated in 8.165231 ms
25/04/01 11:53:50 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:53:50 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:53:50 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 11:53:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 11:53:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 11:53:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:38253 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:53:50 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 11:53:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 11:53:50 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:53:50 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 11:53:50 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 11:53:50 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 11:53:50 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:53:50 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:53:50 INFO metastore: Connected to metastore.
25/04/01 11:53:50 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4e84f4f2-ef53-4192-a05d-63decf8bf0dd, clientType=HIVECLI]
25/04/01 11:53:50 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 11:53:50 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 11:53:50 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 11:53:50 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:53:50 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 11:53:50 INFO metastore: Connected to metastore.
25/04/01 11:53:50 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 11:53:50 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 11:53:50 INFO metastore: Connected to metastore.
25/04/01 11:53:51 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:53:51 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:53:51 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 11:53:51 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:53:51 INFO CodeGenerator: Code generated in 24.472854 ms
25/04/01 11:53:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 11:53:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 11:53:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:38253 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:53:51 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 11:53:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:53:51 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 11:53:51 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:53:51 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:53:51 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:53:51 INFO DAGScheduler: Missing parents: List()
25/04/01 11:53:51 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:53:51 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.1 MiB)
25/04/01 11:53:51 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 11:53:51 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:38253 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 11:53:51 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 11:53:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:53:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 11:53:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:53:51 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:38253 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 11:53:51 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:35753 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 11:53:51 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:35753 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 11:53:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:35753 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 11:53:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 311 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:53:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 11:53:51 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.346 s
25/04/01 11:53:51 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:53:51 INFO DAGScheduler: running: Set()
25/04/01 11:53:51 INFO DAGScheduler: waiting: Set()
25/04/01 11:53:51 INFO DAGScheduler: failed: Set()
25/04/01 11:53:51 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:53:51 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 11:53:51 INFO CodeGenerator: Code generated in 13.678141 ms
25/04/01 11:53:51 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 11:53:51 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:53:51 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:53:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 11:53:51 INFO DAGScheduler: Missing parents: List()
25/04/01 11:53:51 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:53:51 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.7 KiB, free 365.1 MiB)
25/04/01 11:53:51 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 11:53:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:38253 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 11:53:51 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 11:53:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:53:51 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 11:53:51 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 11:53:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:35753 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 11:53:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:44398
25/04/01 11:53:51 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 132 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:53:51 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 11:53:51 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.141 s
25/04/01 11:53:51 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:53:51 INFO DAGScheduler: running: Set()
25/04/01 11:53:51 INFO DAGScheduler: waiting: Set()
25/04/01 11:53:51 INFO DAGScheduler: failed: Set()
25/04/01 11:53:51 INFO CodeGenerator: Code generated in 6.643792 ms
25/04/01 11:53:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 11:53:51 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:53:51 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 11:53:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 11:53:51 INFO DAGScheduler: Missing parents: List()
25/04/01 11:53:51 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:53:51 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 11:53:51 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 11:53:51 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:38253 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:53:51 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 11:53:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:53:51 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 11:53:51 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:53:51 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:35753 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 11:53:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:44398
25/04/01 11:53:51 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 29 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 11:53:51 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 11:53:51 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.035 s
25/04/01 11:53:51 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:53:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 11:53:51 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.037630 s
25/04/01 11:53:51 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 11:53:51 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 11:53:51 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 11:53:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:53:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:53:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:53:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:53:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 11:53:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 11:53:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 11:53:52 INFO CodeGenerator: Code generated in 12.05159 ms
25/04/01 11:53:52 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/01 11:53:52 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/01 11:53:52 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:38253 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 11:53:52 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:53:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 11:53:52 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 11:53:52 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:53:52 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:53:52 INFO DAGScheduler: Parents of final stage: List()
25/04/01 11:53:52 INFO DAGScheduler: Missing parents: List()
25/04/01 11:53:52 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:53:52 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/01 11:53:52 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/01 11:53:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:38253 (size: 14.7 KiB, free: 366.1 MiB)
25/04/01 11:53:52 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 11:53:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:53:52 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 11:53:52 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 11:53:52 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:44659 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 11:53:52 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:44659 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 11:53:53 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1607 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:53:53 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 11:53:53 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.617 s
25/04/01 11:53:53 INFO DAGScheduler: looking for newly runnable stages
25/04/01 11:53:53 INFO DAGScheduler: running: Set()
25/04/01 11:53:53 INFO DAGScheduler: waiting: Set()
25/04/01 11:53:53 INFO DAGScheduler: failed: Set()
25/04/01 11:53:53 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 11:53:53 INFO CodeGenerator: Code generated in 7.212656 ms
25/04/01 11:53:53 INFO CodeGenerator: Code generated in 8.207485 ms
25/04/01 11:53:53 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 11:53:53 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 11:53:53 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 11:53:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 11:53:53 INFO DAGScheduler: Missing parents: List()
25/04/01 11:53:53 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 11:53:53 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/01 11:53:53 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/01 11:53:53 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:38253 (size: 87.8 KiB, free: 366.0 MiB)
25/04/01 11:53:53 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 11:53:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 11:53:53 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 11:53:53 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 11:53:53 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:44659 (size: 87.8 KiB, free: 366.2 MiB)
25/04/01 11:53:53 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:59180
25/04/01 11:53:54 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 921 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 11:53:54 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 11:53:54 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.946 s
25/04/01 11:53:54 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 11:53:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 11:53:54 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.954074 s
25/04/01 11:53:54 INFO FileFormatWriter: Start to commit write Job b91765eb-7114-4976-b628-7c08642ccc4b.
25/04/01 11:53:54 INFO FileFormatWriter: Write Job b91765eb-7114-4976-b628-7c08642ccc4b committed. Elapsed time: 42 ms.
25/04/01 11:53:54 INFO FileFormatWriter: Finished processing stats for write job b91765eb-7114-4976-b628-7c08642ccc4b.
25/04/01 11:53:55 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 11:53:55 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 11:53:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 11:53:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 11:53:55 INFO MemoryStore: MemoryStore cleared
25/04/01 11:53:55 INFO BlockManager: BlockManager stopped
25/04/01 11:53:55 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 11:53:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 11:53:55 INFO SparkContext: Successfully stopped SparkContext
25/04/01 11:53:55 INFO ShutdownHookManager: Shutdown hook called
25/04/01 11:53:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-30809a05-38bb-4372-ac3a-941ea250b3a7
25/04/01 11:53:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-30809a05-38bb-4372-ac3a-941ea250b3a7/pyspark-46da9fd2-a7bd-4c6c-be2d-8de5a7cf6beb
25/04/01 11:53:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-30335ac6-e3d6-46c4-b339-c86c7159eb80
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:12:48 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:12:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:12:48 INFO ResourceUtils: ==============================================================
25/04/01 12:12:48 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:12:48 INFO ResourceUtils: ==============================================================
25/04/01 12:12:48 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:12:48 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:12:48 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:12:48 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:12:48 INFO SecurityManager: Changing view acls to: root
25/04/01 12:12:48 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:12:48 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:12:48 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:12:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:12:48 INFO Utils: Successfully started service 'sparkDriver' on port 38977.
25/04/01 12:12:48 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:12:48 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:12:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:12:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:12:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:12:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5a0abb3c-e32f-4f58-9d41-11989687d40c
25/04/01 12:12:48 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:12:48 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:12:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:12:49 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:12:49 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:12:49 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 24 ms (0 ms spent in bootstraps)
25/04/01 12:12:49 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401121249-0040
25/04/01 12:12:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121249-0040/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:12:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121249-0040/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:12:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121249-0040/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:12:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121249-0040/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:12:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401121249-0040/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:12:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401121249-0040/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:12:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45323.
25/04/01 12:12:49 INFO NettyBlockTransferService: Server created on 7796893c36d7:45323
25/04/01 12:12:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:12:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 45323, None)
25/04/01 12:12:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121249-0040/0 is now RUNNING
25/04/01 12:12:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121249-0040/2 is now RUNNING
25/04/01 12:12:49 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:45323 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 45323, None)
25/04/01 12:12:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401121249-0040/1 is now RUNNING
25/04/01 12:12:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 45323, None)
25/04/01 12:12:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 45323, None)
25/04/01 12:12:49 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:12:49 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:12:49 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:12:50 INFO InMemoryFileIndex: It took 58 ms to list leaf files for 1 paths.
25/04/01 12:12:51 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 12:12:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:51362) with ID 2,  ResourceProfileId 0
25/04/01 12:12:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:38562) with ID 0,  ResourceProfileId 0
25/04/01 12:12:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:47446) with ID 1,  ResourceProfileId 0
25/04/01 12:12:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:44115 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 44115, None)
25/04/01 12:12:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:41013 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 41013, None)
25/04/01 12:12:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:35287 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 35287, None)
25/04/01 12:12:52 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:12:52 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:12:52 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:12:52 INFO CodeGenerator: Code generated in 133.634965 ms
25/04/01 12:12:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:12:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:12:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:45323 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:12:52 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:12:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:12:53 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:12:53 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:12:53 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:12:53 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:12:53 INFO DAGScheduler: Missing parents: List()
25/04/01 12:12:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:12:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:12:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:12:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:45323 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:12:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:12:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:12:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:12:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:12:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:44115 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:12:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:44115 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:12:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1368 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:12:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:12:54 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.431 s
25/04/01 12:12:54 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:12:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:12:54 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.462081 s
25/04/01 12:12:54 INFO CodeGenerator: Code generated in 8.008715 ms
25/04/01 12:12:54 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:12:54 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:12:54 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:12:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:12:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:12:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:45323 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:12:54 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:12:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 12:12:54 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:12:54 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:12:54 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:12:54 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:12:55 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:12:55 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:12:55 INFO metastore: Connected to metastore.
25/04/01 12:12:55 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=cb8c6d44-2f4d-4451-902b-f1e7e472cef1, clientType=HIVECLI]
25/04/01 12:12:55 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:12:55 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:12:55 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:12:55 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:12:55 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:12:55 INFO metastore: Connected to metastore.
25/04/01 12:12:55 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:12:55 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:12:55 INFO metastore: Connected to metastore.
25/04/01 12:12:55 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:12:55 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:12:55 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 12:12:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:12:55 INFO CodeGenerator: Code generated in 21.487737 ms
25/04/01 12:12:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 12:12:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 12:12:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:45323 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:12:55 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:12:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:12:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:45323 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:12:55 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:12:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:44115 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:12:55 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:12:55 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:12:55 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:12:55 INFO DAGScheduler: Missing parents: List()
25/04/01 12:12:55 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:12:55 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/01 12:12:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 12:12:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:45323 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 12:12:55 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:12:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:12:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 12:12:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:12:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:41013 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 12:12:56 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:41013 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:12:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1531 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:12:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:12:57 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.544 s
25/04/01 12:12:57 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:12:57 INFO DAGScheduler: running: Set()
25/04/01 12:12:57 INFO DAGScheduler: waiting: Set()
25/04/01 12:12:57 INFO DAGScheduler: failed: Set()
25/04/01 12:12:57 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:12:57 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:12:57 INFO CodeGenerator: Code generated in 14.172833 ms
25/04/01 12:12:57 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:12:57 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:12:57 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:12:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:12:57 INFO DAGScheduler: Missing parents: List()
25/04/01 12:12:57 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:12:57 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.7 KiB, free 365.1 MiB)
25/04/01 12:12:57 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 12:12:57 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:45323 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:12:57 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 12:12:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:12:57 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:12:57 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:12:57 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:41013 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:12:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:38562
25/04/01 12:12:57 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 144 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:12:57 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:12:57 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.153 s
25/04/01 12:12:57 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:12:57 INFO DAGScheduler: running: Set()
25/04/01 12:12:57 INFO DAGScheduler: waiting: Set()
25/04/01 12:12:57 INFO DAGScheduler: failed: Set()
25/04/01 12:12:57 INFO CodeGenerator: Code generated in 6.541265 ms
25/04/01 12:12:57 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:12:57 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:12:57 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:12:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 12:12:57 INFO DAGScheduler: Missing parents: List()
25/04/01 12:12:57 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:12:57 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 12:12:57 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 12:12:57 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:45323 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:12:57 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 12:12:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:12:57 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 12:12:57 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:12:57 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:41013 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:12:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:38562
25/04/01 12:12:57 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 89 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:12:57 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 12:12:57 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.094 s
25/04/01 12:12:57 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:12:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 12:12:57 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.096901 s
25/04/01 12:12:57 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:12:57 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:12:57 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 12:12:57 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:12:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:12:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:12:57 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:12:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:12:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:12:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:12:57 INFO CodeGenerator: Code generated in 12.300508 ms
25/04/01 12:12:57 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/01 12:12:57 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/01 12:12:57 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:45323 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:12:57 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:12:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:12:57 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:12:57 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:12:57 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:12:57 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:12:57 INFO DAGScheduler: Missing parents: List()
25/04/01 12:12:57 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:12:57 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/01 12:12:57 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/01 12:12:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:45323 (size: 14.7 KiB, free: 366.1 MiB)
25/04/01 12:12:57 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:12:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:12:57 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 12:12:57 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:12:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:35287 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 12:12:58 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:35287 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:12:59 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1616 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:12:59 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:12:59 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.627 s
25/04/01 12:12:59 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:12:59 INFO DAGScheduler: running: Set()
25/04/01 12:12:59 INFO DAGScheduler: waiting: Set()
25/04/01 12:12:59 INFO DAGScheduler: failed: Set()
25/04/01 12:12:59 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:12:59 INFO CodeGenerator: Code generated in 5.970306 ms
25/04/01 12:12:59 INFO CodeGenerator: Code generated in 7.786897 ms
25/04/01 12:12:59 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:12:59 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:12:59 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:12:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 12:12:59 INFO DAGScheduler: Missing parents: List()
25/04/01 12:12:59 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:12:59 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/01 12:12:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/01 12:12:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:45323 (size: 87.8 KiB, free: 366.0 MiB)
25/04/01 12:12:59 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:12:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:12:59 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 12:12:59 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:12:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:35287 (size: 87.8 KiB, free: 366.2 MiB)
25/04/01 12:12:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:47446
25/04/01 12:13:00 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 932 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:13:00 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 12:13:00 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.956 s
25/04/01 12:13:00 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:13:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 12:13:00 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.961679 s
25/04/01 12:13:00 INFO FileFormatWriter: Start to commit write Job 0b8fba82-90c3-4817-b65a-5a6b1c62c633.
25/04/01 12:13:00 INFO FileFormatWriter: Write Job 0b8fba82-90c3-4817-b65a-5a6b1c62c633 committed. Elapsed time: 46 ms.
25/04/01 12:13:00 INFO FileFormatWriter: Finished processing stats for write job 0b8fba82-90c3-4817-b65a-5a6b1c62c633.
25/04/01 12:13:00 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:13:00 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:13:00 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:13:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:13:00 INFO MemoryStore: MemoryStore cleared
25/04/01 12:13:00 INFO BlockManager: BlockManager stopped
25/04/01 12:13:00 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:13:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:13:00 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:13:01 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:13:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-44119b49-f3dd-4685-8e26-d10662783cda
25/04/01 12:13:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba1eccf5-705d-4eb2-b84a-e7fc94145b10
25/04/01 12:13:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-ba1eccf5-705d-4eb2-b84a-e7fc94145b10/pyspark-473c6962-9814-46cc-a1c5-a147dd61380d
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:20:35 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:20:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:20:35 INFO ResourceUtils: ==============================================================
25/04/01 12:20:35 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:20:35 INFO ResourceUtils: ==============================================================
25/04/01 12:20:35 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:20:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:20:35 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:20:35 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:20:35 INFO SecurityManager: Changing view acls to: root
25/04/01 12:20:35 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:20:35 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:20:35 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:20:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:20:36 INFO Utils: Successfully started service 'sparkDriver' on port 41281.
25/04/01 12:20:36 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:20:36 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:20:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:20:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:20:36 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:20:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-86cfcbfa-ed33-4336-9a26-b0e9aadd1b5e
25/04/01 12:20:36 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:20:36 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:20:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:20:36 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:20:36 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:20:36 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 12:20:36 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401122036-0041
25/04/01 12:20:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122036-0041/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:20:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122036-0041/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:20:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122036-0041/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:20:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122036-0041/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:20:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122036-0041/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:20:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122036-0041/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:20:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33415.
25/04/01 12:20:36 INFO NettyBlockTransferService: Server created on 7796893c36d7:33415
25/04/01 12:20:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:20:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 33415, None)
25/04/01 12:20:36 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:33415 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 33415, None)
25/04/01 12:20:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122036-0041/0 is now RUNNING
25/04/01 12:20:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122036-0041/2 is now RUNNING
25/04/01 12:20:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 33415, None)
25/04/01 12:20:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122036-0041/1 is now RUNNING
25/04/01 12:20:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 33415, None)
25/04/01 12:20:36 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:20:37 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:20:37 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:20:38 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/01 12:20:38 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 12:20:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:50768) with ID 1,  ResourceProfileId 0
25/04/01 12:20:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:48506) with ID 2,  ResourceProfileId 0
25/04/01 12:20:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:57126) with ID 0,  ResourceProfileId 0
25/04/01 12:20:38 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:41321 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 41321, None)
25/04/01 12:20:38 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:41159 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 41159, None)
25/04/01 12:20:38 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:41907 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 41907, None)
25/04/01 12:20:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:20:39 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:20:39 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:20:40 INFO CodeGenerator: Code generated in 137.809004 ms
25/04/01 12:20:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:20:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:20:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:33415 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:20:40 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:20:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:20:40 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:20:40 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:20:40 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:20:40 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:20:40 INFO DAGScheduler: Missing parents: List()
25/04/01 12:20:40 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:20:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:20:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:20:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:33415 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:20:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:20:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:20:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:20:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:20:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:41159 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:20:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:41159 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:20:41 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1401 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:20:41 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:20:41 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.464 s
25/04/01 12:20:41 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:20:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:20:41 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.494892 s
25/04/01 12:20:41 INFO CodeGenerator: Code generated in 7.935241 ms
25/04/01 12:20:41 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:20:41 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:20:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:20:41 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:20:41 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:20:41 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:33415 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:20:41 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:20:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 42, in <module>
    spark.sql(f"""
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 723, in sql
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException: STORED AS with file format 'CSV' is invalid.
25/04/01 12:20:42 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 12:20:42 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:20:42 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:20:42 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:20:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:20:42 INFO MemoryStore: MemoryStore cleared
25/04/01 12:20:42 INFO BlockManager: BlockManager stopped
25/04/01 12:20:42 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:20:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:20:42 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:20:42 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:20:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-877019fb-19d3-441f-bf51-97e96140387f
25/04/01 12:20:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-a55ca747-ea07-4aba-8856-7481630aec9a
25/04/01 12:20:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-877019fb-19d3-441f-bf51-97e96140387f/pyspark-b25e25d7-dd4a-4ddb-8345-630da9b8ded9
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:21:10 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:21:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:21:11 INFO ResourceUtils: ==============================================================
25/04/01 12:21:11 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:21:11 INFO ResourceUtils: ==============================================================
25/04/01 12:21:11 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:21:11 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:21:11 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:21:11 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:21:11 INFO SecurityManager: Changing view acls to: root
25/04/01 12:21:11 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:21:11 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:21:11 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:21:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:21:11 INFO Utils: Successfully started service 'sparkDriver' on port 34351.
25/04/01 12:21:11 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:21:11 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:21:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:21:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:21:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:21:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8912e308-6f02-4c10-801a-9e738f34d81c
25/04/01 12:21:11 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:21:11 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:21:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:21:11 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:21:11 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:21:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 12:21:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401122111-0042
25/04/01 12:21:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122111-0042/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:21:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122111-0042/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:21:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122111-0042/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:21:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122111-0042/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:21:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122111-0042/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:21:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122111-0042/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:21:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33771.
25/04/01 12:21:11 INFO NettyBlockTransferService: Server created on 7796893c36d7:33771
25/04/01 12:21:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:21:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 33771, None)
25/04/01 12:21:11 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:33771 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 33771, None)
25/04/01 12:21:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 33771, None)
25/04/01 12:21:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122111-0042/1 is now RUNNING
25/04/01 12:21:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 33771, None)
25/04/01 12:21:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122111-0042/2 is now RUNNING
25/04/01 12:21:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122111-0042/0 is now RUNNING
25/04/01 12:21:12 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:21:12 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:21:12 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:21:13 INFO InMemoryFileIndex: It took 62 ms to list leaf files for 1 paths.
25/04/01 12:21:13 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 12:21:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:37090) with ID 2,  ResourceProfileId 0
25/04/01 12:21:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:37712) with ID 1,  ResourceProfileId 0
25/04/01 12:21:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:50924) with ID 0,  ResourceProfileId 0
25/04/01 12:21:13 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:40107 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 40107, None)
25/04/01 12:21:13 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:46197 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 46197, None)
25/04/01 12:21:13 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:35823 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 35823, None)
25/04/01 12:21:15 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:21:15 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:21:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:21:15 INFO CodeGenerator: Code generated in 131.25007 ms
25/04/01 12:21:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:21:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:21:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:33771 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:21:15 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:21:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:21:15 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:21:15 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:21:15 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:21:15 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:21:15 INFO DAGScheduler: Missing parents: List()
25/04/01 12:21:15 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:21:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:21:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:21:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:33771 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:21:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:21:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:21:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:21:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:21:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:35823 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:21:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:35823 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:21:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1377 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:21:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:21:17 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.444 s
25/04/01 12:21:17 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:21:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:21:17 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.476670 s
25/04/01 12:21:17 INFO CodeGenerator: Code generated in 7.923648 ms
25/04/01 12:21:17 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:21:17 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:21:17 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:21:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:21:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:21:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:33771 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:21:17 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:21:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 12:21:17 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
25/04/01 12:21:17 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:21:17 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:21:17 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:21:17 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:21:17 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:21:17 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:21:17 INFO metastore: Connected to metastore.
25/04/01 12:21:17 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=5a869a26-c49e-47d4-8187-36b3ed52e292, clientType=HIVECLI]
25/04/01 12:21:17 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:21:17 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:21:17 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:21:17 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:21:17 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:21:17 INFO metastore: Connected to metastore.
25/04/01 12:21:17 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:21:17 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:21:17 INFO metastore: Connected to metastore.
25/04/01 12:21:17 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:21:17 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:21:17 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 12:21:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:21:18 INFO CodeGenerator: Code generated in 20.239451 ms
25/04/01 12:21:18 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 12:21:18 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 12:21:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:33771 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:21:18 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:21:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:21:18 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:21:18 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:21:18 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:21:18 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:21:18 INFO DAGScheduler: Missing parents: List()
25/04/01 12:21:18 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:21:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.1 MiB)
25/04/01 12:21:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 12:21:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:33771 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 12:21:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:21:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:21:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 12:21:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:21:18 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:33771 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:21:18 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:35823 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:21:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:40107 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 12:21:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:40107 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:21:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1534 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:21:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:21:19 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.564 s
25/04/01 12:21:19 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:21:19 INFO DAGScheduler: running: Set()
25/04/01 12:21:19 INFO DAGScheduler: waiting: Set()
25/04/01 12:21:19 INFO DAGScheduler: failed: Set()
25/04/01 12:21:19 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:21:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:21:19 INFO CodeGenerator: Code generated in 14.786535 ms
25/04/01 12:21:19 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:21:19 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:21:19 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:21:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:21:19 INFO DAGScheduler: Missing parents: List()
25/04/01 12:21:19 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:21:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.7 KiB, free 365.1 MiB)
25/04/01 12:21:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 12:21:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:33771 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:21:19 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 12:21:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:21:19 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:21:19 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:21:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:40107 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:21:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:37712
25/04/01 12:21:19 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 152 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:21:19 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:21:19 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.160 s
25/04/01 12:21:19 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:21:19 INFO DAGScheduler: running: Set()
25/04/01 12:21:19 INFO DAGScheduler: waiting: Set()
25/04/01 12:21:19 INFO DAGScheduler: failed: Set()
25/04/01 12:21:19 INFO CodeGenerator: Code generated in 6.594205 ms
25/04/01 12:21:19 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:21:19 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:21:19 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:21:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 12:21:19 INFO DAGScheduler: Missing parents: List()
25/04/01 12:21:19 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:21:19 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 12:21:19 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 12:21:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:33771 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:21:19 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 12:21:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:21:19 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 12:21:19 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:21:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:40107 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:21:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:37712
25/04/01 12:21:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 95 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:21:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 12:21:20 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.100 s
25/04/01 12:21:20 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:21:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 12:21:20 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.103398 s
25/04/01 12:21:20 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:21:20 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:21:20 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 12:21:20 INFO FileUtils: Creating directory if it doesn't exist: hdfs://namenode:9000/user/hive/warehouse/products/.hive-staging_hive_2025-04-01_12-21-20_192_5056208484672223761-1
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 54, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o61.insertInto.
: org.apache.spark.SparkException: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict
	at org.apache.spark.sql.hive.execution.InsertIntoHiveTable.processInsert(InsertIntoHiveTable.scala:162)
	at org.apache.spark.sql.hive.execution.InsertIntoHiveTable.run(InsertIntoHiveTable.scala:106)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)
	at org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:481)
	at org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:436)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)

25/04/01 12:21:20 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 12:21:20 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:21:20 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:21:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:21:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:21:20 INFO MemoryStore: MemoryStore cleared
25/04/01 12:21:20 INFO BlockManager: BlockManager stopped
25/04/01 12:21:20 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:21:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:21:20 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:21:20 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:21:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-1fdcfd20-c9ba-474f-8066-d30462ed3bee
25/04/01 12:21:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-d53b9fd2-f698-41fb-ad98-efcd8215f0e1/pyspark-b325d5f0-0443-4e1b-97e8-1844a1f44788
25/04/01 12:21:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-d53b9fd2-f698-41fb-ad98-efcd8215f0e1
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:22:19 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:22:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:22:20 INFO ResourceUtils: ==============================================================
25/04/01 12:22:20 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:22:20 INFO ResourceUtils: ==============================================================
25/04/01 12:22:20 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:22:20 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:22:20 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:22:20 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:22:20 INFO SecurityManager: Changing view acls to: root
25/04/01 12:22:20 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:22:20 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:22:20 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:22:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:22:20 INFO Utils: Successfully started service 'sparkDriver' on port 37437.
25/04/01 12:22:20 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:22:20 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:22:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:22:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:22:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:22:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-85110023-afb6-486d-bc01-1f385e323d2d
25/04/01 12:22:20 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:22:20 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:22:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:22:20 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:22:20 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:22:20 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 12:22:20 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401122220-0043
25/04/01 12:22:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122220-0043/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:22:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122220-0043/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:22:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122220-0043/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:22:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122220-0043/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:22:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122220-0043/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:22:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122220-0043/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:22:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36359.
25/04/01 12:22:20 INFO NettyBlockTransferService: Server created on 7796893c36d7:36359
25/04/01 12:22:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:22:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 36359, None)
25/04/01 12:22:20 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:36359 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 36359, None)
25/04/01 12:22:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122220-0043/1 is now RUNNING
25/04/01 12:22:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122220-0043/2 is now RUNNING
25/04/01 12:22:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122220-0043/0 is now RUNNING
25/04/01 12:22:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 36359, None)
25/04/01 12:22:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 36359, None)
25/04/01 12:22:21 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:22:21 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:22:21 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:22:22 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/01 12:22:22 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 12:22:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:46042) with ID 2,  ResourceProfileId 0
25/04/01 12:22:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:42734) with ID 1,  ResourceProfileId 0
25/04/01 12:22:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:41820) with ID 0,  ResourceProfileId 0
25/04/01 12:22:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:42505 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 42505, None)
25/04/01 12:22:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:35017 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 35017, None)
25/04/01 12:22:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:37481 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 37481, None)
25/04/01 12:22:24 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:22:24 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:22:24 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:22:24 INFO CodeGenerator: Code generated in 134.86621 ms
25/04/01 12:22:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:22:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:22:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:36359 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:22:24 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:22:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:22:24 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:22:24 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:22:24 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:22:24 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:22:24 INFO DAGScheduler: Missing parents: List()
25/04/01 12:22:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:22:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:22:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:22:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:36359 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:22:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:22:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:22:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:22:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:42505 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:22:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:42505 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:22:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1361 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:22:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:22:25 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.425 s
25/04/01 12:22:25 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:22:25 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.456166 s
25/04/01 12:22:26 INFO CodeGenerator: Code generated in 7.86505 ms
25/04/01 12:22:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:22:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:22:26 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:22:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:22:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:22:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:36359 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:22:26 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:22:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 12:22:26 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:22:26 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:22:26 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:22:26 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:22:26 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:22:26 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:22:26 INFO metastore: Connected to metastore.
25/04/01 12:22:26 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=f8dc3214-d86c-4e2f-8319-af90a49ea8e1, clientType=HIVECLI]
25/04/01 12:22:26 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:22:26 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:22:26 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:22:26 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:22:26 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:22:26 INFO metastore: Connected to metastore.
25/04/01 12:22:26 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:22:26 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:22:26 INFO metastore: Connected to metastore.
25/04/01 12:22:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:22:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:22:26 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 12:22:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:22:26 INFO CodeGenerator: Code generated in 24.591936 ms
25/04/01 12:22:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 12:22:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 12:22:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:36359 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:22:26 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:22:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:22:26 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:22:26 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:22:26 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:22:26 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:22:26 INFO DAGScheduler: Missing parents: List()
25/04/01 12:22:26 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:22:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.1 MiB)
25/04/01 12:22:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 12:22:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:36359 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 12:22:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:22:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:22:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 12:22:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:36359 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:22:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:22:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:42505 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:22:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:42505 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 12:22:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:42505 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:22:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 299 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:22:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:22:27 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.314 s
25/04/01 12:22:27 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:22:27 INFO DAGScheduler: running: Set()
25/04/01 12:22:27 INFO DAGScheduler: waiting: Set()
25/04/01 12:22:27 INFO DAGScheduler: failed: Set()
25/04/01 12:22:27 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:22:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:22:27 INFO CodeGenerator: Code generated in 16.157883 ms
25/04/01 12:22:27 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:22:27 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:22:27 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:22:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:22:27 INFO DAGScheduler: Missing parents: List()
25/04/01 12:22:27 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:22:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.7 KiB, free 365.1 MiB)
25/04/01 12:22:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 12:22:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:36359 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:22:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 12:22:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:22:27 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:22:27 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:22:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:42505 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:22:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:46042
25/04/01 12:22:27 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 129 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:22:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:22:27 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.138 s
25/04/01 12:22:27 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:22:27 INFO DAGScheduler: running: Set()
25/04/01 12:22:27 INFO DAGScheduler: waiting: Set()
25/04/01 12:22:27 INFO DAGScheduler: failed: Set()
25/04/01 12:22:27 INFO CodeGenerator: Code generated in 6.665793 ms
25/04/01 12:22:27 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:22:27 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:22:27 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:22:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 12:22:27 INFO DAGScheduler: Missing parents: List()
25/04/01 12:22:27 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:22:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 12:22:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 12:22:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:36359 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:22:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 12:22:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:22:27 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 12:22:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:22:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:42505 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:22:27 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:46042
25/04/01 12:22:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 27 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:22:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 12:22:27 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/01 12:22:27 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:22:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 12:22:27 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.035925 s
25/04/01 12:22:27 WARN HiveExternalCatalog: The table schema given by Hive metastore(struct<stockcode:string,productname:string,productdescription:string,unitprice:string,date:string>) is different from the schema when this table was created by Spark SQL(struct<StockCode:string,ProductName:string,ProductDescription:string,UnitPrice:decimal(10,5),Date:string>). We have to fall back to the table schema from Hive metastore which is not case preserving.
25/04/01 12:22:27 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:22:27 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:22:27 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 12:22:27 INFO FileUtils: Creating directory if it doesn't exist: hdfs://namenode:9000/user/hive/warehouse/products/.hive-staging_hive_2025-04-01_12-22-27_735_4835381285406785320-1
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 56, in <module>
    df.write.mode("append").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o61.insertInto.
: org.apache.spark.SparkException: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict
	at org.apache.spark.sql.hive.execution.InsertIntoHiveTable.processInsert(InsertIntoHiveTable.scala:162)
	at org.apache.spark.sql.hive.execution.InsertIntoHiveTable.run(InsertIntoHiveTable.scala:106)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)
	at org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:481)
	at org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:436)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)

25/04/01 12:22:27 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 12:22:27 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:22:27 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:22:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:22:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:22:27 INFO MemoryStore: MemoryStore cleared
25/04/01 12:22:27 INFO BlockManager: BlockManager stopped
25/04/01 12:22:27 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:22:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:22:27 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:22:27 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:22:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-cb629938-916f-4246-880f-b34026ea068b
25/04/01 12:22:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cb7b5d-7532-43a8-896d-b1faea8c3693/pyspark-8142b14b-9cf4-47ef-a326-86aa32ba6deb
25/04/01 12:22:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-98cb7b5d-7532-43a8-896d-b1faea8c3693
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:24:33 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:24:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:24:33 INFO ResourceUtils: ==============================================================
25/04/01 12:24:33 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:24:33 INFO ResourceUtils: ==============================================================
25/04/01 12:24:33 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:24:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:24:33 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:24:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:24:33 INFO SecurityManager: Changing view acls to: root
25/04/01 12:24:33 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:24:33 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:24:33 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:24:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:24:34 INFO Utils: Successfully started service 'sparkDriver' on port 41395.
25/04/01 12:24:34 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:24:34 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:24:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:24:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:24:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:24:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d7384c11-224d-43e9-8c0f-acf28f54c8f8
25/04/01 12:24:34 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:24:34 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:24:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:24:34 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:24:34 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:24:34 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 12:24:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401122434-0044
25/04/01 12:24:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122434-0044/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:24:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122434-0044/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:24:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122434-0044/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:24:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122434-0044/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:24:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122434-0044/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:24:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122434-0044/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:24:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32953.
25/04/01 12:24:34 INFO NettyBlockTransferService: Server created on 7796893c36d7:32953
25/04/01 12:24:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:24:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 32953, None)
25/04/01 12:24:34 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:32953 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 32953, None)
25/04/01 12:24:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122434-0044/1 is now RUNNING
25/04/01 12:24:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122434-0044/2 is now RUNNING
25/04/01 12:24:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122434-0044/0 is now RUNNING
25/04/01 12:24:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 32953, None)
25/04/01 12:24:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 32953, None)
25/04/01 12:24:34 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:24:34 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:24:35 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:24:36 INFO InMemoryFileIndex: It took 68 ms to list leaf files for 1 paths.
25/04/01 12:24:36 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 12:24:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:57366) with ID 1,  ResourceProfileId 0
25/04/01 12:24:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:42122) with ID 2,  ResourceProfileId 0
25/04/01 12:24:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:47200) with ID 0,  ResourceProfileId 0
25/04/01 12:24:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:41387 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 41387, None)
25/04/01 12:24:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:40291 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 40291, None)
25/04/01 12:24:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:37721 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 37721, None)
25/04/01 12:24:37 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:24:37 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:24:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:24:38 INFO CodeGenerator: Code generated in 137.129511 ms
25/04/01 12:24:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:24:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:24:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:32953 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:24:38 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:24:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:24:38 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:24:38 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:24:38 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:24:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:24:38 INFO DAGScheduler: Missing parents: List()
25/04/01 12:24:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:24:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:24:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:24:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:32953 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:24:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:24:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:24:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:24:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:24:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:40291 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:24:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:40291 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:24:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1408 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:24:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:24:39 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.477 s
25/04/01 12:24:39 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:24:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:24:39 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.508435 s
25/04/01 12:24:39 INFO CodeGenerator: Code generated in 8.123605 ms
25/04/01 12:24:39 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:24:39 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:24:39 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:24:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:24:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:24:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:32953 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:24:39 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:24:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 12:24:40 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:24:40 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:24:40 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:24:40 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:24:40 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:24:40 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:24:40 INFO metastore: Connected to metastore.
25/04/01 12:24:40 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=8a1954d5-5ba7-4be7-9b68-6b8d9360bf5e, clientType=HIVECLI]
25/04/01 12:24:40 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:24:40 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:24:40 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:24:40 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:24:40 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:24:40 INFO metastore: Connected to metastore.
25/04/01 12:24:40 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:24:40 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:24:40 INFO metastore: Connected to metastore.
25/04/01 12:24:40 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:24:40 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:24:40 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 12:24:40 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:24:40 INFO CodeGenerator: Code generated in 22.20299 ms
25/04/01 12:24:40 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 12:24:40 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 12:24:40 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:32953 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:24:40 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:24:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:24:40 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:24:40 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:24:40 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:24:40 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:24:40 INFO DAGScheduler: Missing parents: List()
25/04/01 12:24:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:24:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.1 MiB)
25/04/01 12:24:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 12:24:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:32953 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 12:24:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:24:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:24:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 12:24:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:24:40 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:32953 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:24:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:40291 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 12:24:40 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:40291 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:24:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:40291 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:24:41 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 317 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:24:41 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:24:41 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.345 s
25/04/01 12:24:41 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:24:41 INFO DAGScheduler: running: Set()
25/04/01 12:24:41 INFO DAGScheduler: waiting: Set()
25/04/01 12:24:41 INFO DAGScheduler: failed: Set()
25/04/01 12:24:41 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:24:41 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:24:41 INFO CodeGenerator: Code generated in 15.218718 ms
25/04/01 12:24:41 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:24:41 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:24:41 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:24:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:24:41 INFO DAGScheduler: Missing parents: List()
25/04/01 12:24:41 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:24:41 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.7 KiB, free 365.1 MiB)
25/04/01 12:24:41 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 12:24:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:32953 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:24:41 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 12:24:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:24:41 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:24:41 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:24:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:40291 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:24:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:42122
25/04/01 12:24:41 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 133 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:24:41 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:24:41 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.142 s
25/04/01 12:24:41 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:24:41 INFO DAGScheduler: running: Set()
25/04/01 12:24:41 INFO DAGScheduler: waiting: Set()
25/04/01 12:24:41 INFO DAGScheduler: failed: Set()
25/04/01 12:24:41 INFO CodeGenerator: Code generated in 6.651336 ms
25/04/01 12:24:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:24:41 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:24:41 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:24:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 12:24:41 INFO DAGScheduler: Missing parents: List()
25/04/01 12:24:41 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:24:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 12:24:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 12:24:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:32953 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:24:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 12:24:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:24:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 12:24:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:24:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:40291 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:24:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:42122
25/04/01 12:24:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 30 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:24:41 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 12:24:41 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.035 s
25/04/01 12:24:41 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:24:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 12:24:41 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.038140 s
25/04/01 12:24:41 WARN SetCommand: 'SET hive.exec.dynamic.partition=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.exec.dynamic.partition) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
25/04/01 12:24:41 WARN SetCommand: 'SET hive.exec.dynamic.partition.mode=nonstrict' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.exec.dynamic.partition.mode) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
Traceback (most recent call last):
  File "/opt/bitnami/spark/jobs/load_products_into_hive.py", line 58, in <module>
    df.write.mode("append").partitionBy("date").insertInto(HIVE_TABLE)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 762, in insertInto
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1321, in __call__
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in deco
pyspark.sql.utils.AnalysisException:  insertInto() can't be used together with partitionBy(). Partition columns have already been defined for the table. It is not necessary to use partitionBy().       
25/04/01 12:24:41 INFO SparkContext: Invoking stop() from shutdown hook
25/04/01 12:24:41 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:24:41 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:24:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:24:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:24:41 INFO MemoryStore: MemoryStore cleared
25/04/01 12:24:41 INFO BlockManager: BlockManager stopped
25/04/01 12:24:41 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:24:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:24:41 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:24:41 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:24:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-bb092558-1d42-45d5-925c-df2c75431fd8/pyspark-d128a6f2-9654-4a08-8e54-0a5a21d01aeb
25/04/01 12:24:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-d3c61a08-bf23-4a8c-baa1-ae9504c66c09
25/04/01 12:24:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-bb092558-1d42-45d5-925c-df2c75431fd8
Spark job FAILED!
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:25:28 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:25:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:25:28 INFO ResourceUtils: ==============================================================
25/04/01 12:25:28 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:25:28 INFO ResourceUtils: ==============================================================
25/04/01 12:25:28 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:25:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:25:28 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:25:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:25:28 INFO SecurityManager: Changing view acls to: root
25/04/01 12:25:28 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:25:28 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:25:28 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:25:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:25:28 INFO Utils: Successfully started service 'sparkDriver' on port 37923.
25/04/01 12:25:29 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:25:29 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:25:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:25:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:25:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:25:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-32cbd7cf-6388-4abc-ab17-1400317c35b4
25/04/01 12:25:29 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:25:29 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:25:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:25:29 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:25:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:25:29 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 23 ms (0 ms spent in bootstraps)
25/04/01 12:25:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401122529-0045
25/04/01 12:25:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122529-0045/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:25:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122529-0045/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:25:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122529-0045/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:25:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122529-0045/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:25:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401122529-0045/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:25:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401122529-0045/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:25:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42361.
25/04/01 12:25:29 INFO NettyBlockTransferService: Server created on 7796893c36d7:42361
25/04/01 12:25:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:25:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 42361, None)
25/04/01 12:25:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122529-0045/2 is now RUNNING
25/04/01 12:25:29 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:42361 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 42361, None)
25/04/01 12:25:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122529-0045/0 is now RUNNING
25/04/01 12:25:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 42361, None)
25/04/01 12:25:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401122529-0045/1 is now RUNNING
25/04/01 12:25:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 42361, None)
25/04/01 12:25:29 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:25:29 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:25:29 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:25:31 INFO InMemoryFileIndex: It took 59 ms to list leaf files for 1 paths.
25/04/01 12:25:31 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 12:25:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:37058) with ID 2,  ResourceProfileId 0
25/04/01 12:25:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:48404) with ID 1,  ResourceProfileId 0
25/04/01 12:25:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:52868) with ID 0,  ResourceProfileId 0
25/04/01 12:25:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:40409 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 40409, None)
25/04/01 12:25:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42545 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 42545, None)
25/04/01 12:25:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:34413 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 34413, None)
25/04/01 12:25:32 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:25:32 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:25:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:25:33 INFO CodeGenerator: Code generated in 131.016517 ms
25/04/01 12:25:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:25:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:25:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:42361 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:25:33 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:25:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:25:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:25:33 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:25:33 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:25:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:25:33 INFO DAGScheduler: Missing parents: List()
25/04/01 12:25:33 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:25:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:25:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:25:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:42361 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:25:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:25:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:25:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:25:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.6, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:25:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.6:40409 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:25:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.6:40409 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:25:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1344 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:25:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:25:34 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.407 s
25/04/01 12:25:34 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:25:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:25:34 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.438220 s
25/04/01 12:25:34 INFO CodeGenerator: Code generated in 7.79856 ms
25/04/01 12:25:34 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:25:34 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:25:34 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:25:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:25:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:25:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:42361 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:25:34 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:25:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 12:25:34 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:25:34 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:25:34 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:25:35 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:25:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:25:35 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:25:35 INFO metastore: Connected to metastore.
25/04/01 12:25:35 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=c1d430b7-5ff0-4ce3-966a-a69912463673, clientType=HIVECLI]
25/04/01 12:25:35 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:25:35 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:25:35 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:25:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:25:35 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:25:35 INFO metastore: Connected to metastore.
25/04/01 12:25:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:25:35 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:25:35 INFO metastore: Connected to metastore.
25/04/01 12:25:35 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:25:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:25:35 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 12:25:35 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:25:35 INFO CodeGenerator: Code generated in 21.224922 ms
25/04/01 12:25:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/01 12:25:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/01 12:25:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:42361 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:25:35 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:25:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:25:35 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:25:35 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:25:35 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:25:35 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:25:35 INFO DAGScheduler: Missing parents: List()
25/04/01 12:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:25:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.1 MiB)
25/04/01 12:25:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/01 12:25:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:42361 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 12:25:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:25:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:42361 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:25:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:25:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/01 12:25:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:25:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.6:40409 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:25:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:40409 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 12:25:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:40409 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:25:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 308 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:25:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:25:36 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.323 s
25/04/01 12:25:36 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:25:36 INFO DAGScheduler: running: Set()
25/04/01 12:25:36 INFO DAGScheduler: waiting: Set()
25/04/01 12:25:36 INFO DAGScheduler: failed: Set()
25/04/01 12:25:36 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:25:36 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:25:36 INFO CodeGenerator: Code generated in 14.793659 ms
25/04/01 12:25:36 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:25:36 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:25:36 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:25:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:25:36 INFO DAGScheduler: Missing parents: List()
25/04/01 12:25:36 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:25:36 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.7 KiB, free 365.1 MiB)
25/04/01 12:25:36 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/01 12:25:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:42361 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:25:36 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 12:25:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:25:36 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:25:36 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:25:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:40409 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:25:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:37058
25/04/01 12:25:36 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 132 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:25:36 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:25:36 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.141 s
25/04/01 12:25:36 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:25:36 INFO DAGScheduler: running: Set()
25/04/01 12:25:36 INFO DAGScheduler: waiting: Set()
25/04/01 12:25:36 INFO DAGScheduler: failed: Set()
25/04/01 12:25:36 INFO CodeGenerator: Code generated in 6.493493 ms
25/04/01 12:25:36 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:25:36 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:25:36 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:25:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/01 12:25:36 INFO DAGScheduler: Missing parents: List()
25/04/01 12:25:36 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:25:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/01 12:25:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 12:25:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:42361 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:25:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/01 12:25:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:25:36 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/01 12:25:36 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:25:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:40409 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:25:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:37058
25/04/01 12:25:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 28 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:25:36 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/01 12:25:36 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s
25/04/01 12:25:36 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:25:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/01 12:25:36 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.036932 s
25/04/01 12:25:36 WARN SetCommand: 'SET hive.exec.dynamic.partition=true' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.exec.dynamic.partition) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
25/04/01 12:25:36 WARN SetCommand: 'SET hive.exec.dynamic.partition.mode=nonstrict' might not work, since Spark doesn't support changing the Hive config dynamically. Please pass the Hive-specific config by adding the prefix spark.hadoop (e.g. spark.hadoop.hive.exec.dynamic.partition.mode) when starting a Spark application. For details, see the link: https://spark.apache.org/docs/latest/configuration.html#dynamically-loading-spark-properties.
25/04/01 12:25:36 WARN HiveExternalCatalog: The table schema given by Hive metastore(struct<stockcode:string,productname:string,productdescription:string,unitprice:string,date:string>) is different from the schema when this table was created by Spark SQL(struct<StockCode:string,ProductName:string,ProductDescription:string,UnitPrice:decimal(10,5),Date:string>). We have to fall back to the table schema from Hive metastore which is not case preserving.
25/04/01 12:25:36 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:25:36 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:25:36 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 12:25:36 INFO FileUtils: Creating directory if it doesn't exist: hdfs://namenode:9000/user/hive/warehouse/products/.hive-staging_hive_2025-04-01_12-25-36_445_3776529775181716568-1
25/04/01 12:25:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:25:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:25:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
25/04/01 12:25:36 INFO CodeGenerator: Code generated in 12.125903 ms
25/04/01 12:25:36 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 348.5 KiB, free 364.7 MiB)
25/04/01 12:25:36 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.7 KiB, free 364.7 MiB)
25/04/01 12:25:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:42361 (size: 32.7 KiB, free: 366.1 MiB)
25/04/01 12:25:36 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:25:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:25:36 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:25:36 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:25:36 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:25:36 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:25:36 INFO DAGScheduler: Missing parents: List()
25/04/01 12:25:36 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:25:36 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/01 12:25:36 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/01 12:25:36 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:42361 (size: 14.7 KiB, free: 366.1 MiB)
25/04/01 12:25:36 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:25:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:25:36 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 12:25:36 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:25:36 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:42545 (size: 14.7 KiB, free: 366.3 MiB)
25/04/01 12:25:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:42545 (size: 32.7 KiB, free: 366.3 MiB)
25/04/01 12:25:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1622 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:25:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:25:38 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.632 s
25/04/01 12:25:38 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:25:38 INFO DAGScheduler: running: Set()
25/04/01 12:25:38 INFO DAGScheduler: waiting: Set()
25/04/01 12:25:38 INFO DAGScheduler: failed: Set()
25/04/01 12:25:38 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:25:38 INFO CodeGenerator: Code generated in 8.508645 ms
25/04/01 12:25:38 INFO CodeGenerator: Code generated in 7.810713 ms
25/04/01 12:25:38 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:25:38 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:25:38 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:25:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/01 12:25:38 INFO DAGScheduler: Missing parents: List()
25/04/01 12:25:38 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:25:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 338.3 KiB, free 364.3 MiB)
25/04/01 12:25:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 122.4 KiB, free 364.2 MiB)
25/04/01 12:25:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:42361 (size: 122.4 KiB, free: 366.0 MiB)
25/04/01 12:25:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:25:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:25:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 12:25:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:25:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:42545 (size: 122.4 KiB, free: 366.1 MiB)
25/04/01 12:25:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:48404
25/04/01 12:25:38 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 578 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:25:38 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 12:25:38 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.607 s
25/04/01 12:25:38 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:25:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/01 12:25:38 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.615868 s
25/04/01 12:25:38 INFO FileFormatWriter: Start to commit write Job fd6ca078-93ac-4c70-b8f6-d16e51429d47.
25/04/01 12:25:38 INFO FileFormatWriter: Write Job fd6ca078-93ac-4c70-b8f6-d16e51429d47 committed. Elapsed time: 50 ms.
25/04/01 12:25:38 INFO FileFormatWriter: Finished processing stats for write job fd6ca078-93ac-4c70-b8f6-d16e51429d47.
25/04/01 12:25:39 WARN HiveExternalCatalog: The table schema given by Hive metastore(struct<stockcode:string,productname:string,productdescription:string,unitprice:string,date:string>) is different from the schema when this table was created by Spark SQL(struct<StockCode:string,ProductName:string,ProductDescription:string,UnitPrice:decimal(10,5),Date:string>). We have to fall back to the table schema from Hive metastore which is not case preserving.
25/04/01 12:25:39 INFO Hive: New loading path = hdfs://namenode:9000/user/hive/warehouse/products/.hive-staging_hive_2025-04-01_12-25-36_445_3776529775181716568-1/-ext-10000/date=2025-03-29 with partSpec {date=2025-03-29}
25/04/01 12:25:39 INFO Hive: New loading path = hdfs://namenode:9000/user/hive/warehouse/products/.hive-staging_hive_2025-04-01_12-25-36_445_3776529775181716568-1/-ext-10000/date=2025-03-27 with partSpec {date=2025-03-27}
25/04/01 12:25:39 INFO FileUtils: Creating directory if it doesn't exist: hdfs://namenode:9000/user/hive/warehouse/products/date=2025-03-29
25/04/01 12:25:39 INFO FileUtils: Creating directory if it doesn't exist: hdfs://namenode:9000/user/hive/warehouse/products/date=2025-03-27
25/04/01 12:25:39 INFO Hive: Loaded 2 partitions
25/04/01 12:25:39 WARN HiveExternalCatalog: The table schema given by Hive metastore(struct<stockcode:string,productname:string,productdescription:string,unitprice:string,date:string>) is different from the schema when this table was created by Spark SQL(struct<StockCode:string,ProductName:string,ProductDescription:string,UnitPrice:decimal(10,5),Date:string>). We have to fall back to the table schema from Hive metastore which is not case preserving.
25/04/01 12:25:39 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:25:39 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:25:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:25:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:25:39 INFO MemoryStore: MemoryStore cleared
25/04/01 12:25:39 INFO BlockManager: BlockManager stopped
25/04/01 12:25:39 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:25:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:25:39 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:25:39 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:25:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-c4f57db3-8786-4263-9189-d4a54cd6365d
25/04/01 12:25:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-6377c411-c3b0-40d5-b2d4-3637e85e0599/pyspark-4c7dd576-8b98-4869-b41a-633b05f83e7f
25/04/01 12:25:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-6377c411-c3b0-40d5-b2d4-3637e85e0599
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:42:05 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:42:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:42:05 INFO ResourceUtils: ==============================================================
25/04/01 12:42:05 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:42:05 INFO ResourceUtils: ==============================================================
25/04/01 12:42:05 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:42:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:42:05 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:42:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:42:05 INFO SecurityManager: Changing view acls to: root
25/04/01 12:42:05 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:42:05 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:42:05 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:42:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:42:05 INFO Utils: Successfully started service 'sparkDriver' on port 41681.
25/04/01 12:42:05 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:42:05 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:42:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:42:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:42:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:42:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b508d7f7-44bd-44f5-9555-356371eb246d
25/04/01 12:42:05 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:42:05 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:42:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:42:05 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:42:06 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:42:06 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 12:42:06 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401124206-0046
25/04/01 12:42:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124206-0046/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:42:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124206-0046/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:42:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124206-0046/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:42:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124206-0046/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:42:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124206-0046/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:42:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124206-0046/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:42:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34029.
25/04/01 12:42:06 INFO NettyBlockTransferService: Server created on 7796893c36d7:34029
25/04/01 12:42:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:42:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 34029, None)
25/04/01 12:42:06 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:34029 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 34029, None)
25/04/01 12:42:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124206-0046/2 is now RUNNING
25/04/01 12:42:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124206-0046/1 is now RUNNING
25/04/01 12:42:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 34029, None)
25/04/01 12:42:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 34029, None)
25/04/01 12:42:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124206-0046/0 is now RUNNING
25/04/01 12:42:06 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:42:06 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:42:06 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:42:07 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/01 12:42:07 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 12:42:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:50926) with ID 2,  ResourceProfileId 0
25/04/01 12:42:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:53484) with ID 0,  ResourceProfileId 0
25/04/01 12:42:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:60996) with ID 1,  ResourceProfileId 0
25/04/01 12:42:08 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:34035 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 34035, None)
25/04/01 12:42:08 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:41911 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 41911, None)
25/04/01 12:42:08 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:34405 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 34405, None)
25/04/01 12:42:09 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:42:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:42:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:42:09 INFO CodeGenerator: Code generated in 139.133937 ms
25/04/01 12:42:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:42:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:42:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:34029 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:42:09 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:42:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:42:10 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:42:10 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:42:10 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:42:10 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:42:10 INFO DAGScheduler: Missing parents: List()
25/04/01 12:42:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:42:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:42:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:42:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:34029 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:42:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:42:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:42:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:42:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:34405 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:42:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:34405 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:42:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1380 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:42:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:42:11 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.444 s
25/04/01 12:42:11 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:42:11 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.476717 s
25/04/01 12:42:11 INFO CodeGenerator: Code generated in 8.772365 ms
25/04/01 12:42:11 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:42:11 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:42:11 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:42:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:42:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:42:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:34029 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:42:11 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:42:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 12:42:11 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:42:11 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:42:11 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:42:12 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:42:12 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:42:12 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:42:12 INFO metastore: Connected to metastore.
25/04/01 12:42:12 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=a6d1259d-4484-481e-852e-2216fa75386b, clientType=HIVECLI]
25/04/01 12:42:12 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:42:12 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:42:12 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:42:12 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:42:12 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:42:12 INFO metastore: Connected to metastore.
25/04/01 12:42:12 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:42:12 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:42:12 INFO metastore: Connected to metastore.




25/04/01 12:42:12 INFO DataSourceStrategy: Pruning directories with: 
25/04/01 12:42:12 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:42:12 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:42:12 INFO FileSourceStrategy: Output Data Schema: struct<>
25/04/01 12:42:12 INFO CodeGenerator: Code generated in 13.528955 ms
25/04/01 12:42:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.5 KiB, free 365.2 MiB)
25/04/01 12:42:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 12:42:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:34029 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 12:42:12 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:42:12 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 12:42:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:42:12 INFO CodeGenerator: Code generated in 7.612918 ms
25/04/01 12:42:12 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:42:12 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:42:12 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:42:12 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:42:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
25/04/01 12:42:12 INFO DAGScheduler: Missing parents: List()
25/04/01 12:42:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:42:12 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.0 KiB, free 365.2 MiB)
25/04/01 12:42:12 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 365.2 MiB)
25/04/01 12:42:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:34029 (size: 5.4 KiB, free: 366.2 MiB)
25/04/01 12:42:12 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:42:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:42:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/04/01 12:42:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (172.18.0.8, executor 1, partition 0, PROCESS_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:42:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:34029 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:42:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:34405 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:42:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:41911 (size: 5.4 KiB, free: 366.3 MiB)
25/04/01 12:42:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:60996
25/04/01 12:42:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 750 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:42:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/04/01 12:42:13 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.758 s
25/04/01 12:42:13 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:42:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/04/01 12:42:13 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.767166 s
0




25/04/01 12:42:13 INFO DataSourceStrategy: Pruning directories with: 
25/04/01 12:42:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:42:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:42:13 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, UnitPrice: decimal(10,5) ... 2 more fields>
25/04/01 12:42:13 INFO CodeGenerator: Code generated in 18.039073 ms
25/04/01 12:42:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 350.6 KiB, free 364.8 MiB)
25/04/01 12:42:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.7 KiB, free 364.8 MiB)
25/04/01 12:42:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:34029 (size: 33.7 KiB, free: 366.2 MiB)
25/04/01 12:42:13 INFO SparkContext: Created broadcast 5 from showString at NativeMethodAccessorImpl.java:0
25/04/01 12:42:13 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 0 paths.
25/04/01 12:42:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
+---------+-----------+------------------+---------+----+
|StockCode|ProductName|ProductDescription|UnitPrice|Date|
+---------+-----------+------------------+---------+----+
+---------+-----------+------------------+---------+----+

25/04/01 12:42:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:42:13 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:42:13 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 12:42:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:42:13 INFO CodeGenerator: Code generated in 16.15264 ms
25/04/01 12:42:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 345.6 KiB, free 364.5 MiB)
25/04/01 12:42:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.4 MiB)
25/04/01 12:42:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:34029 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:42:13 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:42:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:42:13 INFO DAGScheduler: Registering RDD 24 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:42:13 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:42:13 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:42:13 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:42:13 INFO DAGScheduler: Missing parents: List()
25/04/01 12:42:13 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:42:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 29.9 KiB, free 364.4 MiB)
25/04/01 12:42:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.4 MiB)
25/04/01 12:42:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:34029 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 12:42:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:42:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:42:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:42:13 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:42:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.8:41911 (size: 14.1 KiB, free: 366.3 MiB)
25/04/01 12:42:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:41911 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:42:14 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 906 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:42:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:42:14 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.917 s
25/04/01 12:42:14 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:42:14 INFO DAGScheduler: running: Set()
25/04/01 12:42:14 INFO DAGScheduler: waiting: Set()
25/04/01 12:42:14 INFO DAGScheduler: failed: Set()
25/04/01 12:42:14 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:42:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:42:14 INFO CodeGenerator: Code generated in 11.171927 ms
25/04/01 12:42:14 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:42:14 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:42:14 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:42:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/04/01 12:42:14 INFO DAGScheduler: Missing parents: List()
25/04/01 12:42:14 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:42:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 37.6 KiB, free 364.3 MiB)
25/04/01 12:42:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 364.3 MiB)
25/04/01 12:42:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:34029 (size: 17.8 KiB, free: 366.1 MiB)
25/04/01 12:42:14 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/01 12:42:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:42:14 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 12:42:14 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:42:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:41911 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:42:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:60996
25/04/01 12:42:14 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 86 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:42:14 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 12:42:14 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.094 s
25/04/01 12:42:14 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:42:14 INFO DAGScheduler: running: Set()
25/04/01 12:42:14 INFO DAGScheduler: waiting: Set()
25/04/01 12:42:14 INFO DAGScheduler: failed: Set()
25/04/01 12:42:14 INFO CodeGenerator: Code generated in 7.168374 ms
25/04/01 12:42:14 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:42:14 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:42:14 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:42:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
25/04/01 12:42:14 INFO DAGScheduler: Missing parents: List()
25/04/01 12:42:14 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:42:14 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KiB, free 364.3 MiB)
25/04/01 12:42:14 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.3 MiB)
25/04/01 12:42:14 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:34029 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:42:14 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:42:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:42:14 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/04/01 12:42:14 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 4) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:42:14 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:41911 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:42:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:60996
25/04/01 12:42:14 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 4) in 27 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:42:14 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/04/01 12:42:14 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/01 12:42:14 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:42:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/04/01 12:42:14 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.035314 s
25/04/01 12:42:14 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:42:14 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:42:14 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 12:42:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:42:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:42:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:42:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:42:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:42:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:42:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:42:15 INFO CodeGenerator: Code generated in 11.09147 ms
25/04/01 12:42:15 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 345.6 KiB, free 364.0 MiB)
25/04/01 12:42:15 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.9 MiB)
25/04/01 12:42:15 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:34029 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:42:15 INFO SparkContext: Created broadcast 10 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:42:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:42:15 INFO DAGScheduler: Registering RDD 35 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 12:42:15 INFO DAGScheduler: Got map stage job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:42:15 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:42:15 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:42:15 INFO DAGScheduler: Missing parents: List()
25/04/01 12:42:15 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:42:15 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 31.8 KiB, free 363.9 MiB)
25/04/01 12:42:15 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 363.9 MiB)
25/04/01 12:42:15 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:34029 (size: 14.7 KiB, free: 366.1 MiB)
25/04/01 12:42:15 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 12:42:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:42:15 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/01 12:42:15 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:42:15 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:41911 (size: 14.7 KiB, free: 366.2 MiB)
25/04/01 12:42:15 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:41911 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:42:15 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 236 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:42:15 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/01 12:42:15 INFO DAGScheduler: ShuffleMapStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.245 s
25/04/01 12:42:15 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:42:15 INFO DAGScheduler: running: Set()
25/04/01 12:42:15 INFO DAGScheduler: waiting: Set()
25/04/01 12:42:15 INFO DAGScheduler: failed: Set()
25/04/01 12:42:15 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:42:15 INFO CodeGenerator: Code generated in 6.432937 ms
25/04/01 12:42:15 INFO CodeGenerator: Code generated in 7.176126 ms
25/04/01 12:42:15 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:42:15 INFO DAGScheduler: Got job 6 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:42:15 INFO DAGScheduler: Final stage: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:42:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
25/04/01 12:42:15 INFO DAGScheduler: Missing parents: List()
25/04/01 12:42:15 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[41] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:42:15 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 238.6 KiB, free 363.7 MiB)
25/04/01 12:42:15 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 363.6 MiB)
25/04/01 12:42:15 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:34029 (size: 87.8 KiB, free: 366.0 MiB)
25/04/01 12:42:15 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1478
25/04/01 12:42:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:42:15 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 12:42:15 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 6) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:42:15 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.8:41911 (size: 87.8 KiB, free: 366.1 MiB)
25/04/01 12:42:15 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.8:60996
25/04/01 12:42:16 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 6) in 885 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:42:16 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 12:42:16 INFO DAGScheduler: ResultStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.906 s
25/04/01 12:42:16 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:42:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/04/01 12:42:16 INFO DAGScheduler: Job 6 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.912030 s
25/04/01 12:42:16 INFO FileFormatWriter: Start to commit write Job c046f351-28d2-4519-b702-73802f21c020.
25/04/01 12:42:16 INFO FileFormatWriter: Write Job c046f351-28d2-4519-b702-73802f21c020 committed. Elapsed time: 37 ms.
25/04/01 12:42:16 INFO FileFormatWriter: Finished processing stats for write job c046f351-28d2-4519-b702-73802f21c020.
25/04/01 12:42:16 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:42:16 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:42:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:42:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:42:16 INFO MemoryStore: MemoryStore cleared
25/04/01 12:42:16 INFO BlockManager: BlockManager stopped
25/04/01 12:42:16 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:42:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:42:16 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:42:16 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:42:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-814a587b-1963-4e87-91a2-491d40425dbb
25/04/01 12:42:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-b15759c8-24bb-4fd9-b648-4dcd4dd17de5/pyspark-1f467802-2351-49a3-b085-87213733f53a
25/04/01 12:42:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-b15759c8-24bb-4fd9-b648-4dcd4dd17de5
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:43:08 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:43:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:43:09 INFO ResourceUtils: ==============================================================
25/04/01 12:43:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:43:09 INFO ResourceUtils: ==============================================================
25/04/01 12:43:09 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:43:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:43:09 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:43:09 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:43:09 INFO SecurityManager: Changing view acls to: root
25/04/01 12:43:09 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:43:09 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:43:09 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:43:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:43:09 INFO Utils: Successfully started service 'sparkDriver' on port 45987.
25/04/01 12:43:09 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:43:09 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:43:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:43:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:43:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:43:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-91c9f1fd-5c15-4196-823c-9f6484b73394
25/04/01 12:43:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:43:09 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:43:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:43:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:43:09 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:43:09 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 21 ms (0 ms spent in bootstraps)
25/04/01 12:43:09 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401124309-0047
25/04/01 12:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124309-0047/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:43:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124309-0047/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124309-0047/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:43:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124309-0047/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124309-0047/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:43:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124309-0047/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:43:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46497.
25/04/01 12:43:09 INFO NettyBlockTransferService: Server created on 7796893c36d7:46497
25/04/01 12:43:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:43:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 46497, None)
25/04/01 12:43:09 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:46497 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 46497, None)
25/04/01 12:43:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 46497, None)
25/04/01 12:43:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 46497, None)
25/04/01 12:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124309-0047/0 is now RUNNING
25/04/01 12:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124309-0047/2 is now RUNNING
25/04/01 12:43:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124309-0047/1 is now RUNNING
25/04/01 12:43:10 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:43:10 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:43:10 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:43:11 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/01 12:43:11 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/01 12:43:11 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:44240) with ID 0,  ResourceProfileId 0
25/04/01 12:43:11 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:60552) with ID 2,  ResourceProfileId 0
25/04/01 12:43:11 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:51802) with ID 1,  ResourceProfileId 0
25/04/01 12:43:11 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:42657 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 42657, None)
25/04/01 12:43:11 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:41275 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 41275, None)
25/04/01 12:43:11 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:37591 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 37591, None)
25/04/01 12:43:12 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:43:12 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:43:12 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:43:13 INFO CodeGenerator: Code generated in 131.470106 ms
25/04/01 12:43:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:43:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:43:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:46497 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:43:13 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:43:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:43:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:43:13 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:43:13 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:13 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:43:13 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:43:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:43:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:46497 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:43:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:43:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:43:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:43:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:37591 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:43:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:37591 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:43:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1386 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:43:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:43:14 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.450 s
25/04/01 12:43:14 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:43:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:43:14 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.481934 s
25/04/01 12:43:15 INFO CodeGenerator: Code generated in 8.033088 ms
25/04/01 12:43:15 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:43:15 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:43:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:43:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:43:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:43:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:46497 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:43:15 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:43:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 12:43:15 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:43:15 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:43:15 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:43:15 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:43:15 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:43:15 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:43:15 INFO metastore: Connected to metastore.
25/04/01 12:43:15 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=515a9bbc-e60d-491f-8b32-8fcf86605413, clientType=HIVECLI]
25/04/01 12:43:15 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:43:15 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:43:15 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:43:15 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:43:15 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:43:15 INFO metastore: Connected to metastore.
25/04/01 12:43:15 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:43:15 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:43:15 INFO metastore: Connected to metastore.




25/04/01 12:43:15 INFO DataSourceStrategy: Pruning directories with: 
25/04/01 12:43:15 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:43:15 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:43:15 INFO FileSourceStrategy: Output Data Schema: struct<>
25/04/01 12:43:16 INFO CodeGenerator: Code generated in 13.829695 ms
25/04/01 12:43:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.5 KiB, free 365.2 MiB)
25/04/01 12:43:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 12:43:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:46497 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 12:43:16 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:43:16 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:46497 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:43:16 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:37591 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:43:16 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 2 paths.
25/04/01 12:43:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:43:16 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:43:16 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
25/04/01 12:43:16 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:16 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:43:16 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:16 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:16 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.9 KiB, free 365.2 MiB)
25/04/01 12:43:16 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 365.2 MiB)
25/04/01 12:43:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:46497 (size: 7.4 KiB, free: 366.2 MiB)
25/04/01 12:43:16 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:16 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
25/04/01 12:43:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks resource profile 0
25/04/01 12:43:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 2, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 12:43:16 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 1, partition 1, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 12:43:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:37591 (size: 7.4 KiB, free: 366.3 MiB)
25/04/01 12:43:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:37591 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 12:43:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:41275 (size: 7.4 KiB, free: 366.3 MiB)
25/04/01 12:43:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 533 ms on 172.18.0.8 (executor 1) (1/2)
25/04/01 12:43:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:41275 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 12:43:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1658 ms on 172.18.0.6 (executor 2) (2/2)
25/04/01 12:43:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:43:17 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.677 s
25/04/01 12:43:17 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:43:17 INFO DAGScheduler: running: Set()
25/04/01 12:43:17 INFO DAGScheduler: waiting: Set()
25/04/01 12:43:17 INFO DAGScheduler: failed: Set()
25/04/01 12:43:17 INFO CodeGenerator: Code generated in 7.678081 ms
25/04/01 12:43:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:43:17 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:43:17 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:43:17 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:17 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:17 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KiB, free 365.2 MiB)
25/04/01 12:43:17 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 12:43:17 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:46497 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:43:17 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:43:17 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:43:17 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:43:17 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:41275 (size: 5.5 KiB, free: 366.3 MiB)
25/04/01 12:43:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:60552
25/04/01 12:43:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 177 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:43:18 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:43:18 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.183 s
25/04/01 12:43:18 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:43:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 12:43:18 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.188817 s
102




25/04/01 12:43:18 INFO DataSourceStrategy: Pruning directories with: 
25/04/01 12:43:18 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:43:18 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:43:18 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, UnitPrice: decimal(10,5) ... 2 more fields>
25/04/01 12:43:18 INFO CodeGenerator: Code generated in 14.661164 ms
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 350.6 KiB, free 364.8 MiB)
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 33.7 KiB, free 364.8 MiB)
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:46497 (size: 33.7 KiB, free: 366.2 MiB)
25/04/01 12:43:18 INFO SparkContext: Created broadcast 6 from showString at NativeMethodAccessorImpl.java:0
25/04/01 12:43:18 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 2 paths.
25/04/01 12:43:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:43:18 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 12:43:18 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:43:18 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:18 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:43:18 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 15.5 KiB, free 364.8 MiB)
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 364.8 MiB)
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:46497 (size: 6.4 KiB, free: 366.2 MiB)
25/04/01 12:43:18 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:43:18 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 12:43:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:41275 (size: 6.4 KiB, free: 366.2 MiB)
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:41275 (size: 33.7 KiB, free: 366.2 MiB)
25/04/01 12:43:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 207 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:43:18 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 12:43:18 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0.216 s
25/04/01 12:43:18 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:43:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 12:43:18 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.218877 s
25/04/01 12:43:18 INFO CodeGenerator: Code generated in 8.609914 ms
+---------+--------------------+--------------------+---------+----------+
|StockCode|         ProductName|  ProductDescription|UnitPrice|      Date|
+---------+--------------------+--------------------+---------+----------+
|     1005|The Urbz: Sims in...|          Simulation| 12.95000|2025-03-27|
|     1025|Brain Agey: More ...|              Action| 17.95000|2025-03-27|
|     1026|Grand Theft Auto:...|Action,Racing / D...| 17.95000|2025-03-27|
|     1039|Mario & Luigi: Pa...|Action,Role-Playi...| 29.95000|2025-03-27|
|     1040|       Madden NFL 06|              Sports|  7.95000|2025-03-27|
|     1056|     Dead or Alive 4|              Action| 17.95000|2025-03-27|
|     1062|    Yoshi Touch & Go|              Action| 17.95000|2025-03-27|
|     1077|          Madagascar|           Adventure| 14.95000|2025-03-27|
|     1088|Harry Potter and ...|              Action| 17.95000|2025-03-27|
|     1108| Kingdom of Paradise|Action,Role-Playi...| 12.95000|2025-03-27|
|     1125|The Lord of the R...|Role-Playing (RPG...| 19.95000|2025-03-27|
|    11333|    Valhalla Knights|Action,Role-Playi...| 16.95000|2025-03-27|
|     1166|       Madden NFL 07|              Sports|  4.95000|2025-03-27|
|     1175|Rayman Raving Rab...|              Action| 17.95000|2025-03-27|
|     1179|      Call of Duty 3|              Action| 19.95000|2025-03-27|
|     1200|Mortal Kombat: Un...|              Action| 17.95000|2025-03-27|
|     1224|        Excite Truck|    Racing / Driving| 19.95000|2025-03-27|
|     1227|Metal Gear Solid:...|     Action,Strategy| 17.95000|2025-03-27|
|     1229|Blazing Angels: S...|              Action| 16.95000|2025-03-27|
|     1234|WWE SmackDown vs....|              Sports| 14.95000|2025-03-27|
+---------+--------------------+--------------------+---------+----------+
only showing top 20 rows

25/04/01 12:43:18 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:43:18 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:43:18 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 12:43:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:43:18 INFO CodeGenerator: Code generated in 14.925447 ms
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 345.6 KiB, free 364.4 MiB)
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.4 MiB)
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:46497 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:43:18 INFO SparkContext: Created broadcast 8 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:43:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:43:18 INFO DAGScheduler: Registering RDD 24 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:43:18 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:43:18 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:18 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:43:18 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:18 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 29.9 KiB, free 364.4 MiB)
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.3 MiB)
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:46497 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 12:43:18 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:43:18 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 12:43:18 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.8:37591 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.8:37591 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:43:18 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 241 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:43:18 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 12:43:18 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.246 s
25/04/01 12:43:18 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:43:18 INFO DAGScheduler: running: Set()
25/04/01 12:43:18 INFO DAGScheduler: waiting: Set()
25/04/01 12:43:18 INFO DAGScheduler: failed: Set()
25/04/01 12:43:18 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:43:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:43:18 INFO CodeGenerator: Code generated in 10.872585 ms
25/04/01 12:43:18 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:43:18 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:43:18 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 12:43:18 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:18 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 37.6 KiB, free 364.3 MiB)
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 364.3 MiB)
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:46497 (size: 17.8 KiB, free: 366.1 MiB)
25/04/01 12:43:18 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:43:18 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 12:43:18 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.8:37591 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:43:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:51802
25/04/01 12:43:18 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 111 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:43:18 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:43:18 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.117 s
25/04/01 12:43:18 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:43:18 INFO DAGScheduler: running: Set()
25/04/01 12:43:18 INFO DAGScheduler: waiting: Set()
25/04/01 12:43:18 INFO DAGScheduler: failed: Set()
25/04/01 12:43:18 INFO CodeGenerator: Code generated in 6.614666 ms
25/04/01 12:43:18 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:43:18 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:43:18 INFO DAGScheduler: Final stage: ResultStage 10 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 12:43:18 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:18 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 11.0 KiB, free 364.3 MiB)
25/04/01 12:43:18 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.3 MiB)
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:46497 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:43:18 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:43:18 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 12:43:18 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:43:18 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.8:37591 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:43:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.8:51802
25/04/01 12:43:18 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 26 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:43:18 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 12:43:18 INFO DAGScheduler: ResultStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.029 s
25/04/01 12:43:18 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:43:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/04/01 12:43:18 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.032123 s
25/04/01 12:43:18 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:43:18 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:43:18 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 12:43:19 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:43:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:43:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:43:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:43:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:43:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:43:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:43:19 INFO CodeGenerator: Code generated in 13.246305 ms
25/04/01 12:43:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 345.6 KiB, free 363.9 MiB)
25/04/01 12:43:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.9 MiB)
25/04/01 12:43:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:46497 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:43:19 INFO SparkContext: Created broadcast 12 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:43:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:43:19 INFO DAGScheduler: Registering RDD 35 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 12:43:19 INFO DAGScheduler: Got map stage job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:43:19 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:19 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:43:19 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:19 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[35] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:19 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.8 KiB, free 363.9 MiB)
25/04/01 12:43:19 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 363.9 MiB)
25/04/01 12:43:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:46497 (size: 14.7 KiB, free: 366.0 MiB)
25/04/01 12:43:19 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[35] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:43:19 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 12:43:19 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:43:19 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.6:41275 (size: 14.7 KiB, free: 366.2 MiB)
25/04/01 12:43:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.6:41275 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:43:19 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 399 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:43:19 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 12:43:19 INFO DAGScheduler: ShuffleMapStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.410 s
25/04/01 12:43:19 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:43:19 INFO DAGScheduler: running: Set()
25/04/01 12:43:19 INFO DAGScheduler: waiting: Set()
25/04/01 12:43:19 INFO DAGScheduler: failed: Set()
25/04/01 12:43:19 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:43:19 INFO CodeGenerator: Code generated in 5.581215 ms
25/04/01 12:43:19 INFO CodeGenerator: Code generated in 6.514443 ms
25/04/01 12:43:19 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:43:19 INFO DAGScheduler: Got job 8 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:43:19 INFO DAGScheduler: Final stage: ResultStage 13 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:43:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/04/01 12:43:19 INFO DAGScheduler: Missing parents: List()
25/04/01 12:43:19 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[41] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:43:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 238.6 KiB, free 363.6 MiB)
25/04/01 12:43:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 363.5 MiB)
25/04/01 12:43:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:46497 (size: 87.8 KiB, free: 366.0 MiB)
25/04/01 12:43:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 12:43:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[41] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:43:19 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/04/01 12:43:19 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 9) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:43:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.6:41275 (size: 87.8 KiB, free: 366.1 MiB)
25/04/01 12:43:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.6:60552
25/04/01 12:43:20 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 9) in 525 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:43:20 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/04/01 12:43:20 INFO DAGScheduler: ResultStage 13 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.551 s
25/04/01 12:43:20 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:43:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/04/01 12:43:20 INFO DAGScheduler: Job 8 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.557047 s
25/04/01 12:43:20 INFO FileFormatWriter: Start to commit write Job 0c8ebea2-2cb6-40c4-812d-4026fe3d68ac.
25/04/01 12:43:20 INFO FileFormatWriter: Write Job 0c8ebea2-2cb6-40c4-812d-4026fe3d68ac committed. Elapsed time: 40 ms.
25/04/01 12:43:20 INFO FileFormatWriter: Finished processing stats for write job 0c8ebea2-2cb6-40c4-812d-4026fe3d68ac.
25/04/01 12:43:20 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:43:20 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:43:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:43:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:43:20 INFO MemoryStore: MemoryStore cleared
25/04/01 12:43:20 INFO BlockManager: BlockManager stopped
25/04/01 12:43:20 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:43:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:43:20 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:43:20 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:43:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-719a0763-2f5d-4244-a123-b631861ab4c4
25/04/01 12:43:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-e0f99435-7937-41ea-a14f-02ac73f4b072
25/04/01 12:43:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-e0f99435-7937-41ea-a14f-02ac73f4b072/pyspark-2aae617e-85fd-4420-a7aa-4eec79c31a2d
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/01 12:44:28 INFO SparkContext: Running Spark version 3.2.2
25/04/01 12:44:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/01 12:44:28 INFO ResourceUtils: ==============================================================
25/04/01 12:44:28 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/01 12:44:28 INFO ResourceUtils: ==============================================================
25/04/01 12:44:28 INFO SparkContext: Submitted application: Load product data into Hive
25/04/01 12:44:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/01 12:44:28 INFO ResourceProfile: Limiting resource is cpu
25/04/01 12:44:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/01 12:44:28 INFO SecurityManager: Changing view acls to: root
25/04/01 12:44:28 INFO SecurityManager: Changing modify acls to: root
25/04/01 12:44:28 INFO SecurityManager: Changing view acls groups to: 
25/04/01 12:44:28 INFO SecurityManager: Changing modify acls groups to: 
25/04/01 12:44:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/01 12:44:28 INFO Utils: Successfully started service 'sparkDriver' on port 44001.
25/04/01 12:44:28 INFO SparkEnv: Registering MapOutputTracker
25/04/01 12:44:28 INFO SparkEnv: Registering BlockManagerMaster
25/04/01 12:44:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/01 12:44:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/01 12:44:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/01 12:44:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50ccc795-e4f4-41bd-9b13-0586771f7cfc
25/04/01 12:44:29 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/01 12:44:29 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/01 12:44:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/01 12:44:29 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/01 12:44:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/01 12:44:29 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 22 ms (0 ms spent in bootstraps)
25/04/01 12:44:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250401124429-0048
25/04/01 12:44:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124429-0048/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/01 12:44:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124429-0048/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:44:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124429-0048/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/01 12:44:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124429-0048/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:44:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250401124429-0048/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/01 12:44:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20250401124429-0048/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/01 12:44:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35237.
25/04/01 12:44:29 INFO NettyBlockTransferService: Server created on 7796893c36d7:35237
25/04/01 12:44:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/01 12:44:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 35237, None)
25/04/01 12:44:29 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:35237 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 35237, None)
25/04/01 12:44:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124429-0048/0 is now RUNNING
25/04/01 12:44:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124429-0048/2 is now RUNNING
25/04/01 12:44:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 35237, None)
25/04/01 12:44:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250401124429-0048/1 is now RUNNING
25/04/01 12:44:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 35237, None)
25/04/01 12:44:29 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/01 12:44:29 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/01 12:44:29 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/01 12:44:31 INFO InMemoryFileIndex: It took 59 ms to list leaf files for 1 paths.
25/04/01 12:44:31 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/01 12:44:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:56426) with ID 0,  ResourceProfileId 0
25/04/01 12:44:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:48092) with ID 1,  ResourceProfileId 0
25/04/01 12:44:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:58556) with ID 2,  ResourceProfileId 0
25/04/01 12:44:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:40035 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 40035, None)
25/04/01 12:44:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:35587 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 35587, None)
25/04/01 12:44:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:40733 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 40733, None)
25/04/01 12:44:32 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:44:32 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/01 12:44:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:44:33 INFO CodeGenerator: Code generated in 131.3196 ms
25/04/01 12:44:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/01 12:44:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/01 12:44:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:35237 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:44:33 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:44:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:44:33 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/01 12:44:33 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:44:33 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:33 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:44:33 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:33 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/01 12:44:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/01 12:44:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:35237 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:44:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:44:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/01 12:44:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/01 12:44:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:40035 (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:44:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:40035 (size: 32.6 KiB, free: 366.3 MiB)
25/04/01 12:44:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1363 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:44:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/01 12:44:34 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.427 s
25/04/01 12:44:34 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:44:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/01 12:44:34 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.457070 s
25/04/01 12:44:34 INFO CodeGenerator: Code generated in 8.348844 ms
25/04/01 12:44:34 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:44:34 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:44:34 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/01 12:44:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/01 12:44:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/01 12:44:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:35237 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:44:34 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/01 12:44:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
root
 |-- StockCode: string (nullable = true)
 |-- ProductName: string (nullable = true)
 |-- ProductDescription: string (nullable = true)
 |-- Date: string (nullable = true)
 |-- UnitPrice: string (nullable = true)

root
 |-- stockcode: string (nullable = true)
 |-- productname: string (nullable = true)
 |-- productdescription: string (nullable = true)
 |-- unitprice: decimal(10,5) (nullable = true)
 |-- date: string (nullable = true)

25/04/01 12:44:34 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:44:34 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/01 12:44:34 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/01 12:44:35 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/01 12:44:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:44:35 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:44:35 INFO metastore: Connected to metastore.
25/04/01 12:44:35 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=8c912246-00d1-4a22-af93-f2d678f75ea6, clientType=HIVECLI]
25/04/01 12:44:35 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/01 12:44:35 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/01 12:44:35 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/01 12:44:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:44:35 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/01 12:44:35 INFO metastore: Connected to metastore.
25/04/01 12:44:35 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/01 12:44:35 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/01 12:44:35 INFO metastore: Connected to metastore.




25/04/01 12:44:35 INFO DataSourceStrategy: Pruning directories with: 
25/04/01 12:44:35 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:44:35 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:44:35 INFO FileSourceStrategy: Output Data Schema: struct<>
25/04/01 12:44:35 INFO CodeGenerator: Code generated in 14.346596 ms
25/04/01 12:44:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 349.5 KiB, free 365.2 MiB)
25/04/01 12:44:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 33.4 KiB, free 365.2 MiB)
25/04/01 12:44:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:35237 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 12:44:35 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:44:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:35237 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/01 12:44:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:40035 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/01 12:44:35 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 2 paths.
25/04/01 12:44:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:44:35 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/01 12:44:35 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/04/01 12:44:35 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:35 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:44:35 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.9 KiB, free 365.2 MiB)
25/04/01 12:44:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 365.2 MiB)
25/04/01 12:44:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:35237 (size: 7.4 KiB, free: 366.2 MiB)
25/04/01 12:44:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:35 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/04/01 12:44:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
25/04/01 12:44:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 0, partition 0, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 12:44:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.18.0.8, executor 1, partition 1, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 12:44:35 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.18.0.6, executor 2, partition 2, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 12:44:35 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.18.0.2, executor 0, partition 3, ANY, 5025 bytes) taskResourceAssignments Map()
25/04/01 12:44:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:40035 (size: 7.4 KiB, free: 366.3 MiB)
25/04/01 12:44:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:40035 (size: 33.4 KiB, free: 366.2 MiB)
25/04/01 12:44:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:35587 (size: 7.4 KiB, free: 366.3 MiB)
25/04/01 12:44:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:40733 (size: 7.4 KiB, free: 366.3 MiB)
25/04/01 12:44:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 645 ms on 172.18.0.2 (executor 0) (1/4)
25/04/01 12:44:36 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 644 ms on 172.18.0.2 (executor 0) (2/4)
25/04/01 12:44:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:35587 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 12:44:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:40733 (size: 33.4 KiB, free: 366.3 MiB)
25/04/01 12:44:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 1868 ms on 172.18.0.8 (executor 1) (3/4)
25/04/01 12:44:37 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 1871 ms on 172.18.0.6 (executor 2) (4/4)
25/04/01 12:44:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/01 12:44:37 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.890 s
25/04/01 12:44:37 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:44:37 INFO DAGScheduler: running: Set()
25/04/01 12:44:37 INFO DAGScheduler: waiting: Set()
25/04/01 12:44:37 INFO DAGScheduler: failed: Set()
25/04/01 12:44:37 INFO CodeGenerator: Code generated in 8.948088 ms
25/04/01 12:44:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:44:37 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:44:37 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/01 12:44:37 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KiB, free 365.2 MiB)
25/04/01 12:44:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/01 12:44:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:35237 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:44:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:44:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/01 12:44:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:44:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:35587 (size: 5.5 KiB, free: 366.3 MiB)
25/04/01 12:44:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:48092
25/04/01 12:44:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 175 ms on 172.18.0.8 (executor 1) (1/1)
25/04/01 12:44:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/01 12:44:37 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.180 s
25/04/01 12:44:37 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:44:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
25/04/01 12:44:37 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.185722 s
204




25/04/01 12:44:37 INFO DataSourceStrategy: Pruning directories with: 
25/04/01 12:44:37 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:44:37 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:44:37 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, UnitPrice: decimal(10,5) ... 2 more fields>
25/04/01 12:44:37 INFO CodeGenerator: Code generated in 15.912244 ms
25/04/01 12:44:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 350.6 KiB, free 364.8 MiB)
25/04/01 12:44:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 33.7 KiB, free 364.8 MiB)
25/04/01 12:44:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:35237 (size: 33.7 KiB, free: 366.2 MiB)
25/04/01 12:44:37 INFO SparkContext: Created broadcast 6 from showString at NativeMethodAccessorImpl.java:0
25/04/01 12:44:37 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 2 paths.
25/04/01 12:44:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:44:37 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
25/04/01 12:44:37 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:44:37 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:37 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:44:37 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:37 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 15.5 KiB, free 364.8 MiB)
25/04/01 12:44:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 364.8 MiB)
25/04/01 12:44:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:35237 (size: 6.4 KiB, free: 366.2 MiB)
25/04/01 12:44:37 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:44:37 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/04/01 12:44:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6) (172.18.0.2, executor 0, partition 0, ANY, 5036 bytes) taskResourceAssignments Map()
25/04/01 12:44:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:40035 (size: 6.4 KiB, free: 366.2 MiB)
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:40035 (size: 33.7 KiB, free: 366.2 MiB)
25/04/01 12:44:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 201 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:44:38 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/04/01 12:44:38 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0.209 s
25/04/01 12:44:38 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:44:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/04/01 12:44:38 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.211226 s
25/04/01 12:44:38 INFO CodeGenerator: Code generated in 7.782216 ms
+---------+--------------------+--------------------+---------+----------+
|StockCode|         ProductName|  ProductDescription|UnitPrice|      Date|
+---------+--------------------+--------------------+---------+----------+
|     1005|The Urbz: Sims in...|          Simulation| 12.95000|2025-03-27|
|     1025|Brain Agey: More ...|              Action| 17.95000|2025-03-27|
|     1026|Grand Theft Auto:...|Action,Racing / D...| 17.95000|2025-03-27|
|     1039|Mario & Luigi: Pa...|Action,Role-Playi...| 29.95000|2025-03-27|
|     1040|       Madden NFL 06|              Sports|  7.95000|2025-03-27|
|     1056|     Dead or Alive 4|              Action| 17.95000|2025-03-27|
|     1062|    Yoshi Touch & Go|              Action| 17.95000|2025-03-27|
|     1077|          Madagascar|           Adventure| 14.95000|2025-03-27|
|     1088|Harry Potter and ...|              Action| 17.95000|2025-03-27|
|     1108| Kingdom of Paradise|Action,Role-Playi...| 12.95000|2025-03-27|
|     1125|The Lord of the R...|Role-Playing (RPG...| 19.95000|2025-03-27|
|    11333|    Valhalla Knights|Action,Role-Playi...| 16.95000|2025-03-27|
|     1166|       Madden NFL 07|              Sports|  4.95000|2025-03-27|
|     1175|Rayman Raving Rab...|              Action| 17.95000|2025-03-27|
|     1179|      Call of Duty 3|              Action| 19.95000|2025-03-27|
|     1200|Mortal Kombat: Un...|              Action| 17.95000|2025-03-27|
|     1224|        Excite Truck|    Racing / Driving| 19.95000|2025-03-27|
|     1227|Metal Gear Solid:...|     Action,Strategy| 17.95000|2025-03-27|
|     1229|Blazing Angels: S...|              Action| 16.95000|2025-03-27|
|     1234|WWE SmackDown vs....|              Sports| 14.95000|2025-03-27|
+---------+--------------------+--------------------+---------+----------+
only showing top 20 rows

25/04/01 12:44:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:44:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:44:38 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/01 12:44:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:44:38 INFO CodeGenerator: Code generated in 14.281504 ms
25/04/01 12:44:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 345.6 KiB, free 364.4 MiB)
25/04/01 12:44:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.4 MiB)
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:35237 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:44:38 INFO SparkContext: Created broadcast 8 from count at NativeMethodAccessorImpl.java:0
25/04/01 12:44:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:44:38 INFO DAGScheduler: Registering RDD 24 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/01 12:44:38 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:44:38 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:38 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:44:38 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:38 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 29.9 KiB, free 364.4 MiB)
25/04/01 12:44:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.3 MiB)
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:35237 (size: 14.1 KiB, free: 366.1 MiB)
25/04/01 12:44:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:44:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/04/01 12:44:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 7) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:40733 (size: 14.1 KiB, free: 366.2 MiB)
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:40733 (size: 32.6 KiB, free: 366.2 MiB)
25/04/01 12:44:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 7) in 307 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:44:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/04/01 12:44:38 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.313 s
25/04/01 12:44:38 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:44:38 INFO DAGScheduler: running: Set()
25/04/01 12:44:38 INFO DAGScheduler: waiting: Set()
25/04/01 12:44:38 INFO DAGScheduler: failed: Set()
25/04/01 12:44:38 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:44:38 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/01 12:44:38 INFO CodeGenerator: Code generated in 11.541672 ms
25/04/01 12:44:38 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/01 12:44:38 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:44:38 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/04/01 12:44:38 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:38 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:38 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 37.6 KiB, free 364.3 MiB)
25/04/01 12:44:38 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 364.3 MiB)
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 7796893c36d7:35237 (size: 17.8 KiB, free: 366.1 MiB)
25/04/01 12:44:38 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:44:38 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/01 12:44:38 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.6:40733 (size: 17.8 KiB, free: 366.2 MiB)
25/04/01 12:44:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:58556
25/04/01 12:44:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 114 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:44:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/01 12:44:38 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.121 s
25/04/01 12:44:38 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:44:38 INFO DAGScheduler: running: Set()
25/04/01 12:44:38 INFO DAGScheduler: waiting: Set()
25/04/01 12:44:38 INFO DAGScheduler: failed: Set()
25/04/01 12:44:38 INFO CodeGenerator: Code generated in 6.128916 ms
25/04/01 12:44:38 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/01 12:44:38 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:44:38 INFO DAGScheduler: Final stage: ResultStage 10 (count at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
25/04/01 12:44:38 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:38 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 11.0 KiB, free 364.3 MiB)
25/04/01 12:44:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.3 MiB)
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 7796893c36d7:35237 (size: 5.5 KiB, free: 366.1 MiB)
25/04/01 12:44:38 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:44:38 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/04/01 12:44:38 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:44:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.6:40733 (size: 5.5 KiB, free: 366.2 MiB)
25/04/01 12:44:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:58556
25/04/01 12:44:38 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 86 ms on 172.18.0.6 (executor 2) (1/1)
25/04/01 12:44:38 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/04/01 12:44:38 INFO DAGScheduler: ResultStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.091 s
25/04/01 12:44:38 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:44:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/04/01 12:44:38 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.092803 s
25/04/01 12:44:38 INFO FileSourceStrategy: Pushed Filters: 
25/04/01 12:44:38 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/01 12:44:38 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/01 12:44:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:44:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:44:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:44:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:44:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/01 12:44:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/01 12:44:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/01 12:44:39 INFO CodeGenerator: Code generated in 12.060318 ms
25/04/01 12:44:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 345.6 KiB, free 363.9 MiB)
25/04/01 12:44:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 363.9 MiB)
25/04/01 12:44:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 7796893c36d7:35237 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:44:39 INFO SparkContext: Created broadcast 12 from insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:44:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/01 12:44:39 INFO DAGScheduler: Registering RDD 35 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 3
25/04/01 12:44:39 INFO DAGScheduler: Got map stage job 7 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:44:39 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:39 INFO DAGScheduler: Parents of final stage: List()
25/04/01 12:44:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:39 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[35] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:39 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.8 KiB, free 363.9 MiB)
25/04/01 12:44:39 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 363.9 MiB)
25/04/01 12:44:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 7796893c36d7:35237 (size: 14.7 KiB, free: 366.0 MiB)
25/04/01 12:44:39 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[35] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:44:39 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
25/04/01 12:44:39 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 10) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/01 12:44:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.2:40035 (size: 14.7 KiB, free: 366.2 MiB)
25/04/01 12:44:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.2:40035 (size: 32.6 KiB, free: 366.1 MiB)
25/04/01 12:44:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 10) in 352 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:44:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/04/01 12:44:39 INFO DAGScheduler: ShuffleMapStage 11 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.363 s
25/04/01 12:44:39 INFO DAGScheduler: looking for newly runnable stages
25/04/01 12:44:39 INFO DAGScheduler: running: Set()
25/04/01 12:44:39 INFO DAGScheduler: waiting: Set()
25/04/01 12:44:39 INFO DAGScheduler: failed: Set()
25/04/01 12:44:39 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/01 12:44:39 INFO CodeGenerator: Code generated in 6.384048 ms
25/04/01 12:44:39 INFO CodeGenerator: Code generated in 7.733186 ms
25/04/01 12:44:39 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/01 12:44:39 INFO DAGScheduler: Got job 8 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/01 12:44:39 INFO DAGScheduler: Final stage: ResultStage 13 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/01 12:44:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
25/04/01 12:44:39 INFO DAGScheduler: Missing parents: List()
25/04/01 12:44:39 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[41] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/01 12:44:39 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 238.6 KiB, free 363.6 MiB)
25/04/01 12:44:39 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 363.5 MiB)
25/04/01 12:44:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 7796893c36d7:35237 (size: 87.8 KiB, free: 366.0 MiB)
25/04/01 12:44:39 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1478
25/04/01 12:44:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[41] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/01 12:44:39 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
25/04/01 12:44:39 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 11) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/01 12:44:39 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.2:40035 (size: 87.8 KiB, free: 366.1 MiB)
25/04/01 12:44:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.2:56426
25/04/01 12:44:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 11) in 542 ms on 172.18.0.2 (executor 0) (1/1)
25/04/01 12:44:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/04/01 12:44:40 INFO DAGScheduler: ResultStage 13 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.567 s
25/04/01 12:44:40 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/01 12:44:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/04/01 12:44:40 INFO DAGScheduler: Job 8 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.573307 s
25/04/01 12:44:40 INFO FileFormatWriter: Start to commit write Job b119290b-de5b-4d4c-92be-3e7db19d8c21.
25/04/01 12:44:40 INFO FileFormatWriter: Write Job b119290b-de5b-4d4c-92be-3e7db19d8c21 committed. Elapsed time: 41 ms.
25/04/01 12:44:40 INFO FileFormatWriter: Finished processing stats for write job b119290b-de5b-4d4c-92be-3e7db19d8c21.
25/04/01 12:44:40 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/01 12:44:40 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/01 12:44:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/01 12:44:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/01 12:44:40 INFO MemoryStore: MemoryStore cleared
25/04/01 12:44:40 INFO BlockManager: BlockManager stopped
25/04/01 12:44:40 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/01 12:44:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/01 12:44:40 INFO SparkContext: Successfully stopped SparkContext
25/04/01 12:44:40 INFO ShutdownHookManager: Shutdown hook called
25/04/01 12:44:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-5aadabfd-28e9-492c-a353-42a9e2f3bc1b
25/04/01 12:44:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-5aadabfd-28e9-492c-a353-42a9e2f3bc1b/pyspark-3193e5ec-7064-4b70-a552-deca0f553441
25/04/01 12:44:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-1d10df98-a314-4035-b88d-97a45b16b000
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/02 08:17:06 INFO SparkContext: Running Spark version 3.2.2
25/04/02 08:17:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/02 08:17:07 INFO ResourceUtils: ==============================================================
25/04/02 08:17:07 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/02 08:17:07 INFO ResourceUtils: ==============================================================
25/04/02 08:17:07 INFO SparkContext: Submitted application: Load product data into Hive
25/04/02 08:17:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/02 08:17:07 INFO ResourceProfile: Limiting resource is cpu
25/04/02 08:17:07 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/02 08:17:07 INFO SecurityManager: Changing view acls to: root
25/04/02 08:17:07 INFO SecurityManager: Changing modify acls to: root
25/04/02 08:17:07 INFO SecurityManager: Changing view acls groups to: 
25/04/02 08:17:07 INFO SecurityManager: Changing modify acls groups to: 
25/04/02 08:17:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/02 08:17:07 INFO Utils: Successfully started service 'sparkDriver' on port 41303.
25/04/02 08:17:07 INFO SparkEnv: Registering MapOutputTracker
25/04/02 08:17:07 INFO SparkEnv: Registering BlockManagerMaster
25/04/02 08:17:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/02 08:17:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/02 08:17:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/02 08:17:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cd4a9e5c-be48-4fe7-a7cf-c52961335cfe
25/04/02 08:17:07 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/02 08:17:07 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/02 08:17:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/02 08:17:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/02 08:17:07 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/02 08:17:07 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 27 ms (0 ms spent in bootstraps)
25/04/02 08:17:07 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250402081707-0061
25/04/02 08:17:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41815.
25/04/02 08:17:07 INFO NettyBlockTransferService: Server created on 7796893c36d7:41815
25/04/02 08:17:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/02 08:17:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 41815, None)
25/04/02 08:17:08 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:41815 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 41815, None)
25/04/02 08:17:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 41815, None)
25/04/02 08:17:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 41815, None)
25/04/02 08:17:08 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/02 08:17:08 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/02 08:17:08 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/02 08:17:09 INFO InMemoryFileIndex: It took 173 ms to list leaf files for 1 paths.
25/04/02 08:17:10 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
25/04/02 08:17:13 INFO FileSourceStrategy: Pushed Filters: 
25/04/02 08:17:13 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/02 08:17:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/02 08:17:13 INFO CodeGenerator: Code generated in 164.861689 ms
25/04/02 08:17:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/02 08:17:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/02 08:17:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:41815 (size: 32.6 KiB, free: 366.3 MiB)
25/04/02 08:17:13 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/02 08:17:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:17:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/02 08:17:13 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:13 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:13 INFO DAGScheduler: Parents of final stage: List()
25/04/02 08:17:13 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/02 08:17:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/02 08:17:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:41815 (size: 5.8 KiB, free: 366.3 MiB)
25/04/02 08:17:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/02 08:17:19 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250402081707-0061/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/02 08:17:19 INFO StandaloneSchedulerBackend: Granted executor ID app-20250402081707-0061/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/02 08:17:19 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250402081707-0061/1 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/02 08:17:19 INFO StandaloneSchedulerBackend: Granted executor ID app-20250402081707-0061/1 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/02 08:17:19 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250402081707-0061/2 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/02 08:17:19 INFO StandaloneSchedulerBackend: Granted executor ID app-20250402081707-0061/2 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/02 08:17:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250402081707-0061/1 is now RUNNING
25/04/02 08:17:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250402081707-0061/2 is now RUNNING
25/04/02 08:17:19 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250402081707-0061/0 is now RUNNING
25/04/02 08:17:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:36626) with ID 2,  ResourceProfileId 0
25/04/02 08:17:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:45020) with ID 0,  ResourceProfileId 0
25/04/02 08:17:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:54506) with ID 1,  ResourceProfileId 0
25/04/02 08:17:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:42101 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.8, 42101, None)
25/04/02 08:17:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:34921 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 34921, None)
25/04/02 08:17:21 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:36389 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.6, 36389, None)
25/04/02 08:17:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.8, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/02 08:17:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.8:42101 (size: 5.8 KiB, free: 366.3 MiB)
25/04/02 08:17:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.8:42101 (size: 32.6 KiB, free: 366.3 MiB)
25/04/02 08:17:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1522 ms on 172.18.0.8 (executor 2) (1/1)
25/04/02 08:17:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/02 08:17:22 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 8.931 s
25/04/02 08:17:22 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/02 08:17:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/02 08:17:22 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 8.970591 s
25/04/02 08:17:22 INFO CodeGenerator: Code generated in 9.704189 ms
25/04/02 08:17:22 INFO FileSourceStrategy: Pushed Filters: 
25/04/02 08:17:22 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/02 08:17:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/02 08:17:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/02 08:17:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/02 08:17:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:41815 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:17:22 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/02 08:17:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:17:23 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/02 08:17:23 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/02 08:17:23 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/02 08:17:23 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/02 08:17:23 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/02 08:17:23 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/02 08:17:23 INFO metastore: Connected to metastore.
25/04/02 08:17:23 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=07bdc361-7d03-4740-9d2d-3ea607d97b05, clientType=HIVECLI]
25/04/02 08:17:23 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/02 08:17:23 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/02 08:17:23 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/02 08:17:23 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/02 08:17:23 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/02 08:17:23 INFO metastore: Connected to metastore.
25/04/02 08:17:23 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/02 08:17:23 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/02 08:17:23 INFO metastore: Connected to metastore.
25/04/02 08:17:23 INFO FileSourceStrategy: Pushed Filters: 
25/04/02 08:17:23 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/02 08:17:23 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/02 08:17:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/02 08:17:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:41815 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/02 08:17:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.8:42101 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/02 08:17:23 INFO CodeGenerator: Code generated in 39.171551 ms
25/04/02 08:17:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/02 08:17:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/02 08:17:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:41815 (size: 32.6 KiB, free: 366.2 MiB)
25/04/02 08:17:23 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/02 08:17:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:17:24 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/02 08:17:24 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:24 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:24 INFO DAGScheduler: Parents of final stage: List()
25/04/02 08:17:24 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:24 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/02 08:17:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/02 08:17:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:41815 (size: 14.1 KiB, free: 366.2 MiB)
25/04/02 08:17:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/02 08:17:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.6, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/02 08:17:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.6:36389 (size: 14.1 KiB, free: 366.3 MiB)
25/04/02 08:17:25 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.6:36389 (size: 32.6 KiB, free: 366.3 MiB)
25/04/02 08:17:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1723 ms on 172.18.0.6 (executor 1) (1/1)
25/04/02 08:17:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/02 08:17:25 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.737 s
25/04/02 08:17:25 INFO DAGScheduler: looking for newly runnable stages
25/04/02 08:17:25 INFO DAGScheduler: running: Set()
25/04/02 08:17:25 INFO DAGScheduler: waiting: Set()
25/04/02 08:17:25 INFO DAGScheduler: failed: Set()
25/04/02 08:17:25 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/02 08:17:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/02 08:17:25 INFO CodeGenerator: Code generated in 15.219885 ms
25/04/02 08:17:25 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/02 08:17:25 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:25 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/02 08:17:25 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:25 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.7 KiB, free 365.1 MiB)
25/04/02 08:17:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/02 08:17:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:41815 (size: 17.8 KiB, free: 366.2 MiB)
25/04/02 08:17:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:25 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/02 08:17:25 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.6, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/02 08:17:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.6:36389 (size: 17.8 KiB, free: 366.2 MiB)
25/04/02 08:17:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.6:54506
25/04/02 08:17:26 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 162 ms on 172.18.0.6 (executor 1) (1/1)
25/04/02 08:17:26 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/02 08:17:26 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.172 s
25/04/02 08:17:26 INFO DAGScheduler: looking for newly runnable stages
25/04/02 08:17:26 INFO DAGScheduler: running: Set()
25/04/02 08:17:26 INFO DAGScheduler: waiting: Set()
25/04/02 08:17:26 INFO DAGScheduler: failed: Set()
25/04/02 08:17:26 INFO CodeGenerator: Code generated in 7.40541 ms
25/04/02 08:17:26 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/02 08:17:26 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:26 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/02 08:17:26 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:26 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:26 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/02 08:17:26 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/02 08:17:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:41815 (size: 5.5 KiB, free: 366.2 MiB)
25/04/02 08:17:26 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:26 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/02 08:17:26 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.6, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/02 08:17:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.6:36389 (size: 5.5 KiB, free: 366.2 MiB)
25/04/02 08:17:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.6:54506
25/04/02 08:17:26 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 89 ms on 172.18.0.6 (executor 1) (1/1)
25/04/02 08:17:26 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/02 08:17:26 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.094 s
25/04/02 08:17:26 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/02 08:17:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/02 08:17:26 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.097439 s
25/04/02 08:17:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/02 08:17:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/02 08:17:26 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/02 08:17:26 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/02 08:17:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/02 08:17:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/02 08:17:26 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/02 08:17:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/02 08:17:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/02 08:17:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/02 08:17:26 INFO CodeGenerator: Code generated in 12.745456 ms
25/04/02 08:17:26 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/02 08:17:26 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/02 08:17:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:41815 (size: 32.6 KiB, free: 366.1 MiB)
25/04/02 08:17:26 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/02 08:17:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/02 08:17:26 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/02 08:17:26 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:26 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:26 INFO DAGScheduler: Parents of final stage: List()
25/04/02 08:17:26 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:26 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:26 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/02 08:17:26 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/02 08:17:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:41815 (size: 14.7 KiB, free: 366.1 MiB)
25/04/02 08:17:26 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:26 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/02 08:17:26 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.2, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/02 08:17:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:34921 (size: 14.7 KiB, free: 366.3 MiB)
25/04/02 08:17:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:34921 (size: 32.6 KiB, free: 366.3 MiB)
25/04/02 08:17:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1796 ms on 172.18.0.2 (executor 0) (1/1)
25/04/02 08:17:28 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/02 08:17:28 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.809 s
25/04/02 08:17:28 INFO DAGScheduler: looking for newly runnable stages
25/04/02 08:17:28 INFO DAGScheduler: running: Set()
25/04/02 08:17:28 INFO DAGScheduler: waiting: Set()
25/04/02 08:17:28 INFO DAGScheduler: failed: Set()
25/04/02 08:17:28 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/02 08:17:28 INFO CodeGenerator: Code generated in 7.652441 ms
25/04/02 08:17:28 INFO CodeGenerator: Code generated in 8.126319 ms
25/04/02 08:17:28 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/02 08:17:28 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/02 08:17:28 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/02 08:17:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/02 08:17:28 INFO DAGScheduler: Missing parents: List()
25/04/02 08:17:28 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/02 08:17:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/02 08:17:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/02 08:17:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:41815 (size: 87.8 KiB, free: 366.0 MiB)
25/04/02 08:17:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/02 08:17:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/02 08:17:28 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/02 08:17:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.2, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/02 08:17:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:34921 (size: 87.8 KiB, free: 366.2 MiB)
25/04/02 08:17:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:45020
25/04/02 08:17:29 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 971 ms on 172.18.0.2 (executor 0) (1/1)
25/04/02 08:17:29 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/02 08:17:29 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.996 s
25/04/02 08:17:29 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/02 08:17:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/02 08:17:29 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 1.003495 s
25/04/02 08:17:29 INFO FileFormatWriter: Start to commit write Job 07f00018-cb95-4fda-81c3-47650ae39e3f.
25/04/02 08:17:29 INFO FileFormatWriter: Write Job 07f00018-cb95-4fda-81c3-47650ae39e3f committed. Elapsed time: 35 ms.
25/04/02 08:17:29 INFO FileFormatWriter: Finished processing stats for write job 07f00018-cb95-4fda-81c3-47650ae39e3f.
25/04/02 08:17:29 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/02 08:17:29 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/02 08:17:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/02 08:17:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/02 08:17:29 INFO MemoryStore: MemoryStore cleared
25/04/02 08:17:29 INFO BlockManager: BlockManager stopped
25/04/02 08:17:29 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/02 08:17:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/02 08:17:29 INFO SparkContext: Successfully stopped SparkContext
25/04/02 08:17:29 INFO ShutdownHookManager: Shutdown hook called
25/04/02 08:17:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-844e4e5c-9db8-405b-833f-6b809129cf92
25/04/02 08:17:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-a3bc4ede-e902-4e09-87b1-4da6d6df8edb/pyspark-3b53870f-0e91-404d-81d6-3d2b0fe7d647
25/04/02 08:17:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-a3bc4ede-e902-4e09-87b1-4da6d6df8edb
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/03 08:49:11 INFO SparkContext: Running Spark version 3.2.2
25/04/03 08:49:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/03 08:49:11 INFO ResourceUtils: ==============================================================
25/04/03 08:49:11 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/03 08:49:11 INFO ResourceUtils: ==============================================================
25/04/03 08:49:11 INFO SparkContext: Submitted application: Load product data into Hive
25/04/03 08:49:11 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/03 08:49:11 INFO ResourceProfile: Limiting resource is cpu
25/04/03 08:49:11 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/03 08:49:11 INFO SecurityManager: Changing view acls to: root
25/04/03 08:49:11 INFO SecurityManager: Changing modify acls to: root
25/04/03 08:49:11 INFO SecurityManager: Changing view acls groups to: 
25/04/03 08:49:11 INFO SecurityManager: Changing modify acls groups to: 
25/04/03 08:49:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/03 08:49:11 INFO Utils: Successfully started service 'sparkDriver' on port 37867.
25/04/03 08:49:11 INFO SparkEnv: Registering MapOutputTracker
25/04/03 08:49:11 INFO SparkEnv: Registering BlockManagerMaster
25/04/03 08:49:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/03 08:49:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/03 08:49:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/03 08:49:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8352352e-0211-45ba-b7f7-42c8f2288ae2
25/04/03 08:49:11 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/03 08:49:11 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/03 08:49:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/03 08:49:12 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/03 08:49:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/03 08:49:12 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 24 ms (0 ms spent in bootstraps)
25/04/03 08:49:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250403084912-0067
25/04/03 08:49:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40767.
25/04/03 08:49:12 INFO NettyBlockTransferService: Server created on 7796893c36d7:40767
25/04/03 08:49:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/03 08:49:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 40767, None)
25/04/03 08:49:12 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:40767 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 40767, None)
25/04/03 08:49:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 40767, None)
25/04/03 08:49:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 40767, None)
25/04/03 08:49:12 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/03 08:49:12 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/03 08:49:12 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/03 08:49:13 INFO InMemoryFileIndex: It took 62 ms to list leaf files for 1 paths.
25/04/03 08:49:13 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
25/04/03 08:49:16 INFO FileSourceStrategy: Pushed Filters: 
25/04/03 08:49:16 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/03 08:49:16 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/03 08:49:16 INFO CodeGenerator: Code generated in 232.730615 ms
25/04/03 08:49:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/03 08:49:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/03 08:49:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:40767 (size: 32.6 KiB, free: 366.3 MiB)
25/04/03 08:49:16 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/03 08:49:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:16 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/03 08:49:16 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:16 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:16 INFO DAGScheduler: Parents of final stage: List()
25/04/03 08:49:16 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/03 08:49:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/03 08:49:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:40767 (size: 5.8 KiB, free: 366.3 MiB)
25/04/03 08:49:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/03 08:49:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250403084912-0067/0 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/03 08:49:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20250403084912-0067/0 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/03 08:49:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250403084912-0067/1 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/03 08:49:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20250403084912-0067/1 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/03 08:49:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250403084912-0067/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/03 08:49:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20250403084912-0067/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/03 08:49:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250403084912-0067/0 is now RUNNING
25/04/03 08:49:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250403084912-0067/1 is now RUNNING
25/04/03 08:49:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250403084912-0067/2 is now RUNNING
25/04/03 08:49:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:41424) with ID 0,  ResourceProfileId 0
25/04/03 08:49:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:46420) with ID 2,  ResourceProfileId 0
25/04/03 08:49:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:50934) with ID 1,  ResourceProfileId 0
25/04/03 08:49:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:39425 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.2, 39425, None)
25/04/03 08:49:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:42835 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 42835, None)
25/04/03 08:49:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:32897 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.8, 32897, None)
25/04/03 08:49:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 0, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/03 08:49:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:39425 (size: 5.8 KiB, free: 366.3 MiB)
25/04/03 08:49:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:39425 (size: 32.6 KiB, free: 366.3 MiB)
25/04/03 08:49:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1614 ms on 172.18.0.2 (executor 0) (1/1)
25/04/03 08:49:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/03 08:49:22 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 5.592 s
25/04/03 08:49:22 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/03 08:49:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/03 08:49:22 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.658938 s
25/04/03 08:49:22 INFO CodeGenerator: Code generated in 10.957571 ms
25/04/03 08:49:22 INFO FileSourceStrategy: Pushed Filters: 
25/04/03 08:49:22 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/03 08:49:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/03 08:49:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/03 08:49:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/03 08:49:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:40767 (size: 32.6 KiB, free: 366.2 MiB)
25/04/03 08:49:22 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/03 08:49:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:22 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/03 08:49:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/03 08:49:22 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/03 08:49:23 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/03 08:49:23 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/03 08:49:23 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/03 08:49:23 INFO metastore: Connected to metastore.
25/04/03 08:49:23 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=853c2602-d21b-4496-b944-0de150dcc133, clientType=HIVECLI]
25/04/03 08:49:23 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/03 08:49:23 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/03 08:49:23 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/03 08:49:23 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/03 08:49:23 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/03 08:49:23 INFO metastore: Connected to metastore.
25/04/03 08:49:23 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/03 08:49:23 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/03 08:49:23 INFO metastore: Connected to metastore.
25/04/03 08:49:23 INFO FileSourceStrategy: Pushed Filters: 
25/04/03 08:49:23 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/03 08:49:23 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/03 08:49:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:40767 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/03 08:49:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:39425 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/03 08:49:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/03 08:49:23 INFO CodeGenerator: Code generated in 29.077674 ms
25/04/03 08:49:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/03 08:49:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/03 08:49:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:40767 (size: 32.6 KiB, free: 366.2 MiB)
25/04/03 08:49:23 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/03 08:49:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:23 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/03 08:49:23 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:23 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:23 INFO DAGScheduler: Parents of final stage: List()
25/04/03 08:49:23 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:23 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/03 08:49:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/03 08:49:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:40767 (size: 14.1 KiB, free: 366.2 MiB)
25/04/03 08:49:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/03 08:49:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/03 08:49:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:32897 (size: 14.1 KiB, free: 366.3 MiB)
25/04/03 08:49:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:32897 (size: 32.6 KiB, free: 366.3 MiB)
25/04/03 08:49:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1795 ms on 172.18.0.8 (executor 1) (1/1)
25/04/03 08:49:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/03 08:49:25 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.809 s
25/04/03 08:49:25 INFO DAGScheduler: looking for newly runnable stages
25/04/03 08:49:25 INFO DAGScheduler: running: Set()
25/04/03 08:49:25 INFO DAGScheduler: waiting: Set()
25/04/03 08:49:25 INFO DAGScheduler: failed: Set()
25/04/03 08:49:25 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/03 08:49:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/03 08:49:25 INFO CodeGenerator: Code generated in 16.009684 ms
25/04/03 08:49:25 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/03 08:49:25 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:25 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/03 08:49:25 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:25 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.1 MiB)
25/04/03 08:49:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/03 08:49:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:40767 (size: 17.8 KiB, free: 366.2 MiB)
25/04/03 08:49:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:25 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/03 08:49:25 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/03 08:49:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:32897 (size: 17.8 KiB, free: 366.2 MiB)
25/04/03 08:49:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:50934
25/04/03 08:49:25 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 175 ms on 172.18.0.8 (executor 1) (1/1)
25/04/03 08:49:25 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/03 08:49:25 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.186 s
25/04/03 08:49:25 INFO DAGScheduler: looking for newly runnable stages
25/04/03 08:49:25 INFO DAGScheduler: running: Set()
25/04/03 08:49:25 INFO DAGScheduler: waiting: Set()
25/04/03 08:49:25 INFO DAGScheduler: failed: Set()
25/04/03 08:49:25 INFO CodeGenerator: Code generated in 7.869986 ms
25/04/03 08:49:25 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/03 08:49:25 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:25 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/03 08:49:25 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:25 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/03 08:49:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/03 08:49:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:40767 (size: 5.5 KiB, free: 366.2 MiB)
25/04/03 08:49:25 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:25 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/03 08:49:25 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.8, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/03 08:49:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:32897 (size: 5.5 KiB, free: 366.2 MiB)
25/04/03 08:49:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:50934
25/04/03 08:49:26 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 93 ms on 172.18.0.8 (executor 1) (1/1)
25/04/03 08:49:26 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/03 08:49:26 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.099 s
25/04/03 08:49:26 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/03 08:49:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/03 08:49:26 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.101863 s
25/04/03 08:49:26 INFO FileSourceStrategy: Pushed Filters: 
25/04/03 08:49:26 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/03 08:49:26 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/03 08:49:26 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/03 08:49:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/03 08:49:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/03 08:49:26 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/03 08:49:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/03 08:49:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/03 08:49:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/03 08:49:26 INFO CodeGenerator: Code generated in 15.916591 ms
25/04/03 08:49:26 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/03 08:49:26 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/03 08:49:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:40767 (size: 32.6 KiB, free: 366.1 MiB)
25/04/03 08:49:26 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/03 08:49:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/03 08:49:26 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/03 08:49:26 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:26 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:26 INFO DAGScheduler: Parents of final stage: List()
25/04/03 08:49:26 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:26 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:26 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/03 08:49:26 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/03 08:49:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:40767 (size: 14.7 KiB, free: 366.1 MiB)
25/04/03 08:49:26 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:26 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/03 08:49:26 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/03 08:49:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:42835 (size: 14.7 KiB, free: 366.3 MiB)
25/04/03 08:49:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:42835 (size: 32.6 KiB, free: 366.3 MiB)
25/04/03 08:49:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1771 ms on 172.18.0.6 (executor 2) (1/1)
25/04/03 08:49:28 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/03 08:49:28 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.785 s
25/04/03 08:49:28 INFO DAGScheduler: looking for newly runnable stages
25/04/03 08:49:28 INFO DAGScheduler: running: Set()
25/04/03 08:49:28 INFO DAGScheduler: waiting: Set()
25/04/03 08:49:28 INFO DAGScheduler: failed: Set()
25/04/03 08:49:28 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/03 08:49:28 INFO CodeGenerator: Code generated in 7.305839 ms
25/04/03 08:49:28 INFO CodeGenerator: Code generated in 8.865728 ms
25/04/03 08:49:28 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/03 08:49:28 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/03 08:49:28 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/03 08:49:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/03 08:49:28 INFO DAGScheduler: Missing parents: List()
25/04/03 08:49:28 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/03 08:49:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/03 08:49:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/03 08:49:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:40767 (size: 87.8 KiB, free: 366.0 MiB)
25/04/03 08:49:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/03 08:49:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/03 08:49:28 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/03 08:49:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/03 08:49:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:42835 (size: 87.8 KiB, free: 366.2 MiB)
25/04/03 08:49:28 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:46420
25/04/03 08:49:29 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 972 ms on 172.18.0.6 (executor 2) (1/1)
25/04/03 08:49:29 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/03 08:49:29 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.995 s
25/04/03 08:49:29 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/03 08:49:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/03 08:49:29 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 1.004233 s
25/04/03 08:49:29 INFO FileFormatWriter: Start to commit write Job c4bdf8a1-2201-4c27-9ab6-d3055a4fa036.
25/04/03 08:49:29 INFO FileFormatWriter: Write Job c4bdf8a1-2201-4c27-9ab6-d3055a4fa036 committed. Elapsed time: 37 ms.
25/04/03 08:49:29 INFO FileFormatWriter: Finished processing stats for write job c4bdf8a1-2201-4c27-9ab6-d3055a4fa036.
25/04/03 08:49:29 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/03 08:49:29 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/03 08:49:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/03 08:49:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/03 08:49:29 INFO MemoryStore: MemoryStore cleared
25/04/03 08:49:29 INFO BlockManager: BlockManager stopped
25/04/03 08:49:29 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/03 08:49:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/03 08:49:29 INFO SparkContext: Successfully stopped SparkContext
25/04/03 08:49:29 INFO ShutdownHookManager: Shutdown hook called
25/04/03 08:49:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-1d51ca6f-dffb-465e-b673-abaaba8532c7/pyspark-d64629df-3865-4287-850c-0c1e9054c41c
25/04/03 08:49:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-98183344-e50c-4d7f-9b91-3192f1c10c82
25/04/03 08:49:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-1d51ca6f-dffb-465e-b673-abaaba8532c7
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/04 08:14:33 INFO SparkContext: Running Spark version 3.2.2
25/04/04 08:14:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/04 08:14:33 INFO ResourceUtils: ==============================================================
25/04/04 08:14:33 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/04 08:14:33 INFO ResourceUtils: ==============================================================
25/04/04 08:14:33 INFO SparkContext: Submitted application: Load product data into Hive
25/04/04 08:14:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/04 08:14:33 INFO ResourceProfile: Limiting resource is cpu
25/04/04 08:14:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/04 08:14:33 INFO SecurityManager: Changing view acls to: root
25/04/04 08:14:33 INFO SecurityManager: Changing modify acls to: root
25/04/04 08:14:33 INFO SecurityManager: Changing view acls groups to: 
25/04/04 08:14:33 INFO SecurityManager: Changing modify acls groups to: 
25/04/04 08:14:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/04 08:14:33 INFO Utils: Successfully started service 'sparkDriver' on port 41971.
25/04/04 08:14:33 INFO SparkEnv: Registering MapOutputTracker
25/04/04 08:14:33 INFO SparkEnv: Registering BlockManagerMaster
25/04/04 08:14:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/04 08:14:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/04 08:14:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/04 08:14:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-42d6a328-b006-4214-96be-1fafc5870c99
25/04/04 08:14:33 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/04 08:14:33 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/04 08:14:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/04 08:14:33 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/04 08:14:33 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/04 08:14:33 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 26 ms (0 ms spent in bootstraps)
25/04/04 08:14:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250404081434-0071
25/04/04 08:14:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33383.
25/04/04 08:14:34 INFO NettyBlockTransferService: Server created on 7796893c36d7:33383
25/04/04 08:14:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/04 08:14:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 33383, None)
25/04/04 08:14:34 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:33383 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 33383, None)
25/04/04 08:14:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 33383, None)
25/04/04 08:14:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 33383, None)
25/04/04 08:14:34 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/04 08:14:34 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/04 08:14:34 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/04 08:14:35 INFO InMemoryFileIndex: It took 116 ms to list leaf files for 1 paths.
25/04/04 08:14:35 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
25/04/04 08:14:37 INFO FileSourceStrategy: Pushed Filters: 
25/04/04 08:14:37 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/04 08:14:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/04 08:14:38 INFO CodeGenerator: Code generated in 224.199244 ms
25/04/04 08:14:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/04 08:14:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:33383 (size: 32.6 KiB, free: 366.3 MiB)
25/04/04 08:14:38 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/04 08:14:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/04 08:14:38 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/04 08:14:38 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:38 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:38 INFO DAGScheduler: Parents of final stage: List()
25/04/04 08:14:38 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/04 08:14:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/04 08:14:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:33383 (size: 5.8 KiB, free: 366.3 MiB)
25/04/04 08:14:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/04 08:14:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250404081434-0071/0 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/04 08:14:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250404081434-0071/0 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/04 08:14:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250404081434-0071/1 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/04 08:14:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250404081434-0071/1 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/04 08:14:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250404081434-0071/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/04 08:14:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250404081434-0071/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/04 08:14:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250404081434-0071/0 is now RUNNING
25/04/04 08:14:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250404081434-0071/2 is now RUNNING
25/04/04 08:14:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250404081434-0071/1 is now RUNNING
25/04/04 08:14:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:51424) with ID 2,  ResourceProfileId 0
25/04/04 08:14:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:43304) with ID 1,  ResourceProfileId 0
25/04/04 08:14:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:46846) with ID 0,  ResourceProfileId 0
25/04/04 08:14:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:38081 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 38081, None)
25/04/04 08:14:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:40231 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.2, 40231, None)
25/04/04 08:14:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:33651 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 33651, None)
25/04/04 08:14:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/04 08:14:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:40231 (size: 5.8 KiB, free: 366.3 MiB)
25/04/04 08:14:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:40231 (size: 32.6 KiB, free: 366.3 MiB)
25/04/04 08:14:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1604 ms on 172.18.0.2 (executor 1) (1/1)
25/04/04 08:14:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/04 08:14:42 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.787 s
25/04/04 08:14:42 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/04 08:14:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/04 08:14:42 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.825879 s
25/04/04 08:14:42 INFO CodeGenerator: Code generated in 8.938223 ms
25/04/04 08:14:42 INFO FileSourceStrategy: Pushed Filters: 
25/04/04 08:14:42 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/04 08:14:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/04 08:14:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/04 08:14:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/04 08:14:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:33383 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:42 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/04 08:14:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/04 08:14:42 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/04 08:14:42 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/04 08:14:42 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/04 08:14:42 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/04 08:14:42 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/04 08:14:43 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/04 08:14:43 INFO metastore: Connected to metastore.
25/04/04 08:14:43 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=6f02aa2e-74a8-486b-a146-c16479d76c22, clientType=HIVECLI]
25/04/04 08:14:43 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/04 08:14:43 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/04 08:14:43 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/04 08:14:43 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/04 08:14:43 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/04 08:14:43 INFO metastore: Connected to metastore.
25/04/04 08:14:43 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/04 08:14:43 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/04 08:14:43 INFO metastore: Connected to metastore.
25/04/04 08:14:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:33383 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/04 08:14:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:40231 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/04 08:14:43 INFO FileSourceStrategy: Pushed Filters: 
25/04/04 08:14:43 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/04 08:14:43 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/04 08:14:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/04 08:14:43 INFO CodeGenerator: Code generated in 27.627558 ms
25/04/04 08:14:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/04 08:14:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/04 08:14:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:33383 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:43 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/04 08:14:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/04 08:14:43 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/04 08:14:43 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:43 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:43 INFO DAGScheduler: Parents of final stage: List()
25/04/04 08:14:43 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:43 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/04 08:14:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/04 08:14:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:33383 (size: 14.1 KiB, free: 366.2 MiB)
25/04/04 08:14:43 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/04 08:14:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/04 08:14:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:40231 (size: 14.1 KiB, free: 366.3 MiB)
25/04/04 08:14:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:40231 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 400 ms on 172.18.0.2 (executor 1) (1/1)
25/04/04 08:14:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/04 08:14:43 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.413 s
25/04/04 08:14:43 INFO DAGScheduler: looking for newly runnable stages
25/04/04 08:14:43 INFO DAGScheduler: running: Set()
25/04/04 08:14:43 INFO DAGScheduler: waiting: Set()
25/04/04 08:14:43 INFO DAGScheduler: failed: Set()
25/04/04 08:14:43 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/04 08:14:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/04 08:14:44 INFO CodeGenerator: Code generated in 17.148484 ms
25/04/04 08:14:44 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/04 08:14:44 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:44 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/04 08:14:44 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:44 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.1 MiB)
25/04/04 08:14:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/04 08:14:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:33383 (size: 17.8 KiB, free: 366.2 MiB)
25/04/04 08:14:44 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/04 08:14:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/04 08:14:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:40231 (size: 17.8 KiB, free: 366.2 MiB)
25/04/04 08:14:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:43304
25/04/04 08:14:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 152 ms on 172.18.0.2 (executor 1) (1/1)
25/04/04 08:14:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/04 08:14:44 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.162 s
25/04/04 08:14:44 INFO DAGScheduler: looking for newly runnable stages
25/04/04 08:14:44 INFO DAGScheduler: running: Set()
25/04/04 08:14:44 INFO DAGScheduler: waiting: Set()
25/04/04 08:14:44 INFO DAGScheduler: failed: Set()
25/04/04 08:14:44 INFO CodeGenerator: Code generated in 7.248678 ms
25/04/04 08:14:44 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/04 08:14:44 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:44 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/04 08:14:44 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:44 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:44 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/04 08:14:44 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/04 08:14:44 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:33383 (size: 5.5 KiB, free: 366.2 MiB)
25/04/04 08:14:44 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:44 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/04 08:14:44 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/04 08:14:44 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:40231 (size: 5.5 KiB, free: 366.2 MiB)
25/04/04 08:14:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:43304
25/04/04 08:14:44 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 35 ms on 172.18.0.2 (executor 1) (1/1)
25/04/04 08:14:44 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/04 08:14:44 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.040 s
25/04/04 08:14:44 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/04 08:14:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/04 08:14:44 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.042933 s
25/04/04 08:14:44 INFO FileSourceStrategy: Pushed Filters: 
25/04/04 08:14:44 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/04 08:14:44 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/04 08:14:44 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/04 08:14:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/04 08:14:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/04 08:14:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/04 08:14:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/04 08:14:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/04 08:14:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/04 08:14:44 INFO CodeGenerator: Code generated in 15.844815 ms
25/04/04 08:14:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/04 08:14:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/04 08:14:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:33383 (size: 32.6 KiB, free: 366.1 MiB)
25/04/04 08:14:44 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/04 08:14:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/04 08:14:44 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/04 08:14:44 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:44 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:44 INFO DAGScheduler: Parents of final stage: List()
25/04/04 08:14:44 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:44 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/04 08:14:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/04 08:14:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:33383 (size: 14.7 KiB, free: 366.1 MiB)
25/04/04 08:14:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:44 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/04 08:14:44 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.2, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/04 08:14:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:40231 (size: 14.7 KiB, free: 366.2 MiB)
25/04/04 08:14:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:40231 (size: 32.6 KiB, free: 366.2 MiB)
25/04/04 08:14:44 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 310 ms on 172.18.0.2 (executor 1) (1/1)
25/04/04 08:14:44 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/04 08:14:44 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.323 s
25/04/04 08:14:44 INFO DAGScheduler: looking for newly runnable stages
25/04/04 08:14:44 INFO DAGScheduler: running: Set()
25/04/04 08:14:44 INFO DAGScheduler: waiting: Set()
25/04/04 08:14:44 INFO DAGScheduler: failed: Set()
25/04/04 08:14:44 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/04 08:14:44 INFO CodeGenerator: Code generated in 7.072188 ms
25/04/04 08:14:44 INFO CodeGenerator: Code generated in 10.630701 ms
25/04/04 08:14:44 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/04 08:14:44 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/04 08:14:44 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/04 08:14:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/04 08:14:44 INFO DAGScheduler: Missing parents: List()
25/04/04 08:14:44 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/04 08:14:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/04 08:14:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/04 08:14:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:33383 (size: 87.8 KiB, free: 366.0 MiB)
25/04/04 08:14:45 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/04 08:14:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/04 08:14:45 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/04 08:14:45 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/04 08:14:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:40231 (size: 87.8 KiB, free: 366.1 MiB)
25/04/04 08:14:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:43304
25/04/04 08:14:46 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 1004 ms on 172.18.0.2 (executor 1) (1/1)
25/04/04 08:14:46 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/04 08:14:46 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.038 s
25/04/04 08:14:46 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/04 08:14:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/04 08:14:46 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 1.049589 s
25/04/04 08:14:46 INFO FileFormatWriter: Start to commit write Job a556e6f2-4303-44ee-bcdf-1be87d047b1e.
25/04/04 08:14:46 INFO FileFormatWriter: Write Job a556e6f2-4303-44ee-bcdf-1be87d047b1e committed. Elapsed time: 45 ms.
25/04/04 08:14:46 INFO FileFormatWriter: Finished processing stats for write job a556e6f2-4303-44ee-bcdf-1be87d047b1e.
25/04/04 08:14:46 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/04 08:14:46 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/04 08:14:46 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/04 08:14:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/04 08:14:46 INFO MemoryStore: MemoryStore cleared
25/04/04 08:14:46 INFO BlockManager: BlockManager stopped
25/04/04 08:14:46 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/04 08:14:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/04 08:14:46 INFO SparkContext: Successfully stopped SparkContext
25/04/04 08:14:46 INFO ShutdownHookManager: Shutdown hook called
25/04/04 08:14:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-a0767f16-6471-46e5-a67f-f9e3a756bf80
25/04/04 08:14:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-a0767f16-6471-46e5-a67f-f9e3a756bf80/pyspark-53e88d14-f286-40a2-8eb8-123b446bd023
25/04/04 08:14:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-55052345-4ec1-4416-b2f3-755c3cafae2f
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/05 07:04:52 INFO SparkContext: Running Spark version 3.2.2
25/04/05 07:04:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/05 07:04:53 INFO ResourceUtils: ==============================================================
25/04/05 07:04:53 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/05 07:04:53 INFO ResourceUtils: ==============================================================
25/04/05 07:04:53 INFO SparkContext: Submitted application: Load product data into Hive
25/04/05 07:04:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/05 07:04:53 INFO ResourceProfile: Limiting resource is cpu
25/04/05 07:04:53 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/05 07:04:53 INFO SecurityManager: Changing view acls to: root
25/04/05 07:04:53 INFO SecurityManager: Changing modify acls to: root
25/04/05 07:04:53 INFO SecurityManager: Changing view acls groups to: 
25/04/05 07:04:53 INFO SecurityManager: Changing modify acls groups to: 
25/04/05 07:04:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/05 07:04:53 INFO Utils: Successfully started service 'sparkDriver' on port 34241.
25/04/05 07:04:53 INFO SparkEnv: Registering MapOutputTracker
25/04/05 07:04:53 INFO SparkEnv: Registering BlockManagerMaster
25/04/05 07:04:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/05 07:04:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/05 07:04:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/05 07:04:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2d50565c-3a95-4feb-9e29-5000e510a51f
25/04/05 07:04:53 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/05 07:04:53 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/05 07:04:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/05 07:04:54 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/05 07:04:54 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4041
25/04/05 07:04:54 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/05 07:04:54 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 27 ms (0 ms spent in bootstraps)
25/04/05 07:04:54 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250405070454-0078
25/04/05 07:04:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43823.
25/04/05 07:04:54 INFO NettyBlockTransferService: Server created on 7796893c36d7:43823
25/04/05 07:04:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/05 07:04:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 43823, None)
25/04/05 07:04:54 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:43823 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 43823, None)
25/04/05 07:04:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 43823, None)
25/04/05 07:04:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 43823, None)
25/04/05 07:04:54 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/05 07:04:54 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/05 07:04:54 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/05 07:04:55 INFO InMemoryFileIndex: It took 52 ms to list leaf files for 1 paths.
25/04/05 07:04:55 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/04/05 07:04:57 INFO FileSourceStrategy: Pushed Filters: 
25/04/05 07:04:57 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/05 07:04:57 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/05 07:04:58 INFO CodeGenerator: Code generated in 170.49538 ms
25/04/05 07:04:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/05 07:04:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/05 07:04:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:43823 (size: 32.6 KiB, free: 366.3 MiB)
25/04/05 07:04:58 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/05 07:04:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/05 07:04:58 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/05 07:04:58 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/05 07:04:58 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/05 07:04:58 INFO DAGScheduler: Parents of final stage: List()
25/04/05 07:04:58 INFO DAGScheduler: Missing parents: List()
25/04/05 07:04:58 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/05 07:04:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/05 07:04:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/05 07:04:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:43823 (size: 5.8 KiB, free: 366.3 MiB)
25/04/05 07:04:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/05 07:04:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/05 07:04:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/05 07:05:00 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250405070454-0078/0 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/05 07:05:00 INFO StandaloneSchedulerBackend: Granted executor ID app-20250405070454-0078/0 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/05 07:05:00 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250405070454-0078/1 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/05 07:05:00 INFO StandaloneSchedulerBackend: Granted executor ID app-20250405070454-0078/1 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/05 07:05:00 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250405070454-0078/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/05 07:05:00 INFO StandaloneSchedulerBackend: Granted executor ID app-20250405070454-0078/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/05 07:05:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250405070454-0078/2 is now RUNNING
25/04/05 07:05:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250405070454-0078/0 is now RUNNING
25/04/05 07:05:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250405070454-0078/1 is now RUNNING
25/04/05 07:05:01 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:45990) with ID 1,  ResourceProfileId 0
25/04/05 07:05:01 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:33276) with ID 0,  ResourceProfileId 0
25/04/05 07:05:01 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:39846) with ID 2,  ResourceProfileId 0
25/04/05 07:05:01 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:41033 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.2, 41033, None)
25/04/05 07:05:01 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:46397 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 46397, None)
25/04/05 07:05:01 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:32855 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 32855, None)
25/04/05 07:05:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/05 07:05:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:41033 (size: 5.8 KiB, free: 366.3 MiB)
25/04/05 07:05:02 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:41033 (size: 32.6 KiB, free: 366.3 MiB)
25/04/05 07:05:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1649 ms on 172.18.0.2 (executor 1) (1/1)
25/04/05 07:05:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/05 07:05:03 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 5.019 s
25/04/05 07:05:03 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 07:05:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/05 07:05:03 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 5.056698 s
25/04/05 07:05:03 INFO CodeGenerator: Code generated in 8.8087 ms
25/04/05 07:05:03 INFO FileSourceStrategy: Pushed Filters: 
25/04/05 07:05:03 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/05 07:05:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/05 07:05:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/05 07:05:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/05 07:05:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:43823 (size: 32.6 KiB, free: 366.2 MiB)
25/04/05 07:05:03 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/05 07:05:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/05 07:05:03 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/05 07:05:03 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/05 07:05:03 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/05 07:05:04 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/05 07:05:04 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/05 07:05:04 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/05 07:05:04 INFO metastore: Connected to metastore.
25/04/05 07:05:04 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=14b20e65-b81d-46b4-8f7d-b0b909440174, clientType=HIVECLI]
25/04/05 07:05:04 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/05 07:05:04 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/05 07:05:04 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/05 07:05:04 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/05 07:05:04 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/05 07:05:04 INFO metastore: Connected to metastore.
25/04/05 07:05:04 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/05 07:05:04 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/05 07:05:04 INFO metastore: Connected to metastore.
25/04/05 07:05:04 INFO FileSourceStrategy: Pushed Filters: 
25/04/05 07:05:04 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/05 07:05:04 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/05 07:05:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:43823 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/05 07:05:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:41033 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/05 07:05:04 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/05 07:05:04 INFO CodeGenerator: Code generated in 29.533074 ms
25/04/05 07:05:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/05 07:05:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/05 07:05:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:43823 (size: 32.6 KiB, free: 366.2 MiB)
25/04/05 07:05:04 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/05 07:05:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/05 07:05:04 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/05 07:05:04 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/05 07:05:04 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/05 07:05:04 INFO DAGScheduler: Parents of final stage: List()
25/04/05 07:05:04 INFO DAGScheduler: Missing parents: List()
25/04/05 07:05:04 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/05 07:05:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/05 07:05:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/05 07:05:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:43823 (size: 14.1 KiB, free: 366.2 MiB)
25/04/05 07:05:04 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/05 07:05:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/05 07:05:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/05 07:05:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.2, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/05 07:05:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.2:41033 (size: 14.1 KiB, free: 366.3 MiB)
25/04/05 07:05:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.2:41033 (size: 32.6 KiB, free: 366.2 MiB)
25/04/05 07:05:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 415 ms on 172.18.0.2 (executor 1) (1/1)
25/04/05 07:05:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/05 07:05:05 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.432 s
25/04/05 07:05:05 INFO DAGScheduler: looking for newly runnable stages
25/04/05 07:05:05 INFO DAGScheduler: running: Set()
25/04/05 07:05:05 INFO DAGScheduler: waiting: Set()
25/04/05 07:05:05 INFO DAGScheduler: failed: Set()
25/04/05 07:05:05 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/05 07:05:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/05 07:05:05 INFO CodeGenerator: Code generated in 15.979645 ms
25/04/05 07:05:05 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/05 07:05:05 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/05 07:05:05 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/05 07:05:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/05 07:05:05 INFO DAGScheduler: Missing parents: List()
25/04/05 07:05:05 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/05 07:05:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.1 MiB)
25/04/05 07:05:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/05 07:05:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:43823 (size: 17.8 KiB, free: 366.2 MiB)
25/04/05 07:05:05 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/05 07:05:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/05 07:05:05 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/05 07:05:05 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/05 07:05:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.2:41033 (size: 17.8 KiB, free: 366.2 MiB)
25/04/05 07:05:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.2:45990
25/04/05 07:05:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 146 ms on 172.18.0.2 (executor 1) (1/1)
25/04/05 07:05:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/05 07:05:05 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.156 s
25/04/05 07:05:05 INFO DAGScheduler: looking for newly runnable stages
25/04/05 07:05:05 INFO DAGScheduler: running: Set()
25/04/05 07:05:05 INFO DAGScheduler: waiting: Set()
25/04/05 07:05:05 INFO DAGScheduler: failed: Set()
25/04/05 07:05:05 INFO CodeGenerator: Code generated in 7.615846 ms
25/04/05 07:05:05 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/05 07:05:05 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/05 07:05:05 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/05 07:05:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/05 07:05:05 INFO DAGScheduler: Missing parents: List()
25/04/05 07:05:05 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/05 07:05:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/05 07:05:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/05 07:05:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:43823 (size: 5.5 KiB, free: 366.2 MiB)
25/04/05 07:05:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/05 07:05:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/05 07:05:05 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/05 07:05:05 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/05 07:05:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.2:41033 (size: 5.5 KiB, free: 366.2 MiB)
25/04/05 07:05:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.2:45990
25/04/05 07:05:05 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 29 ms on 172.18.0.2 (executor 1) (1/1)
25/04/05 07:05:05 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/05 07:05:05 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.035 s
25/04/05 07:05:05 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 07:05:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/05 07:05:05 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.038066 s
25/04/05 07:05:05 INFO FileSourceStrategy: Pushed Filters: 
25/04/05 07:05:05 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/05 07:05:05 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/05 07:05:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/05 07:05:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/05 07:05:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/05 07:05:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/05 07:05:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/05 07:05:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/05 07:05:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/05 07:05:05 INFO CodeGenerator: Code generated in 13.405502 ms
25/04/05 07:05:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/05 07:05:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/05 07:05:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:43823 (size: 32.6 KiB, free: 366.1 MiB)
25/04/05 07:05:05 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/05 07:05:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/05 07:05:05 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/05 07:05:05 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/05 07:05:05 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/05 07:05:05 INFO DAGScheduler: Parents of final stage: List()
25/04/05 07:05:05 INFO DAGScheduler: Missing parents: List()
25/04/05 07:05:05 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/05 07:05:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/05 07:05:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/05 07:05:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:43823 (size: 14.7 KiB, free: 366.1 MiB)
25/04/05 07:05:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/05 07:05:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/05 07:05:05 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/05 07:05:05 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.6, executor 2, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/05 07:05:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.6:46397 (size: 14.7 KiB, free: 366.3 MiB)
25/04/05 07:05:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.6:46397 (size: 32.6 KiB, free: 366.3 MiB)
25/04/05 07:05:07 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 1940 ms on 172.18.0.6 (executor 2) (1/1)
25/04/05 07:05:07 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/05 07:05:07 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 1.950 s
25/04/05 07:05:07 INFO DAGScheduler: looking for newly runnable stages
25/04/05 07:05:07 INFO DAGScheduler: running: Set()
25/04/05 07:05:07 INFO DAGScheduler: waiting: Set()
25/04/05 07:05:07 INFO DAGScheduler: failed: Set()
25/04/05 07:05:07 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/05 07:05:07 INFO CodeGenerator: Code generated in 6.79016 ms
25/04/05 07:05:07 INFO CodeGenerator: Code generated in 8.461997 ms
25/04/05 07:05:07 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/05 07:05:07 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/05 07:05:07 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/05 07:05:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/05 07:05:07 INFO DAGScheduler: Missing parents: List()
25/04/05 07:05:07 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/05 07:05:07 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/05 07:05:07 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/05 07:05:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:43823 (size: 87.8 KiB, free: 366.0 MiB)
25/04/05 07:05:07 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/05 07:05:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/05 07:05:07 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/05 07:05:07 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.6, executor 2, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/05 07:05:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.6:46397 (size: 87.8 KiB, free: 366.2 MiB)
25/04/05 07:05:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.6:39846
25/04/05 07:05:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 953 ms on 172.18.0.6 (executor 2) (1/1)
25/04/05 07:05:08 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/05 07:05:08 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.980 s
25/04/05 07:05:08 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/05 07:05:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/05 07:05:08 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.989711 s
25/04/05 07:05:08 INFO FileFormatWriter: Start to commit write Job 9b1c888f-8625-45bf-9cdb-d0c9e2304330.
25/04/05 07:05:08 INFO FileFormatWriter: Write Job 9b1c888f-8625-45bf-9cdb-d0c9e2304330 committed. Elapsed time: 35 ms.
25/04/05 07:05:08 INFO FileFormatWriter: Finished processing stats for write job 9b1c888f-8625-45bf-9cdb-d0c9e2304330.
25/04/05 07:05:09 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4041
25/04/05 07:05:09 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/05 07:05:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/05 07:05:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/05 07:05:09 WARN Dispatcher: Message RemoteProcessDisconnected(172.18.0.8:33276) dropped. Could not find BlockManagerEndpoint1.
25/04/05 07:05:09 INFO MemoryStore: MemoryStore cleared
25/04/05 07:05:09 INFO BlockManager: BlockManager stopped
25/04/05 07:05:09 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/05 07:05:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/05 07:05:09 INFO SparkContext: Successfully stopped SparkContext
25/04/05 07:05:09 INFO ShutdownHookManager: Shutdown hook called
25/04/05 07:05:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-65eec36e-9977-44ae-b988-b1bc4a17b247
25/04/05 07:05:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-aa241196-a522-4c9c-9581-0a39d2136dea
25/04/05 07:05:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-aa241196-a522-4c9c-9581-0a39d2136dea/pyspark-0950c54e-0bd0-4e80-aa5f-6f09417c6bd0
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/06 00:06:06 INFO SparkContext: Running Spark version 3.2.2
25/04/06 00:06:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/06 00:06:06 INFO ResourceUtils: ==============================================================
25/04/06 00:06:06 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/06 00:06:06 INFO ResourceUtils: ==============================================================
25/04/06 00:06:06 INFO SparkContext: Submitted application: Load product data into Hive
25/04/06 00:06:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/06 00:06:06 INFO ResourceProfile: Limiting resource is cpu
25/04/06 00:06:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/06 00:06:06 INFO SecurityManager: Changing view acls to: root
25/04/06 00:06:06 INFO SecurityManager: Changing modify acls to: root
25/04/06 00:06:06 INFO SecurityManager: Changing view acls groups to: 
25/04/06 00:06:06 INFO SecurityManager: Changing modify acls groups to: 
25/04/06 00:06:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/06 00:06:06 INFO Utils: Successfully started service 'sparkDriver' on port 44699.
25/04/06 00:06:06 INFO SparkEnv: Registering MapOutputTracker
25/04/06 00:06:06 INFO SparkEnv: Registering BlockManagerMaster
25/04/06 00:06:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/06 00:06:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/06 00:06:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/06 00:06:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6d9149ee-81c2-479f-9f19-3b4f32190fd4
25/04/06 00:06:06 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/06 00:06:07 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/06 00:06:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/06 00:06:07 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://7796893c36d7:4040
25/04/06 00:06:07 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/06 00:06:07 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.10:7077 after 29 ms (0 ms spent in bootstraps)
25/04/06 00:06:07 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250406000607-0086
25/04/06 00:06:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46291.
25/04/06 00:06:07 INFO NettyBlockTransferService: Server created on 7796893c36d7:46291
25/04/06 00:06:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/06 00:06:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 7796893c36d7, 46291, None)
25/04/06 00:06:07 INFO BlockManagerMasterEndpoint: Registering block manager 7796893c36d7:46291 with 366.3 MiB RAM, BlockManagerId(driver, 7796893c36d7, 46291, None)
25/04/06 00:06:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 7796893c36d7, 46291, None)
25/04/06 00:06:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 7796893c36d7, 46291, None)
25/04/06 00:06:07 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/06 00:06:07 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/06 00:06:07 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/06 00:06:08 INFO InMemoryFileIndex: It took 59 ms to list leaf files for 1 paths.
25/04/06 00:06:09 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/06 00:06:10 INFO FileSourceStrategy: Pushed Filters: 
25/04/06 00:06:10 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/06 00:06:10 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/06 00:06:11 INFO CodeGenerator: Code generated in 150.017965 ms
25/04/06 00:06:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/06 00:06:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/06 00:06:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 7796893c36d7:46291 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 00:06:11 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/06 00:06:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:11 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/06 00:06:11 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:11 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:11 INFO DAGScheduler: Parents of final stage: List()
25/04/06 00:06:11 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/06 00:06:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/06 00:06:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 7796893c36d7:46291 (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 00:06:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/06 00:06:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406000607-0086/0 on worker-20250401103611-172.18.0.8-40113 (172.18.0.8:40113) with 4 core(s)
25/04/06 00:06:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406000607-0086/0 on hostPort 172.18.0.8:40113 with 4 core(s), 1024.0 MiB RAM
25/04/06 00:06:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406000607-0086/1 on worker-20250401103611-172.18.0.2-40987 (172.18.0.2:40987) with 4 core(s)
25/04/06 00:06:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406000607-0086/1 on hostPort 172.18.0.2:40987 with 4 core(s), 1024.0 MiB RAM
25/04/06 00:06:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250406000607-0086/2 on worker-20250401103611-172.18.0.6-43309 (172.18.0.6:43309) with 4 core(s)
25/04/06 00:06:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20250406000607-0086/2 on hostPort 172.18.0.6:43309 with 4 core(s), 1024.0 MiB RAM
25/04/06 00:06:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406000607-0086/0 is now RUNNING
25/04/06 00:06:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406000607-0086/1 is now RUNNING
25/04/06 00:06:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250406000607-0086/2 is now RUNNING
25/04/06 00:06:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:33428) with ID 2,  ResourceProfileId 0
25/04/06 00:06:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.2:43402) with ID 1,  ResourceProfileId 0
25/04/06 00:06:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.8:42796) with ID 0,  ResourceProfileId 0
25/04/06 00:06:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.2:42817 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.2, 42817, None)
25/04/06 00:06:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:36011 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 36011, None)
25/04/06 00:06:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.8:43247 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.8, 43247, None)
25/04/06 00:06:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.2, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/06 00:06:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.2:42817 (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 00:06:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.2:42817 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 00:06:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1408 ms on 172.18.0.2 (executor 1) (1/1)
25/04/06 00:06:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/06 00:06:15 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.013 s
25/04/06 00:06:15 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 00:06:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/06 00:06:15 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.052122 s
25/04/06 00:06:15 INFO CodeGenerator: Code generated in 8.282913 ms
25/04/06 00:06:15 INFO FileSourceStrategy: Pushed Filters: 
25/04/06 00:06:15 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/06 00:06:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/06 00:06:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/06 00:06:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/06 00:06:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 7796893c36d7:46291 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 00:06:15 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/06 00:06:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:15 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/06 00:06:15 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/06 00:06:15 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/06 00:06:15 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/06 00:06:15 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 00:06:15 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/06 00:06:16 INFO metastore: Connected to metastore.
25/04/06 00:06:16 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=cc2445ad-b587-47b8-98e2-dfe66924ad88, clientType=HIVECLI]
25/04/06 00:06:16 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/06 00:06:16 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/06 00:06:16 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/06 00:06:16 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 00:06:16 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/06 00:06:16 INFO metastore: Connected to metastore.
25/04/06 00:06:16 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/06 00:06:16 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/06 00:06:16 INFO metastore: Connected to metastore.
25/04/06 00:06:16 INFO FileSourceStrategy: Pushed Filters: 
25/04/06 00:06:16 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/06 00:06:16 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/06 00:06:16 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 7796893c36d7:46291 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/06 00:06:16 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.2:42817 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/06 00:06:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 00:06:16 INFO CodeGenerator: Code generated in 23.619727 ms
25/04/06 00:06:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/06 00:06:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/06 00:06:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 7796893c36d7:46291 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 00:06:16 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/06 00:06:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:16 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/06 00:06:16 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:16 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:16 INFO DAGScheduler: Parents of final stage: List()
25/04/06 00:06:16 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:16 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:16 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/06 00:06:16 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/06 00:06:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 7796893c36d7:46291 (size: 14.1 KiB, free: 366.2 MiB)
25/04/06 00:06:16 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:16 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/06 00:06:16 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.8, executor 0, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/06 00:06:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.8:43247 (size: 14.1 KiB, free: 366.3 MiB)
25/04/06 00:06:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.8:43247 (size: 32.6 KiB, free: 366.3 MiB)
25/04/06 00:06:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1583 ms on 172.18.0.8 (executor 0) (1/1)
25/04/06 00:06:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/06 00:06:18 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.595 s
25/04/06 00:06:18 INFO DAGScheduler: looking for newly runnable stages
25/04/06 00:06:18 INFO DAGScheduler: running: Set()
25/04/06 00:06:18 INFO DAGScheduler: waiting: Set()
25/04/06 00:06:18 INFO DAGScheduler: failed: Set()
25/04/06 00:06:18 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/06 00:06:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/06 00:06:18 INFO CodeGenerator: Code generated in 14.993961 ms
25/04/06 00:06:18 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/06 00:06:18 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:18 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/06 00:06:18 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:18 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:18 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.1 MiB)
25/04/06 00:06:18 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/06 00:06:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 7796893c36d7:46291 (size: 17.8 KiB, free: 366.2 MiB)
25/04/06 00:06:18 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:18 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/06 00:06:18 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/06 00:06:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.8:43247 (size: 17.8 KiB, free: 366.2 MiB)
25/04/06 00:06:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.8:42796
25/04/06 00:06:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 148 ms on 172.18.0.8 (executor 0) (1/1)
25/04/06 00:06:18 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/06 00:06:18 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.157 s
25/04/06 00:06:18 INFO DAGScheduler: looking for newly runnable stages
25/04/06 00:06:18 INFO DAGScheduler: running: Set()
25/04/06 00:06:18 INFO DAGScheduler: waiting: Set()
25/04/06 00:06:18 INFO DAGScheduler: failed: Set()
25/04/06 00:06:18 INFO CodeGenerator: Code generated in 6.50669 ms
25/04/06 00:06:18 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/06 00:06:18 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:18 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/06 00:06:18 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:18 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/06 00:06:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/06 00:06:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 7796893c36d7:46291 (size: 5.5 KiB, free: 366.2 MiB)
25/04/06 00:06:18 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:18 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/06 00:06:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.8, executor 0, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/06 00:06:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.8:43247 (size: 5.5 KiB, free: 366.2 MiB)
25/04/06 00:06:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.8:42796
25/04/06 00:06:18 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 87 ms on 172.18.0.8 (executor 0) (1/1)
25/04/06 00:06:18 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/06 00:06:18 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.092 s
25/04/06 00:06:18 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 00:06:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/06 00:06:18 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.094864 s
25/04/06 00:06:18 INFO FileSourceStrategy: Pushed Filters: 
25/04/06 00:06:18 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/06 00:06:18 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/06 00:06:18 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 00:06:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/06 00:06:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/06 00:06:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 00:06:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/06 00:06:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/06 00:06:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/06 00:06:18 INFO CodeGenerator: Code generated in 11.504374 ms
25/04/06 00:06:18 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/06 00:06:18 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/06 00:06:18 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 7796893c36d7:46291 (size: 32.6 KiB, free: 366.1 MiB)
25/04/06 00:06:18 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/06 00:06:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/06 00:06:18 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/06 00:06:18 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:18 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:18 INFO DAGScheduler: Parents of final stage: List()
25/04/06 00:06:18 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:18 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:18 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/06 00:06:18 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/06 00:06:18 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 7796893c36d7:46291 (size: 14.7 KiB, free: 366.1 MiB)
25/04/06 00:06:18 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:18 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/06 00:06:18 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.2, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/06 00:06:18 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.2:42817 (size: 14.7 KiB, free: 366.3 MiB)
25/04/06 00:06:18 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.2:42817 (size: 32.6 KiB, free: 366.2 MiB)
25/04/06 00:06:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 491 ms on 172.18.0.2 (executor 1) (1/1)
25/04/06 00:06:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/06 00:06:19 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.501 s
25/04/06 00:06:19 INFO DAGScheduler: looking for newly runnable stages
25/04/06 00:06:19 INFO DAGScheduler: running: Set()
25/04/06 00:06:19 INFO DAGScheduler: waiting: Set()
25/04/06 00:06:19 INFO DAGScheduler: failed: Set()
25/04/06 00:06:19 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/06 00:06:19 INFO CodeGenerator: Code generated in 6.906605 ms
25/04/06 00:06:19 INFO CodeGenerator: Code generated in 8.247223 ms
25/04/06 00:06:19 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/06 00:06:19 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/06 00:06:19 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/06 00:06:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/06 00:06:19 INFO DAGScheduler: Missing parents: List()
25/04/06 00:06:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/06 00:06:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/06 00:06:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/06 00:06:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 7796893c36d7:46291 (size: 87.8 KiB, free: 366.0 MiB)
25/04/06 00:06:19 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/06 00:06:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/06 00:06:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/06 00:06:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.2, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/06 00:06:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.2:42817 (size: 87.8 KiB, free: 366.1 MiB)
25/04/06 00:06:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.2:43402
25/04/06 00:06:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 945 ms on 172.18.0.2 (executor 1) (1/1)
25/04/06 00:06:20 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/06 00:06:20 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.968 s
25/04/06 00:06:20 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/06 00:06:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/06 00:06:20 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.976878 s
25/04/06 00:06:20 INFO FileFormatWriter: Start to commit write Job 23e5eb4a-5e51-4065-b078-8df81801dedb.
25/04/06 00:06:20 INFO FileFormatWriter: Write Job 23e5eb4a-5e51-4065-b078-8df81801dedb committed. Elapsed time: 35 ms.
25/04/06 00:06:20 INFO FileFormatWriter: Finished processing stats for write job 23e5eb4a-5e51-4065-b078-8df81801dedb.
25/04/06 00:06:20 INFO SparkUI: Stopped Spark web UI at http://7796893c36d7:4040
25/04/06 00:06:20 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/06 00:06:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/06 00:06:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/06 00:06:20 INFO MemoryStore: MemoryStore cleared
25/04/06 00:06:20 INFO BlockManager: BlockManager stopped
25/04/06 00:06:20 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/06 00:06:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/06 00:06:20 INFO SparkContext: Successfully stopped SparkContext
25/04/06 00:06:20 INFO ShutdownHookManager: Shutdown hook called
25/04/06 00:06:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-b4855bbd-4daf-43e9-b12d-17c2cff2e57f/pyspark-bf7cd385-1354-4410-bbfd-bd277b5e249c
25/04/06 00:06:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-b4855bbd-4daf-43e9-b12d-17c2cff2e57f
25/04/06 00:06:20 INFO ShutdownHookManager: Deleting directory /tmp/spark-df356ba7-41e4-4c91-8ff1-ec0c71c60ff3
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/07 00:05:15 INFO SparkContext: Running Spark version 3.2.2
25/04/07 00:05:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/07 00:05:15 INFO ResourceUtils: ==============================================================
25/04/07 00:05:15 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/07 00:05:15 INFO ResourceUtils: ==============================================================
25/04/07 00:05:15 INFO SparkContext: Submitted application: Load product data into Hive
25/04/07 00:05:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/07 00:05:15 INFO ResourceProfile: Limiting resource is cpu
25/04/07 00:05:15 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/07 00:05:15 INFO SecurityManager: Changing view acls to: root
25/04/07 00:05:15 INFO SecurityManager: Changing modify acls to: root
25/04/07 00:05:15 INFO SecurityManager: Changing view acls groups to: 
25/04/07 00:05:15 INFO SecurityManager: Changing modify acls groups to: 
25/04/07 00:05:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/07 00:05:15 INFO Utils: Successfully started service 'sparkDriver' on port 33823.
25/04/07 00:05:15 INFO SparkEnv: Registering MapOutputTracker
25/04/07 00:05:15 INFO SparkEnv: Registering BlockManagerMaster
25/04/07 00:05:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/07 00:05:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/07 00:05:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/07 00:05:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-77e5c3e1-98ee-4fcc-be94-bef609cb28c0
25/04/07 00:05:15 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/07 00:05:16 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/07 00:05:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/04/07 00:05:16 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://cfd5ae002cf8:4040
25/04/07 00:05:16 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/07 00:05:16 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.13:7077 after 24 ms (0 ms spent in bootstraps)
25/04/07 00:05:16 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250407000516-0002
25/04/07 00:05:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33189.
25/04/07 00:05:16 INFO NettyBlockTransferService: Server created on cfd5ae002cf8:33189
25/04/07 00:05:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/07 00:05:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, cfd5ae002cf8, 33189, None)
25/04/07 00:05:16 INFO BlockManagerMasterEndpoint: Registering block manager cfd5ae002cf8:33189 with 366.3 MiB RAM, BlockManagerId(driver, cfd5ae002cf8, 33189, None)
25/04/07 00:05:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, cfd5ae002cf8, 33189, None)
25/04/07 00:05:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, cfd5ae002cf8, 33189, None)
25/04/07 00:05:16 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/07 00:05:16 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/07 00:05:16 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/07 00:05:18 INFO InMemoryFileIndex: It took 74 ms to list leaf files for 1 paths.
25/04/07 00:05:18 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
25/04/07 00:05:22 INFO FileSourceStrategy: Pushed Filters: 
25/04/07 00:05:22 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/07 00:05:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/07 00:05:23 INFO CodeGenerator: Code generated in 335.725879 ms
25/04/07 00:05:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/07 00:05:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/07 00:05:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on cfd5ae002cf8:33189 (size: 32.6 KiB, free: 366.3 MiB)
25/04/07 00:05:23 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/07 00:05:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/07 00:05:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/07 00:05:23 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:23 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:23 INFO DAGScheduler: Parents of final stage: List()
25/04/07 00:05:23 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/07 00:05:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/07 00:05:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on cfd5ae002cf8:33189 (size: 5.8 KiB, free: 366.3 MiB)
25/04/07 00:05:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/07 00:05:38 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
25/04/07 00:05:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250407000516-0002/0 on worker-20250406221201-172.18.0.7-43403 (172.18.0.7:43403) with 4 core(s)
25/04/07 00:05:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250407000516-0002/0 on hostPort 172.18.0.7:43403 with 4 core(s), 1024.0 MiB RAM
25/04/07 00:05:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250407000516-0002/1 on worker-20250406221201-172.18.0.3-43441 (172.18.0.3:43441) with 4 core(s)
25/04/07 00:05:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250407000516-0002/1 on hostPort 172.18.0.3:43441 with 4 core(s), 1024.0 MiB RAM
25/04/07 00:05:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250407000516-0002/2 on worker-20250406221201-172.18.0.11-45757 (172.18.0.11:45757) with 4 core(s)
25/04/07 00:05:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20250407000516-0002/2 on hostPort 172.18.0.11:45757 with 4 core(s), 1024.0 MiB RAM
25/04/07 00:05:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250407000516-0002/0 is now RUNNING
25/04/07 00:05:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250407000516-0002/1 is now RUNNING
25/04/07 00:05:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250407000516-0002/2 is now RUNNING
25/04/07 00:05:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.11:41298) with ID 2,  ResourceProfileId 0
25/04/07 00:05:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.3:45716) with ID 1,  ResourceProfileId 0
25/04/07 00:05:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:35054) with ID 0,  ResourceProfileId 0
25/04/07 00:05:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.3:36313 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.3, 36313, None)
25/04/07 00:05:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:40205 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.7, 40205, None)
25/04/07 00:05:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.11:36833 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.11, 36833, None)
25/04/07 00:05:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.11, executor 2, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/07 00:05:41 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.11:36833 (size: 5.8 KiB, free: 366.3 MiB)
25/04/07 00:05:41 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.11:36833 (size: 32.6 KiB, free: 366.3 MiB)
25/04/07 00:05:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1409 ms on 172.18.0.11 (executor 2) (1/1)
25/04/07 00:05:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/07 00:05:42 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 18.951 s
25/04/07 00:05:42 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/07 00:05:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/07 00:05:42 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 19.003950 s
25/04/07 00:05:42 INFO CodeGenerator: Code generated in 8.240581 ms
25/04/07 00:05:42 INFO FileSourceStrategy: Pushed Filters: 
25/04/07 00:05:42 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/07 00:05:42 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/07 00:05:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/07 00:05:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/07 00:05:42 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on cfd5ae002cf8:33189 (size: 32.6 KiB, free: 366.2 MiB)
25/04/07 00:05:42 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/07 00:05:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/07 00:05:42 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/07 00:05:42 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/07 00:05:42 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/07 00:05:42 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/07 00:05:42 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/07 00:05:42 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/07 00:05:42 INFO metastore: Connected to metastore.
25/04/07 00:05:42 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=f0dc7b82-7c7a-4331-a033-650c5d3777ac, clientType=HIVECLI]
25/04/07 00:05:42 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/07 00:05:42 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/07 00:05:42 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/07 00:05:42 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/07 00:05:42 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/07 00:05:42 INFO metastore: Connected to metastore.
25/04/07 00:05:43 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/07 00:05:43 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/07 00:05:43 INFO metastore: Connected to metastore.
25/04/07 00:05:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on cfd5ae002cf8:33189 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/07 00:05:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.11:36833 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/07 00:05:43 INFO FileSourceStrategy: Pushed Filters: 
25/04/07 00:05:43 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/07 00:05:43 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/07 00:05:43 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/07 00:05:43 INFO CodeGenerator: Code generated in 24.264837 ms
25/04/07 00:05:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/07 00:05:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/07 00:05:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on cfd5ae002cf8:33189 (size: 32.6 KiB, free: 366.2 MiB)
25/04/07 00:05:43 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/07 00:05:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/07 00:05:43 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/07 00:05:43 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:43 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:43 INFO DAGScheduler: Parents of final stage: List()
25/04/07 00:05:43 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:43 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/07 00:05:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/07 00:05:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on cfd5ae002cf8:33189 (size: 14.1 KiB, free: 366.2 MiB)
25/04/07 00:05:43 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/07 00:05:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.3, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/07 00:05:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.3:36313 (size: 14.1 KiB, free: 366.3 MiB)
25/04/07 00:05:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.3:36313 (size: 32.6 KiB, free: 366.3 MiB)
25/04/07 00:05:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1579 ms on 172.18.0.3 (executor 1) (1/1)
25/04/07 00:05:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/07 00:05:44 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 1.592 s
25/04/07 00:05:44 INFO DAGScheduler: looking for newly runnable stages
25/04/07 00:05:44 INFO DAGScheduler: running: Set()
25/04/07 00:05:44 INFO DAGScheduler: waiting: Set()
25/04/07 00:05:44 INFO DAGScheduler: failed: Set()
25/04/07 00:05:44 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/07 00:05:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/07 00:05:44 INFO CodeGenerator: Code generated in 13.958051 ms
25/04/07 00:05:44 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/07 00:05:44 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:44 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/07 00:05:44 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:44 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.1 MiB)
25/04/07 00:05:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/07 00:05:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on cfd5ae002cf8:33189 (size: 17.8 KiB, free: 366.2 MiB)
25/04/07 00:05:44 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/07 00:05:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.3, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.3:36313 (size: 17.8 KiB, free: 366.2 MiB)
25/04/07 00:05:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.3:45716
25/04/07 00:05:45 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 143 ms on 172.18.0.3 (executor 1) (1/1)
25/04/07 00:05:45 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/07 00:05:45 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.152 s
25/04/07 00:05:45 INFO DAGScheduler: looking for newly runnable stages
25/04/07 00:05:45 INFO DAGScheduler: running: Set()
25/04/07 00:05:45 INFO DAGScheduler: waiting: Set()
25/04/07 00:05:45 INFO DAGScheduler: failed: Set()
25/04/07 00:05:45 INFO CodeGenerator: Code generated in 6.422316 ms
25/04/07 00:05:45 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/07 00:05:45 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:45 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/07 00:05:45 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:45 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/07 00:05:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on cfd5ae002cf8:33189 (size: 5.5 KiB, free: 366.2 MiB)
25/04/07 00:05:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:45 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/07 00:05:45 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.3, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.3:36313 (size: 5.5 KiB, free: 366.2 MiB)
25/04/07 00:05:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.3:45716
25/04/07 00:05:45 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 84 ms on 172.18.0.3 (executor 1) (1/1)
25/04/07 00:05:45 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/07 00:05:45 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.087 s
25/04/07 00:05:45 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/07 00:05:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/07 00:05:45 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.090304 s
25/04/07 00:05:45 INFO FileSourceStrategy: Pushed Filters: 
25/04/07 00:05:45 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/07 00:05:45 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/07 00:05:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/07 00:05:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/07 00:05:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/07 00:05:45 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/07 00:05:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/07 00:05:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/07 00:05:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/07 00:05:45 INFO CodeGenerator: Code generated in 12.361185 ms
25/04/07 00:05:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/07 00:05:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on cfd5ae002cf8:33189 (size: 32.6 KiB, free: 366.1 MiB)
25/04/07 00:05:45 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/07 00:05:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/07 00:05:45 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/07 00:05:45 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:45 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:45 INFO DAGScheduler: Parents of final stage: List()
25/04/07 00:05:45 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:45 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/07 00:05:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on cfd5ae002cf8:33189 (size: 14.7 KiB, free: 366.1 MiB)
25/04/07 00:05:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:45 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/07 00:05:45 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.3, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.3:36313 (size: 14.7 KiB, free: 366.2 MiB)
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.3:36313 (size: 32.6 KiB, free: 366.2 MiB)
25/04/07 00:05:45 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 265 ms on 172.18.0.3 (executor 1) (1/1)
25/04/07 00:05:45 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/07 00:05:45 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.274 s
25/04/07 00:05:45 INFO DAGScheduler: looking for newly runnable stages
25/04/07 00:05:45 INFO DAGScheduler: running: Set()
25/04/07 00:05:45 INFO DAGScheduler: waiting: Set()
25/04/07 00:05:45 INFO DAGScheduler: failed: Set()
25/04/07 00:05:45 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/07 00:05:45 INFO CodeGenerator: Code generated in 6.75162 ms
25/04/07 00:05:45 INFO CodeGenerator: Code generated in 7.922661 ms
25/04/07 00:05:45 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/07 00:05:45 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/07 00:05:45 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/07 00:05:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/07 00:05:45 INFO DAGScheduler: Missing parents: List()
25/04/07 00:05:45 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/07 00:05:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/07 00:05:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on cfd5ae002cf8:33189 (size: 87.8 KiB, free: 366.0 MiB)
25/04/07 00:05:45 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/07 00:05:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/07 00:05:45 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/07 00:05:45 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.3, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/07 00:05:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.3:36313 (size: 87.8 KiB, free: 366.1 MiB)
25/04/07 00:05:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.3:45716
25/04/07 00:05:46 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 879 ms on 172.18.0.3 (executor 1) (1/1)
25/04/07 00:05:46 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/07 00:05:46 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.905 s
25/04/07 00:05:46 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/07 00:05:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/07 00:05:46 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.914481 s
25/04/07 00:05:46 INFO FileFormatWriter: Start to commit write Job 4373cc00-f7e4-4630-b376-7cd9a26a388f.
25/04/07 00:05:46 INFO FileFormatWriter: Write Job 4373cc00-f7e4-4630-b376-7cd9a26a388f committed. Elapsed time: 35 ms.
25/04/07 00:05:46 INFO FileFormatWriter: Finished processing stats for write job 4373cc00-f7e4-4630-b376-7cd9a26a388f.
25/04/07 00:05:47 INFO SparkUI: Stopped Spark web UI at http://cfd5ae002cf8:4040
25/04/07 00:05:47 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/07 00:05:47 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/07 00:05:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/07 00:05:47 INFO MemoryStore: MemoryStore cleared
25/04/07 00:05:47 INFO BlockManager: BlockManager stopped
25/04/07 00:05:47 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/07 00:05:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/07 00:05:47 INFO SparkContext: Successfully stopped SparkContext
25/04/07 00:05:47 INFO ShutdownHookManager: Shutdown hook called
25/04/07 00:05:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-e2f20371-29f5-44f0-a14d-edc9767a7e2b
25/04/07 00:05:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-4a34f942-1902-472f-975c-fdf4f051c9ea/pyspark-2a4179f2-4621-4a1b-ab38-ab41bed881e7
25/04/07 00:05:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-4a34f942-1902-472f-975c-fdf4f051c9ea
Spark job completed successfully.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
25/04/08 00:05:22 INFO SparkContext: Running Spark version 3.2.2
25/04/08 00:05:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/08 00:05:22 INFO ResourceUtils: ==============================================================
25/04/08 00:05:22 INFO ResourceUtils: No custom resources configured for spark.driver.
25/04/08 00:05:22 INFO ResourceUtils: ==============================================================
25/04/08 00:05:22 INFO SparkContext: Submitted application: Load product data into Hive
25/04/08 00:05:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/04/08 00:05:22 INFO ResourceProfile: Limiting resource is cpu
25/04/08 00:05:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/04/08 00:05:23 INFO SecurityManager: Changing view acls to: root
25/04/08 00:05:23 INFO SecurityManager: Changing modify acls to: root
25/04/08 00:05:23 INFO SecurityManager: Changing view acls groups to: 
25/04/08 00:05:23 INFO SecurityManager: Changing modify acls groups to: 
25/04/08 00:05:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
25/04/08 00:05:23 INFO Utils: Successfully started service 'sparkDriver' on port 39971.
25/04/08 00:05:23 INFO SparkEnv: Registering MapOutputTracker
25/04/08 00:05:23 INFO SparkEnv: Registering BlockManagerMaster
25/04/08 00:05:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/04/08 00:05:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/04/08 00:05:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/04/08 00:05:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5cdfc9ec-2849-4530-b7f6-73069edaae45
25/04/08 00:05:23 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/04/08 00:05:23 INFO SparkEnv: Registering OutputCommitCoordinator
25/04/08 00:05:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/04/08 00:05:23 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/04/08 00:05:23 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://98d2d932c324:4041
25/04/08 00:05:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
25/04/08 00:05:23 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.18:7077 after 31 ms (0 ms spent in bootstraps)
25/04/08 00:05:23 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250408000523-0002
25/04/08 00:05:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32769.
25/04/08 00:05:23 INFO NettyBlockTransferService: Server created on 98d2d932c324:32769
25/04/08 00:05:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/08 00:05:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 98d2d932c324, 32769, None)
25/04/08 00:05:23 INFO BlockManagerMasterEndpoint: Registering block manager 98d2d932c324:32769 with 366.3 MiB RAM, BlockManagerId(driver, 98d2d932c324, 32769, None)
25/04/08 00:05:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 98d2d932c324, 32769, None)
25/04/08 00:05:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 98d2d932c324, 32769, None)
25/04/08 00:05:24 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/04/08 00:05:24 INFO SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir.
25/04/08 00:05:24 INFO SharedState: Warehouse path is 'file:/user/hive/warehouse'.
25/04/08 00:05:25 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
25/04/08 00:05:25 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
25/04/08 00:05:27 INFO FileSourceStrategy: Pushed Filters: 
25/04/08 00:05:27 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
25/04/08 00:05:27 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/08 00:05:27 INFO CodeGenerator: Code generated in 166.895479 ms
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 345.7 KiB, free 366.0 MiB)
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.9 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 98d2d932c324:32769 (size: 32.6 KiB, free: 366.3 MiB)
25/04/08 00:05:27 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/04/08 00:05:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:27 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/04/08 00:05:27 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:27 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:27 INFO DAGScheduler: Parents of final stage: List()
25/04/08 00:05:27 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.6 KiB, free 365.9 MiB)
25/04/08 00:05:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 365.9 MiB)
25/04/08 00:05:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 98d2d932c324:32769 (size: 5.8 KiB, free: 366.3 MiB)
25/04/08 00:05:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/04/08 00:05:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250408000523-0002/0 on worker-20250407214357-172.18.0.4-36701 (172.18.0.4:36701) with 4 core(s)
25/04/08 00:05:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20250408000523-0002/0 on hostPort 172.18.0.4:36701 with 4 core(s), 1024.0 MiB RAM
25/04/08 00:05:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250408000523-0002/1 on worker-20250407214357-172.18.0.7-35443 (172.18.0.7:35443) with 4 core(s)
25/04/08 00:05:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20250408000523-0002/1 on hostPort 172.18.0.7:35443 with 4 core(s), 1024.0 MiB RAM
25/04/08 00:05:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250408000523-0002/2 on worker-20250407214357-172.18.0.6-37199 (172.18.0.6:37199) with 4 core(s)
25/04/08 00:05:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20250408000523-0002/2 on hostPort 172.18.0.6:37199 with 4 core(s), 1024.0 MiB RAM
25/04/08 00:05:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250408000523-0002/1 is now RUNNING
25/04/08 00:05:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250408000523-0002/0 is now RUNNING
25/04/08 00:05:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250408000523-0002/2 is now RUNNING
25/04/08 00:05:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.7:37846) with ID 1,  ResourceProfileId 0
25/04/08 00:05:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.4:60138) with ID 0,  ResourceProfileId 0
25/04/08 00:05:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.6:42006) with ID 2,  ResourceProfileId 0
25/04/08 00:05:30 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.4:36133 with 366.3 MiB RAM, BlockManagerId(0, 172.18.0.4, 36133, None)
25/04/08 00:05:30 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.7:44939 with 366.3 MiB RAM, BlockManagerId(1, 172.18.0.7, 44939, None)
25/04/08 00:05:30 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.6:38683 with 366.3 MiB RAM, BlockManagerId(2, 172.18.0.6, 38683, None)
25/04/08 00:05:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.7, executor 1, partition 0, ANY, 4907 bytes) taskResourceAssignments Map()
25/04/08 00:05:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.7:44939 (size: 5.8 KiB, free: 366.3 MiB)
25/04/08 00:05:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.7:44939 (size: 32.6 KiB, free: 366.3 MiB)
25/04/08 00:05:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1405 ms on 172.18.0.7 (executor 1) (1/1)
25/04/08 00:05:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/04/08 00:05:31 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 4.052 s
25/04/08 00:05:31 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/08 00:05:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/04/08 00:05:31 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 4.092628 s
25/04/08 00:05:31 INFO CodeGenerator: Code generated in 8.133439 ms
25/04/08 00:05:31 INFO FileSourceStrategy: Pushed Filters: 
25/04/08 00:05:31 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/08 00:05:31 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/04/08 00:05:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 345.7 KiB, free 365.6 MiB)
25/04/08 00:05:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.5 MiB)
25/04/08 00:05:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 98d2d932c324:32769 (size: 32.6 KiB, free: 366.2 MiB)
25/04/08 00:05:31 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/04/08 00:05:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:32 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/08 00:05:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/04/08 00:05:32 INFO HiveConf: Found configuration file file:/opt/bitnami/spark/conf/hive-site.xml
25/04/08 00:05:32 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/user/hive/warehouse
25/04/08 00:05:32 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/08 00:05:32 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/08 00:05:32 INFO metastore: Connected to metastore.
25/04/08 00:05:32 INFO SQLStdHiveAccessController: Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4c693e4c-5cda-47bf-be05-e34040ef10b4, clientType=HIVECLI]
25/04/08 00:05:32 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
25/04/08 00:05:32 INFO metastore: Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
25/04/08 00:05:32 INFO metastore: Closed a connection to metastore, current connections: 0
25/04/08 00:05:32 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/08 00:05:32 INFO metastore: Opened a connection to metastore, current connections: 1
25/04/08 00:05:32 INFO metastore: Connected to metastore.
25/04/08 00:05:32 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
25/04/08 00:05:32 INFO metastore: Opened a connection to metastore, current connections: 2
25/04/08 00:05:32 INFO metastore: Connected to metastore.
25/04/08 00:05:32 INFO FileSourceStrategy: Pushed Filters: 
25/04/08 00:05:32 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/08 00:05:32 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, Date: string>
25/04/08 00:05:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 98d2d932c324:32769 in memory (size: 5.8 KiB, free: 366.2 MiB)
25/04/08 00:05:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.7:44939 in memory (size: 5.8 KiB, free: 366.3 MiB)
25/04/08 00:05:32 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/08 00:05:32 INFO CodeGenerator: Code generated in 26.061717 ms
25/04/08 00:05:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 345.6 KiB, free 365.2 MiB)
25/04/08 00:05:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 365.2 MiB)
25/04/08 00:05:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 98d2d932c324:32769 (size: 32.6 KiB, free: 366.2 MiB)
25/04/08 00:05:32 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0
25/04/08 00:05:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:32 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/04/08 00:05:32 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:32 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:32 INFO DAGScheduler: Parents of final stage: List()
25/04/08 00:05:32 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:32 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 29.9 KiB, free 365.2 MiB)
25/04/08 00:05:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 365.1 MiB)
25/04/08 00:05:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 98d2d932c324:32769 (size: 14.1 KiB, free: 366.2 MiB)
25/04/08 00:05:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/04/08 00:05:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.18.0.7, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/08 00:05:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.7:44939 (size: 14.1 KiB, free: 366.3 MiB)
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.7:44939 (size: 32.6 KiB, free: 366.2 MiB)
25/04/08 00:05:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 312 ms on 172.18.0.7 (executor 1) (1/1)
25/04/08 00:05:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/04/08 00:05:33 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.325 s
25/04/08 00:05:33 INFO DAGScheduler: looking for newly runnable stages
25/04/08 00:05:33 INFO DAGScheduler: running: Set()
25/04/08 00:05:33 INFO DAGScheduler: waiting: Set()
25/04/08 00:05:33 INFO DAGScheduler: failed: Set()
25/04/08 00:05:33 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/08 00:05:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
25/04/08 00:05:33 INFO CodeGenerator: Code generated in 14.223793 ms
25/04/08 00:05:33 INFO DAGScheduler: Registering RDD 16 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
25/04/08 00:05:33 INFO DAGScheduler: Got map stage job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:33 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
25/04/08 00:05:33 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:33 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 37.6 KiB, free 365.1 MiB)
25/04/08 00:05:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.8 KiB, free 365.1 MiB)
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 98d2d932c324:32769 (size: 17.8 KiB, free: 366.2 MiB)
25/04/08 00:05:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/04/08 00:05:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.18.0.7, executor 1, partition 0, NODE_LOCAL, 4446 bytes) taskResourceAssignments Map()
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.7:44939 (size: 17.8 KiB, free: 366.2 MiB)
25/04/08 00:05:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.7:37846
25/04/08 00:05:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 139 ms on 172.18.0.7 (executor 1) (1/1)
25/04/08 00:05:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/04/08 00:05:33 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.147 s
25/04/08 00:05:33 INFO DAGScheduler: looking for newly runnable stages
25/04/08 00:05:33 INFO DAGScheduler: running: Set()
25/04/08 00:05:33 INFO DAGScheduler: waiting: Set()
25/04/08 00:05:33 INFO DAGScheduler: failed: Set()
25/04/08 00:05:33 INFO CodeGenerator: Code generated in 6.799668 ms
25/04/08 00:05:33 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
25/04/08 00:05:33 INFO DAGScheduler: Got job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:33 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
25/04/08 00:05:33 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:33 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.0 KiB, free 365.1 MiB)
25/04/08 00:05:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 98d2d932c324:32769 (size: 5.5 KiB, free: 366.2 MiB)
25/04/08 00:05:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
25/04/08 00:05:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 3) (172.18.0.7, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.7:44939 (size: 5.5 KiB, free: 366.2 MiB)
25/04/08 00:05:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.7:37846
25/04/08 00:05:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 3) in 29 ms on 172.18.0.7 (executor 1) (1/1)
25/04/08 00:05:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/04/08 00:05:33 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
25/04/08 00:05:33 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/08 00:05:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/04/08 00:05:33 INFO DAGScheduler: Job 3 finished: count at NativeMethodAccessorImpl.java:0, took 0.036191 s
25/04/08 00:05:33 INFO FileSourceStrategy: Pushed Filters: 
25/04/08 00:05:33 INFO FileSourceStrategy: Post-Scan Filters: 
25/04/08 00:05:33 INFO FileSourceStrategy: Output Data Schema: struct<StockCode: string, ProductName: string, ProductDescription: string, Date: string, UnitPrice: string ... 3 more fields>
25/04/08 00:05:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/08 00:05:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/08 00:05:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/08 00:05:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/08 00:05:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/04/08 00:05:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/04/08 00:05:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
25/04/08 00:05:33 INFO CodeGenerator: Code generated in 12.931159 ms
25/04/08 00:05:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 345.6 KiB, free 364.7 MiB)
25/04/08 00:05:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 364.7 MiB)
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 98d2d932c324:32769 (size: 32.6 KiB, free: 366.1 MiB)
25/04/08 00:05:33 INFO SparkContext: Created broadcast 7 from insertInto at NativeMethodAccessorImpl.java:0
25/04/08 00:05:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/04/08 00:05:33 INFO DAGScheduler: Registering RDD 24 (insertInto at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/04/08 00:05:33 INFO DAGScheduler: Got map stage job 4 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:33 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:33 INFO DAGScheduler: Parents of final stage: List()
25/04/08 00:05:33 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:33 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.8 KiB, free 364.7 MiB)
25/04/08 00:05:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 364.7 MiB)
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 98d2d932c324:32769 (size: 14.7 KiB, free: 366.1 MiB)
25/04/08 00:05:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[24] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/04/08 00:05:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 4) (172.18.0.7, executor 1, partition 0, ANY, 4896 bytes) taskResourceAssignments Map()
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.7:44939 (size: 14.7 KiB, free: 366.2 MiB)
25/04/08 00:05:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.7:44939 (size: 32.6 KiB, free: 366.2 MiB)
25/04/08 00:05:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 4) in 249 ms on 172.18.0.7 (executor 1) (1/1)
25/04/08 00:05:34 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/04/08 00:05:34 INFO DAGScheduler: ShuffleMapStage 7 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.262 s
25/04/08 00:05:34 INFO DAGScheduler: looking for newly runnable stages
25/04/08 00:05:34 INFO DAGScheduler: running: Set()
25/04/08 00:05:34 INFO DAGScheduler: waiting: Set()
25/04/08 00:05:34 INFO DAGScheduler: failed: Set()
25/04/08 00:05:34 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
25/04/08 00:05:34 INFO CodeGenerator: Code generated in 7.040483 ms
25/04/08 00:05:34 INFO CodeGenerator: Code generated in 9.539497 ms
25/04/08 00:05:34 INFO SparkContext: Starting job: insertInto at NativeMethodAccessorImpl.java:0
25/04/08 00:05:34 INFO DAGScheduler: Got job 5 (insertInto at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/04/08 00:05:34 INFO DAGScheduler: Final stage: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0)
25/04/08 00:05:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
25/04/08 00:05:34 INFO DAGScheduler: Missing parents: List()
25/04/08 00:05:34 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0), which has no missing parents
25/04/08 00:05:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 238.6 KiB, free 364.4 MiB)
25/04/08 00:05:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 87.8 KiB, free 364.3 MiB)
25/04/08 00:05:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 98d2d932c324:32769 (size: 87.8 KiB, free: 366.0 MiB)
25/04/08 00:05:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1478
25/04/08 00:05:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at insertInto at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/04/08 00:05:34 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/04/08 00:05:34 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 5) (172.18.0.7, executor 1, partition 0, NODE_LOCAL, 4457 bytes) taskResourceAssignments Map()
25/04/08 00:05:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.7:44939 (size: 87.8 KiB, free: 366.1 MiB)
25/04/08 00:05:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.7:37846
25/04/08 00:05:35 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 5) in 857 ms on 172.18.0.7 (executor 1) (1/1)
25/04/08 00:05:35 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/04/08 00:05:35 INFO DAGScheduler: ResultStage 9 (insertInto at NativeMethodAccessorImpl.java:0) finished in 0.880 s
25/04/08 00:05:35 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/04/08 00:05:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/04/08 00:05:35 INFO DAGScheduler: Job 5 finished: insertInto at NativeMethodAccessorImpl.java:0, took 0.886459 s
25/04/08 00:05:35 INFO FileFormatWriter: Start to commit write Job 5976ca5f-2232-4940-be4f-cbcf7e09d32c.
25/04/08 00:05:35 INFO FileFormatWriter: Write Job 5976ca5f-2232-4940-be4f-cbcf7e09d32c committed. Elapsed time: 37 ms.
25/04/08 00:05:35 INFO FileFormatWriter: Finished processing stats for write job 5976ca5f-2232-4940-be4f-cbcf7e09d32c.
25/04/08 00:05:35 INFO SparkUI: Stopped Spark web UI at http://98d2d932c324:4041
25/04/08 00:05:35 INFO StandaloneSchedulerBackend: Shutting down all executors
25/04/08 00:05:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
25/04/08 00:05:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/04/08 00:05:35 INFO MemoryStore: MemoryStore cleared
25/04/08 00:05:35 INFO BlockManager: BlockManager stopped
25/04/08 00:05:35 INFO BlockManagerMaster: BlockManagerMaster stopped
25/04/08 00:05:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/04/08 00:05:35 INFO SparkContext: Successfully stopped SparkContext
25/04/08 00:05:35 INFO ShutdownHookManager: Shutdown hook called
25/04/08 00:05:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-ebae975d-e33b-4cc3-9fca-b053615faca5/pyspark-7f9c7013-d2b1-470e-9bad-b92781aa15bf
25/04/08 00:05:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-737c689b-d39b-474b-a904-8dc39ea95a81
25/04/08 00:05:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-ebae975d-e33b-4cc3-9fca-b053615faca5
Spark job completed successfully.
