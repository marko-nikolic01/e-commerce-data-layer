<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers>
    <hudson.triggers.TimerTrigger>
      <spec>15 0 * * *</spec>
    </hudson.triggers.TimerTrigger>
  </triggers>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <org.jvnet.hudson.plugins.SSHBuilder plugin="ssh@158.ve2a_e90fb_7319">
      <siteName>root@spark-master:22</siteName>
      <command>echo &quot;Starting Spark job...&quot; | tee -a spark_job.log

LOG_FILE=/opt/bitnami/spark/logs/load_countries_into_hdfs.log

export JAVA_HOME=/opt/bitnami/java
export PATH=$JAVA_HOME/bin:$PATH
export PATH=$PATH:/opt/bitnami/python/bin
export PYSPARK_PYTHON=/opt/bitnami/python/bin/python3
export CORE_CONF_fs_defaultFS=hdfs://namenode:9000

/opt/bitnami/spark/bin/spark-submit --master spark://spark-master:7077 /opt/bitnami/spark/jobs/load_countries_into_hive.py 2&gt;&amp;1 | tee -a &quot;$LOG_FILE&quot;

exit_code=${PIPESTATUS[0]}

if [ $exit_code -ne 0 ]; then
  echo &quot;Spark job FAILED!&quot; | tee -a &quot;$LOG_FILE&quot;
  exit 1
else
  echo &quot;Spark job completed successfully.&quot; | tee -a &quot;$LOG_FILE&quot;
fi
</command>
      <execEachLine>false</execEachLine>
      <hideCommand>false</hideCommand>
    </org.jvnet.hudson.plugins.SSHBuilder>
  </builders>
  <publishers/>
  <buildWrappers/>
</project>