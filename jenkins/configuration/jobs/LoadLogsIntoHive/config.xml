<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers>
    <hudson.triggers.TimerTrigger>
      <spec>5 0-23/4 * * *</spec>
    </hudson.triggers.TimerTrigger>
  </triggers>
  <concurrentBuild>false</concurrentBuild>
  <builders/>
  <publishers>
    <hudson.tasks.Mailer plugin="mailer@489.vd4b_25144138f">
      <recipients>nikolicmarko1243@gamail.com</recipients>
      <dontNotifyEveryUnstableBuild>false</dontNotifyEveryUnstableBuild>
      <sendToIndividuals>false</sendToIndividuals>
    </hudson.tasks.Mailer>
  </publishers>
  <buildWrappers>
    <org.jvnet.hudson.plugins.SSHBuildWrapper plugin="ssh@158.ve2a_e90fb_7319">
      <siteName>root@spark-master:22</siteName>
      <preScript>echo &quot;Starting Spark job...&quot; | tee -a spark_job.log

LOG_FILE=/opt/bitnami/spark/logs/load_logs_into_hive.log

export JAVA_HOME=/opt/bitnami/java
export PATH=$JAVA_HOME/bin:$PATH
export PATH=$PATH:/opt/bitnami/python/bin
export PYSPARK_PYTHON=/opt/bitnami/python/bin/python3
export CORE_CONF_fs_defaultFS=hdfs://namenode:9000

/opt/bitnami/spark/bin/spark-submit --master spark://spark-master:7077 /opt/bitnami/spark/jobs/load_logs_into_hive.py 2&gt;&amp;1 | tee -a &quot;$LOG_FILE&quot;

exit_code=${PIPESTATUS[0]}

if [ $exit_code -ne 0 ]; then
  echo &quot;Spark job FAILED!&quot; | tee -a &quot;$LOG_FILE&quot;
  exit 1
else
  echo &quot;Spark job completed successfully.&quot; | tee -a &quot;$LOG_FILE&quot;
fi
</preScript>
      <postScript></postScript>
      <hideCommand>false</hideCommand>
    </org.jvnet.hudson.plugins.SSHBuildWrapper>
  </buildWrappers>
</project>