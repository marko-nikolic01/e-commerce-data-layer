<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers>
    <hudson.triggers.TimerTrigger>
      <spec>10 0-23/4 * * *</spec>
    </hudson.triggers.TimerTrigger>
  </triggers>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <org.jvnet.hudson.plugins.SSHBuilder plugin="ssh@158.ve2a_e90fb_7319">
      <siteName>root@spark-master:22</siteName>
      <command>echo &quot;Starting Spark job...&quot; | tee -a spark_job.log

LOG_FILE=/opt/bitnami/spark/logs/analyze_e_commerce_data.log

export JAVA_HOME=/opt/bitnami/java
export PATH=$JAVA_HOME/bin:$PATH
export PATH=$PATH:/opt/bitnami/python/bin
export PYSPARK_PYTHON=/opt/bitnami/python/bin/python3
export CORE_CONF_fs_defaultFS=hdfs://namenode:9000
export POSTGRES_USER=postgres
export POSTGRES_PASSWORD=postgres
export POSTGRES_URI=jdbc:postgresql://postgres:5432
export CORE_CONF_fs_defaultFS=hdfs://namenode:9000

/opt/bitnami/spark/bin/spark-submit --master spark://spark-master:7077 --jars /opt/bitnami/spark/jars/postgresql-42.2.23.jar /opt/bitnami/spark/jobs/analyze_e_commerce_data.py 2&gt;&amp;1 | tee -a &quot;$LOG_FILE&quot;

exit_code=${PIPESTATUS[0]}

if [ $exit_code -ne 0 ]; then
  echo &quot;Spark job FAILED!&quot; | tee -a &quot;$LOG_FILE&quot;
  exit 1
else
  echo &quot;Spark job completed successfully.&quot; | tee -a &quot;$LOG_FILE&quot;
fi
</command>
      <execEachLine>false</execEachLine>
      <hideCommand>false</hideCommand>
    </org.jvnet.hudson.plugins.SSHBuilder>
    <org.jvnet.hudson.plugins.SSHBuilder plugin="ssh@158.ve2a_e90fb_7319">
      <siteName>root@spark-master:22</siteName>
      <command>echo &quot;Starting Spark job...&quot; | tee -a spark_job.log

LOG_FILE=/opt/bitnami/spark/logs/load_unprocessed_logs_into_hive.log

export JAVA_HOME=/opt/bitnami/java
export PATH=$JAVA_HOME/bin:$PATH
export PATH=$PATH:/opt/bitnami/python/bin
export PYSPARK_PYTHON=/opt/bitnami/python/bin/python3
export CORE_CONF_fs_defaultFS=hdfs://namenode:9000

/opt/bitnami/spark/bin/spark-submit --master spark://spark-master:7077 /opt/bitnami/spark/jobs/load_unprocessed_logs_into_hive.py 2&gt;&amp;1 | tee -a &quot;$LOG_FILE&quot;

exit_code=${PIPESTATUS[0]}

if [ $exit_code -ne 0 ]; then
  echo &quot;Spark job FAILED!&quot; | tee -a &quot;$LOG_FILE&quot;
  exit 1
else
  echo &quot;Spark job completed successfully.&quot; | tee -a &quot;$LOG_FILE&quot;
fi
</command>
      <execEachLine>false</execEachLine>
      <hideCommand>false</hideCommand>
    </org.jvnet.hudson.plugins.SSHBuilder>
  </builders>
  <publishers>
    <hudson.tasks.Mailer plugin="mailer@489.vd4b_25144138f">
      <recipients>nikolicmarko1243@gmail.com</recipients>
      <dontNotifyEveryUnstableBuild>false</dontNotifyEveryUnstableBuild>
      <sendToIndividuals>false</sendToIndividuals>
    </hudson.tasks.Mailer>
  </publishers>
  <buildWrappers/>
</project>